<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="initial-scale=1.0, width=device-width"/><meta property="og:description" content="Network 분야에 관심이 많은 개발자로 Computer Engineering 관련 Posting을 주로 다룹니다."/><meta property="og:type" content="blog"/><meta property="og:site_name" content="JustLog"/><meta property="og:image" content="https://euidong.github.io/logo192.png"/><title>3. Arithmetic</title><meta property="og:title" content="3. Arithmetic"/><meta name="description" content="컴퓨터 구조에서 기본이 되는 사칙연산과 소수의 표현방식(Floating Point)을 다룬다."/><meta property="og:description" content="컴퓨터 구조에서 기본이 되는 사칙연산과 소수의 표현방식(Floating Point)을 다룬다."/><meta property="og:url" content="https://euidong.github.io/posts/architecture-arithmetic"/><link rel="canonical" href="https://euidong.github.io/posts/architecture-arithmetic"/><meta property="og:image" content="https://euidong.github.io/images/default.jpg"/><meta name="next-head-count" content="13"/><link rel="icon" href="https://euidong.github.io/favicon.png"/><link rel="apple-touch-icon" href="https://euidong.github.io/logo192.png"/><script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-7452732177557701" crossorigin="anonymous"></script><link rel="preload" href="/_next/static/css/d4ec5c8b3df09443.css" as="style"/><link rel="stylesheet" href="/_next/static/css/d4ec5c8b3df09443.css" data-n-g=""/><link rel="preload" href="/_next/static/css/4e506edd7924fba2.css" as="style"/><link rel="stylesheet" href="/_next/static/css/4e506edd7924fba2.css" data-n-p=""/><link rel="preload" href="/_next/static/css/936c1a0848bb34d6.css" as="style"/><link rel="stylesheet" href="/_next/static/css/936c1a0848bb34d6.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-9b312e20a4e32339.js" defer=""></script><script src="/_next/static/chunks/framework-81da43a8dcd978d9.js" defer=""></script><script src="/_next/static/chunks/main-7b6c38cbad60dfcf.js" defer=""></script><script src="/_next/static/chunks/pages/_app-36e51ff140372195.js" defer=""></script><script src="/_next/static/chunks/78e521c3-cbc72355a4ceeb71.js" defer=""></script><script src="/_next/static/chunks/175675d1-f160d4a5df49f5d3.js" defer=""></script><script src="/_next/static/chunks/675-ae8e8a351ce30ae2.js" defer=""></script><script src="/_next/static/chunks/602-aae13ef79a8283ee.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bslug%5D-3a18390189e5c715.js" defer=""></script><script src="/_next/static/zo17-VIt9hmdxew6D07b5/_buildManifest.js" defer=""></script><script src="/_next/static/zo17-VIt9hmdxew6D07b5/_ssgManifest.js" defer=""></script><script src="/_next/static/zo17-VIt9hmdxew6D07b5/_middlewareManifest.js" defer=""></script></head><body><div id="__next"><div class="Layout_wrapper__dKJSz root"><header class="Layout_header__XosLl" style="position:sticky"><div><button tabindex="1" class="SideBarToggler_search_bar_toggler__CEuUg"><svg stroke="currentColor" fill="none" stroke-width="0" viewBox="0 0 24 24" height="35px" width="35px" xmlns="http://www.w3.org/2000/svg"><path d="M2 6C2 5.44772 2.44772 5 3 5H21C21.5523 5 22 5.44772 22 6C22 6.55228 21.5523 7 21 7H3C2.44772 7 2 6.55228 2 6Z" fill="currentColor"></path><path d="M2 12.0322C2 11.4799 2.44772 11.0322 3 11.0322H21C21.5523 11.0322 22 11.4799 22 12.0322C22 12.5845 21.5523 13.0322 21 13.0322H3C2.44772 13.0322 2 12.5845 2 12.0322Z" fill="currentColor"></path><path d="M3 17.0645C2.44772 17.0645 2 17.5122 2 18.0645C2 18.6167 2.44772 19.0645 3 19.0645H21C21.5523 19.0645 22 18.6167 22 18.0645C22 17.5122 21.5523 17.0645 21 17.0645H3Z" fill="currentColor"></path></svg></button><nav class="SideBar_side_bar__wrapper--close__8Nwnr"><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/">Home</a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/tags">Tags</a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/Algorithm">Algorithm<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->11<!-- -->)<!-- --></span></a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/Computer%20Architecture">Computer Architecture<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->7<!-- -->)<!-- --></span></a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/Tech">Tech<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->17<!-- -->)<!-- --></span></a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/Web">Web<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->4<!-- -->)<!-- --></span></a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/Network">Network<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->11<!-- -->)<!-- --></span></a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/AI">AI<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->7<!-- -->)<!-- --></span></a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/Paper">Paper<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->1<!-- -->)<!-- --></span></a></nav></div><a class="Logo_logo___yD0t" tabindex="1" href="/"></a><div><button class="SearchBarToggler_search_bar_toggler__3dHbA" tabindex="2"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="25px" width="25px" xmlns="http://www.w3.org/2000/svg"><path d="M11.742 10.344a6.5 6.5 0 1 0-1.397 1.398h-.001c.03.04.062.078.098.115l3.85 3.85a1 1 0 0 0 1.415-1.414l-3.85-3.85a1.007 1.007 0 0 0-.115-.1zM12 6.5a5.5 5.5 0 1 1-11 0 5.5 5.5 0 0 1 11 0z"></path></svg></button></div></header><section><div class="Post_post__wrapper__Qq8vV"><h1 class="Post_post__title__CYNLY">3. Arithmetic</h1><p class="Post_post__date__Sx37s">2022년 4월 27일 20시 50분</p><ul class="Post_post__tags__SU5Ql"><li class="Post_post__tags__element__SYmey"># Computer Organization And Design</li><li class="Post_post__tags__element__SYmey"># Arithmetic</li></ul><article class="markdown-body MarkDown_markdown-body__ABwUt"><h2>Intro<!-- --></h2>
<!-- --><p>컴퓨터 구조에서 기본이 되는 <!-- --><strong>사칙연산<!-- --></strong>과 <!-- --><strong>소수<!-- --></strong>의 표현방식(<!-- --><strong>Floating Point<!-- --></strong>)을 다룬다.<!-- --></p>
<!-- --><h2>Overflow<!-- --></h2>
<!-- --><p>시작하기에 앞서서 Overflow라는 개념을 알고가야한다. Overflow란 특정 변수의 표현범위를 벗어나는 경우에 발생하게 되는 에러 상황을 의미한다. 일반적인 사람의 생각에는 수의 범위가 있는 것은 이상할 수 있지만, 컴퓨터에서는 이것이 매우 당연하다. 무한대를 표현하는 것은 사실상 컴퓨터로는 불가능하다. 대신 매우 큰 수를 통해서 표현하는 것이 컴퓨터에게는 일반적이다. 예를 들어 우리가 빈번하게 사용하는 integer 변수 type은 그 값의 범위가 정해져있다. 이는 대게 하나의 변수를 표현하기 위해서 4bytes를 사용하는데 이는 32bits이기 때문에, 최대 <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2<!-- --></mn><mn>32<!-- --></mn></msup></mrow><annotation encoding="application/x-tex">2^{32}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord">2<!-- --></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">32<!-- --></span></span></span></span></span></span></span></span></span></span></span></span></span>까지가 표현의 범위가 되는 것이다. 여기에 음수를 표현하게 되는 경우에는 범위가 <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−<!-- --></mo><msup><mn>2<!-- --></mn><mn>31<!-- --></mn></msup></mrow><annotation encoding="application/x-tex">-2^{31}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8974em;vertical-align:-0.0833em"></span><span class="mord">−<!-- --></span><span class="mord"><span class="mord">2<!-- --></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">31<!-- --></span></span></span></span></span></span></span></span></span></span></span></span></span> ~ <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2<!-- --></mn><mn>31<!-- --></mn></msup></mrow><annotation encoding="application/x-tex">2^{31}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord">2<!-- --></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">31<!-- --></span></span></span></span></span></span></span></span></span></span></span></span></span>로 제한된다. 따라서, 이렇게 범위를 벗어나는 경우에 대해서는 programming language 마다 처리가 달라지지만, 대게 에러를 발생시키는 것이 일반적이다. (python에서는 알아서 범위를 추가한다.)<!-- --></p>
<!-- --><h2>덧셈 / 뺄셈<!-- --></h2>
<!-- --><p>덧셈은 각 자릿수의 합과 이전 자릿수에서 올림된 수(Carry)의 합이라고 다시 해석할 수 있다.
이진수에서는 결국 올림된 수와 두 수가 만들어 낼 수 있는 경우의 수는 00 ~ 11이다.<!-- --></p>



























































<!-- --><table><thead><tr><th style="text-align:left">A<!-- --></th><th style="text-align:left">B<!-- --></th><th style="text-align:left">Carry<!-- --></th><th style="text-align:left">Result<!-- --></th></tr></thead><tbody><tr><td style="text-align:left">0<!-- --></td><td style="text-align:left">0<!-- --></td><td style="text-align:left">0<!-- --></td><td style="text-align:left">00<!-- --></td></tr><tr><td style="text-align:left">0<!-- --></td><td style="text-align:left">0<!-- --></td><td style="text-align:left">1<!-- --></td><td style="text-align:left">01<!-- --></td></tr><tr><td style="text-align:left">0<!-- --></td><td style="text-align:left">1<!-- --></td><td style="text-align:left">0<!-- --></td><td style="text-align:left">01<!-- --></td></tr><tr><td style="text-align:left">0<!-- --></td><td style="text-align:left">1<!-- --></td><td style="text-align:left">1<!-- --></td><td style="text-align:left">10<!-- --></td></tr><tr><td style="text-align:left">1<!-- --></td><td style="text-align:left">0<!-- --></td><td style="text-align:left">0<!-- --></td><td style="text-align:left">01<!-- --></td></tr><tr><td style="text-align:left">1<!-- --></td><td style="text-align:left">0<!-- --></td><td style="text-align:left">1<!-- --></td><td style="text-align:left">10<!-- --></td></tr><tr><td style="text-align:left">1<!-- --></td><td style="text-align:left">1<!-- --></td><td style="text-align:left">0<!-- --></td><td style="text-align:left">10<!-- --></td></tr><tr><td style="text-align:left">1<!-- --></td><td style="text-align:left">1<!-- --></td><td style="text-align:left">1<!-- --></td><td style="text-align:left">11<!-- --></td></tr></tbody></table>
<!-- --><p>이를 수행하기 위해서 우리는 XOR 2개와 AND 2개 그리고 OR 1개로 만들 수 있다.(C&#x27;와 S가 결과값이다.)<!-- --></p>































































































<!-- --><table><thead><tr><th style="text-align:left">A<!-- --></th><th style="text-align:left">B<!-- --></th><th style="text-align:left">Carry(C)<!-- --></th><th style="text-align:left">A XOR B(D)<!-- --></th><th style="text-align:left">A AND B(E)<!-- --></th><th style="text-align:left">C AND D(F)<!-- --></th><th style="text-align:left">E OR F(C&#x27;)<!-- --></th><th style="text-align:left">C XOR D(S)<!-- --></th></tr></thead><tbody><tr><td style="text-align:left">0<!-- --></td><td style="text-align:left">0<!-- --></td><td style="text-align:left">0<!-- --></td><td style="text-align:left">0<!-- --></td><td style="text-align:left">0<!-- --></td><td style="text-align:left">0<!-- --></td><td style="text-align:left">0<!-- --></td><td style="text-align:left">0<!-- --></td></tr><tr><td style="text-align:left">0<!-- --></td><td style="text-align:left">0<!-- --></td><td style="text-align:left">1<!-- --></td><td style="text-align:left">0<!-- --></td><td style="text-align:left">0<!-- --></td><td style="text-align:left">0<!-- --></td><td style="text-align:left">0<!-- --></td><td style="text-align:left">1<!-- --></td></tr><tr><td style="text-align:left">0<!-- --></td><td style="text-align:left">1<!-- --></td><td style="text-align:left">0<!-- --></td><td style="text-align:left">1<!-- --></td><td style="text-align:left">0<!-- --></td><td style="text-align:left">0<!-- --></td><td style="text-align:left">0<!-- --></td><td style="text-align:left">1<!-- --></td></tr><tr><td style="text-align:left">0<!-- --></td><td style="text-align:left">1<!-- --></td><td style="text-align:left">1<!-- --></td><td style="text-align:left">1<!-- --></td><td style="text-align:left">0<!-- --></td><td style="text-align:left">1<!-- --></td><td style="text-align:left">1<!-- --></td><td style="text-align:left">0<!-- --></td></tr><tr><td style="text-align:left">1<!-- --></td><td style="text-align:left">0<!-- --></td><td style="text-align:left">0<!-- --></td><td style="text-align:left">1<!-- --></td><td style="text-align:left">0<!-- --></td><td style="text-align:left">0<!-- --></td><td style="text-align:left">0<!-- --></td><td style="text-align:left">1<!-- --></td></tr><tr><td style="text-align:left">1<!-- --></td><td style="text-align:left">0<!-- --></td><td style="text-align:left">1<!-- --></td><td style="text-align:left">1<!-- --></td><td style="text-align:left">0<!-- --></td><td style="text-align:left">1<!-- --></td><td style="text-align:left">1<!-- --></td><td style="text-align:left">0<!-- --></td></tr><tr><td style="text-align:left">1<!-- --></td><td style="text-align:left">1<!-- --></td><td style="text-align:left">0<!-- --></td><td style="text-align:left">0<!-- --></td><td style="text-align:left">1<!-- --></td><td style="text-align:left">0<!-- --></td><td style="text-align:left">1<!-- --></td><td style="text-align:left">0<!-- --></td></tr><tr><td style="text-align:left">1<!-- --></td><td style="text-align:left">1<!-- --></td><td style="text-align:left">1<!-- --></td><td style="text-align:left">0<!-- --></td><td style="text-align:left">1<!-- --></td><td style="text-align:left">0<!-- --></td><td style="text-align:left">1<!-- --></td><td style="text-align:left">1<!-- --></td></tr></tbody></table>
<!-- --><p><img src="https://upload.wikimedia.org/wikipedia/commons/5/57/Fulladder.gif" alt="fullAdder"/></p>
<!-- --><h3>음수<!-- --></h3>
<!-- --><p>음수는 기본적으로 2의 보수라는 방식을 활용한다. 만약 특정 수를 음수로 변환하고 싶다면 전체 수를 반전 시킨 후 <!-- --><code>+1<!-- --></code>을 수행하는 방식이다. 이를 통해서, 우리는 쉽게 음수를 생성할 수 있다. 그리고 놀랍게도 특정 수를 음수로 변환하고 덧셈을 하게 되면, 이것이 바로 뺄셈이 된다.<!-- --></p>
<!-- --><h2>곱셈<!-- --></h2>
<!-- --><p>먼저 이진수의 곱셈은 아래와 같이 십진수에서의 곱셈 연산과 방법은 같다.<!-- --></p>
<!-- --><p>곱해지는 수(multiplicand), 곱하는 수(multipler), 곱해진 결과(product)이다.<!-- --></p>
<!-- --><p><img src="/images/multiplication.png" alt="곱셈 예제"/></p>
<!-- --><p>하지만, 여기서 하나의 특징을 발견할 수 있다. 각 자릿수의 결과값은 곱하는 수에 의해서 결정된다는 점이다. 곱하는 수가 1이면, 곱해지는 수의 해당 자릿수가 결과값이 되고, 0이면 무조건 0이라는 결과가 나온다는 것을 알 수 있다. 따라서, 다음과 같은 알고리즘에 따라서 연산이 수행된다는 것을 알 수 있다.<!-- --></p>
<!-- --><p><img src="/images/multiplication-flow.png" alt="곱셈 알고리즘"/></p>
<!-- --><p>만약, 음수의 곱셈의 경우에는 간단하게 해당 값을 양수로 변환하고, 연산을 수행한 뒤에 다시 음수로 변환하는 방식을 수행한다.<!-- --></p>
<!-- --><h2>나눗셈<!-- --></h2>
<!-- --><p>나눗셈은 역시 동일하다.<!-- --></p>
<!-- --><p>나누어지는 수(Dividend), 나누는 수(Divisor), 몫(Quotient), 나머지(Remainder) 이다.<!-- --></p>
<!-- --><p><img src="/images/division.png" alt="나눗셈 예제"/></p>
<!-- --><p>이때는 역으로 나누는 수를 오른쪽으로 32번 shift하여 매우 큰 수로 만들고, 나머지를 나누어지는 수로 초기화하여 차근차근 빼보면서 양수이면 빼고, 음수이면 되돌리기를 반복하면서 몫과 나머지를 계산할 수 있다.<!-- --></p>
<!-- --><p><img src="/images/division-flow.png" alt="나눗셈 알고리즘"/></p>
<!-- --><h2>실수 연산<!-- --></h2>
<!-- --><p>위에서는 여태까지 정수의 연산을 다루었지만, 소수점을 포함하는 실수 연산을 수행할 때에는 달라지는 사항이 꽤나있다.<!-- --></p>
<!-- --><p>먼저, 실수를 표기하기 위한 방법을 먼저 보자.<!-- --></p>
<!-- --><p><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>31231.<!-- --></mn><msub><mn>4<!-- --></mn><mrow><mo stretchy="false">(<!-- --></mo><mn>10<!-- --></mn><mo stretchy="false">)<!-- --></mo></mrow></msub><mo>=<!-- --></mo><mn>3.1231<!-- --></mn><msub><mn>4<!-- --></mn><mrow><mo stretchy="false">(<!-- --></mo><mn>10<!-- --></mn><mo stretchy="false">)<!-- --></mo></mrow></msub><mo>×<!-- --></mo><mn>1<!-- --></mn><msup><mn>0<!-- --></mn><msub><mn>4<!-- --></mn><mrow><mo stretchy="false">(<!-- --></mo><mn>10<!-- --></mn><mo stretchy="false">)<!-- --></mo></mrow></msub></msup></mrow><annotation encoding="application/x-tex">31231.4_{(10)} = 3.12314_{(10)} \times 10^{4_{(10)}}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9996em;vertical-align:-0.3552em"></span><span class="mord">31231.<!-- --></span><span class="mord"><span class="mord">4<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mtight">10<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.9996em;vertical-align:-0.3552em"></span><span class="mord">3.1231<!-- --></span><span class="mord"><span class="mord">4<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mtight">10<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×<!-- --></span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8175em"></span><span class="mord">1<!-- --></span><span class="mord"><span class="mord">0<!-- --></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8175em"><span style="top:-3.0664em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mtight">4<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3448em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5357em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mtight">10<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.3695em"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<!-- --><p><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>100101.<!-- --></mn><msub><mn>1<!-- --></mn><mrow><mo stretchy="false">(<!-- --></mo><mn>2<!-- --></mn><mo stretchy="false">)<!-- --></mo></mrow></msub><mo>=<!-- --></mo><mn>1.00101<!-- --></mn><msub><mn>1<!-- --></mn><mrow><mo stretchy="false">(<!-- --></mo><mn>2<!-- --></mn><mo stretchy="false">)<!-- --></mo></mrow></msub><mo>×<!-- --></mo><msup><mn>2<!-- --></mn><mrow><mn>10<!-- --></mn><msub><mn>1<!-- --></mn><mrow><mo stretchy="false">(<!-- --></mo><mn>2<!-- --></mn><mo stretchy="false">)<!-- --></mo></mrow></msub></mrow></msup></mrow><annotation encoding="application/x-tex">100101.1_{(2)}= 1.001011_{(2)} \times 2^{101_{(2)}} <!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9996em;vertical-align:-0.3552em"></span><span class="mord">100101.<!-- --></span><span class="mord"><span class="mord">1<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mtight">2<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.9996em;vertical-align:-0.3552em"></span><span class="mord">1.00101<!-- --></span><span class="mord"><span class="mord">1<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mtight">2<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×<!-- --></span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8175em"></span><span class="mord"><span class="mord">2<!-- --></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8175em"><span style="top:-3.0664em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">10<!-- --></span><span class="mord mtight"><span class="mord mtight">1<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3448em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5357em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mtight">2<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.3695em"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<!-- --><p>이를 일반적으로 normalization이라고 하며, 이진수 체계에서는 다음과 같은 형태를 갖게 된다.<!-- --></p>
<!-- --><p><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>1.xxxxx<!-- --></mtext><mo>×<!-- --></mo><msup><mn>2<!-- --></mn><mrow><mi>y<!-- --></mi><mi>y<!-- --></mi><mi>y<!-- --></mi><mi>y<!-- --></mi><mi>y<!-- --></mi></mrow></msup></mrow><annotation encoding="application/x-tex">\text{1.xxxxx} \times 2^{yyyyy}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord text"><span class="mord">1.xxxxx<!-- --></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×<!-- --></span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6644em"></span><span class="mord"><span class="mord">2<!-- --></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">yyyyy<!-- --></span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<!-- --><p>따라서, 대게 실수를 표현할 때에는 x부분(fraction)과 y부분(exponent) 그리고 부호를 표현(sign)하는 부분으로 나누어서 저장한다. 이 또한, 4byte를 통해서 표현할 경우에는 x부분에 8bits, y부분에 23bits 그리고 부호에 1bit를 할당한다.<!-- --></p>
<!-- --><p>따라서, 일반적으로 표현하면 다음과 같이 쓰는 것이 일반적인 실수의 표현이다.<!-- --></p>
<!-- --><p><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(<!-- --></mo><mo>−<!-- --></mo><mn>1<!-- --></mn><msup><mo stretchy="false">)<!-- --></mo><mi>s<!-- --></mi></msup><mo>×<!-- --></mo><mo stretchy="false">(<!-- --></mo><mn>1<!-- --></mn><mo>+<!-- --></mo><mtext>Fraction<!-- --></mtext><mo stretchy="false">)<!-- --></mo><mo>×<!-- --></mo><msup><mn>2<!-- --></mn><mrow><mo stretchy="false">(<!-- --></mo><mtext>Exponent<!-- --></mtext><mo stretchy="false">)<!-- --></mo></mrow></msup></mrow><annotation encoding="application/x-tex">(-1)^s \times(1+\text{Fraction})\times2^{(\text{Exponent})}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(<!-- --></span><span class="mord">−<!-- --></span><span class="mord">1<!-- --></span><span class="mclose"><span class="mclose">)<!-- --></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">s<!-- --></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×<!-- --></span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(<!-- --></span><span class="mord">1<!-- --></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+<!-- --></span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord text"><span class="mord">Fraction<!-- --></span></span><span class="mclose">)<!-- --></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×<!-- --></span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.888em"></span><span class="mord"><span class="mord">2<!-- --></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord text mtight"><span class="mord mtight">Exponent<!-- --></span></span><span class="mclose mtight">)<!-- --></span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<!-- --><p>단, 모두 0이면 0으로 친다. floating point 연산은 후에 더 시간이 있으면 자세히 다루겠다.<!-- --></p>
<!-- --><h2>Reference<!-- --></h2>
<!-- --><ul>
<!-- --><li>David A. Patterson, John L. Hennessy, Computer Organization and Design<!-- --></li>
<!-- --><li>Full Adder 이미지는 WIKIPEDIA full adder의 발췌이다. (<!-- --><a href="https://upload.wikimedia.org/wikipedia/commons/5/57/Fulladder.gif">https://upload.wikimedia.org/wikipedia/commons/5/57/Fulladder.gif<!-- --></a>)<!-- --></li>
<!-- --></ul></article><div class="Comment_comment__wrapper___sKTf"><h2 class="Comment_comment__title__hLmXO">Comments</h2><section></section></div><div class="ColumnCard_column_card__list__background__kZObh"><h2 class="ColumnCard_column_card__list__title__pawoL">Related Posts</h2><div class="ColumnCard_column_card__list__wrapper__lsbEP"><div class="ColumnCard_column_card__wrapper__iVPbY"><a class="ColumnCard_column_card__thumbnail__wrapper__M3Kfm" href="/posts/architecture-base"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27320%27%20height=%27320%27/%3e"/></span><img alt="1. Base" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" class="ColumnCard_column_card__thumbnail__bx9FL" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="1. Base" srcSet="https://euidong.github.io/images/default.jpg?imwidth=384 1x, https://euidong.github.io/images/default.jpg?imwidth=640 2x" src="https://euidong.github.io/images/default.jpg?imwidth=640" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" class="ColumnCard_column_card__thumbnail__bx9FL" loading="lazy"/></noscript></span></a><div class="ColumnCard_column_card__tray__v9oLc"><a class="ColumnCard_column_card__tray__title__fEApg" tabindex="-1" href="/posts/architecture-base">1. Base</a><ul class="ColumnCard_column_card__tray__tag__UUiD6"><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/Computer%20Organization%20And%20Design"># <!-- -->Computer Organization And Design<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/ISA"># <!-- -->ISA<!-- --></a></ul></div></div><div class="ColumnCard_column_card__wrapper__iVPbY"><a class="ColumnCard_column_card__thumbnail__wrapper__M3Kfm" href="/posts/architecture-instruction"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27320%27%20height=%27320%27/%3e"/></span><img alt="2. Instruction" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" class="ColumnCard_column_card__thumbnail__bx9FL" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="2. Instruction" srcSet="https://euidong.github.io/images/default.jpg?imwidth=384 1x, https://euidong.github.io/images/default.jpg?imwidth=640 2x" src="https://euidong.github.io/images/default.jpg?imwidth=640" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" class="ColumnCard_column_card__thumbnail__bx9FL" loading="lazy"/></noscript></span></a><div class="ColumnCard_column_card__tray__v9oLc"><a class="ColumnCard_column_card__tray__title__fEApg" tabindex="-1" href="/posts/architecture-instruction">2. Instruction</a><ul class="ColumnCard_column_card__tray__tag__UUiD6"><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/Computer%20Organization%20And%20Design"># <!-- -->Computer Organization And Design<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/Instruction"># <!-- -->Instruction<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/ISA"># <!-- -->ISA<!-- --></a></ul></div></div><div class="ColumnCard_column_card__wrapper__iVPbY"><a class="ColumnCard_column_card__thumbnail__wrapper__M3Kfm" href="/posts/architecture-processor"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27320%27%20height=%27320%27/%3e"/></span><img alt="4. Processing" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" class="ColumnCard_column_card__thumbnail__bx9FL" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="4. Processing" srcSet="https://euidong.github.io/images/default.jpg?imwidth=384 1x, https://euidong.github.io/images/default.jpg?imwidth=640 2x" src="https://euidong.github.io/images/default.jpg?imwidth=640" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" class="ColumnCard_column_card__thumbnail__bx9FL" loading="lazy"/></noscript></span></a><div class="ColumnCard_column_card__tray__v9oLc"><a class="ColumnCard_column_card__tray__title__fEApg" tabindex="-1" href="/posts/architecture-processor">4. Processing</a><ul class="ColumnCard_column_card__tray__tag__UUiD6"><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/Computer%20Organization%20And%20Design"># <!-- -->Computer Organization And Design<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/Processing"># <!-- -->Processing<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/MIPS%20Implementation"># <!-- -->MIPS Implementation<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/Pipeline"># <!-- -->Pipeline<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/Branch%20Prediction"># <!-- -->Branch Prediction<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/SuperScalar"># <!-- -->SuperScalar<!-- --></a></ul></div></div><div class="ColumnCard_column_card__wrapper__iVPbY"><a class="ColumnCard_column_card__thumbnail__wrapper__M3Kfm" href="/posts/architecture-memory"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27320%27%20height=%27320%27/%3e"/></span><img alt="5. Memory Hierarchy" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" class="ColumnCard_column_card__thumbnail__bx9FL" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="5. Memory Hierarchy" srcSet="https://euidong.github.io/images/default.jpg?imwidth=384 1x, https://euidong.github.io/images/default.jpg?imwidth=640 2x" src="https://euidong.github.io/images/default.jpg?imwidth=640" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" class="ColumnCard_column_card__thumbnail__bx9FL" loading="lazy"/></noscript></span></a><div class="ColumnCard_column_card__tray__v9oLc"><a class="ColumnCard_column_card__tray__title__fEApg" tabindex="-1" href="/posts/architecture-memory">5. Memory Hierarchy</a><ul class="ColumnCard_column_card__tray__tag__UUiD6"><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/Computer%20Organization%20And%20Design"># <!-- -->Computer Organization And Design<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/Memory"># <!-- -->Memory<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/Memory%20Hierarchy"># <!-- -->Memory Hierarchy<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/Cache"># <!-- -->Cache<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/Directed%20Mapping"># <!-- -->Directed Mapping<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/Virtual%20Memory"># <!-- -->Virtual Memory<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/Page"># <!-- -->Page<!-- --></a></ul></div></div><div class="ColumnCard_column_card__wrapper__iVPbY"><a class="ColumnCard_column_card__thumbnail__wrapper__M3Kfm" href="/posts/architecture-parallel-processors"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27320%27%20height=%27320%27/%3e"/></span><img alt="6. Parallel Processors" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" class="ColumnCard_column_card__thumbnail__bx9FL" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="6. Parallel Processors" srcSet="https://euidong.github.io/images/default.jpg?imwidth=384 1x, https://euidong.github.io/images/default.jpg?imwidth=640 2x" src="https://euidong.github.io/images/default.jpg?imwidth=640" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" class="ColumnCard_column_card__thumbnail__bx9FL" loading="lazy"/></noscript></span></a><div class="ColumnCard_column_card__tray__v9oLc"><a class="ColumnCard_column_card__tray__title__fEApg" tabindex="-1" href="/posts/architecture-parallel-processors">6. Parallel Processors</a><ul class="ColumnCard_column_card__tray__tag__UUiD6"><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/Computer%20Organization%20And%20Design"># <!-- -->Computer Organization And Design<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/Multi%20Processors"># <!-- -->Multi Processors<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/Multi%20Threading"># <!-- -->Multi Threading<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/MTU"># <!-- -->MTU<!-- --></a></ul></div></div></div></div></div></section><footer class="Layout_footer__EL5v8"><div class="Layout_footer__copyright__r5baC"><span>Copyright © euidong</span><br/><span>모든 컨텐츠에 대한 저작권은 작성자에게 존재합니다. <!-- --><br/>불법 복제를 통한 상업적 사용을 절대적으로 금지합니다. <!-- --><br/>단, 비상업적 이용의 경우 출처 및 링크를 적용한다면 자유롭게 사용가능 합니다.<!-- --></span><span>Also I use photos by<!-- --> <!-- --><a href="https://unsplash.com/@lorenzoherrera?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" tabindex="-1">Lorenzo Herrera</a> <!-- -->on<!-- --> <!-- --><a href="https://unsplash.com/s/photos/tech?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" tabindex="-1">Unsplash</a></span></div><div class="Layout_footer__contents__YZWSm"><a class="Layout_footer__contents__link__K_TKH" href="https://github.com/euidong" target="_blank" rel="noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="60" width="60" xmlns="http://www.w3.org/2000/svg"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path></svg><span>github</span></a><a class="Layout_footer__contents__link__K_TKH" href="https://euidong.github.io/portfolio" target="_blank" rel="noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="60" width="60" xmlns="http://www.w3.org/2000/svg"><path d="M6 8a3 3 0 1 0 0-6 3 3 0 0 0 0 6zm-5 6s-1 0-1-1 1-4 6-4 6 3 6 4-1 1-1 1H1zM11 3.5a.5.5 0 0 1 .5-.5h4a.5.5 0 0 1 0 1h-4a.5.5 0 0 1-.5-.5zm.5 2.5a.5.5 0 0 0 0 1h4a.5.5 0 0 0 0-1h-4zm2 3a.5.5 0 0 0 0 1h2a.5.5 0 0 0 0-1h-2zm0 3a.5.5 0 0 0 0 1h2a.5.5 0 0 0 0-1h-2z"></path></svg><span>portfolio</span></a><a class="Layout_footer__contents__link__K_TKH" href="https://chrome.google.com/webstore/detail/bonfire/nkooidijgbppkojdgkoafcoppnohdfka?hl=ko" target="_blank" rel="noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" version="1.1" viewBox="0 0 16 16" height="60" width="60" xmlns="http://www.w3.org/2000/svg"><path d="M5.016 16c-1.066-2.219-0.498-3.49 0.321-4.688 0.897-1.312 1.129-2.61 1.129-2.61s0.706 0.917 0.423 2.352c1.246-1.387 1.482-3.598 1.293-4.445 2.817 1.969 4.021 6.232 2.399 9.392 8.631-4.883 2.147-12.19 1.018-13.013 0.376 0.823 0.448 2.216-0.313 2.893-1.287-4.879-4.468-5.879-4.468-5.879 0.376 2.516-1.364 5.268-3.042 7.324-0.059-1.003-0.122-1.696-0.649-2.656-0.118 1.823-1.511 3.309-1.889 5.135-0.511 2.473 0.383 4.284 3.777 6.197z"></path></svg><span>chat</span></a></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"content":"\n## Intro\n\n컴퓨터 구조에서 기본이 되는 **사칙연산**과 **소수**의 표현방식(**Floating Point**)을 다룬다.\n\n## Overflow\n\n시작하기에 앞서서 Overflow라는 개념을 알고가야한다. Overflow란 특정 변수의 표현범위를 벗어나는 경우에 발생하게 되는 에러 상황을 의미한다. 일반적인 사람의 생각에는 수의 범위가 있는 것은 이상할 수 있지만, 컴퓨터에서는 이것이 매우 당연하다. 무한대를 표현하는 것은 사실상 컴퓨터로는 불가능하다. 대신 매우 큰 수를 통해서 표현하는 것이 컴퓨터에게는 일반적이다. 예를 들어 우리가 빈번하게 사용하는 integer 변수 type은 그 값의 범위가 정해져있다. 이는 대게 하나의 변수를 표현하기 위해서 4bytes를 사용하는데 이는 32bits이기 때문에, 최대 $2^{32}$까지가 표현의 범위가 되는 것이다. 여기에 음수를 표현하게 되는 경우에는 범위가 $-2^{31}$ ~ $2^{31}$로 제한된다. 따라서, 이렇게 범위를 벗어나는 경우에 대해서는 programming language 마다 처리가 달라지지만, 대게 에러를 발생시키는 것이 일반적이다. (python에서는 알아서 범위를 추가한다.)\n\n## 덧셈 / 뺄셈\n\n덧셈은 각 자릿수의 합과 이전 자릿수에서 올림된 수(Carry)의 합이라고 다시 해석할 수 있다.\n이진수에서는 결국 올림된 수와 두 수가 만들어 낼 수 있는 경우의 수는 00 ~ 11이다.\n\n| A    | B    | Carry | Result |\n| :--- | :--- | :---- | :----- |\n| 0    | 0    | 0     | 00     |\n| 0    | 0    | 1     | 01     |\n| 0    | 1    | 0     | 01     |\n| 0    | 1    | 1     | 10     |\n| 1    | 0    | 0     | 01     |\n| 1    | 0    | 1     | 10     |\n| 1    | 1    | 0     | 10     |\n| 1    | 1    | 1     | 11     |\n\n이를 수행하기 위해서 우리는 XOR 2개와 AND 2개 그리고 OR 1개로 만들 수 있다.(C'와 S가 결과값이다.)\n\n| A    | B    | Carry(C) | A XOR B(D) | A AND B(E) | C AND D(F) | E OR F(C') | C XOR D(S) |\n| :--- | :--- | :------- | :--------- | :--------- | :--------- | :--------- | :--------- |\n| 0    | 0    | 0        | 0          | 0          | 0          | 0          | 0          |\n| 0    | 0    | 1        | 0          | 0          | 0          | 0          | 1          |\n| 0    | 1    | 0        | 1          | 0          | 0          | 0          | 1          |\n| 0    | 1    | 1        | 1          | 0          | 1          | 1          | 0          |\n| 1    | 0    | 0        | 1          | 0          | 0          | 0          | 1          |\n| 1    | 0    | 1        | 1          | 0          | 1          | 1          | 0          |\n| 1    | 1    | 0        | 0          | 1          | 0          | 1          | 0          |\n| 1    | 1    | 1        | 0          | 1          | 0          | 1          | 1          |\n\n![fullAdder](https://upload.wikimedia.org/wikipedia/commons/5/57/Fulladder.gif)\n\n### 음수\n\n음수는 기본적으로 2의 보수라는 방식을 활용한다. 만약 특정 수를 음수로 변환하고 싶다면 전체 수를 반전 시킨 후 `+1`을 수행하는 방식이다. 이를 통해서, 우리는 쉽게 음수를 생성할 수 있다. 그리고 놀랍게도 특정 수를 음수로 변환하고 덧셈을 하게 되면, 이것이 바로 뺄셈이 된다.\n\n## 곱셈\n\n먼저 이진수의 곱셈은 아래와 같이 십진수에서의 곱셈 연산과 방법은 같다.\n\n곱해지는 수(multiplicand), 곱하는 수(multipler), 곱해진 결과(product)이다.\n\n![곱셈 예제](/images/multiplication.png)\n\n하지만, 여기서 하나의 특징을 발견할 수 있다. 각 자릿수의 결과값은 곱하는 수에 의해서 결정된다는 점이다. 곱하는 수가 1이면, 곱해지는 수의 해당 자릿수가 결과값이 되고, 0이면 무조건 0이라는 결과가 나온다는 것을 알 수 있다. 따라서, 다음과 같은 알고리즘에 따라서 연산이 수행된다는 것을 알 수 있다.\n\n![곱셈 알고리즘](/images/multiplication-flow.png)\n\n만약, 음수의 곱셈의 경우에는 간단하게 해당 값을 양수로 변환하고, 연산을 수행한 뒤에 다시 음수로 변환하는 방식을 수행한다.\n\n## 나눗셈\n\n나눗셈은 역시 동일하다.\n\n나누어지는 수(Dividend), 나누는 수(Divisor), 몫(Quotient), 나머지(Remainder) 이다.\n\n![나눗셈 예제](/images/division.png)\n\n이때는 역으로 나누는 수를 오른쪽으로 32번 shift하여 매우 큰 수로 만들고, 나머지를 나누어지는 수로 초기화하여 차근차근 빼보면서 양수이면 빼고, 음수이면 되돌리기를 반복하면서 몫과 나머지를 계산할 수 있다.\n\n![나눗셈 알고리즘](/images/division-flow.png)\n\n## 실수 연산\n\n위에서는 여태까지 정수의 연산을 다루었지만, 소수점을 포함하는 실수 연산을 수행할 때에는 달라지는 사항이 꽤나있다.\n\n먼저, 실수를 표기하기 위한 방법을 먼저 보자.\n\n$$31231.4_{(10)} = 3.12314_{(10)} \\times 10^{4_{(10)}}$$\n\n$$100101.1_{(2)}= 1.001011_{(2)} \\times 2^{101_{(2)}} $$\n\n이를 일반적으로 normalization이라고 하며, 이진수 체계에서는 다음과 같은 형태를 갖게 된다.\n\n$$\\text{1.xxxxx} \\times 2^{yyyyy}$$\n\n따라서, 대게 실수를 표현할 때에는 x부분(fraction)과 y부분(exponent) 그리고 부호를 표현(sign)하는 부분으로 나누어서 저장한다. 이 또한, 4byte를 통해서 표현할 경우에는 x부분에 8bits, y부분에 23bits 그리고 부호에 1bit를 할당한다.\n\n따라서, 일반적으로 표현하면 다음과 같이 쓰는 것이 일반적인 실수의 표현이다.\n\n$$(-1)^s \\times(1+\\text{Fraction})\\times2^{(\\text{Exponent})}$$\n\n단, 모두 0이면 0으로 친다. floating point 연산은 후에 더 시간이 있으면 자세히 다루겠다.\n\n## Reference\n\n- David A. Patterson, John L. Hennessy, Computer Organization and Design\n- Full Adder 이미지는 WIKIPEDIA full adder의 발췌이다. (\u003chttps://upload.wikimedia.org/wikipedia/commons/5/57/Fulladder.gif\u003e)\n","slug":"architecture-arithmetic","date":"2022-04-27 20:50","title":"3. Arithmetic","category":"Computer Architecture","tags":["Computer Organization And Design","Arithmetic"],"desc":"컴퓨터 구조에서 기본이 되는 사칙연산과 소수의 표현방식(Floating Point)을 다룬다.","thumbnailSrc":"https://euidong.github.io/images/default.jpg"},"relatedPosts":[{"content":"\n## Intro\n\nComputer Organization and Design이라는 책을 정리하고 되돌아볼 것이다. 여기서는 가장 기본이 되는 Idea들을 정리할 것이다.\n\n## 1\\. 8 Greate Ideas\n\n컴퓨터 구조를 설계하는 과정에서 중요하게 여겨지는 8가지 핵심 아이디어들이다. 뿐만 아니라 이는 전체적인 컴퓨터 과학에서 중요하다고 볼 수 있는 아이디어들이다. 따라서, 앞으로의 Posting에서 Why라는 의문이 든다면, 아래 8가지 이유 중의 하나로 설명할 수 있다.\n\n1. **Moore's Law**  \n    18 ~ 24 개월마다 컴퓨터 성능의 지대한 영향을 미치는 IC 칩의 성능이 2배씩 성장한다는 Moore의 주장에서 유래하였다. 즉, **컴퓨터의 성능은 지수적으로 빠르게 성장을 하고 있음을 의미한다.** 이로 인해 구조를 설계하는 과정에서도 현재의 IC 칩의 성능에 맞추는 것이 아닌 이보다 더 큰 성능을 타겟으로 설정을 한다.\n2. **Abstraction**  \n    우리 말로 추상화라고 표현하며, 복잡한 하위 내용을 모두 기술하지 않고, 간단하게 표현하여 이를 쉽게 사용할 수 있도록 하는 방식이다. 이를 통해서, **설계 과정에서의 복잡도를 줄일 수 있다.**\n3. **Common Case Fast**  \n    **드물게 일어나는 case보다는 일반적인 case를 빠르게 만듬으로써 성능을 향상시킬 수 있다.** 드물게 일어나는 case는 매우 복잡하고, 해결하기도 난해할 수 있다. 하지만, 대게의 경우 일반적인 case는 간단하다. 이를 최적화하는 것이 전체적인 시스템 성능 향상에 큰 도움이 되는 것은 당연하며 해결도 매우 쉽다.\n4. **Performance via Parallelism**  \n    성능 향상을 위한 방법은 크게 두 가지이다. 하나는 하나의 장치의 성능을 올리는 것이고 또 하나가 바로 **하나의 작업을 여러 명이 동시에 수행하는 방식이다.**\n5. **Performance via Pipelining**  \n    성능 향상을 위한 병렬처리 방식 중에서 가장 유명한 방식이 pipelining이다. 쉽게 생각하면, 분업이라고 할 수 있다. **여러 명이서 하나의 목적을 위해 일을 할 때, 효율적으로 작업하기 위해서 업무를 분담하여 동시에 작업**하는 방식이다.\n6. **Performance via Prediction**  \n    우리는 무슨 작업을 할 때, 아직 결정되지 않은 사항 때문에 기다리는 경우가 있는데, 이것이 어떻게 될지를 **예측하여 기다리지 않고, 미리 진행하자**는 발상에서 나온 것이다. 만약, 이 예측의 적중률이 높다면, 성능 향상에 굉장한 도움을 줄 수 있다.\n7. **Hierarchy of Memories**  \n    컴퓨터의 사용자가 원하는 메모리는 빠르고, 크고, 싸야 한다. 하지만, 빠르기 위해서는 비싸야하고, 크기 위해서도 비싸야 한다. 그래서 생각해낸 방법이 계층화이다. **빠르고, 작은 memory를 위로 쌓고, 느리고, 큰 memory를 아래로 쌓음으로써 비용을 절감**하자는 것이다.\n8. **Dependability via Redundancy**  \n    컴퓨터는 빠르기만 해서 되는 것은 아니다. **신뢰**할 수 있는 시스템을 구축해야 한다. 실패하지 않는 시스템을 구축하는 것은 매우 힘든 일이기 때문에, 우리는 **여분 장치**를 두어 이를 통해서 실패 시에 이를 떠맡을 수 있도록 하는 설계를 해야 한다.\n\n## 2\\. Below Your Program\n\nprogram 밑에는 무엇이 있는가?\n\n우리의 program은 모두 application software이고, 이는 hardware 바로 위에 존재하는 것이 아닌 system software위에서 동작하게 된다.\n\n![kernel](/images/kernel.png)\n\n**System Software**는 Hardware를 직접적으로 제어하거나 computer가 작동하기 위해 필수적이며 기본적인 softwre를 말한다. 그 중에서 가장 대표적인 것이 OS이고 **OS**는 사실상 우리가 보는 Software와 Hardware 간의 interface역할을 한다. 예를 들어, memory 관리, process 관리 등(이는 OS 에서 자세히 배웁시다.)을 수행한다. 반면, **Application** **Software**는 직접적으로 hardware를 관리하거나 필수적인 요소는 아니지만 computer를 통해서 가치있는 작업을 수행하도록 한다. 대표적인 예시가 웹브라우저, word, game 등이 여기에 포함된다.\n\n  그렇다면, 우리가 만든 코드(Application Software)가 어떻게 실행되어질 수 있을까? 이 또한, System Software인 compiler, assembler, linker, loader의 도움을 통해서 실행되어진다. **compiler**는 우리가 고 수준의 언어(C++, Java, 등)로 만든 software code를 Assembly 언어로 변경한다. 그러면, 이를 **Assembler**가 0과 1로 이루어진 기계어로 번역해준다. 해당 작업이 끝나면, **Linker**가 나타나 여러 개로 나뉘어져있던 이 파일과 기존 라이브러리를 하나의 파일로 묶어주는 역할을 한다. 이 작업을 마치고 만들어진 최종 파일을 실행하고자할 때, **Loader**는 이를 memory에 올리는 역할을 한다. 이렇게 실행된 program은 여기서 그치지 않고, memory의 아예 다른 영역에 위치하는 library도 불러와서 사용하는 것이 가능하다. 이것을 **Dynamic Linked Library**(DLL)라고 한다.\n\n![run-process](/images/run-process.png)\n\n이렇게 하나의 코드를 작성하면, 실제로 실행되기까지 여러 작업들을 거쳐야만 한다. 그럼에도 assembly 언어나 기계어를 사용하여 코딩을 하지 않는 이유는 아래 세 가지 이유가 주요하다.\n\n1. 사람이 이해하기 쉽다.\n2. 생산성을 높일 수 있다.\n3. Compiler와 assembly를 통해서 어디서든 돌아가는 프로그램을 제작할 수 있다.\n\n## 3\\. Under the Covers\n\n우리의 컴퓨터는 어떻게 이루어지는가를 크고 얇게 한 번 알아볼 것이다.\n\n- **Input Device** : 우리의 입력을 받는 부분이다. 마우스, 키보드, 터치스크린 등이 있다.\n- **Output Device** : 우리가 출력을 받는 부분이다. 모니터, 프린터 등이 있다.\n- **IC(Integrated Circuits, Chip)** : 집적 회로로 번역되어지며, 통상 우리가 chip이라고 부르는 녀석들이다. 이들은 적게는 수십개 많게는 억 단위 이상에 이르는 양의 transister를 가지고 있고, 이를 통해서 데이터를 저장하거나 처리하는 역할을 할 수 있다. 즉, IC를 통해서 CPU, Memory를 만들 수 있다.\n  - trasistor: 쉽게 말해서 전기를 통해서 on/off를 수행할 수 있는 switch라고 볼 수 있다. 이를 통해서, 데이터를 연산하거나 저장하는 것이 가능하다.\n- **CPU (Central Processor Unit, Processor, MicroProcessor)** : 중앙 처리 장치라는 의미로, 각종 연산과 I/O Device 처리 등의 중심 역학을 수행한다. CPU는 크게 두 개의 요소로 이루어진다.\n  - DataPath : 수학적인 연산을 수행한다.\n  - Control : program의 instruction이 무엇을 요구하는지를 입출력 장치, memory 또는 datapath에 전달합니다.\n- **Memory(RAM(Random Access Memory), main memory, primary memory)** : 실행되고 있는 프로그램이 위치하는 곳이다. 실행되는 프로그램에 대한 정보와 같은 내용을 포함한다고 할 수 있다. 이는 DRAM으로 이루어진다. 또한, Random Access Memory라고 불리는 이유는 어느 위치에 데이터를 저장하고 있어도 해당 데이터를 찾는데 걸리는 시간이 동일하기 때문이다.\n  - DRAM(Dynamic Random Access Memory) : IC chip을 통해서 만들어진다. 여기서 Random Access란 접근할 때, 앞에서부터 차례로 접근하는 것이 아닌 한 번에 바로 짚을 수 있음을 의미한다.\n- **Cache Memory** : 대게 Cache라고도 부르며, Processor 내부에 존재하는 memory라고 볼 수 있다. 즉, 실제 Memory의 buffer 기능을 한다. 여기서는 SRAM을 사용한다.\n\n- SRAM(Static Random Aceess Memory) : DRAM보다는 빠르지만, 집적도가 낮고 더 비싸기 때문에 많이 사용할 수는 없는 chip이다. 하지만, 성능 향상을 위해서 processor 바로 앞에 buffer로써 사용한다.\n- buffer : 자료구조의 queue를 이용한 것으로, 처리를 요청한 대상과 처리를 수행하는 대상 사이에서 데이터를 잠깐 보관하기 위한 장소로 사용된다.\n\n- **Secondary Memory** : main memory는 휘발성이라는 특징을 갖고 있기 때문에 시스템이 종료되어 전기가 더 이상 공급되지 않으면, 모든 데이터는 날라간다. 이를 막기 위해서 그리고 부족한 main memory의 저장공간을 보조하기 위해서 보조 기억 장치를 사용한다. 이것에 사용되는 것은 크게 두 가지 이다.\n  - magnatic disk : 자기 disk를 이용해서 정보를 저장하는 방식이다. 전기가 공급되지 않음에도 정보를 저장하고 있을 수 있다.\n  - flash memory : 반도체를 이용하여 데이터를 저장하며, DRAM보다는 느리지만, 더 싸고 휘발성이 없다.\n- **Instruction Set Architecture(ISA, architecture)** : 0과 1로 이루어진 기계어가 들어왔을 때, 이것이 무슨 의미인지를 나타내는 instruction \bSet에 따라 CPU가 알맞은 연산을 수행하는 architecture이다.\n  - Instruction \bSet : hardware에게 동작을 요청하는 하나의 명령어를 Instruction이라고 한다. 이들이 무슨 역할을 하는지를 정리해놓은 것이 Instruction Set이다. 이를 통해서, Operating System은 hardware에 접근하여 특정 동작을 수행시킬 수 있다.\n  - ABI(Application Binary Interface) : application 단에 programmer가 hardware 작업 등을 수행하기 위하여 호출할 수 있다. 이를 통해서, binary한 동작도 application programmer가 조작할 수 있다. 일반적인 API와 역할이 동일하지만, programming language가 아닌 machine language를 사용하여 구현되기 때문에 hardware 접근 등에 제한이 없다.\n\n## 4\\. Performance\n\n우리가 Computer의 성능을 측정하는 것은 중요하다. 왜냐하면, 이를 지표로 계속해서 computer의 성능을 향상시켜야 하기 때문이다.\n\n그래서 우리는 다음과 같이 표현하는 것이 일반적이다.\n\n$$\\text{Excution Time} = \\text{Clock Cycle Time} \\times {\\text{Number of Instruction}} \\times {CPI}$$\n\n즉, **총 실행 시간**(Execution Time)은 **한 번 Clock이 회전하는데 걸리는 시간**(Clock Cycle Time)에 해당 **program의 instruction 수**(Number of Instruction) 그리고 **하나의 instruction을 처리하는데 걸리는 clock cycle의 횟수**(CPI)라고 볼 수 있다.\n\n즉, 우리가 특정 프로그램을 빠르게 돌리고 싶다면, 다음과 같은 식으로 생각할 수 있다.\n\n1. 한 번 회전하는데 걸리는 시간을 줄이기 위해 클락 frequency를 높인다. **하지만, 회전열로 인해 현재는 frequency를 올리는 것은 포기하고 있다.**\n2. 프로그램을 잘 짜거나 Compiler를 더욱 더 최적화하여 instruction의 수를 줄인다.\n3. 하드웨어를 잘 설계해서 명령 하나를 처리하는데 걸리는 시간(CPI)을 줄인다.\n4. 동시에 여러 CPU를 실행시켜서, 실행을 하는 unit 자체를 더 만드는 방법도 있다.\n\n따라서, 앞으로 우리가 Performance를 올리기 위해서, Compiler를 어떻게 최적화할지를 개략적으로 배우며, 하드웨어를 어떻게 잘 설계할지를 자세히 알아볼 것이다. 또한, Parallelism을 통해서 작업을 더 빠르게 수행하는 방법 또한 다룰 것이다.\n\n---\n\n## \\+ Amdahl's Law\n\n작업의 성능을 개선시켰을 때 이전과 비교하여 얼마나 효율이 증가했는지를 보여주는 지표이다.\n\n$$1\\over{(1-P) + {P\\over{S}}}$$\n\n여기서 개선된 작업이 전체에서 차지하는 비율을 P라고 하고, 해당 작업의 향상된 작업 효율을 S라고 한다.\n\n만약, 전체에 10%를 차지하는 작업을 2배 빠르게 진행한다면,\n\n$${1\\over{(1-0.1) + {0.1\\over{2}}}} = {1\\over{0.95}} \\approx 1.05$$\n\n따라서, 단기간의 성능향상을 하고 싶다면, 비율이 큰 작업의 성능향상을 꾀하는 것이 좋다는 것을 알 수 있다.\n\n## Reference\n\n- David A. Patterson, John L. Hennessy, Computer Organization and Design\n","slug":"architecture-base","date":"2022-04-12 09:00","title":"1. Base","category":"Computer Architecture","tags":["Computer Organization And Design","ISA"],"desc":"Computer Organization and Design이라는 책을 정리하고 되돌아볼 것이다. 여기서는 가장 기본이 되는 Idea들을 정리할 것이다.","thumbnailSrc":"https://euidong.github.io/images/default.jpg"},{"content":"\n## Intro\n\n컴퓨터가 알아들을 수 있는 명령을 우리는 Instruction이라고 한다. 그렇다면, 이들을 모아놓은 단어장(Vocabulary)는 **Instruction set**이 되는 것이다. 이런 의미에서 현대의 computer는 이를 기반으로 동작하도록 설계되었기 때문에, 이를 **Instruction set architecture**라고 부른다. 해당 책에서는 MIPS를 기준으로 하기 때문에 똑같이 MIPS를 기준으로 설명합니다. 이는 다른 processor들과 매우 유사하니 이를 배우면 쉽게 다른 것도 이해할 수 있을 것이다.\n\n그렇다면, Instruction이란 무엇일까? 이는 기계어(0과 1로 이루어진 이진수 체계)의 형태로 표현된다. 따라서, 이를 Assembly Instruction이라고도 한다. 이는 hardware에게 특정 동작을 수행하도록 하는 명령어라고 할 수 있다. 그렇기에 우리가 실행하거나 작성하는 모든 program들은 사실 Instruction들의 집합이라고 볼 수 있다. 실제로 Computer에서 Program이 동작할 때, 이는 Computer는 memory에 program의 내용과 program에서 사용할 data들을 위한 공간을 배정해준다. 그런 후에 실제로 실행될 때에는 program의 Instruction을 차례차례 읽어가면서 실행하는 것이다.\n\n## Assembly Instruction의 구성요소\n\n기본적으로 MIPS는 32bit(=4Bytes) 시스템을 사용한다. 따라서, 하나의 Instruction은 4 Bytes로 표현된다. 이를 하나의 가장 단위라고 여겨서 word라고도 부른다. 따라서, 64bit(=8Bytes) CPU에서는 1 word가 8 Bytes가 될 수도 있다. 결국 모든 Instruction이 0과 1로 이루어진다. 하지만, 이는 너무 읽기 어렵기 때문에 우선 Assembly(기계어보다는 사람의 언어에 가깝지만 아주 원초적인 형태의 언어) Instruction을 알아볼 것이다. 이를 기계어로 바꾸는 것은 해당 포스팅의 밑에서 다룬다.\n\n### 1\\. Operand\n\n연산을 위해서 필요한 것은 연산자와 피연산자이다. 보통의 programming 언어에서는 이를 변수라고 한다.\n\nMIPS에서는 총 두 가지의 변수 type이 존재한다.\n\n1. **Constant**  \n    하나의 상수로써 동작하는 변수이다. 주어진 범위 내에서 자유롭게 상수로 사용가능하다.\n2. **Register No**  \n    하드웨어 상의 register들과 programming에서의 변수와 차이점이 있다면, 바로 갯수의 제한이 있다는 것이다. 보통은 갯수를 32개로 제한한다. 그렇게 하는 것이 효율적이라고 찾아냈다고 한다. 더 많이 써도 Clock Cycle이 더 소모될 뿐이고, 적다면 표현력이 부족해지 수도 있다. 또한, 하나의 register의 크기 또한 우리는 대게 32bit(1 word)로 제한한다. 이를 표현할 때에는 보통 \\$ 표시를 활용하고, register는 특정 목적을 위해서 지정되어 있다. (밑에 표를 참고)  \n    Instruction에서는 Register를 가르키기 위해서 5bit를 사용한다. $2^5$이면 모든 Register를 구분할 수 있기 때문이다.\n3. **Memory Address**  \n    해당 공간에는 기본적으로 register에 담기진 못한 모든 정보가 저장된다. 왜냐하면, register 가 하나의 변수를 표현할 수 있는데 만약, 변수가 32개를 넘어간다면, 이를 처리하는 것이 매우 버거워진다. 따라서, 이를 임시로 저장해두어야 한다. 따라서, 이를 memory에 잠깐 저장하는데 이를 **spilling register**라고 부른다.  \n    좀 더 복잡한 데이터 구조를 가지는 경우에도 이를 모두 register에 담는 것은 불가능하다. 따라서, 우리는 Memory라는 것을 활용한다. Memory는 8bit 단위로 한 칸으로 나누어 4개의 칸을 합친 것을 하나의 단위로 봅니다. (왜냐하면 이것이 4x8bit = 32bit = 1word가 되기 때문이다.) 따라서, 우리가 특정 값에 접근할 때에는 4의 배수로 접근하는 것이 올바른 접근이다. 또한, 하나의 데이터가 4개의 칸으로 쪼개지기 때문에 저장 방법에 차이가 있을 수 있다. 어떤 사람들은 앞 자리부터 차곡차곡 넣을 수도 있지만, 누구는 역순으로도 넣을 수 있기 때문에 이를 유의해야 한다. MIPS에서는 앞에서붙터 차곡차곡 넣는 Big Endian 방식을 사용한다. (즉, 4개 중 가장 낮은 주소값에 높은 값을 의미하는 값(MSB)이 쓰인다.)  \n    하나의 Memory address를 가르키기 위해서는 32bit가 필요하다. 이렇게 하여 $2^{32}$ = 4GB 이하까지의 Memory는 가르킬 수 있는 것이다. Instruction 자체가 32bit인데, 이를 Instruction에 바로 넣을 수는 없기 때문에 특정 Memory address를 가르키기 위해서 별도의 register에 해당 Memory의 address를 저장해두고 해당 지점부터 offset을 constant로 전달하는 식으로 표기한다.(여기서 4의 배수로 memory가 표현되므로, 2bit를 뺀다고 해도 30bit로 여전히 많다.)\n\n다음은 MIPS의 Register와 Memory를 나타낸 것이다.\n\n![registers](/images/registers.png)\n\n상식적으로 알아두고 갈 부분은 reigster는 직접적으로 연산이 이루어지는 곳이기 때문에, register에 접근하는 비용이 memory에 접근하는 부분보다 확연하게 비용이 싸다.(시간이 짧게 걸린다.) 따라서, 이를 효율적으로 다루어주는 것이 효율 향상에 도움이 된다.\n\n#### 2\\. Operation\n\n모든 computer는 기본적인 연산을 수행할 수 있어야 한다. MIPS에서는 다음과 같은 표기법을 사용한다.\n\n```plaintext\n1. \u003c명령어(operation)\u003e \u003c연산자(operand) 1\u003e \u003c연산자(operand) 2\u003e \u003c연산자(operand) 3\u003e\n\n2. \u003c명령어(operation)\u003e \u003c연산자(operand) 1\u003e \u003c연산자(operand) 2\u003e\n\n3. \u003c명령어(operation)\u003e \u003c연산자(operand)\u003e\n```\n\n마치 우리가 영어를 처음 배울 때, 1형식, 2형식 배우는 형태랑 유사하다. 그리고 여기서는 모든 문장이 명령형으로 구성된다는 점을 유의하자. 이에 따라서, 다음 MIPS의 피연산자(operand)와 주요 Operation을 살펴보자.\n\n\u003e **Add / Substract**\n\n`add [연산자1] [연산자2] [연산자3]`\n\n모든 연산의 기본으로 위의 형태 중에서 첫번째에 해당한다. 이를 수학 기호로 나타내면 다음과 같다.\n\n`[연산자1] = [연산자2] + [연산자3]`\n\nSubstraction 연산도 이와 동일하게 동작한다.\n\n\u003e **Load / Save**\n\n우리가 Register에 특정 데이터를 저장하기를 원한다면, $zero register 에 저장하기를 원하는 값 또는 register를 add해서 해당 register에 저장하면 된다.\n\n`add [저장을 원하는 register No] [$zero] [1234]`\n\n하지만, Memory에 데이터를 저장하기 위해서는 별도의 명령어가 필요하다. 그것이 save 명령어 입니다. 앞 서 말한 것과 같이 memory address를 직접적으로 Instruction에 표현할 수는 없기 때문에 특정 register에 주소값을 저장하고, 해당 주소를 base로 해서 offset을 더해서 주소를 찾는 형태로 수행한다.\n\n`sw [불러올 register No] [Memory의 Base Address를 가진 register No] offset`\n\n이와 반대로 Memory에서 데이터를 register로 불러올 때에도 별도의 명령어가 필요하다.\n\n`lw [불러올 register No] [Memory의 Base Address를 가진 register No] offset`\n\n\u003e **Jump**\n\nInstruction 역시 Memory에 상주하고 있는데, 만약 필요에 따라 이전 Instruction으로 돌아가거나 Instruction을 뛰어넘어야 한다면, 그때 사용할 수 있는 Instruction이다.\n\n`j [이동할 instruction offset]`\n\n\u003e **Branch**\n\nBranch(분기)는 특정 조건의 부합 여부를 확인하고, Jump를 수행하는 Instruction이다. 이를 위한 operator가 beq, bne가 있다.\n\n`beq [비교할 register1] [비교할 register2] [이동할 instruction offset]`\n\nregister1과 2가 서로 동일하다면, 해당 instruction offset으로 이동하라는 의미이다. bne는 반대로 두 register가 다를 때에 이동할 수 있다.\n\n\u003e **기타 주요 명령어**\n\n![instruction](/images/instruction.png)\n\n\\* PC : Program Counter의 줄임말로 현재 실행하고 있는 Program에서 어느 위치의 Instruction을 실행시키고 있는지를 나타낸다. 이를 이용해서 CPU는 다음 Instruction을 불러온다.\n\n\\* offset : offset은 대게 instruction 단위로 나타내기 때문에 1 offset은 4Bytes를 의미한다. 따라서, offset을 실제 주소에 더할 때에는 곱하기 4(실제로는 shift left 2)를 해야한다. 이로 인해서, 현재 Instruction의 다음 Instruction의 주소를 PC+4 라고 한다.\n\n---\n\n## Instruction를 이용한 Programming 언어 기본 요소 구현\n\n### 1\\. 조건문 (if / else)\n\n```pseudo\nif (i == j) \n f = g + h;\nelse\n f = g - h;\n```\n\n다음과 같은 c의 조건문 코드를 아래와 같은 Instruction들로 변환이 가능하다.\n\n```pseudo\nbne $s3, $s4, Else # go to Else if i != j\nadd $s0, $s1, $s2 # f = g + h (skipped if i != j)\nj Exit # go to Exit\n\nElse: \nsub $s0, $s1, $s2 # f = g - h (skipped if i = j)\n\nExit:\n```\n\n여기서 Else는 임의의 offset을 나타낸다. 따라서, \"Else:\"라고 표시된 부분에 해당하는 offset이라고 생각하면 된다.\n\nSwitch/Case 문 같은 경우는 if/else로 변환해서 나타내기도 하고, 아니면 Switching 위치를 적어놓은 Table을 만들어서 해당 위치로 바로 이동하는 식으로 구현하기도 한다.\n\n### 2\\. 반복문 (while)\n\n```pseudo\nwhile(save[i] == k)\n i += 1;\n```\n\n다음과 같은 c의 반복문을 아래와 같은 Instruction들로 변환이 가능하다.\n\n```pseudo\n# $t1 : save[i] address pointer\n# $t0 : save[i] value\n# $s3 : i\n# $s6 : save의 base address (save[0] address pointer)\n# $s5 : k\n\n# sll shift left \"\u003c\u003c\" 를 의미합니다. \n# 즉, 아래에서는 두 번하므로, *2^2를 의미합니다.\nLoop: \nsll $t1, $s3, 2 # temp reg $t1 = i * 4\nadd $t1, $t1, $s6 # $t1 = address of save[i]\nlw $t0, 0($t1) # temp reg $t0 = save[i]\nbne $t0, $s5, Exit # go to Exit if save[i] != k\naddi $s3, $s3, 1 # i = i + 1\nj Loop # go to Loop\n\nExit:\n```\n\n### 3\\. 함수 (function)\n\nprocedure는 대게 function(함수)이라고도 불린다. 함수를 우리는 하나의 예시를 통해서 설명할 수 있다.\n\nprocedure를 비밀 작전을 맡고 떠난 spy라고 하자. 작전은 자원을 습득하여, 특정 작업을 수행하고, 흔적을 감춘 뒤에, 바람직한 결과를 들고 돌아오는 것을 의미한다. 즉, spy는 작업을 마치고, 원하는 결과를 갖고 왔지만, 해당 결과 외에는 아무것도 바뀌지 않기를 기대한다. (누군가한테 의심받지 않아야하기 때문에)\n\n이러한 과정이 똑같이 함수의 호출마다 발생한다. 아래는 이를 다소 축약한 형태입니다.\n\n1. parameter를 procedure가 접근할 수 있는 곳에 위치시킵니다.\n2. control을 procedure(callee)로 옮깁니다.\n3. procedure는 해당하는 자원(parameter)을 습득합니다.\n4. 목표한 바를 수행합니다.\n5. 결과값을 자신을 호출한 program(caller)이 접근할 수 있는 곳에 위치시킵니다.\n6. control을 호출한 곳(caller)으로 넘깁니다.\n\n\\* 여기서 control이 이동했다는 것은 \bPC값이 PC+4가 아닌 함수의 주소로 이동했다는 것을 의미합니다.\n\n이를 구현하기 위해서 우리는 다음과 같은 별도의 register를 사용합니다.\n\n```pseudo\n$a0 - $a3 : 4 argument(=parameter) registers.\n$v0 - $v1 : 2 return value registers.\n$ra : 1 return address register. 원래 위치를 기억하기 위한 register.\n```\n\n\\$a와 \\$v는 사실 함수 사용에서 필수적이기 때문에 쉽게 받아들일 수 있지만, \\$ra가 의아할 수 있을 것이다. 이는 procedure를 호출했던 시점으로 다시 돌아오기 위해서 호출한 시점의 주소(실제로는 호출한 시점에서 다음 Instruction의 주소)를 저장하고 있는 것이다. 이러한 과정 즉, \\$ra에 저장과 jump를 동시에 해주는 것이 jal instruction이다. 이는 바로 다음 instruction을 가르키도록 하여 PC+4로 저장하고, 특정 지점으로 이동한다. 그리고 돌아올 때에는 jr instruction을 이용해서 \\$ra로 돌아올 수 있다.\n\n만약, 더 많은 변수를 return value, argument로 쓰고 싶다면 우리는 이를 memory로 옮기는 과정을 수행해야 한다. 이때, computer 에서는 stack이라는 구조를 사용한다. (실제로 구현하는 것은 아니고, 마치 stack 처럼 사용하기에 이렇게 부른다.) Stack pointer라는 register(\\$sp)를 이용하여 현재 사용하고자 하는 data가 stack의 어디를 가르키고 있는지를 저장한다.\n\n\u003e **실제 예제**\n\n```c\nint leaf_example (int g, int h, int i, int j) {\n int f;\n \n f = (g + h) - (i + j);\n return f;\n}\n```\n\n```c\nleaf_example:\naddi $sp, $sp, –12 # adjust stack to make room for 3 items\nsw $t1, 8($sp) # save register $t1 for use afterwards\nsw $t0, 4($sp) # save register $t0 for use afterwards\nsw $s0, 0($sp) # save register $s0 for use afterwards\n\nadd $t0,$a0,$a1 # register $t0 contains g + h\nadd $t1,$a2,$a3 # register $t1 contains i + j\nsub $s0,$t0,$t1 # f = $t0 – $t1, which is (g + h)–(i + j)\n\nadd $v0,$s0,$zero # returns f ($v0 = $s0 + 0)\n\nlw $s0, 0($sp)  # restore register $s0 for caller\nlw $t0, 4($sp)  # restore register $t0 for caller\nlw $t1, 8($sp)  # restore register $t1 for caller\naddi $sp,$sp,12 # adjust stack to delete 3 items\n\njr $ra # jump back to calling routine\n```\n\n해당 방식을 통해서, 만약 우리가 argument를 각 argument register 채워주고, \"jal leaf\\_example\"를 수행하게 되면, 해당 함수를 실행하는 것과 같은 동작을 하게 되는 것이다.\n\n하지만, 더 고민해야 하는 경우가 있다. 바로 함수 안에서 또 함수를 호출하는 경우이다.\n\n\u003e **Nested Function call(Function 내부에서 Function의 호출)**\n\nprocedure가 또 procedure를 호출하는 경우에는 어떻게 해야할까? 이 때에는 간단한게 stack의 retuern address를 저장해놓고, \\$ra를 덮어씌우는 식으로 작동한다. 아래는 recursive call을 수행한 경우를 담은 내용이다.\n\n```c\nint fact (int n) {\n if (n \u003c 1) \n  return 1;\n else\n  return n * fact(n-1); \n}\n```\n\n```pseudo\nfact:\naddi  $sp, $sp, –8    # adjust stack for 2 items\nsw    $ra, 4($sp)     # save the return address\nsw    $a0, 0($sp)     # save the argument n\n# slti 는 $a0의 값이 상수보다 작다면, 0 크다면 1이 저장됩니다.\nslti  $t0, $a0, 1     # test for n \u003c 1\nbeq   $t0, $zero, L1  # if n \u003e= 1, go to L1\n\naddi  $sp, $sp, 8     # pop 2 items off stack\n\naddi  $v0, $zero, 1   # return 1\njr    $ra             # return to caller\n\nL1: addi $a0,$a0,–1   # n \u003e= 1: argument gets (n – 1)\njal fact              # call fact with (n –1)\n\nlw $a0, 0($sp)        # return from jal: restore argument n \nlw $ra, 4($sp)        # restore the return address\naddi $sp, $sp, 8      # adjust stack pointer to pop 2 items\n\nmul $v0,$a0,$v0       # return n * fact (n – 1)\njr   $ra              # return to the caller\n```\n\n이제 끝일 거 같지만, 마지막으로 생각해야 할 게 있다. 바로 내부에서 또 local variable을 선언한 경우이다. 이 경우에도 memory에 공간에 저장해야 하는데 이때에도 stack pointer를 이동 시켜서 구현하는 것은 후에 동작에 혼란을 야기할 수 있다. 따라서, frame pointer라는 것을 추가로 할당하였다. 이는 함수의 진입 시점에 stack pointer의 초기 위치를 가르킨다. 따라서, 쉽게 후에 돌아올 지점을 알 수 있기에 stack pointer를 더 유동적으로 움직일 수 있다.\n\n---\n\n## 여러 변수 형태 표현법\n\n### Signed Numbers\n\n일반적으로 unsigned number라고 하면, 0과 양수를 포함하는 범위이다. 하지만, signed number는 음수까지 포함한다. 그렇다면, 컴퓨터에서는 음수를 어떻게 표현할 수 있을까?\n\n사람의 머리로 가장 쉽게 생각할 수 있는 방법은 부호를 나타내기 위한 별도의 표시 bit를 하나 넣어주면 될 거 같다는 생각을 할 것이다. 이것이 정확하다. 바로 오른쪽 끝에 있는 bit가 1이면 음수 0이면 양수로 보는 방식이다. 1이 맨 앞에 올 때는 0이 원래 1의 역할을 대신한다. 그리고 0이 앞에 올 때는 원래 계산하던대로 수행하면 된다. 그러면 놀랍게도 우리가 생각하는 것처럼 덧셈 뺄셈 연산이 동작한다. 그리고 오른쪽 끝에 있는 수를 우리는 MST 라고 하고, 이를 sign bit라고 부른다.\n\n```pseudo\n0000 0000 0000 0000 0000 0000 0000 0000(two) = 0(ten) \n0000 0000 0000 0000 0000 0000 0000 0001(two) = 1(ten)\n0000 0000 0000 0000 0000 0000 0000 0010(two) = 2(ten)\n...\n0111 1111 1111 1111 1111 1111 1111 1101(two) = 2,147,483,645(ten)\n0111 1111 1111 1111 1111 1111 1111 1110(two) = 2,147,483,646(ten)\n0111 1111 1111 1111 1111 1111 1111 1111(two) = 2,147,483,647(ten)\n1000 0000 0000 0000 0000 0000 0000 0000(two) = –2,147,483,648(ten)\n1000 0000 0000 0000 0000 0000 0000 0001(two) = –2,147,483,647(ten)\n1000 0000 0000 0000 0000 0000 0000 0010(two) = –2,147,483,646(ten)\n...\n1111 1111 1111 1111 1111 1111 1111 1101(two) = –3(ten)\n1111 1111 1111 1111 1111 1111 1111 1110(two) = –2(ten)\n1111 1111 1111 1111 1111 1111 1111 1111(two) = –1(ten) \n```\n\n\u003e **Proof**\n\n```pseudo\n# 덧셈\n  1111 1111 1111 1110 (-2)\n+                   1 (+1)\n----------------------\n  1111 1111 1111 1111 (-1)\n\n\n                   11  (+3)\n+ 1111 1111 1111 1000  (-8)\n----------------------\n  1111 1111 1111 1011  (-5)\n\n\n# 뺄셈 1\n  1111 1111 1111 1110 (-2)\n-                   1 (+1)\n----------------------\n  1111 1111 1111 1101 (-3)\n\n\n# 뺄셈 2\n                   11  (+3)\n- 1111 1111 1111 1000  (-8)\n----------------------\n                   11  (+3)\n+ 0000 0000 0000 1000  (+8)\n----------------------\n  0000 0000 0000 1011  (+11)\n```\n\n연산을 하다보면, 당연히 너무 큰 양수를 더하게 되면 overflow가 발생할 수 있는데 이 경우 운영체제마다 compiler마다 처리 방식이 상이하다. C에서는 overflow가 되면 그대로 값을 내놓기 때문에, 대게 굉장히 큰 음수가 나오게 된다.\n\n### Character\n\ncomputer에서 수가 아닌 값을 어떻게 표현할 수 있는가는 ASCII code 표가 답해줄 수 있을 것이다. 하나의 문자를 우리는 character라고 부르고, ASCII code 표와 같은 방식을 통해서 수를 글자로 변환하여 표현한다. 또한, 하나의 문자가 아닌 단어, 문장에 이르게 되면 이를 우리는 string이라고 하며, 이는 이 데이터의 길이를 표기하기 위해서 다음 3가지 중 하나를 선택하게 된다.\n\n1. string의 가장 앞에 길이를 나타내는 값을 넣어준다.\n2. string을 구조체로 만들어서 길이를 나타내는 값을 따로 넣는다.\n3. string의 가장 끝 문자를 구분자로 채워서 구분할 수 있도록 한다. ⇒ C에서는 \\\\0 을 사용하여 구분한다.\n\n---\n\n## Representing Instruction with Machine Language\n\n위에 나온 MIPS Assembly code를 이제 MIPS의 기계어로 변환하는 과정을 수행할 것이다.\n\n다시 한 번 설명하자면, 우리의 program들은 사실상 instruction의 집합이라고 볼 수 있다. 또한, 현대의 컴퓨터는 이러한 instruction들을 memory에 마치 데이터처럼 쌓아서 실행시킨다. 그래서 우리는 이러한 프로그램 실행 방식을 **stored program** 이라고 부른다. 우리는 위에서 memory에 데이터를 저장하기 위해서 하나의 word 즉 32bit를 사용했다. 따라서, 우리의 instruction도 하나의 word 단위로 표현한다.\n\n아래 그림은 32bit의 각 각 부분이 무엇을 의미하는지를 표현한 것이다. 위의 연산을 표시하기 위해서 다음과 같이 word를 구분한다. 이때 주의할 점은 큰 값을 처리할 때에는 I-Type을 사용하기 때문에 형태가 기본형인 R-Type과는 다소 다른 것을 볼 수 있다.\n\n\u003e **R-Type**\n\n![r-type](/images/r-type.png)\n\n- op : opcode라고 불리며, instruction의 동작이 무엇인지를 정의한다. (ex. add, jump, ...)\n- rs : first source register\n- rt : second source register\n- rd : destination register. 연산의 결과값이 저장되는 위치를 의미한다.\n- shamt : shift amount라는 의미로 shift 연산을 사용할 때 이용된다.\n- funct : op field에서 구체적인 동작을 정의할 때 사용한다.\n\n\u003e **I-Type**\n\n![i-type](/images/i-type.png)\n\n- op : opcode라고 불리며, instruction의 동작이 무엇인지를 정의한다. (ex. addi, jump, ...)\n- rs : first source register\n- rt : second source register\n- constraint or address : 긴 값이 필요한 연산에서는 다음과 같은 형태로 표현한다.\n\n## Addressing\n\nMIPS는 여러가지 instruction을 가지고 있기 때문에, 주소를 targeting하는 방식도 여러가지이다. 또한, 따른 instruction set architecture에서도 다양한 방법을 통해서 memory의 주소를 가르킨다.\n\n1. Immediate addressing : 상수를 통해 직접 address를 지정하는 방식이다.\n2. Register addressing : register로 address를 지정하는 방식이다.\n3. Base addressing : 상수에 특정 register값을 더해서 구하는 방식이다.(MIPS → Load Word, Save Word)\n4. PC-relative addressing : PC 값에 상수 값을 더해서 구하는 방식이다. (MIPS → Branch)\n5. Psedodirect addressing : PC의 맨앞 내자리를 가져와서 쓰는 방식이다. (MIPS → Jump)\n\n## Reference\n\n- David A. Patterson, John L. Hennessy, Computer Organization and Design\n","slug":"architecture-instruction","date":"2022-04-14 09:00","title":"2. Instruction","category":"Computer Architecture","tags":["Computer Organization And Design","Instruction","ISA"],"desc":"컴퓨터가 알아들을 수 있는 명령을 우리는 Instruction이라고 한다. 그렇다면, 이들을 모아놓은 단어장(Vocabulary)는 Instruction set이 되는 것이다. 이런 의미에서 현대의 computer는 이를 기반으로 동작하도록 설계되었기 때문에, 이를 Instruction set architecture라고 부른다. 해당 책에서는 MIPS를 기준으로 하기 때문에 똑같이 MIPS를 기준으로 설명합니다. 이는 다른 processor들과 매우 유사하니 이를 배우면 쉽게 다른 것도 이해할 수 있을 것이다.그렇다면, Instruction이란 무엇일까? 이는 기계어(0과 1로 이루어진 이진수 체계)의 형태로 표현된다. 따라서, 이를 Assembly Instruction이라고도 한다. 이는 hardware에게 특정 동작을 수행하도록 하는 명령어라고 할 수 있다. 그렇기에 우리가 실행하거나 작성하는 모든 program들은 사실 Instruction들의 집합이라고 볼 수 있다. 실제로 Computer에서 Program이 동작할 때, 이는 Computer는 memory에 program의 내용과 program에서 사용할 data들을 위한 공간을 배정해준다. 그런 후에 실제로 실행될 때에는 program의 Instruction을 차례차례 읽어가면서 실행하는 것이다.","thumbnailSrc":"https://euidong.github.io/images/default.jpg"},{"content":"\n해당 내용은 이전에 다루었던, [논리회로 리뷰 내용](/posts/digital-logic-circuit)을 보고 보는 것을 추천합니다.\n\n## Intro\n\n우리의 컴퓨터 시스템은 결국 Finite State Machine(유한상태장치)라고 할 수 있다. 즉, 순서에 따라 유한한 상태에서 다음 상태로 넘어가면서, Output을 계속해서 내보내는 장치라는 것이다. 이때 하나의 작업은 하나의 Clock 단위로 수행되며, 연속적은 작업 처리를 통해서 컴퓨터는 사용자가 요구한 명령을 수행하게 된다.\n\n## Processor\n\nprocessor와 program의 성능을 측정하기 위해서 우리는 다음과 같은 식을 활용하였다.\n\n$$\\text{instruction count} \\times \\text{Clock Cycle Time} \\times \\text{Clock Cycles per Instruction}$$\n\n[2. post](/posts/architecture-instruction)에서는 Instruction Count를 관리하고, 어떻게 계산되는지를 보았다면, **해당 포스팅에서는 Clock Cycle Time과 Clock Cycle per Instruction이 어떻게 구성되는지를 알아보며, 이들을 어떻게 줄일 수 있는지를 알아볼 것이다.**\n\n이를 위해서 우리는\n\n1. MIPS CPU의 가장 기본적인 구현\n2. pipeline된 MIPS\n3. Instruction 단계에서의 병렬화\n\n를 살펴볼 것이다.\n\n```plaintext\n 🤔 주의\n\n 해당 단계에서는 다음과 같은 사항은 배제한다.\n 1. multiply, shift, divide 연산\n 2. floating point 연산\n\n 결론적으로, 앞으로 구현할 MIPS에서는 다음과 같은 연산을 할 수 있다.\n 1. Memory에 접근하는 Load Word, Store Word\n 2. 기본 연산자 ADD, SUB, AND, OR, 등\n 3. Branch 구문 (BEQ, JUMP)\n```\n\n## 1. 기본적인 MIPS 구현(Single Cycle CPU)\n\n기본적인 processor에서 program이 동작은 다음과 같다.\n\n1. PC(Program Counter)를 Memory에 보내서 code를 포함한 부분을 특정하여 Instruction을 불러온다.(Instruction Fetch)\n2. 하나 또는 두 개의 register를 읽어서 Instruction을 수행한다.\n\n따라서, 이를 수행할 수 있는 논리 구조를 간략히 그려보면, 다음과 같은 형태를 가지게 됩니다.\n\n![Basic MIPS](/images/basic-mips.png)\n\n먼저, PC값의 형성 부분부터 보면 기본적으로 PC는 현재값에 4를 더하는 연산이기 때문에 상단에서 더한 값이 바로 다음 Clock에 적용된다고 할 수 있다. 그런데, 만약 Jump나 Branch 연산이 들어온다면, 해당 PC값에 특정값을 더한 결과로 이동하게 될 수 도 있다.\n\n그리고, 나머지 부분은 PC를 통해서 첫번째 박스에서 Instruction을 골라내고, Instruction의 특정 부분에서 OP와 register 등에 대한 정보를 토대로 Register와 상수 등을 이용하여 ALU 장치에서 OP 정보에 따라 연산을 수행한 뒤에 결과값을 특정 Register에 돌려주거나 Memory에 저장하도록 한다.\n\n물론 위에서는 **mux**(Multiplexor)에서 사용하는 데이터에 대한 내용은 빠져있지만, 아래 그림을 보면 더 정확하게 이해할 수 있을 것이다. 여러가지 경우의 수 중 상황의 따라서 output이 다른 경우에 mux를 사용하게 되는데, 여기서는 Instruction의 특정부분을 통해서 Control bits를 얻어내고, mux를 설치하여 적절하게 행동하도록 제어하고 있다.\n\n대표적인 예시로 아까 PC값을 선택하는 부분이 보다 명확하게 표시되는 것을 볼 수 있다. 현재 계산된 PC+4를 사용할 것인지 아니면, Branch 명령어에서 계산된 값을 사용할 것인지를 Control bit가 결정하는 것을 볼 수 있다.\n\n![Basic MIPS 2](/images/basic-mips2.png)\n\n이제부터는 각 단계별로 뜯어서 살펴본다.\n\n### 1) IF 단계 - Instruction Fetch\n\n해당 단계에서는 PC에 저장된 값에 따라서, Memory에서 Instruction을 추출하면서 PC에 4가 더해지는 것을 볼 수 있다. 그리고, Instruction의 특정 부분과 연산이 수행되는 것을 볼 수 있는데 이는 Branch 구문에 의한 이동을 위해서 주소를 저장해놓는 것이다.\n\n그리고, 이를 mux와 signal bit를 통해서, 최종적으로 다음 Program의 line을 가르킬 수 있다.\n\n![MIPS IF](/images/mips-if.png)\n\n### 2) ID 단계 - Instruction Decode and Register File Read\n\n해당 단계에서는 크게 두가지의 일을 한다.\n\n첫 번째는, Instruction에 포함된 정보를 기반으로 하여 Register를 선택하고, 해당 Register에 해당하는 정보를 내보내는 것이며,\n\n![MIPS ID](/images/mips-id1.png)\n\n두 번째는, Control bits를 생성하는 역할이다.\n\n![MIPS ID](/images/mips-id2.png)\n\n### 3) EX 단계 - Execution or Address Calculating\n\n다음 단계에서는 `R-Type`, `I-Type`에 따라서 두번째(2nd) Register를 사용할지 아니면, 상수로 받아들일지를 선택해야 한다. 이는 이전 단계(ID)에서 생성했던 Control bit를 mux에 통과시키는 식으로 구현한다.\n\n이후에는 control bit들을 통해서 연산의 종류를 선택한 후에, ALU 내부에서 연산을 수행하여 결과값을 내보낸다.\n\n결과값은 일반적인 결과를 내보내며, 추가적으로 beq 또는 여타 연산의 결과를 쉽게 알리기 위해서 zero라는 output으로 결과값이 0인지를 알려준다. 이는 다른 beq와 같은 연산에서 control bit로 사용한다.\n\n![MIPS EX](/images/mips-ex.png)\n\n### 4) MEM 단계 - Data Memory Access\n\nData Memory에 접근하는 동작으로 만약 Memory에 데이터를 update하는 동작을 한다면, MemWrite가 1로 설정되어있고, 이를 보고 명령어를 처리하게 된다.(read도 동일하게 MemRead를 활용한다.) 물리적으로 CPU와 떨어져있는 장비이기 때문에 접근하는데 많은 시간이 소요된다. 따라서, MIPS의 Instruction 실행의 모든 단계들 중에서 가장 오랜 시간이 필요한 연산이라고 할 수 있다.\n\n![MIPS MEM](/images/mips-mem.png)\n\n### 5) WB 단계 - Write Back\n\n실제로 Register의 값을 update해주는 부분으로 register의 update는 Data Memory에서 값을 불러오거나 연산 결과를 받을 때 사용하기 때문에 둘 중에 어떤 경우인지를 확인하여 데이터를 update한다.\n\n![MIPS WB](/images/mips-wb.png)\n\n위와 같이 하나의 Instruction을 수행하기 위한 일련의 작업이 한 Clock을 단위로 실행되는 경우를 Single Cycle CPU라고 한다.\n\n### 2. Pipelining\n\n가장 기본적인 구조를 살펴보았으니 위의 형태를 최적화하기 위한 가장 효과적이였고, 모든 CPU에서 사용되고 있는 설계 방법을 설명할 것이다. 위의 과정을 보고 있으면 우리는 비효율을 하나 발견하게 된다. **바로 특정 단계가 실행 중인 동안에 해당 단계에 포함되지 않은 장비들은 놀려지고 있다는 점이다.** 즉, 위에서 processor의 성능을 측정하는 지표인 Clock Cycle Time이 증가한다. 따라서, 모든 장비를 계속해서 실행시키기 위해서, 한 단계가 한 Clock이 되도록 하는 방법이 고안되었다.(Multi Cycle CPU)\n\n하나의 예를 살펴보자.\n\n세차장에 갔다고 하자. 우리는 당연히 일열로 서서 자신의 차례가 되기를 기다린다. 하나의 장비가 세차에 들어가기 전에 사람에 의해서 먼저 비누거품을 내는 단계가 있다면, 우리는 당연히 줄을 서있는 동안 세차장 아르바이트생이 비누칠을 해주기를 기다릴 것이다. 하지만, 해당 세차장에서는 만약 기다리는 동안 해주는 것이 아니라 세차 기계가 이전 차량에 대한 작업을 마치고 안정적으로 작업이 끝난 후에 비누칠을 해준다고 하자. 이것은 굉장한 짜증을 유발하는 요소가 될 것이다.\n\n따라서, Single Cycle CPU를 사용하는 것은 하드웨어 장비를 최적화하지 못한 사례라고 할 수 있다.\n\n위와 같이 단게를 나누어 여러 Cycle에 나누어 하나의 명령어를 처리하게 되면, 우리는 다음과 같은 효과를 얻게 된다.\n\n1. Clock Cycle Time이 줄어든다.\n2. 하나의 CPU가 동시에 여러 개의 명령어를 실행하게 할 수도 있다.(**Instruction Overlapping**)\n\n![Pipeline Example](/images/pipeline-example.png)\n\n이렇게 Instruction을 동시에(병렬적으로) 실행할 수 있다면, 1개의 Cycle 동안 Hardware 장치의 잉여 시간을 최소화할 수 있다.\n\n하지만, tradeoff 역시 존재한다.\n\n1. 각 단계의 연산이 끝난 후에 해당 값을 보관할 추가적인 하드웨어 장비(register)가 필요하다.\n2. Clock이 올라가고, 떨어지는 동안의 미세한 시간의 추가로 시간 비용이 증가한다.\n3. Clock Cycle Time은 반드시 하나의 상수로 정해져야 하기 때문에 가장 실행 시간이 긴 단계에 의존하게 된다. 즉, 실행시간이 더 짧은 단계라고 할지라도 다른 긴 단계가 있다면 기다려야 한다.\n4. 2와 3번을 이유로 결론상 하나의 Instruction을 수행하는데 걸리는 시간은 증가할 수 밖에 없다.\n   그렇기에 결론상 단계를 생각없이 무조건 잘게 자른다고 좋은 것이 아니다. 바로 균등하게 많이 나눌 수 있는 만큼 나누는 것이 좋은 것이다.\n5. Instruction을 동시에 실행하는 것으로 인한 문제가 발생할 수 있다(Hazard). 이는 바로 다음 부분에서 다룬다.\n\n### Hazard\n\nHarzard는 아래와 같이 총 3가지의 종류가 있다.\n\n\u003e **1. Structural Hazard**\n\nHardware가 구조적으로 동시에 특정 Instruction 조합을 처리하지 못할 경우를 의미한다. 즉, 서로 다른 pipeline stage에서 동일한 resource(Hardware)에 접근하고자 할 때 발생할 수 있다. 만약 Instruction Memory와 Data Memory의 분리가 되어 있지 않은 경우에는 이러한 문제가 IF, MEM 단계에서 발생할 수도 있지만, MIPS에서는 발생하지 않는다.\n\n\u003e **2. Data Hazard**\n\n바로 Instruction이 서로 연관(의존)되어있을 때의 문제이다.\n\n다음과 같은 상황을 가정해보자. 우리가 memory에서 데이터를 불러와서 3을 더하는 연산을 한다고 하자. 그렇다면 명령어는 다음과 같다.\n\n```assembly\nlw $v 0\naddi $v 3\n```\n\n이를 실행하면 불행하게도 load가 채 끝나기도 전에 채워지지 않은 \\$v에 3이 더해지는 것을 알 수 있다.\n\n이를 해결하기 위해서 3가지의 선택지가 있다.\n\n1. 의존성이 있는 명령어가 실행 중인 경우 끝날 때까지 대기 (**Stall**)\n   가장 간단한 방법이지만, pipelining을 통한 성능 향상을 감소시킬 수 있다.\n2. Compiler 단에서 의존이 발생하는 Instruction 사이에 순서가 상관없는 Instruction을 끼워넣어서 resource가 낭비되지 않으면서 hazard가 발생하지 않도록 한다. (**Reordering**)\n   Hazard를 해결하는 좋은 방법이지만, 항상 이것이 가능할 수는 없다.\n3. 추가적인 Hardware를 사용하여 결과값을 필요로 하는 resource에게는 단계를 생략하고 넘긴다. (**Forwarding**, **Bypassing**)\n   현재까지는 가장 괜찮다고 받아들여지는 방법이다. 예를 들어서, EX 단계에서 ALU 연산이 끝나자마자 Write Back을 자체적으로 수행해주면 총 3번의 stall을 1번으로 줄일 수 있다.\n\n\u003e **3. Control Hazard**\n\nBranch Hazard라고도 불리며, 이전 Instruction의 결과에 따라서 실행시킬 Instruction이 변화할 때, 어느 Instruction을 실행시킬지 알 수 없기 때문에 발생하는 Hazard이다. (JUMP, BEQ)\n\n이 경우에도 총 3가지의 선택지를 가진다.\n\n1. 성공적으로 분기문이 실행될 때까지 대기한다.(**Stall**)\n2. 어느 곳으로 Branch가 될지를 예상하여, 미리 시행해둔다. (**Branch Prediction**)\n   Resource를 최적화한다. 별도의 hardware를 설치하여 미리 JUMP 및 Branch address를 계산해 놓는다(**Hardware Optimization**)는 가정이 필요하다. 또한, 예측이 얼마나 적중하는가 역시 굉장히 중요한 요소로 작용한다.\n   대게 이러한 예측은 두 가지의 종류가 있다.\n   1. 정적 예측\n      쉽게 생각할 수 있는 것은 반드시 실패한다고 생각하거나 성공한다고 생각해서 진행하는 방식이다. 좀 더 복잡한 방식은 loop문에 의한 branch인 경우 branch가 수행될 확률이 높다는 것을 기반으로 하여 성공 가능성이 크다고 예측할 수 있다.\n   2. 동적 예측\n      이전 예측들을 기반으로 하여 현재 예측을 수행하는 방식이다. 이를 사용하면, 여러 번 반복되는 행위에 대한 예측율이 상당히 높아진다. 대게, 우리가 하는 분기문이 loop 등에 의한 경우가 많으므로 좋다고 할 수 있다. 또한, 최근에는 machine learning을 활용하여 예측을 수행하는 방식 또한 나오고 있다.\n3. Branch 여부에 상관없는 요청을 Control Hazard에 의해서 발생하는 구간에 넣는다. (**Delayed Decision**)\n\n## Parallelism via Instruction\n\nPipelining을 통해서, Instruction을 동시에 여러 개 실행시킬 수 있는 환경이 구축되었다. 그 와중에 resourece 자체를 하나 이상 두어서 Instruction을 동시에 수행할 수 있도록 하는 방식이 고안되었는데, 이를 Multiple Issue processor라고 한다.\n\n이를 대표하는 방식은 크게 두가지로 나눌 수 있다.\n\n### 1. Static Multiple Issue\n\n이는 compiler가 program을 기계어로 번역하는 과정에서 이루어지며, 대표적으로 다음과 같은 것들이 있다.\n\n1. VLIW(Very Long Instruction Word)\n   의존성이 없는 여러 Instruction을 하나의 Instruction으로 뭉쳐서 실행시키는 방법이다. 이를 통해서 중첩되는 OPCODE 및 기타 처리 등을 최소화할 수 있다. Processor가 해당 기능을 지원하는 경우에만 사용가능하다.\n2. Loop Unrolling\n   loop를 풀어서 여러 개의 Instruction으로 만들어서 branch로 인한 비용을 줄일 수 있다.\n\n### 2. Dynamic Multiple Issue\n\nprocessor에서 직접 Instruction이 실행되는 동안 이루어진다. 이는 여러 개의 pipeline을 CPU에 두어 이를 SuperScalar 방식이라고도 한다. 이를 효율적으로 수행하기 위해서는 앞 서 보았던 Compiler 단에서의 조율도 필요하며, 실행 중에 Instruction을 어떻게 나눌 것인가에 대한 Dynamic Scheduling 역시 매우 중요하다. 대표적인 예시가 OoO(Out of Order) Execution을 이용하는 것이다. Instruction의 Fetch를 순서대로가 아닌 의존성에 알맞게 실행되도록 조절하는 방식이다.\n\n## Reference\n\n- David A. Patterson, John L. Hennessy, Computer Organization and Design\n","slug":"architecture-processor","date":"2022-04-28 19:25","title":"4. Processing","category":"Computer Architecture","tags":["Computer Organization And Design","Processing","MIPS Implementation","Pipeline","Branch Prediction","SuperScalar"],"desc":"우리의 컴퓨터 시스템은 결국 Finite State Machine(유한상태장치)라고 할 수 있다. 즉, 순서에 따라 유한한 상태에서 다음 상태로 넘어가면서, Output을 계속해서 내보내는 장치라는 것이다. 이때 하나의 작업은 하나의 Clock 단위로 수행되며, 연속적은 작업 처리를 통해서 컴퓨터는 사용자가 요구한 명령을 수행하게 된다.","thumbnailSrc":"https://euidong.github.io/images/default.jpg"},{"content":"\n## Intro\n\n컴퓨터를 사용할 때, 우리는 기본적으로 Memory가 무한한 크기를 가지고 있기를 바란다. 하지만, 이를 실제로 구현하는 것은 비용적으로도, 기술적으로도 불가능하다. 따라서, 이를 마치 존재하는 것처럼 느끼도록 하는 Virtual Memory라는 기술을 사용한다.\n\n## Locality\n\nVirtual Memory를 위한 핵심은 `Locality`를 활용하는 것이다. 동작에는 인과가 존재하고, 그렇기에 직전에 자신이 했던 행동 그리고 근처의 대상들이 했던 행동이 지금의 자신이 할 행동에 영향을 주는 것은 어찌보면 당연한 사실이다. 이러한 특징이 `Locality`이다. 이를 이용해서 우리는 Memory를 마치 무한인 것처럼 느낄 수 있게 할 수 있다.\n\n1. **Temporal Locality**\n   하나의 Instruction 또는 data가 사용되었다면, 해당 내용은 곧 다시 사용될 확률이 매우 높다.(반복문일 경우에는 극명하게 드러날 것이다.)\n2. **Spatial Locality**\n   하나의 Instruction 또는 data가 사용되었다면, 후에 이 근처에 있는 내용을 사용할 확률이 매우 높다. (일반적으로 연속적으로 동작하는 경우가 많기 때문에 근처의 명령어들을 같이 가져올 수 있다면, 가져오는 것은 합리적이다.)\n\n이를 활용하기 위해서, 우리는 **Memory Hierarcy**라는 방법을 사용한다. 즉, 메모리를 계층화하는 것이다. 모든 장치를 빠르고, 크고, 싸게 만들 수 있으면 좋겠지만, 실제로는 불가능하기에 빠르고, 작은 장치를 processor에 가까이에 두고, 그 보다는 덜 빠르고, 큰 장치를 좀 더 거리를 두고 위치시키는 방식이다. 이렇게 하면 이용자에게 싸면서, 빠른 시스템을 제공할 수 있다.\n\n이를 위해서, 우리는 더 멀리 있는 Memory에서 정보를 복사해서 더 상위의 Memory에 붙여넣기하는 것이다. 계층 구조이기 때문에 한 번에 수행되는 것이 아니라 여러 단계가 있다면, 차근차근 순서에 맞춰서 수행된다. 즉, 단계를 skip하여 이동하는 것은 불가능하다.\n\n만약, 상위 Memory 장치에서 원하는 정보(Block, Line)를 찾았다면 이를 `hit`라고 하고, 찾지 못했다면 이를 `miss`라고 한다. 또한, `hit time`은 상위 Memory가 해당 Block에 접근하는데 걸리는 시간을 의미한다. 반대로 `miss penalty`는 상위 Memory로 해당 Block을 위치시키는 시간과 Block을 processor에 전달하는 시간까지를 포함한다.\n\n---\n\n시작하기에 앞 서, 컴퓨터 공학을 공부하는 누구나 겪는 현상이라고 생각하는데 바로 Memory 파트는 언어가 매우 자기 멋대로 나오는 경향이 있다. 즉, 깔끔한 정리가 되지는 않았다. Memory가 어떨 때는 Main Memory를 의미하다가 전체 모든 저장 장치를 의미하기도 한다. 따라서, 이 아래부터는 다음과 같이 엄격하게 분리하여 설명한다.\n\n1. Memory : 모든 저장 장치들을 의미한다. 즉, cache, secondary storage, main memory 등을 모두 포함한 개념이다.\n2. Cache : Processor에 붙어서 바로 동작하는 Memory 장치\n3. Main Memory : 우리가 주로 RAM이라고 부르는 장치\n4. Secondary Storage : 주로 HDD, SSD로 이루어지는 보조 기억 장치\n\n## Memory Components\n\n시작하기에 앞서 실제로 메모리를 이루는 구성요소들을 먼저 살펴보고 간다.\n\n1. **DRAM**(**Dynamic Random Access Memory**)\n   Main Memory에 주로 사용되는 장치로 SRAM보다는 느리지만, 확실히 많은 데이터를 저장할 수 있다. 하나의 bit를 저장하기 위해서 1개의 transistor를 사용하는데, 이 transistor에서 전력이 새어 나가기 때문에 정보를 잃는 것을 막기 위해서 주기적으로 refresh를 해주어야 한다.\n   Random Access라는 의미는 순차적으로 앞에서부터 탐색하는 방식이 아니고, 찾고자하는 데이터를 바로 찾을 수 있다는 의미이다. 따라서, 앞에서부터 찾는 방식보다 더 빠를 수 밖에 없다.\n   휘발성 저장 장치이기 때문에 전력이 공급되지 않으면 정보를 모두 잃는다.\n2. **SRAM**(**Static Random Access Memory**)\n   Cache에 주로 사용되는 장치로 매우 빠른 연산이 가능하지만, 크기를 크게 만들기 위해서는 비용이 너무 비싸진다는 단점이 있다. 하나의 bit를 처리하기 위해서 6개의 transistor를 사용한다. 이 덕분에 전력을 다시 공급해주는 refresh 과정이 필요없다.\n   과거에는 processor 밖에서 chip 형태로 존재하였지만, 점점 회로가 집적이 되며, processor에 통합되었다.\n   휘발성 저장 장치이기 때문에 전력이 공급되지 않으면 정보를 모두 잃는다.\n3. **Flash Memory**\n   Electrically Erasable Programmable Read-Only Memory(EEPROM)의 한 종류이다. 다른 장치들과는 달리 write가 flash memory를 닳게 만들 수 있다. 따라서, 대부분의 flash memory는 한 bit를 쓰기가 집중되는 현상을 막기 위해서, 이를 분산시키는 방식을 사용한다. (wear leveling, 쓰기 횟수에 제한이 존재한다.) 이는 대게 모바일 장치들의 저장 장치로 많이 사용되며, PC에서 사용하는 SSD와 매우 유사하다.\n4. **Magnetic Disk**\n   일명 자기 테이프 방식으로, 다른 장치들과는 다르게 자기력을 이용하여 정보를 저장하는 방식이다. 실제로 물리적으로 존재하는 Disk로 하여 Hard Disk라고도 부른다.이를 읽고 쓰기 위해서는 arm(팔)이라는 개체가 disk의 정보가 스여진 위치로 이동해야 읽을 수 있다. 따라서, 이것이 물리적으로 움직이는 시간이 소요되기 때문에 여타 Random Access 장비보다 느릴 수 밖에 없다. 하지만, 이를 통해서 저장할 수 있는 정보의 양은 매우 많다.\n\n## Cache\n\nMain Memory와 Processor 사이에서 memory hierarchy를 수행하는 장치라고 한다. 하지만, 현대에는 이러한 구조에 영감을 받아서 cache를 여러 곳에서 사용하기 때문에, 많은 분야에서 이를 **locality의 장점을 활용하기 위한 일종의 저장소**라는 의미로 많이 사용한다.\n\n### Cache의 역할\n\nCache가 수행하는 역할은 저장 장치이기 때문에 읽기와 쓰기가 가능해야 한다.\n\n\u003e **Read**\n\n읽기를 수행하기 위해서 Cache에서는 다음과 같은 동작을 수행할 수 있어야 한다.\n\n1. **Main Memory의 데이터를 일부 저장할 수 있어야 한다.**\n   Cache는 Main Memory보다 크기가 작기 때문에 Main Memory의 모든 데이터를 저장하지 못한다. 따라서, 일부분을 저장하는데 이를 저장할 때, 기존의 Main Memory에서의 데이터의 address를 cache의 크기만큼 나누어 cache의 범위에 들어오도록 하는 것이 Directed Mapping이다. 따라서, 다음과 같은 식이 성립한다.(여기서의 Block이란 한 번에 cache로 가져올 데이터의 단위를 의미한다.)\n   $\\text{Cache에서 Block의 주소} =$ $\\text{(Main Memory에서 Block의 주소)} \\%$ $\\text{(Cache의 용량)}$\n2. **특정 word가 cache에 존재하는지 확인할 수 있어야 한다.**\n   이를 위해서 우리는 tag를 이용한다. cache 공간으로 address가 변환되어서 생략된 address를 포함하고 있다. 즉, cache의 index로 쓰이지 않은 Main Memory Address의 상위값을 가지고 있다. 쉽게 생각해서 위에서 만들어진 Cache의 Block 주소가 나머지라면, tag는 몫이라고 볼 수 있다. 따라서, tag는 담기는 데이터에 따라서, 계속해서 변하여 저장되는 값이다.\n3. **해당 데이터가 타당한지 확인할 수 있어야 한다.**\n   만약, system을 막 booting시켰다면, cache에는 모두 이상한 값이 들어갈 것이다. 따라서, 잘못된 값을 참조할 수도 있다. 따라서, 우리는 **valid bit**(1 bit)를 이용하여, 해당 값이 적절하게 할당한 값인지를 표기한다.\n4. **덮어 씌우기가 가능해야 한다.**\n   이 경우는 간단히 덮어 씌어버린다. 이는 앞 서 설명한 **temporal locality**와 일맥상통한다. 최근에 쓴 데이터가 다시 호출할 확률이 높기 때문이다.\n\n\u003e **Example**\n\n왼쪽이 Cache고, 오른쪽이 Main Memory이다.\n\n1. 초기 상태  \n  ![directed-mapping-1](/images/directed-mapping-1.png)\n2. 001011 요청  \n  ![directed-mapping-2](/images/directed-mapping-2.png)\n3. 001011 재요청  \n  ![directed-mapping-3](/images/directed-mapping-3.png)\n4. 110011 요청  \n  ![directed-mapping-4](/images/directed-mapping-4.png)\n\nBlock 단위를 4Bytes로 했다면, 하나의 word 단위가 Block의 단위가 될 것이다. 그렇지 않고 더 큰 단위로 Block을 저장할 수도 있다. 일반적으로는 이 Block의 단위를 늘리면 miss rate를 낮출 수 있다. 근처의 데이터를 한 번에 여러 개 가지므로, **spatial locality**를 활용할 수 있다. 하지만, 과도하게 늘리게 되면, 오히려 이로 인해서 index가 표현할 수 있는 범위가 점점 작아진다. (한 마디로 cache의 전체 크기(용량)은 고정이기 때문에, 가로를 의미하는 block의 사이즈가 늘어나면, 세로를 의미하는 index의 범위가 줄어들 수 밖에 없다.) 이로 인해서 block size를 너무 크게 늘리게 되어도, miss rate는 증가하게 된다. 뿐만 아니라 miss penalty도 크게 증가한다. 해당 데이터를 cache에 끌어오는 동안의 시간이 증가할 것이기 때문이다. 따라서, 적당한 크기의 block 사이즈를 지정해야 한다.\n\n마지막으로, Cache를 읽기를 요청하였지만 해당 정보가 없는 경우 이를 `Miss`라고 하는데, `Miss`가 발생하면 이 데이터를 Main Memory에서 불러오기 위해서 어쩔 수 없이 우리는 stall을 수행해야 한다. 이러한 `Miss`는 굉장한 비용을 발생시키기 때문에 대게 세가지 방식에 의해서 이를 해결한다.\n\n1. Multiprocess or Multithread 환경에서는 다른 process를 해당 stall 동안 실행시켜서 이를 해결한다.\n2. OoO(Out of Order) Execution을 지원하는 장비에서는 이를 통해서 stall을 방지한다.\n3. Software를 개발할 당시에 해당 사항을 인지하고 최적화를 수행하는 것이다. cache의 hit 정도를 아래 그림에서 오른쪽과 같이 설정하게 되면, 결론적으로 hit 확률이 급격하게 증가하는 것을 알 수 있다. 이런식으로 Cache 크기에 유의하여 소프트웨어를 해당 장치에 최적화하는 방식도 존재한다.\n\n![software-optimize](/images/software-optimize.png)\n\n\u003e **Write**\n\n데이터를 Main Memory로 write하는 상황을 생각해보자. cache에서 작업을 진행하여 해당 위치에만 데이터를 최신화하게 되면, 필연적으로 cache와 Main Memory 사이에서 불일치가 발생할 수 밖에 없다. 따라서, 이를 해결하기 위한 방법이 세 가지가 있다.\n\n1. **Write Through**\n   가장 간단한 방법으로, write가 발생하면, 모든 저장 장치의 일관성을 유지하기 위해 모두 update 해주는 것이다. 그러나, 이 write의 비용이 엄청나게 크다는 것을 알기 때문에 이를 최대한 적게 하는 것이 사실상 performance 향상에 핵심이라고 생각하면, 이는 실제로 사용하기에는 무리가 있다.\n2. **Write Buffer**\n   Main Memory에 쓰이기를 기다리는 buffer를 만들어 놓고, 해당 장치에서 write를 일임하여 놓는 방식이다. 이를 이용하게 되면, Write의 완료를 cache에서 더 이상 기달릴 필요가 없다. 하지만, Write 명령어를 processor가 처라하는 속도가 buffer가 Main Memory에 쓰는 속도보다 훨씬 빠르기 때문에 당연하게 buffer가 꽉찰 수 있다. 그렇게 되면, 반드시 공간이 날 때까지 stall을 해야만 한다.\n3. **Write Back**\n   이 방식은 일관성을 포기하는 방식이다. 즉, 데이터를 가지고 있다가 실제로 이 값이 다른 값으로 변경될 때, cache의 특정 index에 있는 값이 다른 tag의 값으로 변경될 때에만 데이터를 쓰는 방식이다. 또는 강제적으로 하위 memory로의 저장을 요구할 경우에만 쓰도록 한다. 이를 이용하면, 성능은 확연히 올라가지만, 불일치성으로 인해 발생하는 문제를 해결하기 위해서 더 복잡한 요구사항이 발생한다. (일단 cache의 table에 각 row에 해당 값이 하위 Memory에서 copy된 이후로 변경되었는지를 표시하는 dirty bit가 필요하며, multi processor 환경에서는 더 큰 문제를 야기한다.)\n\n### 더 나은 Cache 저장법\n\n`Directed Mapping`을 통해서 Cache에 데이터를 저장하게 되면, 특정 Block이 위치할 수 있는 장소가 고정되어 버린다. 만약, index가 겹치는 값이 동시에 여러 번 사용된다면, miss rate가 크게 증가할 수 밖에 없다. 여기서, cache의 위치를 고정하지 않고, 자유롭게 하여 이러한 문제는 크게 줄일려고 하는 방법이 있다.\n\ntag에 모든 address 값을 저장하고, index를 address의 값으로 전혀 사용하지 않는 방식이 있다. 이것을 `full-associative cache`라고 한다. 이 경우에는 해당하는 index 범위에서 tag가 존재하는지를 확인하기 위해서 추가적인 연산이 필요하지만, hardware 장치를 추가적으로 배치하여 이를 동시에 실행시켜 성능을 향상시키는 방식을 택한다. 이 방식은 결론적으로 많은 hardware 장비를 추가적으로 요구하기 때문에 매우 비싸진다. 따라서, 적당한 합의점을 찾는 것이 `set-associative cache`이다. 이는 index 값을 일부만 이용하는 방식이라고 할 수 있다. 즉, 3bits를 index로 사용하는 cache에서 상위 n개의 bit만 실제로 사용하여 표현하는 것이다. 동일한 index를 가진 block은 $2^{전체 bit 수 - n}$ 존재하게 된다. 여기서, 이제부터 tag를 통해서 사용해서 검색을 수행하는 것이다. 따라서, 만약 n이 전체 bit 수와 같아 진다면, 이것이 `full-associative cache`가 되는 것이고, n = 0이라면, 일반적인 `Directed Mapping`이 되는 것이다.\n\n![set-associative](/images/set-associative.png)\n\n그렇다면, 이렇게 여러 개의 index가 data를 담을 수 있는 그릇이 될 때, 어느 위치에 값을 덮어 씌우는 것이 현명할 것인가는 **temporal locality**에 따라서 우리는 가장 쓰인지 오래된 index에 값을 덮어씌운다. 이것이 LRU(Least Recently Used) 방식이다. 이를 구현하기 위해서는 cache에 추가적인 reference bit라는 것을 위치시킨다.\n\n### MultiLevel Cache\n\n이제 cache를 여러 개 층(multilevel cache)을 이루어 사용한다고 해보자. process에 가까운 쪽을 primary cache라고 하고, 그 다음을 secondary cache라고 하자. 만약, primary cache에서 miss가 발생했을 대, secondary cache에 있으면, miss penalty를 줄일 수 있을 것이다. 하지만, secondary cache도 miss가 나면, miss penalty자체가 증가한다. 왜냐하면, secondary 로 불러오고, 다시 primary로 옮겨야 하기 때문이다. 그렇기에 무조건 cache를 많이 둔다고 좋은 것은 아니다. 적절한 cahce를 설정하는 것이 중요하고, 대게 이는 3개 정도로 한다.\n\n그리고 직관적으로 각 cache를 보면, primary cache는 hit time을 줄이는 것이 목표이고, secondary cache는 miss rate를 줄여야 한다. 그래서, primary cache에서는 block size를 줄이고, associative의 크기를 줄이지만, secondary cache에서는 block size를 키울 뿐만 아니라 associative의 크기 역시 키우는 것이 일반적이다.\n\n## Virtual Memory\n\nMain Memory를 안정적으로 관리하기 위해서, Virtual Memory라는 개념을 도입한다. 이는 실제로 존재하는 Main Memory와 Secondary Storage의 주소(**Physical Address**)를 가상의 주소(**Virtual Address**)로 바꾸고, 필요에 따라 이를 번역하여 사용함으로써, 하나의 process가 마치 Main Memory 하나를 장악하고 있는 거 같은 느낌을 느끼도록 할 수 있다. 왜냐하면, 당장에 쓰지 않는 process의 data는 Secondary Storage로 빼놓고, Virtual Address로 번역 시에는 해당 위치를 가르키도록 하면 된다. 그러면, 마치 각 process는 Main Memory 이상의 data를 갖고 있는 것 같다고 느낄 수 있다. 이러한 Virtual Memory를 이용하면 다음과 같은 작업을 쉽게할 수 있다.\n\n1. **동일한 장치에서 program 간의 Memory 영역을 구분할 때**, 일반적으로 Main Memory에 있는 데이터 역시 **locality**에 따라 계속해서 바뀌게 되는데, 특정 process 전체 크기를 실행 중일 동안 계속해서 제공한다면, 유연한 동작이 어렵다. 따라서, Virtual Memory는 이를 더 쉽게 하도록 돕는다.\n2. **동일한 장치 내에서 돌아가는 Virtual Machine간의 Main Memory 영역을 구분할 때**, 각 Virtual Memory는 Physical Memory로 번역되었을 때, 서로 충돌하지 않는 것을 보장하기 때문에 서로 다른 process간에 간섭이 없음을 보장할 수 있다.\n3. **Main Memory 보다 큰 크기의 Program을 돌리고자 할 때**, Main Memory 이상의 process를 돌리기 위해서는 Secondary Storage에 직접적인 접근을 수행해야 하는데, 이를 수행하지 않고, 실제로 현재 사용하지 않는 Memory 공간의 데이터는 Secondary Storage로 옮기고 이를 가르키는 Virtual Address만 바꾸어주면 되기 때문에, 쉽게 Main Memory 보다 큰 크기의 Program을 동작시키는 것도 가능하다.\n\nVirtual Memory 방식은 각 program, Virtual Machine마다 고유한 address space를 가지기 때문에 각자 독립되었다고 볼 수 있다. 그렇기에 각자가 서로의 동작으로 인한 영향을 받지 않는다. 즉, 다른 process에서 사용 중인 Memory에 접근할 수 없을 뿐만 아니라 이들에 의해서 발생하는 Memory의 변화가 자신이 진행 중인 process에 영향을 미치지 않는다. 즉, protection를 제공한다고 할 수 있다.\n\n또한, program을 상호간의 영향이 없는 조각으로 나눈 Overlay 단위로 나누어 초과되는 용량은 Secondary Storage에 상주시키고, 필요에 따라 Main Memory로 올려서 실행시킬 수 있다. 따라서, 용량이 부족한 Main Memory에서도 이보다 큰 크기의 Program을 동작시킬 수 있다.\n\nCache의 방식과 매우 유사하지만, 언어의 기원이 다르기 때문에 여기서는 Block을 **Page**라고 부른다. 그리고, 이 Page의 크기는 Page Offset이라고 표기한다. 따라서, **Virtual Address**는 사실상 두 개의 Part로 나뉘어진다. 첫 번째는 **Virtual Page Number**이고, 하나의 **Page offset**이다. 또한, Miss는 **Page Fault**라는 말로 바뀌어진다. 마지막으로, Virtual Address에 Mapping 되는 Physical Address를 Physical Page Number와 Page offset으로 이루어진다.\n\n위에서 말한 것처럼 Virtual Address를 Physical Address로 바꾸는 과정을 **Address Translation**이라고 한다.\n\n### Page 관리\n\n\u003e **Virtual Page Number를 통해서 실제 Physical Page Number로 변환하기**\n\n기존의 Cache에서도 Miss로 인한 비용도 컸지만, **Page Fault**의 비용은 이보다도 훨씬 크다고 할 수 있다. 이를 막기 위해서, Cache에서는 Full Associative한 구조를 가져갔지만, Main Memory는 Cache보다 훨씬 크기 때문에 이를 위한 추가적인 Hardware를 추가하는 것은 경제적으로 불가능하다고 볼 수 있다. 따라서, Main Memory에 존재하는 Page의 Address를 Mapping하기 위해서 table을 이용한다. 이를 **Page Table**이라고 부른다. 이는 Main Memory에 상중하고 있다. 각 각의 program은 고유의 Page Table을 하나씩 가지게 되며, Page Table 자체의 처음과 끝을 가르키는 register를 가지고 있다(**Page Table Register**). 그리고 Page Table에는 Virtual Page가 지금 어느 Physical Address에 존재하는지에 대한 정보와 이것이 Main Memory에 있는지를 표기하는 Valid Bit가 존재한다. 만약, Valid Bit가 0이라면, 이는 해당 Page가 지금 Main Memory가 아닌 Secondary Storage에 존재한다는 뜻이다.\n\n따라서, Page를 찾는 과정은 다음과 같다.\n\n1. Page Table Register를 기반으로 하여 Main Memory에서 **Page Table을 찾는다**.\n2. Virtual Address의 Virtual Page Number를 이용해서 Page Table에서 Page를 조회한다.\n3. Valid Bit를 확인하여 해당 Page가 현재 Main Memory에 존재하는지 아니면 Secondary Storage에 존재하는지를 확인한다.\n4. 이제 실제 Physical Page Number를 얻어와서, 기존의 Page Offset을 합치면, 이것이 Physical Address가 된다.\n\n```plaintext\n  \n  🤔 Page Table의 크기가 너무 크면 어떻게 될까?\n\n  Page가 너무 많아지면, Page Table의 크기가 너무 커질 수 있다.\n  따라서, 이를 해결하기 위해서 계층 구조를 가지고 정리한다. \n  즉, Page Table의 Table이 생기는 형태라고 보면 되겠다.\n\n```\n\n\u003e **Page Fault**\n\n위에서 말한대로 Page Fault가 발생한다면, 즉 Valid Bit가 0인 경우, 해당 Page를 Secondary Storage에서 찾고, 이를 Main Memory의 어느 위치에 놓을지를 결정해야 한다.\n\n우리가 번역한 Physical Address는 Secondary Storage의 직접적인 주소를 의미하기도 하지만 대게는 이를 이용해서 실제 Secondary Storage의 주소를 찾을 수 있도록 하는 자료구조를 가르키도록 되어있다. 그래서, 우리의 Operating System은 Process가 생성될 때, Process의 모든 Page를 Secondary Storage에 저장할 공간을 생성한다. 이를 `Swap Space`라고 부르며, 해당 Virtual Page가 실제 disk의 어디에 저장될지를 기록한 자료구조이다.\n\n만약, 이제 모든 Main Memory가 Page로 가득 차 있다면, OS는 어떤 Page를 대체할 것인지를 선택한다. 이때는 LRU(Least Recently Used) Algorithm을 사용한다. 지금까지 가장 사용하지 않은 Page를 삭제하는 것이다. 이를 구현할 때는 Reference bit를 설정하고, 주기적으로 0으로 변경하기를 반복하면서, 해당 Page를 사용할 때마다 1로 변경주는 것을 수행하는 것이다. 그리고, Page Fault가 발생할 시에 Reference Bit가 0인 대상이 있다면, 이를 우선으로 제거하는 방식이다.\n\n\u003e **Write**\n\nWrite하는 것은 굉장히 많은 시간을 소요한다. 따라서, Virtual Memory System에서는 이를 최소화하는 것을 목표로 하기 때문에 이전에 소개한 Write Back이 default이다.\n\n\u003e **TLB를 이용한 변환작업 속도 향상**\n\nPage Table이 실제로 Main Memory에 저장되기 때문에 우리는 Page를 조회하기 위해서 결국 무조건 Main Memory에 한 번 접근해야 한다. 이는 많은 시간을 소요하는 동작이기에 이를 최소화할 방법이 필요했다. 또한, Temporarl / Spatial Locality에 따라 사용한 Page는 다시 사용할 확룰이 많다. 따라서, 대게의 processor에서는 이를 위한 특별한 cache를 추가로 가지고 있다. 이것이 TLB(Translate Lookaside Buffer)이다. (아마 Translation cache라고 부르는 것이 더 자연스럽긴 할 것이다.) 따라서, TLB는 Virtual Page Number와 Dirty Bit, 그리고 Reference Bit를 가진다. TLB를 설계할 때에는 fully associative하게 만드는 것이 기본이다. 왜냐하면, TLB 자체가 매우 작고, hit rate가 성능에 큰 영향을 미치기 때문이다. 이렇게 구축하는 것이 성능에 큰 도움이 된다. 또한, replacing을 할 때에도 LRU를 구현할 수도 있지만 대게 이를 구현하기가 너무 경제적으로 어렵기 때문에, 대부분의 system은 랜덤하게 고르는 것을 선택한다고 한다.\n\n따라서, Page를 얻는 과정은 다음과 같다고 다시 요약할 수 있다.\n\n1. Page Table Register를 기반으로 하여 TLB에서 **Page Table을 찾는다**. 존재하지 않는다면, Main Memory에서 조회해야 한다.(TLB miss)\n2. Virtual Address의 Virtual Page Number를 이용해서 Page Table에서 Page를 조회한다.\n3. Valid Bit를 확인하여 해당 Page가 현재 Main Memory에 존재하는지 아니면 Secondary Storage에 존재하는지를 확인한다.\n4. 이제 실제 Physical Page Number를 얻어와서, 기존의 Page Offset을 합치면, 이것이 Physical Address가 된다.\n5. 이를 통해서, 조회를 수행하는데 만약, Secondary Storage에 있었다면, LRU를 이용해서 Page Swap을 수행하여 Page를 Main Memory로 올린다.\n6. 만약, TLB miss가 발생했었다면, 해당 Page 정보를 업데이트한다.\n\n자주 헷갈릴 수 있는 TLB miss가 Page Fault가 아니라는 것을 꼭 명심하자.\n\n![Virtual Memory](/images/virtual-memory.png)\n\n## **Reference**\n\n- David A. Patterson, John L. Hennessy, Computer Organization and Design\n","slug":"architecture-memory","date":"2022-04-29 19:25","title":"5. Memory Hierarchy","category":"Computer Architecture","tags":["Computer Organization And Design","Memory","Memory Hierarchy","Cache","Directed Mapping","Virtual Memory","Page"],"desc":"컴퓨터를 사용할 때, 우리는 기본적으로 Memory가 무한한 크기를 가지고 있기를 바란다. 하지만, 이를 실제로 구현하는 것은 비용적으로도, 기술적으로도 불가능하다. 따라서, 이를 마치 존재하는 것처럼 느끼도록 하는 Virtual Memory라는 기술을 사용한다.","thumbnailSrc":"https://euidong.github.io/images/default.jpg"},{"content":"\n## Intro\n\n우리가 원하는 것은 강한 performance를 발휘하면서도, 가용성(availability, 끊김 없이 사용할 수 있는 능력의 정도)가 높은 computer를 만드는 것이다. 이를 위해서, 우리는 단순히 하나의 processor를 정교하게 만들기보다는 동등한 기능을 하는 여러 개의 processor를 연결하여 사용하는 것이 더 효율적이라는 것이라는 것을 알아냈다. (이를 software가 잘 활용할 수만 있다면, 성능이 크게 향상될 것이다.)\n\n- 하나의 장치를 동작시키는 방식보다 적은 에너지로 같은 작업을 수행할 수 있다. (동시에 실행시키기 때문에 더 짧은 시간 사용할 수 있다.)\n- n개의 processor에서 하나가 실패하여도 n-1개는 정상 작동하기 때문에 전체 시스템은 문제 없이 동작한다. (Redundant, 추가자원을 통해서 가용성을 향상시킴)\n\n이에 따라 우리는 multi-processor를 사용한다.\n이는 multi-processor가 어떻게 존재하느냐에 따라서 다음과 같은 형태로 나눈다.\n\n1. **Multicore Microprocessor** : 하나의 IC(집적 회로) 칩에 여러 개의 processor(core)가 존재한다.\n2. **Multiple Processor** : IC칩의 갯수를 늘린다.\n3. **Cluster System** : Machine(Computer) 자체의 갯수를 늘린다.\n\n따라서, 개인 PC에서는 Multiple Multicore Microprocessor를 지원하고, 있는 상황이고, Datacenter와 같은 환경에서는 이러한 Machine들이 여러 개 존재하는 Cluster System이라고 생각하면 되겠다.\n\n또한, 이용하는 방식에 따라 크게 두 가지로 나눌 수 있다.\n\n1. Task Level Parallelism(=Process Level Parallelism) : 동시에 독립된 여러 program을 실행시키는 방식\n2. Parallel Processing Program : 동시에 여러 개의 processor를 이용하여 하나의 program을 실행시키는 방식\n\n## Parallel Processing Program의 구현\n\n하나의 작업을 더 빠르게 처리하기 위하여 multiple processor를 사용하는 software를 작성하는 것은 어렵다. 이는 processor의 수가 늘어날 수록 심해진다. multiprocessor program을 이용할 경우에, 수가 늘어날 수록 우리는 다음과 같은 작업에 대한 부담을 가질 수 밖에 없다.\n\n1. **Scheduling** : process 또는 thread를 scheduling하여 어떤 것을 먼저 실행시킬지에 대한 scheduling 역시 큰 부담이다.\n2. **Partitioning** : Memory의 구간을 각 processor에게 어떻게 나누고 서로 독립되게 존재하기 위한 관리를 수행하는 것 역시 큰 부담이 된다.\n3. **Balancing the Load** : 작업을 각 processor에게 균등히 분배하는 것 역시 어렵다.\n4. **Time to Synchronize** : 여러 개가 동시에 하나의 process를 실행시키면, 읽고 쓰기에서 충돌이 발생하는 것에 의한 문제가 발생하고 이를 해결하기 위해서 시간을 사용할 수 밖에 없다.\n5. **Overhead for Communication** : 각 processor간의 의사소통에 너무 큰 비용이 발생하는 경우 오히려 하나의 processor가 실행시키는 것보다 더 많은 시간을 요구할 수도 있다.\n\n이 모든 것을 software에서 제대로 관리할 수 있을 때, 그제서야 우리는 multi processor 시스템을 제대로 활용할 수 있는 것이다.\n\n우리가 processor의 갯수를 늘림으로써 얻을 수 있는 혜택은 각 processor에 전달되는 작업의 수를 균등하게 나누어, 기존에 하나의 processor가 할 수 없던 일을 처리(weak scaling)하거나, 기존의 문제를 더 빠르게 처리(strong scaling)할 수 있다.\n\n## Data Stream, Instruction Stream\n\nprocessor들로 들어오는 data의 양을 의미하는 **Data Stream**과 instruction의 양을 의미하는 **Instruction Stream**에 따라서, 우리는 각 processor들을 다양한 이름으로 부른다.\n\n1. **SISD**(Single Instruction Stream, Single Data Stream) : 대게 single processor일 경우 이와 같은 형태를 채택한다.\n2. **MIMD**(Multiple Instrunction Stream, Multiple Data Stream) : Multiple Processor System에서는 당연히 이와 같은 시스템을 채택한다.\n3. **MISD**(Multiple Instrunction Stream, Single Data Stream) : 잘 사용하지 않는 형태이다. 대게는 Data의 처리가 더 많이 발생하기 때문이다.\n4. **SIMD**(Single Instruction Stream, Multiple Data Stream) : 하나의 Instruction을 이용하여 복합적인 여러 개의 데이터를 한 번에 처리하는 vector 연산 등을 빠르게 처리할 수 있다.\n   1. vector 연산 하나가 for loop 하나를 의미할 수 있다. 이는 processor part의 각 pipeline 단계에서 fetch와 decode에 의한 비용을 크게 감소시킬 수 있다.\n   2. 하나의 vector 연산은 내부에서 각각이 독립적으로 수행되기 때문에, data hazard를 check하는 비용이 발생하지 않는다. 👉 따라서, vector의 각 요소를 모두 검사하는 것이 아닌 vector 외부 간의 data hazard 유무만 확인하면 된다.\n   3. Main Memory에서 데이터를 불러올 경우에도 각 요소를 불러오는 것이 아닌 한 번에 가져올 수 있기 때문에 매우 빠르다.\n   4. Loop를 표현이 vector 연산으로 대체되기 때문에, Loop Branch가 줄어든다.\n\n## Hardware Multithreading\n\nprogrammer의 입장에서 MIMD는 hardware multithreading처럼 동작한다고 생각하게 한다. 이는 processor의 사용성을 최대화하기 위해서, 특정 thread가 stall 되었을 때, 다른 thread를 수행하도록 하는 방식이다. 즉, 하나의 processor에서 여러 개의 thread를 실행시킨다는 것이다. 그러기 위해 사실상 여러 processor가 존재하는 multiprocessor 환경에서 서로간 실행 환경을 서로 공유해야 한다. 이를 실현하려면, 각 thread의 독립된 상태를 복사할 수 있어야 한다. 즉, 각 각의 register file과 PC가 존재해야 한다. 이들 간의 Memory 공유 같은 경우는 이전에 보았던 Virtual Memory 정보를 공유하여 수행하게 된다. 그리고 무엇보다 중요한 것은 이 실행하는 thread를 바꾸는 시간적 비용이 작아야 한다. 이를 위해서, process가 아닌 thread를 바꾸는 것이다. process를 바꾸는 것보다는 비용이 훨씬 적기 때문이다.\n\nthread를 변경 시에 어떤 방법을 택할 것인가 역시 중요한데, 아래와 같은 방법론이 존재한다.\n\n\u003e **1. Fine Grained Multithreading**\n\nthread의 명령어를 round robine 방식을 이용하여 매번 바꾸면서 실행시키는 방식이다. 변경한 thread 역시 stall이 된 thread라면, 건너뛰고 다음 thread를 실행시킨다.\n\n- 장점 : stall 기간이 짧던 길던 이로 인한 손실을 감추고, 그 동안 다른 thread를 실행시킬 수 있다.\n- 단점 : 실행 준비가 된 상태(stall이 아닌 상태)에서도 다음 차례가 올 때까지 반드시 기다려야 하기 때문에 하나의 thread에 대한 처리 속도가 dramatic하게 줄어든다.\n\n\u003e **2. Coarse Grained Multithreading**\n\n하나의 thread에 대한 Instruction만 처리하다가 stall이 발생했을 때에만 thread를 변경하도록 하는 방식이다.\n\n- 장점 : 하나의 thread에 대한 처리 속도의 손실이 적고, switching을 빨리 하는 것에 대한 부담이 적다.\n- 단점 : 하나의 thread에 대한 Instruction만 처리하기 때문에, thread를 변경하는 것에 대한 비용이 크다. (long pipeline setup time) 따라서, 짧은 기간의 stall인 경우에는 해당 stall이 끝나길 기다린다.\n\n\u003e **3. Simultaneous Multithreading(SMT)**\n\nThread Level에서 Parallelism과 Instruction Level에서의 Parallelism을 동시에 수행하는 방식이다. Multiple Instruction 시스템에서는 더 많은 functional unit(register, pc, etc)이 있기 때문에 이를 Multi Threading에서도 적절히 사용할 수 있다는 접근법에서 나왔다. 여기서는 register renaming과 dynamic scheduling을 이용하여 multiple thread에서 여러 개의 Instruction을 빈틈없이 배치할 수 있다. 의존성은 dynamic scheduling이 해결하고, register renaming을 통해 필요에 따라 여분의 register를 불러와서 사용하는 것이 가능해졌다. 이를 통해서 위의 두 방식으로 할 수 없었던, multi processor를 최대한으로 사용하는 효과를 볼 수 있다.\n\n![multi-threading](/images/multi-threading.png)\n\n## GPU(Graphic Processing Unit)\n\ngame 산업 및 그래픽 분야의 큰 성장에 힘업어 graphic 처리에 대한 processor의 성능 향상이 필요했다. 즉, 기존 micro processor와 겉아 다용도로 사용되는 것이 아닌 graphic 연산만을 빠르게 처리할 수 있는 processor를 분리할 필요가 생긴 것이다. 이것만을 위해서 만들어진 것이 GPU이다.\n\nGPU는 앞 서 설명한 Multi Threading 기술을 적극 도입했기 때문에 Memory 접근에 따른 Latency가 성능에 큰 영향을 미치지 않는다. 그런 만큼 반대로 높은 Bandwidth를 가진 저장 장치를 필요로 한다.\n\n후에는 이 장치가 수행하는 vector 연산이 여러 용도로 사용됨에 따라 이를 위한 programming language들도 만들어졌다. 대표적인 것이 NVidia가 C를 통해서 만든 CUDA이다.\n\n## Reference\n\n- David A. Patterson, John L. Hennessy, Computer Organization and Design\n","slug":"architecture-parallel-processors","date":"2022-05-02 20:22","title":"6. Parallel Processors","category":"Computer Architecture","tags":["Computer Organization And Design","Multi Processors","Multi Threading","MTU"],"desc":"우리가 원하는 것은 강한 performance를 발휘하면서도, 가용성(availability, 끊김 없이 사용할 수 있는 능력의 정도)가 높은 computer를 만드는 것이다. 이를 위해서, 우리는 단순히 하나의 processor를 정교하게 만들기보다는 동등한 기능을 하는 여러 개의 processor를 연결하여 사용하는 것이 더 효율적이라는 것이라는 것을 알아냈다. (이를 software가 잘 활용할 수만 있다면, 성능이 크게 향상될 것이다.)- 하나의 장치를 동작시키는 방식보다 적은 에너지로 같은 작업을 수행할 수 있다. (동시에 실행시키기 때문에 더 짧은 시간 사용할 수 있다.)- n개의 processor에서 하나가 실패하여도 n-1개는 정상 작동하기 때문에 전체 시스템은 문제 없이 동작한다. (Redundant, 추가자원을 통해서 가용성을 향상시킴)이에 따라 우리는 multi-processor를 사용한다.이는 multi-processor가 어떻게 존재하느냐에 따라서 다음과 같은 형태로 나눈다.1. Multicore Microprocessor : 하나의 IC(집적 회로) 칩에 여러 개의 processor(core)가 존재한다.2. Multiple Processor : IC칩의 갯수를 늘린다.3. Cluster System : Machine(Computer) 자체의 갯수를 늘린다.따라서, 개인 PC에서는 Multiple Multicore Microprocessor를 지원하고, 있는 상황이고, Datacenter와 같은 환경에서는 이러한 Machine들이 여러 개 존재하는 Cluster System이라고 생각하면 되겠다.또한, 이용하는 방식에 따라 크게 두 가지로 나눌 수 있다.1. Task Level Parallelism(=Process Level Parallelism) : 동시에 독립된 여러 program을 실행시키는 방식2. Parallel Processing Program : 동시에 여러 개의 processor를 이용하여 하나의 program을 실행시키는 방식","thumbnailSrc":"https://euidong.github.io/images/default.jpg"}]},"__N_SSG":true},"page":"/posts/[slug]","query":{"slug":"architecture-arithmetic"},"buildId":"zo17-VIt9hmdxew6D07b5","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>