<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="initial-scale=1.0, width=device-width"/><meta property="og:type" content="blog"/><meta property="og:site_name" content="JustLog"/><meta property="og:image" content="https://euidong.github.io/logo192.png"/><title>[ML] 7. Model Selection</title><meta property="og:title" content="[ML] 7. Model Selection"/><meta name="description" content="여태까지 ML을 수행할 수 있는 여러 가지 방법론을 살펴보았다. 그렇다면, 어떤 Model을 선택하고, 학습과 추정을 해야할지 결정해야 한다. 따라서, 여기서는 어떤 것이 좋은 Model이고, 각 Model 간에 어떻게 비교를 수행할 것인지 그리고 더 나아가 Model을 혼합하는 방법에 대해서 알아볼 것이다."/><meta property="og:description" content="여태까지 ML을 수행할 수 있는 여러 가지 방법론을 살펴보았다. 그렇다면, 어떤 Model을 선택하고, 학습과 추정을 해야할지 결정해야 한다. 따라서, 여기서는 어떤 것이 좋은 Model이고, 각 Model 간에 어떻게 비교를 수행할 것인지 그리고 더 나아가 Model을 혼합하는 방법에 대해서 알아볼 것이다."/><meta property="og:url" content="https://euidong.github.io/posts/ml-model-selection"/><link rel="canonical" href="https://euidong.github.io/posts/ml-model-selection"/><meta property="og:image" content="https://euidong.github.io/images/ml-thumbnail.jpg"/><meta name="next-head-count" content="12"/><link rel="icon" href="https://euidong.github.io/favicon.png"/><link rel="apple-touch-icon" href="https://euidong.github.io/logo192.png"/><link rel="preload" href="/_next/static/css/d4ec5c8b3df09443.css" as="style"/><link rel="stylesheet" href="/_next/static/css/d4ec5c8b3df09443.css" data-n-g=""/><link rel="preload" href="/_next/static/css/4e506edd7924fba2.css" as="style"/><link rel="stylesheet" href="/_next/static/css/4e506edd7924fba2.css" data-n-p=""/><link rel="preload" href="/_next/static/css/ce8fdf87155cc385.css" as="style"/><link rel="stylesheet" href="/_next/static/css/ce8fdf87155cc385.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js" id="Adsense-id" data-ad-client="ca-pub-7452732177557701" async="" defer="" data-nscript="beforeInteractive"></script><script src="/_next/static/chunks/webpack-9b312e20a4e32339.js" defer=""></script><script src="/_next/static/chunks/framework-81da43a8dcd978d9.js" defer=""></script><script src="/_next/static/chunks/main-7b6c38cbad60dfcf.js" defer=""></script><script src="/_next/static/chunks/pages/_app-1fd1954bd5db8904.js" defer=""></script><script src="/_next/static/chunks/78e521c3-cbc72355a4ceeb71.js" defer=""></script><script src="/_next/static/chunks/175675d1-f160d4a5df49f5d3.js" defer=""></script><script src="/_next/static/chunks/675-ae8e8a351ce30ae2.js" defer=""></script><script src="/_next/static/chunks/602-b0cb49b9f5da6250.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bslug%5D-81722d9821e3dc3b.js" defer=""></script><script src="/_next/static/7YkH3ZSfLE_PLxr1wR4Mz/_buildManifest.js" defer=""></script><script src="/_next/static/7YkH3ZSfLE_PLxr1wR4Mz/_ssgManifest.js" defer=""></script><script src="/_next/static/7YkH3ZSfLE_PLxr1wR4Mz/_middlewareManifest.js" defer=""></script></head><body><div id="__next"><div class="Layout_wrapper__dKJSz root"><header class="Layout_header__XosLl" style="position:static"><div><button tabindex="1" class="SideBarToggler_search_bar_toggler__CEuUg"><svg stroke="currentColor" fill="none" stroke-width="0" viewBox="0 0 24 24" height="35px" width="35px" xmlns="http://www.w3.org/2000/svg"><path d="M2 6C2 5.44772 2.44772 5 3 5H21C21.5523 5 22 5.44772 22 6C22 6.55228 21.5523 7 21 7H3C2.44772 7 2 6.55228 2 6Z" fill="currentColor"></path><path d="M2 12.0322C2 11.4799 2.44772 11.0322 3 11.0322H21C21.5523 11.0322 22 11.4799 22 12.0322C22 12.5845 21.5523 13.0322 21 13.0322H3C2.44772 13.0322 2 12.5845 2 12.0322Z" fill="currentColor"></path><path d="M3 17.0645C2.44772 17.0645 2 17.5122 2 18.0645C2 18.6167 2.44772 19.0645 3 19.0645H21C21.5523 19.0645 22 18.6167 22 18.0645C22 17.5122 21.5523 17.0645 21 17.0645H3Z" fill="currentColor"></path></svg></button><nav class="SideBar_side_bar__wrapper--close__8Nwnr"><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/">Home</a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/tags">Tags</a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/Algorithm">Algorithm<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->11<!-- -->)<!-- --></span></a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/Computer%20Architecture">Computer Architecture<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->7<!-- -->)<!-- --></span></a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/Tech">Tech<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->17<!-- -->)<!-- --></span></a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/Web">Web<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->4<!-- -->)<!-- --></span></a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/Paper">Paper<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->2<!-- -->)<!-- --></span></a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/Network">Network<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->11<!-- -->)<!-- --></span></a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/AI">AI<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->18<!-- -->)<!-- --></span></a></nav></div><a class="Logo_logo___yD0t" tabindex="1" href="/"></a><div><button class="SearchBarToggler_search_bar_toggler__3dHbA" tabindex="2"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="25px" width="25px" xmlns="http://www.w3.org/2000/svg"><path d="M11.742 10.344a6.5 6.5 0 1 0-1.397 1.398h-.001c.03.04.062.078.098.115l3.85 3.85a1 1 0 0 0 1.415-1.414l-3.85-3.85a1.007 1.007 0 0 0-.115-.1zM12 6.5a5.5 5.5 0 1 1-11 0 5.5 5.5 0 0 1 11 0z"></path></svg></button></div></header><section><div class="Post_post__wrapper__Qq8vV"><h1 class="Post_post__title__CYNLY">[ML] 7. Model Selection</h1><p class="Post_post__date__Sx37s">2022년 11월 8일 16시 07분</p><ul class="Post_post__tags__SU5Ql"><li class="Post_post__tags__element__SYmey"># ML</li><li class="Post_post__tags__element__SYmey"># ModelSelection</li><li class="Post_post__tags__element__SYmey"># CrossValidation</li><li class="Post_post__tags__element__SYmey"># Boosting</li><li class="Post_post__tags__element__SYmey"># AdaBoost</li><li class="Post_post__tags__element__SYmey"># DecisionTree</li><li class="Post_post__tags__element__SYmey"># NetworkPruning</li></ul><article class="markdown-body MarkDown_markdown-body__ABwUt"><h2 id="Intro">Intro<!-- --></h2>
<!-- --><p>여태까지 ML을 수행할 수 있는 여러 가지 방법론을 살펴보았다. 그렇다면, 어떤 Model을 선택하고, 학습과 추정을 해야할지 결정해야 한다. 따라서, 여기서는 어떤 것이 좋은 Model이고, 각 Model 간에 어떻게 비교를 수행할 것인지 그리고 더 나아가 Model을 혼합하는 방법에 대해서 알아볼 것이다.<!-- --></p>
<!-- --><h2 id="What-is-Good-Model?">What is Good Model?<!-- --></h2>
<!-- --><p>우리가 사람 image를 입력받아서 긴 머리를 가진 사람인지 여부를 판단하는 classifier를 만든다고 하자. 이때 어떤 Model이 좋은 Model이 될 수 있을까?<!-- --></p>
<!-- --><p>가장 쉽게 생각할 수 있는 Model은 Fully Connected Neural Network(FCNN)를 구성하는 것이다. 이를 위해서 Image의 각 pixel을 일렬로 줄 세워 입력할 수 밖에 없다. 하지만, 이는 pixel들 간의 인접 관계를 사용할 수 없게 한다는 단점 때문에 높은 성능을 내기가 어려웠다. 따라서, 이를 극복하기 위헤서 제시된 방법이 Convolutional Neural Network(CNN)를 사용하는 것이다. 이는 FCNN을 적용하기 이전에 Image에 Filter를 적용하여 특정 구간을 대표하는 값을 뽑아내서 더 효율적인 학습을 하는 것을 목표로 한다.(물론 더 자세히 다루면 Pooling Layer 등 더 자세한 설명이 필요하지만, 여기서는 자세히 다루지 않는다. 해당 글을 참고하도록 하자. <!-- --><a href="https://halfundecided.medium.com/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-cnn-convolutional-neural-networks-%EC%89%BD%EA%B2%8C-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-836869f88375">🔗 CNN(Convolutional Neural Networks) 쉽게 이해하기<!-- --></a>)<!-- --></p>
<!-- --><p>우리의 뇌에서도 Image를 인식하고 처리하기 위해서, color와 motion 그리고 윤곽 등을 따로 따로 처리한다고 한다. 즉, CNN은 이러한 Domain Knowledge를 활용한 훌륭한 예시 중 하나라고 할 수 있다. 즉, 여기서 말하고자 하는 바는 결국 모든 환경에서 최고의 성능을 보여줄 수 있는 Model은 없다는 것이며, Good Model은 우리가 하고자 하는 일에 따라서 Domain Knowledge를 충실하게 활용하여 최고의 성능을 낼 수 있는 Model이라고 할 수 있다.<!-- --></p>
<!-- --><pre><div class="MarkDown_codeblock__wrapper__S4FFz"><div class="MarkDown_codeblock__header__h3PfO"><span class="MarkDown_codeblock__header__circle__B4MWO"></span><span class="MarkDown_codeblock__header__circle__B4MWO"></span><span class="MarkDown_codeblock__header__circle__B4MWO"></span><span class="MarkDown_codeblock__header__button__aBRNB"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" height="25px" width="25px" xmlns="http://www.w3.org/2000/svg"><g><path fill="none" d="M0 0h24v24H0z"></path><path d="M7 6V3a1 1 0 0 1 1-1h12a1 1 0 0 1 1 1v14a1 1 0 0 1-1 1h-3v3c0 .552-.45 1-1.007 1H4.007A1.001 1.001 0 0 1 3 21l.003-14c0-.552.45-1 1.007-1H7zM5.003 8L5 20h10V8H5.003zM9 6h8v10h2V4H9v2z"></path></g></svg></span></div><div style="color:#f8f8f2;background:#282a36;text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:Consolas, Monaco, &#x27;Andale Mono&#x27;, &#x27;Ubuntu Mono&#x27;, monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:.5em 0;overflow:auto;border-radius:0.3em"><code class="language-plaintext" style="color:#f8f8f2;background:none;text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:Consolas, Monaco, &#x27;Andale Mono&#x27;, &#x27;Ubuntu Mono&#x27;, monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="linenumber react-syntax-highlighter-line-number" style="display:inline-block;min-width:1.25em;padding-right:1em;text-align:right;user-select:none;color:#6272a4">1<!-- --></span><span> 🤔 Data Augmentation
<!-- --></span><span class="linenumber react-syntax-highlighter-line-number" style="display:inline-block;min-width:1.25em;padding-right:1em;text-align:right;user-select:none;color:#6272a4">2<!-- --></span> 
<!-- --><span class="linenumber react-syntax-highlighter-line-number" style="display:inline-block;min-width:1.25em;padding-right:1em;text-align:right;user-select:none;color:#6272a4">3<!-- --></span> Domain Knowledge를 활용하여 Model의 성능을 높일 수 있는 방법은 
<!-- --><span class="linenumber react-syntax-highlighter-line-number" style="display:inline-block;min-width:1.25em;padding-right:1em;text-align:right;user-select:none;color:#6272a4">4<!-- --></span> 단순히 Model 자체를 바꾸는 것 뿐만 아니라 Domain Knowledge를 바탕으로 
<!-- --><span class="linenumber react-syntax-highlighter-line-number" style="display:inline-block;min-width:1.25em;padding-right:1em;text-align:right;user-select:none;color:#6272a4">5<!-- --></span> Data를 추가적으로 더 만들어내는 방법이 있다. 이러한 방법을 
<!-- --><span class="linenumber react-syntax-highlighter-line-number" style="display:inline-block;min-width:1.25em;padding-right:1em;text-align:right;user-select:none;color:#6272a4">6<!-- --></span> Data Augmentation이라고 한다.
<!-- --><span class="linenumber react-syntax-highlighter-line-number" style="display:inline-block;min-width:1.25em;padding-right:1em;text-align:right;user-select:none;color:#6272a4">7<!-- --></span>
<!-- --><span class="linenumber react-syntax-highlighter-line-number" style="display:inline-block;min-width:1.25em;padding-right:1em;text-align:right;user-select:none;color:#6272a4">8<!-- --></span> Image data 같은 경우에는 원본 Image를 약간 회전시키거나 확대하거나 
<!-- --><span class="linenumber react-syntax-highlighter-line-number" style="display:inline-block;min-width:1.25em;padding-right:1em;text-align:right;user-select:none;color:#6272a4">9<!-- --></span> Noise를 주는 등의 작업을 하여 전체 데이터의 크기를 늘릴 수 있다.
<!-- --><span class="linenumber react-syntax-highlighter-line-number" style="display:inline-block;min-width:1.25em;padding-right:1em;text-align:right;user-select:none;color:#6272a4">10<!-- --></span>
<!-- --><span class="linenumber react-syntax-highlighter-line-number" style="display:inline-block;min-width:1.25em;padding-right:1em;text-align:right;user-select:none;color:#6272a4">11<!-- --></span>Text 같은 경우에는 동의어를 활용하여 문장 데이터의 크기를 효과적으로
<!-- --><span class="linenumber react-syntax-highlighter-line-number" style="display:inline-block;min-width:1.25em;padding-right:1em;text-align:right;user-select:none;color:#6272a4">12<!-- --></span>늘리는 것도 가능하다.<!-- --></code></div></div></pre>
<!-- --><p><img src="/images/ml-data-augmentation.png" alt="ml-data-augmentation"/></p>
<!-- --><h2 id="Comparison-between-Models">Comparison between Models<!-- --></h2>
<!-- --><p>여기서 만약 우리가 얻을 수 있는 Model의 종류가 다양하다면 이들을 어떻게 비교하여 하나의 Model을 선택할 수 있을까? 이 역시 중요한 문제이다.<!-- --></p>
<!-- --><p>사실 우리가 학습했던 data를 그대로 평가할 때 사용하는 것은 굉장히 불공평하다고 할 수 있다. 우리가 만들고자 하는 Model은 일반적으로 어느 상황에 두어도 그리고 안본 data일지라도 올바르게 분류하기를 원한다. 즉, 우리의 Model이 <!-- --><strong>Generalization<!-- --></strong>을 수행할 수 있기를 바란다.<!-- --></p>
<!-- --><p>이러한 Model의 <!-- --><strong>Generalization<!-- --></strong> 성능을 측정하기 위해서 자주 사용되는 것이 Dataset을 Train과 Test set으로 나누는 것이다. 하지만, 이것도 부족할 때가 있다. 특정 Model이 특정 Train set에서만 성능이 높을 수도 있기 때문이다. 따라서, 우리는 <!-- --><strong>Cross Validation<!-- --></strong>이라는 방식을 도입한다. 이는 우리가 가진 dataset을 골고루 test와 train set으로 활용하는 방법이다. 즉, 여러 번의 training을 수행하며, test를 수행하기를 반복하는 것이다. 그리고, 이를 평균을 내서 전체적인 Model 성능을 평가하는 방법이다.<!-- --></p>
<!-- --><p><img src="/images/ml-k-fold-cross-validation.png" alt="ml-k-fold-cross-validation"/></p>
<!-- --><p>위와 같이 공평하게 k개로 나누는 방식을 k fold cross validation이라고 하며, 해당 예시는 <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k<!-- --></mi><mo>=<!-- --></mo><mn>4<!-- --></mn></mrow><annotation encoding="application/x-tex">k=4<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">4<!-- --></span></span></span></span></span>인 경우이다. 즉, 위와 같이 Validation을 하기 위해서는 Model의 수가 <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N<!-- --></mi></mrow><annotation encoding="application/x-tex">N<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">N<!-- --></span></span></span></span></span>개라고 할 때, 총 <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N<!-- --></mi><mo>×<!-- --></mo><mi>k<!-- --></mi></mrow><annotation encoding="application/x-tex">N \times k<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">N<!-- --></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×<!-- --></span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k<!-- --></span></span></span></span></span>번의 Training과 Evaluation이 필요하다.<!-- --></p>
<!-- --><p>하지만, 여기서 또 간과한 사실은 hyperparameter가 각 model마다 큰 영향을 미친다는 사실이다. 즉, Hyper Parameter를 정하는 과정 역시 필요한데, 이는 각 각의 Model 내부에서 어떤 Hyper Parameter를 사용할지에 대한 합의가 필요한 것이다. 이를 확인하기 위해서 어쩔 수 없이 우리는 Training과 Evaluation을 수행해야 하며, 이를 위한 data를 별도로 분리해야 한다. 따라서, 우리가 가지는 dataset을 다음과 같이 세개로 나누어야 한다는 것이다.<!-- --></p>
<!-- --><p><img src="/images/ml-dataset.png" alt="ml-dataset"/></p>
<!-- --><p>여기서 더 정당하게 하고 싶다면, 아래와 같은 과정을 반복해야 한다.<!-- --></p>
<!-- --><p><img src="/images/ml-nested-cross-validation.png" alt="ml-nested-cross-validation"/></p>
<!-- --><p>하지만, 이는 굉장히 비용이 커질 수 있다. validation set을 고를 때, <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>k<!-- --></mi><mo mathvariant="normal" lspace="0em" rspace="0em">′<!-- --></mo></msup></mrow><annotation encoding="application/x-tex">k^{\prime}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em">k<!-- --></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′<!-- --></span></span></span></span></span></span></span></span></span></span></span></span></span>개가 필요하다고 한다면, 우리는 <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N<!-- --></mi><mo>×<!-- --></mo><msup><mi>k<!-- --></mi><mo mathvariant="normal" lspace="0em" rspace="0em">′<!-- --></mo></msup><mo>×<!-- --></mo><mi>k<!-- --></mi></mrow><annotation encoding="application/x-tex">N \times k^{\prime} \times k<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">N<!-- --></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×<!-- --></span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8352em;vertical-align:-0.0833em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em">k<!-- --></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′<!-- --></span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×<!-- --></span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k<!-- --></span></span></span></span></span>번의 Training과 Evaluation이 필요한 것이다. 굉장히 비용이 커지기 때문에 대게 validation set까지 cross validation하는 nested cross validation은 상황에 따라 사용되기도 하고, 사용되지 않기도 한다.<!-- --></p>
<!-- --><h2 id="Combining-Simple-Models">Combining Simple Models<!-- --></h2>
<!-- --><p>좋은 Model을 만들 수 있는 방법 중에서 가장 쉽게 생각할 수 있는 것 중에 하나가 여러 개의 Model을 활용하는 방법이다. 쉽게 집단 지성을 활용한다고 볼 수 있다. 이러한 방식을 <!-- --><strong>Ensemble<!-- --></strong>(앙상블)이라고 부르고, 이를 활용할 수 있는 방법은 여러 가지가 있다.<!-- --></p>
<!-- --><ol>
<!-- --><li>서로 다른 여러 개의 Model, 또는 Hyperparameter만을 변경하거나 또는 feature를 다르게 변형하여 Model을 여러 개 생성하고 평균 또는 최댓값을 취하는 방법 (<!-- --><strong>Voting<!-- --></strong>)<!-- --></li>
<!-- --><li>여러 개의 Model을 혼합하지만, 각 단계에 따라서 Model을 선택하는 방법 (<!-- --><strong>Stacking<!-- --></strong>)<!-- --></li>
<!-- --><li>dataset을 여러 번 sampling하여 각 각의 Model을 만들고, 각 Model의 결과를 평균 또는 최댓값을 취하는 방법 (<!-- --><strong>Bagging<!-- --></strong>, <!-- --><strong>Pasting<!-- --></strong>)<!-- --></li>
<!-- --><li>이전과는 달리 앞 서 진행한 Model의 결과를 반영하여 다음 Model에 적용하기를 반복하며, 여러 Model을 제작하고 취합하는 방법 (<!-- --><strong>Boosting<!-- --></strong>)<!-- --></li>
<!-- --></ol>
<!-- --><p>크게는 이렇게 3가지로 나눌 수 있다. 여기서 각각을 자세히 다루지는 않고, <!-- --><strong>Boosting<!-- --></strong> 방식 중에서도 많이 사용되는 방법 중에 하나인 <!-- --><strong>AdaBoost<!-- --></strong>에 대해서 좀 더 자세히 다뤄보도록 하겠다.<!-- --></p>
<!-- --><h3>AdaBoost<!-- --></h3>
<!-- --><p>Adaptive Boosting의 약자인 AdaBoost는 이름에서 볼 수 있듯이 반복적인 작업을 통해서 최종 Model의 성능을 높이는 것을 목표로 한다. 우선 Boosting 방법 자체가 동시에 Model을 학습시키는 것이 아니고, 순차적으로 학습시키면서 성능을 높이는 방법이다. 그렇다면, 우리가 이전 Model들의 학습 과정에서 다음 Model에게 넘겨줄 수 있는 특별한 정보는 무엇일까? 이는 바로 자신들이 잘못 분류한 데이터에 대한 정보이다. 자신들이 잘못 분류한 data들에게 더 높은 가중치를 부여하도록 하여 다음 Model에서는 이를 중심적으로 분류할 수 있도록 하는 방식으로 최종 Model의 성능을 높여보자는 것이 Idea이다.<!-- --></p>
<!-- --><p>그렇다면, 이것이 어떻게 가능할까? 매우 간단한 이진 분류기를 기반으로 이를 설명하도록 하겠다. 우리가 만약 특정 임계값(<!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>θ<!-- --></mi><mi>t<!-- --></mi></msub></mrow><annotation encoding="application/x-tex">\theta_{t}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">θ<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>)보다 작으면 -1, 그렇지 않으면 1이라고 분류하는 아주 간단한 분류기(weak classifier, decision stump)를 가지고 있다고 하자.<!-- --></p>
<!-- --><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>f<!-- --></mi><mi>t<!-- --></mi></msub><mo stretchy="false">(<!-- --></mo><mi>x<!-- --></mi><mo stretchy="false">)<!-- --></mo><mo>=<!-- --></mo><mrow><mo fence="true">{<!-- --></mo><mtable rowspacing="0.36em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−<!-- --></mo><mn>1<!-- --></mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if <!-- --></mtext><mi>x<!-- --></mi><mo>&lt;<!-- --></mo><msub><mi>θ<!-- --></mi><mi>t<!-- --></mi></msub></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1<!-- --></mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mtext>otherwise<!-- --></mtext></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">f_{t}(x) = \begin{cases} -1 &amp; \text{if } x &lt; \theta_{t} \\ 1 &amp; \text{otherwise} \end{cases}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em">f<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(<!-- --></span><span class="mord mathnormal">x<!-- --></span><span class="mclose">)<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:3em;vertical-align:-1.25em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size4">{<!-- --></span></span><span class="mord"><span class="mtable"><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.69em"><span style="top:-3.69em"><span class="pstrut" style="height:3.008em"></span><span class="mord"><span class="mord">−<!-- --></span><span class="mord">1<!-- --></span></span></span><span style="top:-2.25em"><span class="pstrut" style="height:3.008em"></span><span class="mord"><span class="mord">1<!-- --></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:1.19em"><span></span></span></span></span></span><span class="arraycolsep" style="width:1em"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.69em"><span style="top:-3.69em"><span class="pstrut" style="height:3.008em"></span><span class="mord"><span class="mord text"><span class="mord">if <!-- --></span></span><span class="mord mathnormal">x<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&lt;<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">θ<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span><span style="top:-2.25em"><span class="pstrut" style="height:3.008em"></span><span class="mord"><span class="mord text"><span class="mord">otherwise<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:1.19em"><span></span></span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></div>
<!-- --><p>이제 우리는 이 간단한 분류기 T개를 합쳐서 복잡한 분류 문제를 해결할 분류기를 제작할 것이다. 이 때, 각 분류기는 다음과 같은 가중치(<!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α<!-- --></mi><mi>t<!-- --></mi></msub></mrow><annotation encoding="application/x-tex">\alpha_{t}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>)를 가지게 된다.<!-- --></p>
<!-- --><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right" columnspacing=""><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mtext>output<!-- --></mtext><mo>=<!-- --></mo><mtext>sign<!-- --></mtext><mo stretchy="false">(<!-- --></mo><msub><mi>F<!-- --></mi><mi>T<!-- --></mi></msub><mo stretchy="false">(<!-- --></mo><mi>x<!-- --></mi><mo stretchy="false">)<!-- --></mo><mo stretchy="false">)<!-- --></mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><msub><mi>F<!-- --></mi><mi>T<!-- --></mi></msub><mo stretchy="false">(<!-- --></mo><mi>x<!-- --></mi><mo stretchy="false">)<!-- --></mo><mo>=<!-- --></mo><munderover><mo>∑<!-- --></mo><mrow><mi>t<!-- --></mi><mo>=<!-- --></mo><mn>1<!-- --></mn></mrow><mi>T<!-- --></mi></munderover><msub><mi>α<!-- --></mi><mi>t<!-- --></mi></msub><msub><mi>f<!-- --></mi><mi>t<!-- --></mi></msub><mo stretchy="false">(<!-- --></mo><mi>x<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{align*}
\text{output} = \text{sign}(F_{T}(x)) \\
F_{T}(x) = \sum_{t=1}^{T} \alpha_{t} f_{t}(x)
\end{align*}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:4.8954em;vertical-align:-2.1977em"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.6977em"><span style="top:-5.6861em"><span class="pstrut" style="height:3.8283em"></span><span class="mord"><span class="mord text"><span class="mord">output<!-- --></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord text"><span class="mord">sign<!-- --></span></span><span class="mopen">(<!-- --></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">F<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(<!-- --></span><span class="mord mathnormal">x<!-- --></span><span class="mclose">))<!-- --></span></span></span><span style="top:-3.1977em"><span class="pstrut" style="height:3.8283em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">F<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(<!-- --></span><span class="mord mathnormal">x<!-- --></span><span class="mclose">)<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em"><span style="top:-1.8829em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span><span class="mrel mtight">=<!-- --></span><span class="mord mtight">1<!-- --></span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑<!-- --></span></span></span><span style="top:-4.3em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em">f<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(<!-- --></span><span class="mord mathnormal">x<!-- --></span><span class="mclose">)<!-- --></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:2.1977em"><span></span></span></span></span></span></span></span></span></span></span></span></div>
<!-- --><p>그렇다면, 우리는 위 식에서 어떻게 하면, 현명하게 <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>θ<!-- --></mi><mi>t<!-- --></mi></msub><mo separator="true">,<!-- --></mo><msub><mi>α<!-- --></mi><mi>t<!-- --></mi></msub></mrow><annotation encoding="application/x-tex">\theta_{t}, \alpha_{t}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">θ<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,<!-- --></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>를 결정할 수 있을까? 이에 대한 해답으로 <!-- --><strong>AdaBoost<!-- --></strong>는 이전 <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>F<!-- --></mi><mrow><mi>t<!-- --></mi><mo>−<!-- --></mo><mn>1<!-- --></mn></mrow></msub></mrow><annotation encoding="application/x-tex">F_{t-1}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8917em;vertical-align:-0.2083em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">F<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span><span class="mbin mtight">−<!-- --></span><span class="mord mtight">1<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span></span></span></span></span>에 의해 발생한 <!-- --><strong>error<!-- --></strong>에 집중한다.<!-- --></p>
<!-- --><p>우선 <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>F<!-- --></mi><mi>t<!-- --></mi></msub></mrow><annotation encoding="application/x-tex">F_{t}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">F<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>의 Error(<!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E<!-- --></mi><mo stretchy="false">(<!-- --></mo><msub><mi>F<!-- --></mi><mi>t<!-- --></mi></msub><mo stretchy="false">)<!-- --></mo></mrow><annotation encoding="application/x-tex">E(F_{t})<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.05764em">E<!-- --></span><span class="mopen">(<!-- --></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">F<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)<!-- --></span></span></span></span></span>)를 아래와 같다고 하자.<!-- --></p>
<!-- --><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>E<!-- --></mi><mo stretchy="false">(<!-- --></mo><msub><mi>F<!-- --></mi><mi>t<!-- --></mi></msub><mo stretchy="false">)<!-- --></mo><mo>=<!-- --></mo><munderover><mo>∑<!-- --></mo><mrow><mi>i<!-- --></mi><mo>=<!-- --></mo><mn>1<!-- --></mn></mrow><mi>N<!-- --></mi></munderover><mi>exp<!-- --></mi><mo>⁡<!-- --></mo><mo stretchy="false">(<!-- --></mo><mo>−<!-- --></mo><msup><mi>y<!-- --></mi><mrow><mo stretchy="false">(<!-- --></mo><mi>i<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></msup><msub><mi>F<!-- --></mi><mi>t<!-- --></mi></msub><mo stretchy="false">(<!-- --></mo><msup><mi>x<!-- --></mi><mrow><mo stretchy="false">(<!-- --></mo><mi>i<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></msup><mo stretchy="false">)<!-- --></mo><mo stretchy="false">)<!-- --></mo></mrow><annotation encoding="application/x-tex">E(F_{t}) = \sum_{i=1}^{N} \exp(-y^{(i)}F_{t}(x^{(i)}))<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.05764em">E<!-- --></span><span class="mopen">(<!-- --></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">F<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:3.106em;vertical-align:-1.2777em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em"><span style="top:-1.8723em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i<!-- --></span><span class="mrel mtight">=<!-- --></span><span class="mord mtight">1<!-- --></span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑<!-- --></span></span></span><span style="top:-4.3em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop">exp<!-- --></span><span class="mopen">(<!-- --></span><span class="mord">−<!-- --></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">y<!-- --></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mathnormal mtight">i<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">F<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(<!-- --></span><span class="mord"><span class="mord mathnormal">x<!-- --></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mathnormal mtight">i<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span></span></span></span></span><span class="mclose">))<!-- --></span></span></span></span></span></div>
<!-- --><p>즉, 예측이 맞다면 error는 <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1<!-- --></mn><mi>e<!-- --></mi></mfrac></mrow><annotation encoding="application/x-tex">1 \over e<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">e<!-- --></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>, 틀리다면 <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e<!-- --></mi></mrow><annotation encoding="application/x-tex">e<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">e<!-- --></span></span></span></span></span>만큼 error가 증가한다.<!-- --><br/>
여기서 우리는 현재 학습할 Model 이전까지의 Model의 하나의 데이터에 대한 Error를 <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>γ<!-- --></mi><mi>t<!-- --></mi><mrow><mo stretchy="false">(<!-- --></mo><mi>i<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></msubsup></mrow><annotation encoding="application/x-tex">\gamma_{t}^{(i)}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2906em;vertical-align:-0.2458em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em">γ<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em"><span style="top:-2.4542em;margin-left:-0.0556em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span><span style="top:-3.2198em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mathnormal mtight">i<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.2458em"><span></span></span></span></span></span></span></span></span></span></span>라고 정의해보자.<!-- --></p>
<!-- --><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi>γ<!-- --></mi><mi>t<!-- --></mi><mrow><mo stretchy="false">(<!-- --></mo><mi>i<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></msubsup><mo>=<!-- --></mo><mi>exp<!-- --></mi><mo>⁡<!-- --></mo><mo stretchy="false">(<!-- --></mo><mo>−<!-- --></mo><msup><mi>y<!-- --></mi><mrow><mo stretchy="false">(<!-- --></mo><mi>i<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></msup><msub><mi>F<!-- --></mi><mrow><mi>t<!-- --></mi><mo>−<!-- --></mo><mn>1<!-- --></mn></mrow></msub><mo stretchy="false">(<!-- --></mo><msup><mi>x<!-- --></mi><mrow><mo stretchy="false">(<!-- --></mo><mi>i<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></msup><mo stretchy="false">)<!-- --></mo><mo stretchy="false">)<!-- --></mo><mo separator="true">,<!-- --></mo><mspace width="1em"></mspace><msubsup><mi>γ<!-- --></mi><mn>1<!-- --></mn><mrow><mo stretchy="false">(<!-- --></mo><mi>i<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></msubsup><mo>=<!-- --></mo><mn>1<!-- --></mn></mrow><annotation encoding="application/x-tex">\gamma_{t}^{(i)} = \exp(-y^{(i)}F_{t-1}(x^{(i)})),\quad \gamma_{1}^{(i)} = 1<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2906em;vertical-align:-0.2458em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em">γ<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em"><span style="top:-2.4542em;margin-left:-0.0556em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span><span style="top:-3.2198em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mathnormal mtight">i<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.2458em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.3111em;vertical-align:-0.2663em"></span><span class="mop">exp<!-- --></span><span class="mopen">(<!-- --></span><span class="mord">−<!-- --></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">y<!-- --></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mathnormal mtight">i<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">F<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span><span class="mbin mtight">−<!-- --></span><span class="mord mtight">1<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span><span class="mopen">(<!-- --></span><span class="mord"><span class="mord mathnormal">x<!-- --></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mathnormal mtight">i<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span></span></span></span></span><span class="mclose">))<!-- --></span><span class="mpunct">,<!-- --></span><span class="mspace" style="margin-right:1em"></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em">γ<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em"><span style="top:-2.4337em;margin-left:-0.0556em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1<!-- --></span></span></span></span><span style="top:-3.2198em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mathnormal mtight">i<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.2663em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1<!-- --></span></span></span></span></span></div>
<!-- --><p>다시 한 번 <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>γ<!-- --></mi><mi>t<!-- --></mi><mrow><mo stretchy="false">(<!-- --></mo><mi>i<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></msubsup></mrow><annotation encoding="application/x-tex">\gamma_{t}^{(i)}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2906em;vertical-align:-0.2458em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em">γ<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em"><span style="top:-2.4542em;margin-left:-0.0556em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span><span style="top:-3.2198em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mathnormal mtight">i<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.2458em"><span></span></span></span></span></span></span></span></span></span></span>의 의미를 정의하면, 간단하게 이전까지의 Model의 합으로 만든 Model이 잘 분류했다면, <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e<!-- --></mi></mrow><annotation encoding="application/x-tex">e<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">e<!-- --></span></span></span></span></span> 그렇지 않다면, <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1<!-- --></mn><mi>e<!-- --></mi></mfrac></mrow><annotation encoding="application/x-tex">1 \over e<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">e<!-- --></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>가 된다.<!-- --></p>
<!-- --><p>그렇다면, 계속해서 Error 식을 정리해보자.<!-- --></p>
<!-- --><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>E<!-- --></mi><mo stretchy="false">(<!-- --></mo><msub><mi>F<!-- --></mi><mi>t<!-- --></mi></msub><mo stretchy="false">)<!-- --></mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=<!-- --></mo><munderover><mo>∑<!-- --></mo><mrow><mi>i<!-- --></mi><mo>=<!-- --></mo><mn>1<!-- --></mn></mrow><mi>N<!-- --></mi></munderover><mo stretchy="false">{<!-- --></mo><mi>exp<!-- --></mi><mo>⁡<!-- --></mo><mo stretchy="false">(<!-- --></mo><mo>−<!-- --></mo><msup><mi>y<!-- --></mi><mrow><mo stretchy="false">(<!-- --></mo><mi>i<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></msup><msub><mi>F<!-- --></mi><mrow><mi>t<!-- --></mi><mo>−<!-- --></mo><mn>1<!-- --></mn></mrow></msub><mo stretchy="false">(<!-- --></mo><msup><mi>x<!-- --></mi><mrow><mo stretchy="false">(<!-- --></mo><mi>i<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></msup><mo stretchy="false">)<!-- --></mo><mo stretchy="false">)<!-- --></mo><mo>×<!-- --></mo><mi>exp<!-- --></mi><mo>⁡<!-- --></mo><mo stretchy="false">(<!-- --></mo><mo>−<!-- --></mo><msup><mi>y<!-- --></mi><mrow><mo stretchy="false">(<!-- --></mo><mi>i<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></msup><msub><mi>α<!-- --></mi><mi>t<!-- --></mi></msub><msub><mi>f<!-- --></mi><mi>t<!-- --></mi></msub><mo stretchy="false">(<!-- --></mo><msup><mi>x<!-- --></mi><mrow><mo stretchy="false">(<!-- --></mo><mi>i<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></msup><mo stretchy="false">)<!-- --></mo><mo stretchy="false">)<!-- --></mo><mo stretchy="false">}<!-- --></mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=<!-- --></mo><munderover><mo>∑<!-- --></mo><mrow><mi>i<!-- --></mi><mo>=<!-- --></mo><mn>1<!-- --></mn></mrow><mi>N<!-- --></mi></munderover><msubsup><mi>γ<!-- --></mi><mi>t<!-- --></mi><mrow><mo stretchy="false">(<!-- --></mo><mi>i<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></msubsup><mi>exp<!-- --></mi><mo>⁡<!-- --></mo><mo stretchy="false">(<!-- --></mo><mo>−<!-- --></mo><msup><mi>y<!-- --></mi><mrow><mo stretchy="false">(<!-- --></mo><mi>i<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></msup><msub><mi>α<!-- --></mi><mi>t<!-- --></mi></msub><msub><mi>f<!-- --></mi><mi>t<!-- --></mi></msub><mo stretchy="false">(<!-- --></mo><msup><mi>x<!-- --></mi><mrow><mo stretchy="false">(<!-- --></mo><mi>i<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></msup><mo stretchy="false">)<!-- --></mo><mo stretchy="false">)<!-- --></mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=<!-- --></mo><munder><mo>∑<!-- --></mo><mrow><mi>i<!-- --></mi><mo>:<!-- --></mo><msup><mi>y<!-- --></mi><mrow><mo stretchy="false">(<!-- --></mo><mi>i<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></msup><mo>=<!-- --></mo><msub><mi>f<!-- --></mi><mi>t<!-- --></mi></msub><mo stretchy="false">(<!-- --></mo><msup><mi>x<!-- --></mi><mrow><mo stretchy="false">(<!-- --></mo><mi>i<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></msup><mo stretchy="false">)<!-- --></mo></mrow></munder><msubsup><mi>γ<!-- --></mi><mi>t<!-- --></mi><mrow><mo stretchy="false">(<!-- --></mo><mi>i<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></msubsup><mi>exp<!-- --></mi><mo>⁡<!-- --></mo><mo stretchy="false">(<!-- --></mo><mo>−<!-- --></mo><msub><mi>α<!-- --></mi><mi>t<!-- --></mi></msub><mo stretchy="false">)<!-- --></mo><mo>+<!-- --></mo><munder><mo>∑<!-- --></mo><mrow><mi>i<!-- --></mi><mo>:<!-- --></mo><msup><mi>y<!-- --></mi><mrow><mo stretchy="false">(<!-- --></mo><mi>i<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></msup><mo mathvariant="normal">≠<!-- --></mo><msub><mi>f<!-- --></mi><mi>t<!-- --></mi></msub><mo stretchy="false">(<!-- --></mo><msup><mi>x<!-- --></mi><mrow><mo stretchy="false">(<!-- --></mo><mi>i<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></msup><mo stretchy="false">)<!-- --></mo></mrow></munder><msubsup><mi>γ<!-- --></mi><mi>t<!-- --></mi><mrow><mo stretchy="false">(<!-- --></mo><mi>i<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></msubsup><mi>exp<!-- --></mi><mo>⁡<!-- --></mo><mo stretchy="false">(<!-- --></mo><msub><mi>α<!-- --></mi><mi>t<!-- --></mi></msub><mo stretchy="false">)<!-- --></mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=<!-- --></mo><munderover><mo>∑<!-- --></mo><mrow><mi>i<!-- --></mi><mo>=<!-- --></mo><mn>1<!-- --></mn></mrow><mi>N<!-- --></mi></munderover><msubsup><mi>γ<!-- --></mi><mi>t<!-- --></mi><mrow><mo stretchy="false">(<!-- --></mo><mi>i<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></msubsup><mi>exp<!-- --></mi><mo>⁡<!-- --></mo><mo stretchy="false">(<!-- --></mo><mo>−<!-- --></mo><msub><mi>α<!-- --></mi><mi>t<!-- --></mi></msub><mo stretchy="false">)<!-- --></mo><mo>+<!-- --></mo><munder><mo>∑<!-- --></mo><mrow><mi>i<!-- --></mi><mo>:<!-- --></mo><msup><mi>y<!-- --></mi><mrow><mo stretchy="false">(<!-- --></mo><mi>i<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></msup><mo mathvariant="normal">≠<!-- --></mo><msub><mi>f<!-- --></mi><mi>t<!-- --></mi></msub><mo stretchy="false">(<!-- --></mo><msup><mi>x<!-- --></mi><mrow><mo stretchy="false">(<!-- --></mo><mi>i<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></msup><mo stretchy="false">)<!-- --></mo></mrow></munder><msubsup><mi>γ<!-- --></mi><mi>t<!-- --></mi><mrow><mo stretchy="false">(<!-- --></mo><mi>i<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></msubsup><mo stretchy="false">(<!-- --></mo><mi>exp<!-- --></mi><mo>⁡<!-- --></mo><mo stretchy="false">(<!-- --></mo><msub><mi>α<!-- --></mi><mi>t<!-- --></mi></msub><mo stretchy="false">)<!-- --></mo><mo>−<!-- --></mo><mi>exp<!-- --></mi><mo>⁡<!-- --></mo><mo stretchy="false">(<!-- --></mo><mo>−<!-- --></mo><msub><mi>α<!-- --></mi><mi>t<!-- --></mi></msub><mo stretchy="false">)<!-- --></mo><mo stretchy="false">)<!-- --></mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=<!-- --></mo><mi>exp<!-- --></mi><mo>⁡<!-- --></mo><mo stretchy="false">(<!-- --></mo><mo>−<!-- --></mo><msub><mi>α<!-- --></mi><mi>t<!-- --></mi></msub><mo stretchy="false">)<!-- --></mo><munderover><mo>∑<!-- --></mo><mrow><mi>i<!-- --></mi><mo>=<!-- --></mo><mn>1<!-- --></mn></mrow><mi>N<!-- --></mi></munderover><msubsup><mi>γ<!-- --></mi><mi>t<!-- --></mi><mrow><mo stretchy="false">(<!-- --></mo><mi>i<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></msubsup><mo>+<!-- --></mo><mo stretchy="false">(<!-- --></mo><mi>exp<!-- --></mi><mo>⁡<!-- --></mo><mo stretchy="false">(<!-- --></mo><msub><mi>α<!-- --></mi><mi>t<!-- --></mi></msub><mo stretchy="false">)<!-- --></mo><mo>−<!-- --></mo><mi>exp<!-- --></mi><mo>⁡<!-- --></mo><mo stretchy="false">(<!-- --></mo><mo>−<!-- --></mo><msub><mi>α<!-- --></mi><mi>t<!-- --></mi></msub><mo stretchy="false">)<!-- --></mo><mo stretchy="false">)<!-- --></mo><munder><mo>∑<!-- --></mo><mrow><mi>i<!-- --></mi><mo>:<!-- --></mo><msup><mi>y<!-- --></mi><mrow><mo stretchy="false">(<!-- --></mo><mi>i<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></msup><mo mathvariant="normal">≠<!-- --></mo><msub><mi>f<!-- --></mi><mi>t<!-- --></mi></msub><mo stretchy="false">(<!-- --></mo><msup><mi>x<!-- --></mi><mrow><mo stretchy="false">(<!-- --></mo><mi>i<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></msup><mo stretchy="false">)<!-- --></mo></mrow></munder><msubsup><mi>γ<!-- --></mi><mi>t<!-- --></mi><mrow><mo stretchy="false">(<!-- --></mo><mi>i<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></msubsup></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{align*}
E(F_{t}) &amp;= \sum_{i=1}^{N}\{\exp(-y^{(i)}F_{t-1}(x^{(i)})) \times \exp(-y^{(i)}\alpha_{t}f_{t}(x^{(i)}))\} \\
&amp;= \sum_{i=1}^{N} \gamma_{t}^{(i)} \exp(-y^{(i)}\alpha_{t}f_{t}(x^{(i)})) \\
&amp;= \sum_{i:y^{(i)}=f_{t}(x^{(i)})}\gamma_{t}^{(i)}\exp(-\alpha_{t}) + \sum_{i:y^{(i)}\neq f_{t}(x^{(i)})}\gamma_{t}^{(i)}\exp(\alpha_{t}) \\
&amp;= \sum_{i=1}^{N}\gamma_{t}^{(i)}\exp(-\alpha_{t}) + \sum_{i:y^{(i)}\neq f_{t}(x^{(i)})}\gamma_{t}^{(i)}(\exp(\alpha_{t})-\exp(-\alpha_{t})) \\
&amp;= \exp(-\alpha_{t})\sum_{i=1}^{N}\gamma_{t}^{(i)} + (\exp(\alpha_{t})-\exp(-\alpha_{t}))\sum_{i:y^{(i)}\neq f_{t}(x^{(i)})}\gamma_{t}^{(i)}
\end{align*}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:17.118em;vertical-align:-8.309em"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:8.809em"><span style="top:-10.809em"><span class="pstrut" style="height:3.8283em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">E<!-- --></span><span class="mopen">(<!-- --></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">F<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)<!-- --></span></span></span><span style="top:-7.403em"><span class="pstrut" style="height:3.8283em"></span><span class="mord"></span></span><span style="top:-4.7753em"><span class="pstrut" style="height:3.8283em"></span><span class="mord"></span></span><span style="top:-1.0805em"><span class="pstrut" style="height:3.8283em"></span><span class="mord"></span></span><span style="top:2.6142em"><span class="pstrut" style="height:3.8283em"></span><span class="mord"></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:8.309em"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:8.809em"><span style="top:-10.809em"><span class="pstrut" style="height:3.8283em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em"><span style="top:-1.8723em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i<!-- --></span><span class="mrel mtight">=<!-- --></span><span class="mord mtight">1<!-- --></span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑<!-- --></span></span></span><span style="top:-4.3em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em"><span></span></span></span></span></span><span class="mopen">{<!-- --></span><span class="mop">exp<!-- --></span><span class="mopen">(<!-- --></span><span class="mord">−<!-- --></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">y<!-- --></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mathnormal mtight">i<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">F<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span><span class="mbin mtight">−<!-- --></span><span class="mord mtight">1<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span><span class="mopen">(<!-- --></span><span class="mord"><span class="mord mathnormal">x<!-- --></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mathnormal mtight">i<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span></span></span></span></span><span class="mclose">))<!-- --></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×<!-- --></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mop">exp<!-- --></span><span class="mopen">(<!-- --></span><span class="mord">−<!-- --></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">y<!-- --></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mathnormal mtight">i<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em">f<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(<!-- --></span><span class="mord"><span class="mord mathnormal">x<!-- --></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mathnormal mtight">i<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span></span></span></span></span><span class="mclose">))}<!-- --></span></span></span><span style="top:-7.403em"><span class="pstrut" style="height:3.8283em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em"><span style="top:-1.8723em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i<!-- --></span><span class="mrel mtight">=<!-- --></span><span class="mord mtight">1<!-- --></span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑<!-- --></span></span></span><span style="top:-4.3em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em">γ<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em"><span style="top:-2.4542em;margin-left:-0.0556em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span><span style="top:-3.2198em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mathnormal mtight">i<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.2458em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop">exp<!-- --></span><span class="mopen">(<!-- --></span><span class="mord">−<!-- --></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">y<!-- --></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mathnormal mtight">i<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em">f<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(<!-- --></span><span class="mord"><span class="mord mathnormal">x<!-- --></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mathnormal mtight">i<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span></span></span></span></span><span class="mclose">))<!-- --></span></span></span><span style="top:-4.7753em"><span class="pstrut" style="height:3.8283em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em"><span style="top:-1.7586em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i<!-- --></span><span class="mrel mtight">:<!-- --></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">y<!-- --></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.822em"><span style="top:-2.822em;margin-right:0.0714em"><span class="pstrut" style="height:2.5357em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mathnormal mtight">i<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span></span></span></span></span><span class="mrel mtight">=<!-- --></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em">f<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2963em"><span style="top:-2.357em;margin-left:-0.1076em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span><span class="mopen mtight">(<!-- --></span><span class="mord mtight"><span class="mord mathnormal mtight">x<!-- --></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.822em"><span style="top:-2.822em;margin-right:0.0714em"><span class="pstrut" style="height:2.5357em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mathnormal mtight">i<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span></span></span></span></span><span class="mclose mtight">)<!-- --></span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑<!-- --></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:1.5664em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em">γ<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em"><span style="top:-2.4542em;margin-left:-0.0556em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span><span style="top:-3.2198em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mathnormal mtight">i<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.2458em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop">exp<!-- --></span><span class="mopen">(<!-- --></span><span class="mord">−<!-- --></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)<!-- --></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+<!-- --></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em"><span style="top:-1.7586em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i<!-- --></span><span class="mrel mtight">:<!-- --></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">y<!-- --></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.822em"><span style="top:-2.822em;margin-right:0.0714em"><span class="pstrut" style="height:2.5357em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mathnormal mtight">i<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span></span></span></span></span><span class="mrel mtight"><span class="mrel mtight"><span class="mord vbox mtight"><span class="thinbox mtight"><span class="rlap mtight"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="inner"><span class="mord mtight"><span class="mrel mtight"><!-- --></span></span></span><span class="fix"></span></span></span></span></span><span class="mrel mtight">=<!-- --></span></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em">f<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2963em"><span style="top:-2.357em;margin-left:-0.1076em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span><span class="mopen mtight">(<!-- --></span><span class="mord mtight"><span class="mord mathnormal mtight">x<!-- --></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.822em"><span style="top:-2.822em;margin-right:0.0714em"><span class="pstrut" style="height:2.5357em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mathnormal mtight">i<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span></span></span></span></span><span class="mclose mtight">)<!-- --></span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑<!-- --></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:1.5664em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em">γ<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em"><span style="top:-2.4542em;margin-left:-0.0556em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span><span style="top:-3.2198em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mathnormal mtight">i<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.2458em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop">exp<!-- --></span><span class="mopen">(<!-- --></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)<!-- --></span></span></span><span style="top:-1.0805em"><span class="pstrut" style="height:3.8283em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em"><span style="top:-1.8723em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i<!-- --></span><span class="mrel mtight">=<!-- --></span><span class="mord mtight">1<!-- --></span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑<!-- --></span></span></span><span style="top:-4.3em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em">γ<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em"><span style="top:-2.4542em;margin-left:-0.0556em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span><span style="top:-3.2198em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mathnormal mtight">i<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.2458em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop">exp<!-- --></span><span class="mopen">(<!-- --></span><span class="mord">−<!-- --></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)<!-- --></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+<!-- --></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em"><span style="top:-1.7586em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i<!-- --></span><span class="mrel mtight">:<!-- --></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">y<!-- --></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.822em"><span style="top:-2.822em;margin-right:0.0714em"><span class="pstrut" style="height:2.5357em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mathnormal mtight">i<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span></span></span></span></span><span class="mrel mtight"><span class="mrel mtight"><span class="mord vbox mtight"><span class="thinbox mtight"><span class="rlap mtight"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="inner"><span class="mord mtight"><span class="mrel mtight"><!-- --></span></span></span><span class="fix"></span></span></span></span></span><span class="mrel mtight">=<!-- --></span></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em">f<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2963em"><span style="top:-2.357em;margin-left:-0.1076em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span><span class="mopen mtight">(<!-- --></span><span class="mord mtight"><span class="mord mathnormal mtight">x<!-- --></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.822em"><span style="top:-2.822em;margin-right:0.0714em"><span class="pstrut" style="height:2.5357em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mathnormal mtight">i<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span></span></span></span></span><span class="mclose mtight">)<!-- --></span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑<!-- --></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:1.5664em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em">γ<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em"><span style="top:-2.4542em;margin-left:-0.0556em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span><span style="top:-3.2198em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mathnormal mtight">i<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.2458em"><span></span></span></span></span></span></span><span class="mopen">(<!-- --></span><span class="mop">exp<!-- --></span><span class="mopen">(<!-- --></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)<!-- --></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−<!-- --></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mop">exp<!-- --></span><span class="mopen">(<!-- --></span><span class="mord">−<!-- --></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">))<!-- --></span></span></span><span style="top:2.6142em"><span class="pstrut" style="height:3.8283em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mop">exp<!-- --></span><span class="mopen">(<!-- --></span><span class="mord">−<!-- --></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)<!-- --></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em"><span style="top:-1.8723em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i<!-- --></span><span class="mrel mtight">=<!-- --></span><span class="mord mtight">1<!-- --></span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑<!-- --></span></span></span><span style="top:-4.3em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em">γ<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em"><span style="top:-2.4542em;margin-left:-0.0556em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span><span style="top:-3.2198em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mathnormal mtight">i<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.2458em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+<!-- --></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mopen">(<!-- --></span><span class="mop">exp<!-- --></span><span class="mopen">(<!-- --></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)<!-- --></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−<!-- --></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mop">exp<!-- --></span><span class="mopen">(<!-- --></span><span class="mord">−<!-- --></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">))<!-- --></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em"><span style="top:-1.7586em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i<!-- --></span><span class="mrel mtight">:<!-- --></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">y<!-- --></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.822em"><span style="top:-2.822em;margin-right:0.0714em"><span class="pstrut" style="height:2.5357em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mathnormal mtight">i<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span></span></span></span></span><span class="mrel mtight"><span class="mrel mtight"><span class="mord vbox mtight"><span class="thinbox mtight"><span class="rlap mtight"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="inner"><span class="mord mtight"><span class="mrel mtight"><!-- --></span></span></span><span class="fix"></span></span></span></span></span><span class="mrel mtight">=<!-- --></span></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em">f<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2963em"><span style="top:-2.357em;margin-left:-0.1076em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span><span class="mopen mtight">(<!-- --></span><span class="mord mtight"><span class="mord mathnormal mtight">x<!-- --></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.822em"><span style="top:-2.822em;margin-right:0.0714em"><span class="pstrut" style="height:2.5357em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mathnormal mtight">i<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span></span></span></span></span><span class="mclose mtight">)<!-- --></span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑<!-- --></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:1.5664em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em">γ<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em"><span style="top:-2.4542em;margin-left:-0.0556em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span><span style="top:-3.2198em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mathnormal mtight">i<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.2458em"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:8.309em"><span></span></span></span></span></span></span></span></span></span></span></span></div>
<!-- --><p>여기서 Error를 가장 작게 할 수 있는 <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>θ<!-- --></mi><mi>t<!-- --></mi></msub><mo separator="true">,<!-- --></mo><msub><mi>α<!-- --></mi><mi>t<!-- --></mi></msub></mrow><annotation encoding="application/x-tex">\theta_{t}, \alpha_{t}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">θ<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,<!-- --></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>를 찾기 위한 방법은 각 각 다음과 같다.<!-- --></p>
<!-- --><ol>
<!-- --><li>식에서 <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>θ<!-- --></mi><mi>t<!-- --></mi></msub></mrow><annotation encoding="application/x-tex">\theta_{t}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">θ<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>가 바꿀 수 있는 것은 <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f<!-- --></mi><mi>t<!-- --></mi></msub></mrow><annotation encoding="application/x-tex">f_{t}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em">f<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>밖에 없다. 즉 <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mo>∑<!-- --></mo><mrow><mi>i<!-- --></mi><mo>:<!-- --></mo><msup><mi>y<!-- --></mi><mrow><mo stretchy="false">(<!-- --></mo><mi>i<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></msup><mo mathvariant="normal">≠<!-- --></mo><msub><mi>f<!-- --></mi><mi>t<!-- --></mi></msub><mo stretchy="false">(<!-- --></mo><msup><mi>x<!-- --></mi><mrow><mo stretchy="false">(<!-- --></mo><mi>i<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></msup><mo stretchy="false">)<!-- --></mo></mrow></msub><msubsup><mi>γ<!-- --></mi><mi>t<!-- --></mi><mrow><mo stretchy="false">(<!-- --></mo><mi>i<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></msubsup></mrow><annotation encoding="application/x-tex">\sum_{i:y^{(i)}\neq f_{t}(x^{(i)})}\gamma_{t}^{(i)}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.5195em;vertical-align:-0.4747em"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em">∑<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2757em"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i<!-- --></span><span class="mrel mtight">:<!-- --></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">y<!-- --></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.822em"><span style="top:-2.822em;margin-right:0.0714em"><span class="pstrut" style="height:2.5357em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mathnormal mtight">i<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span></span></span></span></span><span class="mrel mtight"><span class="mrel mtight"><span class="mord vbox mtight"><span class="thinbox mtight"><span class="rlap mtight"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="inner"><span class="mord mtight"><span class="mrel mtight"><!-- --></span></span></span><span class="fix"></span></span></span></span></span><span class="mrel mtight">=<!-- --></span></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em">f<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2963em"><span style="top:-2.357em;margin-left:-0.1076em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span><span class="mopen mtight">(<!-- --></span><span class="mord mtight"><span class="mord mathnormal mtight">x<!-- --></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.822em"><span style="top:-2.822em;margin-right:0.0714em"><span class="pstrut" style="height:2.5357em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mathnormal mtight">i<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span></span></span></span></span><span class="mclose mtight">)<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.4747em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em">γ<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em"><span style="top:-2.4542em;margin-left:-0.0556em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span><span style="top:-3.2198em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mathnormal mtight">i<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.2458em"><span></span></span></span></span></span></span></span></span></span></span>를 조정하는 것이다.<!-- --><br/>
즉, <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>γ<!-- --></mi><mi>t<!-- --></mi><mrow><mo stretchy="false">(<!-- --></mo><mi>i<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></msubsup></mrow><annotation encoding="application/x-tex">\gamma_{t}^{(i)}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2906em;vertical-align:-0.2458em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em">γ<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em"><span style="top:-2.4542em;margin-left:-0.0556em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span><span style="top:-3.2198em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mathnormal mtight">i<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.2458em"><span></span></span></span></span></span></span></span></span></span></span>는 이전 분류기(<!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>F<!-- --></mi><mrow><mi>t<!-- --></mi><mo>−<!-- --></mo><mn>1<!-- --></mn></mrow></msub></mrow><annotation encoding="application/x-tex">F_{t-1}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8917em;vertical-align:-0.2083em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">F<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span><span class="mbin mtight">−<!-- --></span><span class="mord mtight">1<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span></span></span></span></span>)가 잘 분류했다면 <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e<!-- --></mi></mrow><annotation encoding="application/x-tex">e<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">e<!-- --></span></span></span></span></span>, 그렇지 않다면 <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1<!-- --></mn><mi>e<!-- --></mi></mfrac></mrow><annotation encoding="application/x-tex">1 \over e<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">e<!-- --></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>가 되는데, 이들의 합이 최소가 되도록 하는 임계값 <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>θ<!-- --></mi><mi>t<!-- --></mi></msub></mrow><annotation encoding="application/x-tex">\theta_{t}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">θ<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>를 찾는 것이다.<!-- --><br/>
즉, 기존 분류기가 잘못 분류한 data에 대해서 더 중점적으로 분류할 수 있도록 가중치를 부여하여 다시 분류한다는 것이다.<!-- --></li>
<!-- --><li>Error를 <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α<!-- --></mi><mi>t<!-- --></mi></msub></mrow><annotation encoding="application/x-tex">\alpha_{t}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>에 대한 미분을 하여, 0이 되도록 하는 <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α<!-- --></mi><mi>t<!-- --></mi></msub></mrow><annotation encoding="application/x-tex">\alpha_{t}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>를 찾으면 된다. 이 과정은 다음과 같다.<!-- --></li>
<!-- --></ol>
<!-- --><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>α<!-- --></mi><mi>t<!-- --></mi></msub><mo>=<!-- --></mo><mfrac><mn>1<!-- --></mn><mn>2<!-- --></mn></mfrac><mi>ln<!-- --></mi><mo>⁡<!-- --></mo><mfrac><mrow><mn>1<!-- --></mn><mo>−<!-- --></mo><msub><mi>ε<!-- --></mi><mi>t<!-- --></mi></msub></mrow><msub><mi>ε<!-- --></mi><mi>t<!-- --></mi></msub></mfrac><mo separator="true">,<!-- --></mo><mspace width="1em"></mspace><msub><mi>ε<!-- --></mi><mi>t<!-- --></mi></msub><mo>=<!-- --></mo><mfrac><mrow><munder><mo>∑<!-- --></mo><mrow><mi>i<!-- --></mi><mo>:<!-- --></mo><msup><mi>y<!-- --></mi><mrow><mo stretchy="false">(<!-- --></mo><mi>i<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></msup><mo mathvariant="normal">≠<!-- --></mo><msub><mi>f<!-- --></mi><mi>t<!-- --></mi></msub><mo stretchy="false">(<!-- --></mo><msup><mi>x<!-- --></mi><mrow><mo stretchy="false">(<!-- --></mo><mi>i<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></msup><mo stretchy="false">)<!-- --></mo></mrow></munder><msubsup><mi>γ<!-- --></mi><mi>t<!-- --></mi><mrow><mo stretchy="false">(<!-- --></mo><mi>i<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></msubsup></mrow><mrow><munderover><mo>∑<!-- --></mo><mi>i<!-- --></mi><mi>N<!-- --></mi></munderover><msubsup><mi>γ<!-- --></mi><mi>t<!-- --></mi><mrow><mo stretchy="false">(<!-- --></mo><mi>i<!-- --></mi><mo stretchy="false">)<!-- --></mo></mrow></msubsup></mrow></mfrac></mrow><annotation encoding="application/x-tex">\alpha_{t} = \frac{1}{2}\ln\frac{1-\varepsilon_{t}}{\varepsilon_{t}},\quad \varepsilon_{t} = \frac{\sum_{i:y^{(i)}\neq f_{t}(x^{(i)})}\gamma_{t}^{(i)}}{\sum_{i}^{N}\gamma_{t}^{(i)}}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:2.1574em;vertical-align:-0.836em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">2<!-- --></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1<!-- --></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop">ln<!-- --></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">ε<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1<!-- --></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−<!-- --></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord"><span class="mord mathnormal">ε<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.836em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mpunct">,<!-- --></span><span class="mspace" style="margin-right:1em"></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">ε<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:3.144em;vertical-align:-1.2345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.9095em"><span style="top:-2.11em"><span class="pstrut" style="height:3.0448em"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em">∑<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i<!-- --></span></span></span></span><span style="top:-3.2029em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em">γ<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em"><span style="top:-2.4542em;margin-left:-0.0556em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span><span style="top:-3.2198em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mathnormal mtight">i<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.2458em"><span></span></span></span></span></span></span></span></span><span style="top:-3.2748em"><span class="pstrut" style="height:3.0448em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.9095em"><span class="pstrut" style="height:3.0448em"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em">∑<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2757em"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i<!-- --></span><span class="mrel mtight">:<!-- --></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">y<!-- --></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.822em"><span style="top:-2.822em;margin-right:0.0714em"><span class="pstrut" style="height:2.5357em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mathnormal mtight">i<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span></span></span></span></span><span class="mrel mtight"><span class="mrel mtight"><span class="mord vbox mtight"><span class="thinbox mtight"><span class="rlap mtight"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="inner"><span class="mord mtight"><span class="mrel mtight"><!-- --></span></span></span><span class="fix"></span></span></span></span></span><span class="mrel mtight">=<!-- --></span></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em">f<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2963em"><span style="top:-2.357em;margin-left:-0.1076em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span><span class="mopen mtight">(<!-- --></span><span class="mord mtight"><span class="mord mathnormal mtight">x<!-- --></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.822em"><span style="top:-2.822em;margin-right:0.0714em"><span class="pstrut" style="height:2.5357em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mathnormal mtight">i<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span></span></span></span></span><span class="mclose mtight">)<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.4747em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em">γ<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em"><span style="top:-2.4542em;margin-left:-0.0556em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span><span style="top:-3.2198em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(<!-- --></span><span class="mord mathnormal mtight">i<!-- --></span><span class="mclose mtight">)<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.2458em"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:1.2345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></div>
<!-- --><p>여기서 <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ε<!-- --></mi><mi>t<!-- --></mi></msub></mrow><annotation encoding="application/x-tex">\varepsilon_{t}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">ε<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>를 자세히 보면, 분모는 decision stump의 최대 Error이고 분자는 현재 decision stump의 Error를 의미한다. 이것이 직접적으로 <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α<!-- --></mi><mi>t<!-- --></mi></msub></mrow><annotation encoding="application/x-tex">\alpha_{t}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>에 영향을 미치는 것이다.<!-- --></p>
<!-- --><p>따라서 이르 조금 더 정리하자면 다음과 같다.<!-- --></p>
<!-- --><ol>
<!-- --><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ε<!-- --></mi><mi>t<!-- --></mi></msub><mo>&gt;<!-- --></mo><mfrac><mn>1<!-- --></mn><mn>2<!-- --></mn></mfrac><mo>⇒<!-- --></mo><msub><mi>α<!-- --></mi><mi>t<!-- --></mi></msub><mo>&lt;<!-- --></mo><mn>0<!-- --></mn></mrow><annotation encoding="application/x-tex">\varepsilon_{t} \gt \frac{1}{2} \rArr \alpha_{t} \lt 0<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6891em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">ε<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&gt;<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2<!-- --></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">⇒<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6891em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&lt;<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0<!-- --></span></span></span></span></span><br/>
<!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ε<!-- --></mi><mi>t<!-- --></mi></msub><mo>&gt;<!-- --></mo><mfrac><mn>1<!-- --></mn><mn>2<!-- --></mn></mfrac></mrow><annotation encoding="application/x-tex">\varepsilon_{t} \gt \frac{1}{2}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6891em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">ε<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&gt;<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2<!-- --></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>라는 것은 사실 <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f<!-- --></mi><mi>t<!-- --></mi></msub></mrow><annotation encoding="application/x-tex">f_{t}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em">f<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>의 성능이 선택지 두 개지 하나를 Random하게 고르는 경우의 확률 <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1<!-- --></mn><mn>2<!-- --></mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{2}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2<!-- --></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>보다 못하다는 것이다. 이 경우에 <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α<!-- --></mi><mi>t<!-- --></mi></msub></mrow><annotation encoding="application/x-tex">\alpha_{t}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>를 음수로 설정하여 적용하는 것이 반대로 확률을 적용하는 것이고, 이것이 전체 성능을 높일 수 있기에 타당하다.<!-- --></li>
<!-- --><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ε<!-- --></mi><mi>t<!-- --></mi></msub><mo>=<!-- --></mo><mfrac><mn>1<!-- --></mn><mn>2<!-- --></mn></mfrac><mo>⇒<!-- --></mo><msub><mi>α<!-- --></mi><mi>t<!-- --></mi></msub><mo>=<!-- --></mo><mn>0<!-- --></mn></mrow><annotation encoding="application/x-tex">\varepsilon_{t} = \frac{1}{2} \rArr \alpha_{t} = 0<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">ε<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2<!-- --></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">⇒<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0<!-- --></span></span></span></span></span><br/>
만약, 성능이 딱 <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1<!-- --></mn><mn>2<!-- --></mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{2}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2<!-- --></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>라면, 더 이상 개선의 여지가 없어진다. 즉, <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α<!-- --></mi><mi>t<!-- --></mi></msub></mrow><annotation encoding="application/x-tex">\alpha_{t}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>를 0으로 설정하여 적용하게 되면, <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>F<!-- --></mi><mi>t<!-- --></mi></msub><mo>=<!-- --></mo><msub><mi>F<!-- --></mi><mrow><mi>t<!-- --></mi><mo>−<!-- --></mo><mn>1<!-- --></mn></mrow></msub></mrow><annotation encoding="application/x-tex">F_{t}=F_{t-1}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">F<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8917em;vertical-align:-0.2083em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">F<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span><span class="mbin mtight">−<!-- --></span><span class="mord mtight">1<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span></span></span></span></span>이 된다. 즉, 더 이상의 Model 중첩은 무의미하다는 것을 의미하므로 해당 단계에 도달하면 학습을 중단한다.<!-- --></li>
<!-- --><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0<!-- --></mn><mo>&lt;<!-- --></mo><msub><mi>ε<!-- --></mi><mi>t<!-- --></mi></msub><mo>&lt;<!-- --></mo><mfrac><mn>1<!-- --></mn><mn>2<!-- --></mn></mfrac><mo>⇒<!-- --></mo><msub><mi>α<!-- --></mi><mi>t<!-- --></mi></msub><mo>&gt;<!-- --></mo><mn>0<!-- --></mn></mrow><annotation encoding="application/x-tex">0 \lt \varepsilon_{t} \lt \frac{1}{2} \rArr \alpha_{t} \gt 0<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6835em;vertical-align:-0.0391em"></span><span class="mord">0<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&lt;<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6891em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">ε<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&lt;<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2<!-- --></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">⇒<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6891em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&gt;<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0<!-- --></span></span></span></span></span><br/>
일반적인 경우로, 새롭게 만든 분류기가 기존 분류기(<!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>F<!-- --></mi><mrow><mi>t<!-- --></mi><mo>−<!-- --></mo><mn>1<!-- --></mn></mrow></msub></mrow><annotation encoding="application/x-tex">F_{t-1}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8917em;vertical-align:-0.2083em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">F<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span><span class="mbin mtight">−<!-- --></span><span class="mord mtight">1<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span></span></span></span></span>)를 보완할 만큼 잘 예측을 하고 있기에 <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α<!-- --></mi><mi>t<!-- --></mi></msub></mrow><annotation encoding="application/x-tex">\alpha_{t}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>를 양수로 설정하여 적용한다.<!-- --></li>
<!-- --><li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ε<!-- --></mi><mi>t<!-- --></mi></msub><mo>→<!-- --></mo><mn>0<!-- --></mn><mo>⇒<!-- --></mo><mi>α<!-- --></mi><mo>→<!-- --></mo><mi mathvariant="normal">∞<!-- --></mi></mrow><annotation encoding="application/x-tex">\varepsilon_{t} \rarr 0 \rArr \alpha \rarr \infin<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">ε<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">→<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">⇒<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">→<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord">∞<!-- --></span></span></span></span></span><br/>
<!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ε<!-- --></mi><mi>t<!-- --></mi></msub></mrow><annotation encoding="application/x-tex">\varepsilon_{t}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">ε<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>가 0에 가까워지면, 즉, <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f<!-- --></mi><mi>t<!-- --></mi></msub></mrow><annotation encoding="application/x-tex">f_{t}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em">f<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>가 모든 data를 정확하게 분류한다면, 사실상 기존 분류기들은 더 이상 의미가 없다. 하나의 <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d<!-- --></mi><mi>e<!-- --></mi><mi>c<!-- --></mi><mi>i<!-- --></mi><mi>s<!-- --></mi><mi>i<!-- --></mi><mi>o<!-- --></mi><mi>n<!-- --></mi><mi>s<!-- --></mi><mi>t<!-- --></mi><mi>u<!-- --></mi><mi>m<!-- --></mi><mi>p<!-- --></mi></mrow><annotation encoding="application/x-tex">decision stump<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal">d<!-- --></span><span class="mord mathnormal">ec<!-- --></span><span class="mord mathnormal">i<!-- --></span><span class="mord mathnormal">s<!-- --></span><span class="mord mathnormal">i<!-- --></span><span class="mord mathnormal">o<!-- --></span><span class="mord mathnormal">n<!-- --></span><span class="mord mathnormal">s<!-- --></span><span class="mord mathnormal">t<!-- --></span><span class="mord mathnormal">u<!-- --></span><span class="mord mathnormal">m<!-- --></span><span class="mord mathnormal">p<!-- --></span></span></span></span></span>로 완벽하게 분류되는 문제였기 때문이다. 즉, <!-- --><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>F<!-- --></mi><mi>t<!-- --></mi></msub><mo>=<!-- --></mo><msub><mi>f<!-- --></mi><mi>t<!-- --></mi></msub></mrow><annotation encoding="application/x-tex">F_{t} = f_{t}<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">F<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em">f<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>가 된다.<!-- --></li>
<!-- --></ol>
<!-- --><h3>Decision Tree<!-- --></h3>
<!-- --><p>앞 선 <!-- --><strong>AdaBoost<!-- --></strong>에서는 Decision Stump를 다루었지만, 더 다양한 분류기를 이용해서 Decision Tree를 구성하는 것도 가능하다. 실제 Stacking 또는 Bagging 등의 작업을 할 때에는 단순한 Decision Stump의 합 같은 형태가 아니라 Tree형태로 구성되는 경우가 많다(Decision을 할 때마다 가지치기를 하며 나뉘는 형태). 그리고 실제로도 이 형태가 인간의 사고 과정도 매우 유사하다. 따라서, 대게의 경우 성능도 좋은 뿐만 아니라 직관적이기 때문에 이러한 방식을 사용해서 여러 Model을 혼합하는 경우도 있다. 이 안에서 Decision을 수행할 때 복잡한 Deep Learning을 수행할 수도 있고, 단순하게 Decision Stump를 사용할 수도 있는 것이다.<!-- --></p>
<!-- --><p><img src="/images/ml-decision-tree.png" alt="ml-decision-tree"/></p>
<!-- --><p>그렇다면, 이러한 Decision Tree를 어떻게 학습하는 게 좋을지를 조금만 살펴보도록 하겠다. 가정을 하나 해보자. 우리가 분류하고자 하는 Category가 10개이고, feature가 100개이다. 이때, 어떤 Feature를 이용한 어떤 Model을 사용한 것을 우선으로 적용해야할까? 이것이 사실 가장 중요한 문제이다. 이를 해결하기 위해서 여러 알고리즘(ID3, CART, 등)이 제시되었다. 하지만, 결국 핵심은 각 각의 단계에서 데이터를 가장 적절하게 나누는 것이 중요한 것이다. 따라서, Model(f)에 대해서 <!-- --><mark><strong>얻을 수 있는 정보의 양<!-- --></strong>(<!-- --><strong>IG<!-- --></strong>, Information Gain)<!-- --></mark>이 많을 수록 좋은 Model이라고 칭하는 것이다. 이를 식으로 표현하면 다음과 같다.<!-- --></p>
<!-- --><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>I<!-- --></mi><mi>G<!-- --></mi><mo stretchy="false">(<!-- --></mo><mi mathvariant="script">D<!-- --></mi><mo separator="true">,<!-- --></mo><mi>f<!-- --></mi><mo stretchy="false">)<!-- --></mo><mo>=<!-- --></mo><mi>I<!-- --></mi><mo stretchy="false">(<!-- --></mo><mi mathvariant="script">D<!-- --></mi><mo stretchy="false">)<!-- --></mo><mo>−<!-- --></mo><munderover><mo>∑<!-- --></mo><mrow><mi>j<!-- --></mi><mo>=<!-- --></mo><mn>1<!-- --></mn></mrow><mi>J<!-- --></mi></munderover><mfrac><msub><mi>D<!-- --></mi><mi>j<!-- --></mi></msub><mi>D<!-- --></mi></mfrac><mi>I<!-- --></mi><mo stretchy="false">(<!-- --></mo><msub><mi mathvariant="script">D<!-- --></mi><mi>j<!-- --></mi></msub><mo stretchy="false">)<!-- --></mo></mrow><annotation encoding="application/x-tex">IG(\mathcal{D}, f) = I(\mathcal{D}) - \sum_{j=1}^{J} \frac{D_{j}}{D}I(\mathcal{D}_{j})<!-- --></annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.07847em">I<!-- --></span><span class="mord mathnormal">G<!-- --></span><span class="mopen">(<!-- --></span><span class="mord mathcal" style="margin-right:0.02778em">D<!-- --></span><span class="mpunct">,<!-- --></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.10764em">f<!-- --></span><span class="mclose">)<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=<!-- --></span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.07847em">I<!-- --></span><span class="mopen">(<!-- --></span><span class="mord mathcal" style="margin-right:0.02778em">D<!-- --></span><span class="mclose">)<!-- --></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−<!-- --></span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:3.2421em;vertical-align:-1.4138em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em"><span style="top:-1.8723em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j<!-- --></span><span class="mrel mtight">=<!-- --></span><span class="mord mtight">1<!-- --></span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑<!-- --></span></span></span><span style="top:-4.3em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em">J<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:1.4138em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3603em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">D<!-- --></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">D<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathnormal" style="margin-right:0.07847em">I<!-- --></span><span class="mopen">(<!-- --></span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em">D<!-- --></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j<!-- --></span></span></span></span></span><span class="vlist-s">​<!-- --></span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mclose">)<!-- --></span></span></span></span></span></div>
<!-- --><p>여기서, 또 그렇다면, I는 무엇인지 궁금할 수 있다. 이는 Impurity(정보의 혼탁도)를 의미하며, 이를 표현하는 지표는 아래와 같은 것들이 있다.<!-- --></p>
<!-- --><ol>
<!-- --><li>Gini Impurity<!-- --></li>
<!-- --><li>Entropy<!-- --></li>
<!-- --><li>Classification Error<!-- --></li>
<!-- --></ol>
<!-- --><p>위 중에서 우리가 <!-- --><a href="/posts/ml-base-knowledge#Information-Theory">🔗 ML Base Knowledge(Information Theory)<!-- --></a>에서 다루었던 <!-- --><strong>Entropy<!-- --></strong>에 기반한 방법이 가장 즐겨서 사용되어진다.<!-- --></p>
<!-- --><p>즉, Entropy에 기반한 설명을 하자면, 우리는 IG(정보 획득량)를 최대화하기 위한 선택을 하게 되면, 해당 결정의 Child들은 적은 Entropy를 가지게 되고 이 과정을 반복해 나가면서 최적화를 수행하는 것이다.<!-- --></p>
<!-- --><p>즉, Decision Tree를 생성할 때에는 여러 가지 feature와 Model을 적용하며 각 Model이 가지는 IG를 기반으로 하여 Tree의 Root에서부터 Model을 선택하며 내려오는 것이다.<!-- --></p>
<!-- --><h2 id="Cutting-down-a-Compex-Model">Cutting down a Compex Model<!-- --></h2>
<!-- --><p>또한, 좋은 Model을 만들기 위해서 아이러니하게도 일부 정보를 삭제하는 것이 도움이 될 때가 있다. 대게 Deep Learning 환경에서 많이 발생하는 경우인데, <!-- --><strong>over fitting<!-- --></strong>으로 인한 문제를 해결하기 위해서 일부 edge를 제거하는 <!-- --><strong>dropout<!-- --></strong>을 수행한다. 이러한 방법은 <!-- --><strong>over fitting<!-- --></strong>을 방지할 뿐만 아니라 학습의 속도 역시 개선할 수 있기 때문에 자주 사용되어진다. 실제로 model의 성능이 증가할 수 있는지에 대해 다룬 논문이 별도로 있으니 참고할 수 있다면 해보도록 하자. 만약 시간이 된다면 이에 대해서도 다룰 수 있도록 하겠다.<!-- --></p>
<!-- --><ul>
<!-- --><li>Frankle, Jonathan, and Michael Carbin. &quot;The lottery ticket hypothesis: Finding sparse, trainable neural networks.&quot; ICRL 2019<!-- --></li>
<!-- --></ul>
<!-- --><h2 id="Reference">Reference<!-- --></h2>
<!-- --><ul>
<!-- --><li>Tumbnail : Photo by <!-- --><a href="https://unsplash.com/@markuswinkler?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Markus Winkler<!-- --></a> on <!-- --><a href="https://unsplash.com/@markuswinkler?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash<!-- --></a></li>
<!-- --><li><a href="https://halfundecided.medium.com/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-cnn-convolutional-neural-networks-%EC%89%BD%EA%B2%8C-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-836869f88375">🔗 CNN(Convolutional Neural Networks) 쉽게 이해하기<!-- --></a></li>
<!-- --></ul></article><div class="Comment_comment__wrapper___sKTf"><h2 class="Comment_comment__title__hLmXO">Comments</h2><section></section></div><div class="ColumnCard_column_card__list__background__kZObh"><h2 class="ColumnCard_column_card__list__title__pawoL">Related Posts</h2><div class="ColumnCard_column_card__list__wrapper__lsbEP"><div class="ColumnCard_column_card__wrapper__iVPbY"><a class="ColumnCard_column_card__thumbnail__wrapper__M3Kfm" href="/posts/ml-base-knowledge"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27320%27%20height=%27320%27/%3e"/></span><img alt="[ML] 0. Base Knowledge" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" class="ColumnCard_column_card__thumbnail__bx9FL" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="[ML] 0. Base Knowledge" srcSet="https://euidong.github.io/images/ml-thumbnail.jpg?imwidth=384 1x, https://euidong.github.io/images/ml-thumbnail.jpg?imwidth=640 2x" src="https://euidong.github.io/images/ml-thumbnail.jpg?imwidth=640" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" class="ColumnCard_column_card__thumbnail__bx9FL" loading="lazy"/></noscript></span></a><div class="ColumnCard_column_card__tray__v9oLc"><a class="ColumnCard_column_card__tray__title__fEApg" tabindex="-1" href="/posts/ml-base-knowledge">[ML] 0. Base Knowledge</a><ul class="ColumnCard_column_card__tray__tag__UUiD6"><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/ML"># <!-- -->ML<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/Probability"># <!-- -->Probability<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/Calculus"># <!-- -->Calculus<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/InformationTheory"># <!-- -->InformationTheory<!-- --></a></ul></div></div><div class="ColumnCard_column_card__wrapper__iVPbY"><a class="ColumnCard_column_card__thumbnail__wrapper__M3Kfm" href="/posts/ml-parametric-estimation"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27320%27%20height=%27320%27/%3e"/></span><img alt="[ML] 1. Parametric Estimation" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" class="ColumnCard_column_card__thumbnail__bx9FL" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="[ML] 1. Parametric Estimation" srcSet="https://euidong.github.io/images/ml-thumbnail.jpg?imwidth=384 1x, https://euidong.github.io/images/ml-thumbnail.jpg?imwidth=640 2x" src="https://euidong.github.io/images/ml-thumbnail.jpg?imwidth=640" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" class="ColumnCard_column_card__thumbnail__bx9FL" loading="lazy"/></noscript></span></a><div class="ColumnCard_column_card__tray__v9oLc"><a class="ColumnCard_column_card__tray__title__fEApg" tabindex="-1" href="/posts/ml-parametric-estimation">[ML] 1. Parametric Estimation</a><ul class="ColumnCard_column_card__tray__tag__UUiD6"><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/ML"># <!-- -->ML<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/MLE"># <!-- -->MLE<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/MAP"># <!-- -->MAP<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/Bayesian"># <!-- -->Bayesian<!-- --></a></ul></div></div><div class="ColumnCard_column_card__wrapper__iVPbY"><a class="ColumnCard_column_card__thumbnail__wrapper__M3Kfm" href="/posts/ml-linear-regression"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27320%27%20height=%27320%27/%3e"/></span><img alt="[ML] 2. Linear Regression" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" class="ColumnCard_column_card__thumbnail__bx9FL" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="[ML] 2. Linear Regression" srcSet="https://euidong.github.io/images/ml-thumbnail.jpg?imwidth=384 1x, https://euidong.github.io/images/ml-thumbnail.jpg?imwidth=640 2x" src="https://euidong.github.io/images/ml-thumbnail.jpg?imwidth=640" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" class="ColumnCard_column_card__thumbnail__bx9FL" loading="lazy"/></noscript></span></a><div class="ColumnCard_column_card__tray__v9oLc"><a class="ColumnCard_column_card__tray__title__fEApg" tabindex="-1" href="/posts/ml-linear-regression">[ML] 2. Linear Regression</a><ul class="ColumnCard_column_card__tray__tag__UUiD6"><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/ML"># <!-- -->ML<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/LinearRegression"># <!-- -->LinearRegression<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/BasisFunction"># <!-- -->BasisFunction<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/Regularization"># <!-- -->Regularization<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/GradientDescent"># <!-- -->GradientDescent<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/Momentum"># <!-- -->Momentum<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/StochasticGradientDescent"># <!-- -->StochasticGradientDescent<!-- --></a></ul></div></div><div class="ColumnCard_column_card__wrapper__iVPbY"><a class="ColumnCard_column_card__thumbnail__wrapper__M3Kfm" href="/posts/ml-logistic-regression"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27320%27%20height=%27320%27/%3e"/></span><img alt="[ML] 3. Logistic Regression" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" class="ColumnCard_column_card__thumbnail__bx9FL" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="[ML] 3. Logistic Regression" srcSet="https://euidong.github.io/images/ml-thumbnail.jpg?imwidth=384 1x, https://euidong.github.io/images/ml-thumbnail.jpg?imwidth=640 2x" src="https://euidong.github.io/images/ml-thumbnail.jpg?imwidth=640" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" class="ColumnCard_column_card__thumbnail__bx9FL" loading="lazy"/></noscript></span></a><div class="ColumnCard_column_card__tray__v9oLc"><a class="ColumnCard_column_card__tray__title__fEApg" tabindex="-1" href="/posts/ml-logistic-regression">[ML] 3. Logistic Regression</a><ul class="ColumnCard_column_card__tray__tag__UUiD6"><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/ML"># <!-- -->ML<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/LogisticRegression"># <!-- -->LogisticRegression<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/Classification"># <!-- -->Classification<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/SigmoidFunction"># <!-- -->SigmoidFunction<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/SoftmaxFunction"># <!-- -->SoftmaxFunction<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/NewtonMethod"># <!-- -->NewtonMethod<!-- --></a></ul></div></div><div class="ColumnCard_column_card__wrapper__iVPbY"><a class="ColumnCard_column_card__thumbnail__wrapper__M3Kfm" href="/posts/ml-svm"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27320%27%20height=%27320%27/%3e"/></span><img alt="[ML] 4. SVM" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" class="ColumnCard_column_card__thumbnail__bx9FL" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="[ML] 4. SVM" srcSet="https://euidong.github.io/images/ml-thumbnail.jpg?imwidth=384 1x, https://euidong.github.io/images/ml-thumbnail.jpg?imwidth=640 2x" src="https://euidong.github.io/images/ml-thumbnail.jpg?imwidth=640" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" class="ColumnCard_column_card__thumbnail__bx9FL" loading="lazy"/></noscript></span></a><div class="ColumnCard_column_card__tray__v9oLc"><a class="ColumnCard_column_card__tray__title__fEApg" tabindex="-1" href="/posts/ml-svm">[ML] 4. SVM</a><ul class="ColumnCard_column_card__tray__tag__UUiD6"><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/ML"># <!-- -->ML<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/SVM"># <!-- -->SVM<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/GeneralClassifier"># <!-- -->GeneralClassifier<!-- --></a></ul></div></div><div class="ColumnCard_column_card__wrapper__iVPbY"><a class="ColumnCard_column_card__thumbnail__wrapper__M3Kfm" href="/posts/ml-multiclass-classification-in-svm"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27320%27%20height=%27320%27/%3e"/></span><img alt="[ML] 5. Multiclass Classification in SVM" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" class="ColumnCard_column_card__thumbnail__bx9FL" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="[ML] 5. Multiclass Classification in SVM" srcSet="https://euidong.github.io/images/ml-thumbnail.jpg?imwidth=384 1x, https://euidong.github.io/images/ml-thumbnail.jpg?imwidth=640 2x" src="https://euidong.github.io/images/ml-thumbnail.jpg?imwidth=640" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" class="ColumnCard_column_card__thumbnail__bx9FL" loading="lazy"/></noscript></span></a><div class="ColumnCard_column_card__tray__v9oLc"><a class="ColumnCard_column_card__tray__title__fEApg" tabindex="-1" href="/posts/ml-multiclass-classification-in-svm">[ML] 5. Multiclass Classification in SVM</a><ul class="ColumnCard_column_card__tray__tag__UUiD6"><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/ML"># <!-- -->ML<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/SVM"># <!-- -->SVM<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/KernelMethod"># <!-- -->KernelMethod<!-- --></a></ul></div></div><div class="ColumnCard_column_card__wrapper__iVPbY"><a class="ColumnCard_column_card__thumbnail__wrapper__M3Kfm" href="/posts/ml-nn"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27320%27%20height=%27320%27/%3e"/></span><img alt="[ML] 6. Neural Network" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" class="ColumnCard_column_card__thumbnail__bx9FL" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="[ML] 6. Neural Network" srcSet="https://euidong.github.io/images/ml-thumbnail.jpg?imwidth=384 1x, https://euidong.github.io/images/ml-thumbnail.jpg?imwidth=640 2x" src="https://euidong.github.io/images/ml-thumbnail.jpg?imwidth=640" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" class="ColumnCard_column_card__thumbnail__bx9FL" loading="lazy"/></noscript></span></a><div class="ColumnCard_column_card__tray__v9oLc"><a class="ColumnCard_column_card__tray__title__fEApg" tabindex="-1" href="/posts/ml-nn">[ML] 6. Neural Network</a><ul class="ColumnCard_column_card__tray__tag__UUiD6"><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/ML"># <!-- -->ML<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/NeuralNetwork"># <!-- -->NeuralNetwork<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/Perceptron"># <!-- -->Perceptron<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/Backpropagation"># <!-- -->Backpropagation<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/CrossEntropyLoss"># <!-- -->CrossEntropyLoss<!-- --></a></ul></div></div><div class="ColumnCard_column_card__wrapper__iVPbY"><a class="ColumnCard_column_card__thumbnail__wrapper__M3Kfm" href="/posts/ml-graphical-model"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27320%27%20height=%27320%27/%3e"/></span><img alt="[ML] 8. Graphical Model" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" class="ColumnCard_column_card__thumbnail__bx9FL" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="[ML] 8. Graphical Model" srcSet="https://euidong.github.io/images/ml-thumbnail.jpg?imwidth=384 1x, https://euidong.github.io/images/ml-thumbnail.jpg?imwidth=640 2x" src="https://euidong.github.io/images/ml-thumbnail.jpg?imwidth=640" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" class="ColumnCard_column_card__thumbnail__bx9FL" loading="lazy"/></noscript></span></a><div class="ColumnCard_column_card__tray__v9oLc"><a class="ColumnCard_column_card__tray__title__fEApg" tabindex="-1" href="/posts/ml-graphical-model">[ML] 8. Graphical Model</a><ul class="ColumnCard_column_card__tray__tag__UUiD6"><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/ML"># <!-- -->ML<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/GraphicalModel"># <!-- -->GraphicalModel<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/ConditionalIndependence"># <!-- -->ConditionalIndependence<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/MarkovRandomField"># <!-- -->MarkovRandomField<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/BayesianNetwork"># <!-- -->BayesianNetwork<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/FactorGraph"># <!-- -->FactorGraph<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/D-Seperation"># <!-- -->D-Seperation<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/Factorization"># <!-- -->Factorization<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/MarkovProperty"># <!-- -->MarkovProperty<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/MessagePassing"># <!-- -->MessagePassing<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/BeliefPropagation"># <!-- -->BeliefPropagation<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/Chow-LiuAlgorithm"># <!-- -->Chow-LiuAlgorithm<!-- --></a></ul></div></div><div class="ColumnCard_column_card__wrapper__iVPbY"><a class="ColumnCard_column_card__thumbnail__wrapper__M3Kfm" href="/posts/ml-clustering"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27320%27%20height=%27320%27/%3e"/></span><img alt="[ML] 9. Clustering" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" class="ColumnCard_column_card__thumbnail__bx9FL" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="[ML] 9. Clustering" srcSet="https://euidong.github.io/images/ml-thumbnail.jpg?imwidth=384 1x, https://euidong.github.io/images/ml-thumbnail.jpg?imwidth=640 2x" src="https://euidong.github.io/images/ml-thumbnail.jpg?imwidth=640" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" class="ColumnCard_column_card__thumbnail__bx9FL" loading="lazy"/></noscript></span></a><div class="ColumnCard_column_card__tray__v9oLc"><a class="ColumnCard_column_card__tray__title__fEApg" tabindex="-1" href="/posts/ml-clustering">[ML] 9. Clustering</a><ul class="ColumnCard_column_card__tray__tag__UUiD6"><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/ML"># <!-- -->ML<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/UnsupervisedLearning"># <!-- -->UnsupervisedLearning<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/Clustering"># <!-- -->Clustering<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/K-means"># <!-- -->K-means<!-- --></a><a tabindex="-1" class="ColumnCard_column_card__tray__tag__li__YRXLc" href="/tags/GMM"># <!-- -->GMM<!-- --></a></ul></div></div></div></div></div></section><footer class="Layout_footer__EL5v8"><div class="Layout_footer__copyright__r5baC"><span>Copyright © euidong</span><br/><span>모든 컨텐츠에 대한 저작권은 작성자에게 존재합니다. <!-- --><br/>불법 복제를 통한 상업적 사용을 절대적으로 금지합니다. <!-- --><br/>단, 비상업적 이용의 경우 출처 및 링크를 적용한다면 자유롭게 사용가능 합니다.<!-- --></span><span>Also I use photos by<!-- --> <!-- --><a href="https://unsplash.com/@lorenzoherrera?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" tabindex="-1">Lorenzo Herrera</a> <!-- -->on<!-- --> <!-- --><a href="https://unsplash.com/s/photos/tech?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" tabindex="-1">Unsplash</a></span></div><div class="Layout_footer__contents__YZWSm"><a class="Layout_footer__contents__link__K_TKH" href="https://github.com/euidong" target="_blank" rel="noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="60" width="60" xmlns="http://www.w3.org/2000/svg"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path></svg><span>github</span></a><a class="Layout_footer__contents__link__K_TKH" href="https://euidong.github.io/portfolio" target="_blank" rel="noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="60" width="60" xmlns="http://www.w3.org/2000/svg"><path d="M6 8a3 3 0 1 0 0-6 3 3 0 0 0 0 6zm-5 6s-1 0-1-1 1-4 6-4 6 3 6 4-1 1-1 1H1zM11 3.5a.5.5 0 0 1 .5-.5h4a.5.5 0 0 1 0 1h-4a.5.5 0 0 1-.5-.5zm.5 2.5a.5.5 0 0 0 0 1h4a.5.5 0 0 0 0-1h-4zm2 3a.5.5 0 0 0 0 1h2a.5.5 0 0 0 0-1h-2zm0 3a.5.5 0 0 0 0 1h2a.5.5 0 0 0 0-1h-2z"></path></svg><span>portfolio</span></a><a class="Layout_footer__contents__link__K_TKH" href="https://chrome.google.com/webstore/detail/bonfire/nkooidijgbppkojdgkoafcoppnohdfka?hl=ko" target="_blank" rel="noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" version="1.1" viewBox="0 0 16 16" height="60" width="60" xmlns="http://www.w3.org/2000/svg"><path d="M5.016 16c-1.066-2.219-0.498-3.49 0.321-4.688 0.897-1.312 1.129-2.61 1.129-2.61s0.706 0.917 0.423 2.352c1.246-1.387 1.482-3.598 1.293-4.445 2.817 1.969 4.021 6.232 2.399 9.392 8.631-4.883 2.147-12.19 1.018-13.013 0.376 0.823 0.448 2.216-0.313 2.893-1.287-4.879-4.468-5.879-4.468-5.879 0.376 2.516-1.364 5.268-3.042 7.324-0.059-1.003-0.122-1.696-0.649-2.656-0.118 1.823-1.511 3.309-1.889 5.135-0.511 2.473 0.383 4.284 3.777 6.197z"></path></svg><span>chat</span></a></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"content":"\n## Intro\n\n여태까지 ML을 수행할 수 있는 여러 가지 방법론을 살펴보았다. 그렇다면, 어떤 Model을 선택하고, 학습과 추정을 해야할지 결정해야 한다. 따라서, 여기서는 어떤 것이 좋은 Model이고, 각 Model 간에 어떻게 비교를 수행할 것인지 그리고 더 나아가 Model을 혼합하는 방법에 대해서 알아볼 것이다.\n\n## What is Good Model?\n\n우리가 사람 image를 입력받아서 긴 머리를 가진 사람인지 여부를 판단하는 classifier를 만든다고 하자. 이때 어떤 Model이 좋은 Model이 될 수 있을까?\n\n가장 쉽게 생각할 수 있는 Model은 Fully Connected Neural Network(FCNN)를 구성하는 것이다. 이를 위해서 Image의 각 pixel을 일렬로 줄 세워 입력할 수 밖에 없다. 하지만, 이는 pixel들 간의 인접 관계를 사용할 수 없게 한다는 단점 때문에 높은 성능을 내기가 어려웠다. 따라서, 이를 극복하기 위헤서 제시된 방법이 Convolutional Neural Network(CNN)를 사용하는 것이다. 이는 FCNN을 적용하기 이전에 Image에 Filter를 적용하여 특정 구간을 대표하는 값을 뽑아내서 더 효율적인 학습을 하는 것을 목표로 한다.(물론 더 자세히 다루면 Pooling Layer 등 더 자세한 설명이 필요하지만, 여기서는 자세히 다루지 않는다. 해당 글을 참고하도록 하자. [🔗 CNN(Convolutional Neural Networks) 쉽게 이해하기](https://halfundecided.medium.com/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-cnn-convolutional-neural-networks-%EC%89%BD%EA%B2%8C-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-836869f88375))\n\n우리의 뇌에서도 Image를 인식하고 처리하기 위해서, color와 motion 그리고 윤곽 등을 따로 따로 처리한다고 한다. 즉, CNN은 이러한 Domain Knowledge를 활용한 훌륭한 예시 중 하나라고 할 수 있다. 즉, 여기서 말하고자 하는 바는 결국 모든 환경에서 최고의 성능을 보여줄 수 있는 Model은 없다는 것이며, Good Model은 우리가 하고자 하는 일에 따라서 Domain Knowledge를 충실하게 활용하여 최고의 성능을 낼 수 있는 Model이라고 할 수 있다.\n\n```plaintext\n 🤔 Data Augmentation\n \n Domain Knowledge를 활용하여 Model의 성능을 높일 수 있는 방법은 \n 단순히 Model 자체를 바꾸는 것 뿐만 아니라 Domain Knowledge를 바탕으로 \n Data를 추가적으로 더 만들어내는 방법이 있다. 이러한 방법을 \n Data Augmentation이라고 한다.\n\n Image data 같은 경우에는 원본 Image를 약간 회전시키거나 확대하거나 \n Noise를 주는 등의 작업을 하여 전체 데이터의 크기를 늘릴 수 있다.\n\nText 같은 경우에는 동의어를 활용하여 문장 데이터의 크기를 효과적으로\n늘리는 것도 가능하다.\n```\n\n![ml-data-augmentation](/images/ml-data-augmentation.png)\n\n## Comparison between Models\n\n여기서 만약 우리가 얻을 수 있는 Model의 종류가 다양하다면 이들을 어떻게 비교하여 하나의 Model을 선택할 수 있을까? 이 역시 중요한 문제이다.\n\n사실 우리가 학습했던 data를 그대로 평가할 때 사용하는 것은 굉장히 불공평하다고 할 수 있다. 우리가 만들고자 하는 Model은 일반적으로 어느 상황에 두어도 그리고 안본 data일지라도 올바르게 분류하기를 원한다. 즉, 우리의 Model이 **Generalization**을 수행할 수 있기를 바란다.\n\n이러한 Model의 **Generalization** 성능을 측정하기 위해서 자주 사용되는 것이 Dataset을 Train과 Test set으로 나누는 것이다. 하지만, 이것도 부족할 때가 있다. 특정 Model이 특정 Train set에서만 성능이 높을 수도 있기 때문이다. 따라서, 우리는 **Cross Validation**이라는 방식을 도입한다. 이는 우리가 가진 dataset을 골고루 test와 train set으로 활용하는 방법이다. 즉, 여러 번의 training을 수행하며, test를 수행하기를 반복하는 것이다. 그리고, 이를 평균을 내서 전체적인 Model 성능을 평가하는 방법이다.\n\n![ml-k-fold-cross-validation](/images/ml-k-fold-cross-validation.png)\n\n위와 같이 공평하게 k개로 나누는 방식을 k fold cross validation이라고 하며, 해당 예시는 $k=4$인 경우이다. 즉, 위와 같이 Validation을 하기 위해서는 Model의 수가 $N$개라고 할 때, 총 $N \\times k$번의 Training과 Evaluation이 필요하다.\n\n하지만, 여기서 또 간과한 사실은 hyperparameter가 각 model마다 큰 영향을 미친다는 사실이다. 즉, Hyper Parameter를 정하는 과정 역시 필요한데, 이는 각 각의 Model 내부에서 어떤 Hyper Parameter를 사용할지에 대한 합의가 필요한 것이다. 이를 확인하기 위해서 어쩔 수 없이 우리는 Training과 Evaluation을 수행해야 하며, 이를 위한 data를 별도로 분리해야 한다. 따라서, 우리가 가지는 dataset을 다음과 같이 세개로 나누어야 한다는 것이다.\n\n![ml-dataset](/images/ml-dataset.png)\n\n여기서 더 정당하게 하고 싶다면, 아래와 같은 과정을 반복해야 한다.\n\n![ml-nested-cross-validation](/images/ml-nested-cross-validation.png)\n\n하지만, 이는 굉장히 비용이 커질 수 있다. validation set을 고를 때, $k^{\\prime}$개가 필요하다고 한다면, 우리는 $N \\times k^{\\prime} \\times k$번의 Training과 Evaluation이 필요한 것이다. 굉장히 비용이 커지기 때문에 대게 validation set까지 cross validation하는 nested cross validation은 상황에 따라 사용되기도 하고, 사용되지 않기도 한다.\n\n## Combining Simple Models\n\n좋은 Model을 만들 수 있는 방법 중에서 가장 쉽게 생각할 수 있는 것 중에 하나가 여러 개의 Model을 활용하는 방법이다. 쉽게 집단 지성을 활용한다고 볼 수 있다. 이러한 방식을 **Ensemble**(앙상블)이라고 부르고, 이를 활용할 수 있는 방법은 여러 가지가 있다.\n\n1. 서로 다른 여러 개의 Model, 또는 Hyperparameter만을 변경하거나 또는 feature를 다르게 변형하여 Model을 여러 개 생성하고 평균 또는 최댓값을 취하는 방법 (**Voting**)\n2. 여러 개의 Model을 혼합하지만, 각 단계에 따라서 Model을 선택하는 방법 (**Stacking**)\n3. dataset을 여러 번 sampling하여 각 각의 Model을 만들고, 각 Model의 결과를 평균 또는 최댓값을 취하는 방법 (**Bagging**, **Pasting**)\n4. 이전과는 달리 앞 서 진행한 Model의 결과를 반영하여 다음 Model에 적용하기를 반복하며, 여러 Model을 제작하고 취합하는 방법 (**Boosting**)\n\n크게는 이렇게 3가지로 나눌 수 있다. 여기서 각각을 자세히 다루지는 않고, **Boosting** 방식 중에서도 많이 사용되는 방법 중에 하나인 **AdaBoost**에 대해서 좀 더 자세히 다뤄보도록 하겠다.\n\n### AdaBoost\n\nAdaptive Boosting의 약자인 AdaBoost는 이름에서 볼 수 있듯이 반복적인 작업을 통해서 최종 Model의 성능을 높이는 것을 목표로 한다. 우선 Boosting 방법 자체가 동시에 Model을 학습시키는 것이 아니고, 순차적으로 학습시키면서 성능을 높이는 방법이다. 그렇다면, 우리가 이전 Model들의 학습 과정에서 다음 Model에게 넘겨줄 수 있는 특별한 정보는 무엇일까? 이는 바로 자신들이 잘못 분류한 데이터에 대한 정보이다. 자신들이 잘못 분류한 data들에게 더 높은 가중치를 부여하도록 하여 다음 Model에서는 이를 중심적으로 분류할 수 있도록 하는 방식으로 최종 Model의 성능을 높여보자는 것이 Idea이다.\n\n그렇다면, 이것이 어떻게 가능할까? 매우 간단한 이진 분류기를 기반으로 이를 설명하도록 하겠다. 우리가 만약 특정 임계값($\\theta_{t}$)보다 작으면 -1, 그렇지 않으면 1이라고 분류하는 아주 간단한 분류기(weak classifier, decision stump)를 가지고 있다고 하자.\n\n$$\nf_{t}(x) = \\begin{cases} -1 \u0026 \\text{if } x \u003c \\theta_{t} \\\\ 1 \u0026 \\text{otherwise} \\end{cases}\n$$\n\n이제 우리는 이 간단한 분류기 T개를 합쳐서 복잡한 분류 문제를 해결할 분류기를 제작할 것이다. 이 때, 각 분류기는 다음과 같은 가중치($\\alpha_{t}$)를 가지게 된다.\n\n$$\n\\begin{align*}\n\\text{output} = \\text{sign}(F_{T}(x)) \\\\\nF_{T}(x) = \\sum_{t=1}^{T} \\alpha_{t} f_{t}(x)\n\\end{align*}\n$$\n\n그렇다면, 우리는 위 식에서 어떻게 하면, 현명하게 $\\theta_{t}, \\alpha_{t}$를 결정할 수 있을까? 이에 대한 해답으로 **AdaBoost**는 이전 $F_{t-1}$에 의해 발생한 **error**에 집중한다.\n\n우선 $F_{t}$의 Error($E(F_{t})$)를 아래와 같다고 하자.\n\n$$\nE(F_{t}) = \\sum_{i=1}^{N} \\exp(-y^{(i)}F_{t}(x^{(i)}))\n$$\n\n즉, 예측이 맞다면 error는 $1 \\over e$, 틀리다면 $e$만큼 error가 증가한다.  \n여기서 우리는 현재 학습할 Model 이전까지의 Model의 하나의 데이터에 대한 Error를 $\\gamma_{t}^{(i)}$라고 정의해보자.\n\n$$\n\\gamma_{t}^{(i)} = \\exp(-y^{(i)}F_{t-1}(x^{(i)})),\\quad \\gamma_{1}^{(i)} = 1\n$$\n\n다시 한 번 $\\gamma_{t}^{(i)}$의 의미를 정의하면, 간단하게 이전까지의 Model의 합으로 만든 Model이 잘 분류했다면, $e$ 그렇지 않다면, $1 \\over e$가 된다.\n\n그렇다면, 계속해서 Error 식을 정리해보자.\n\n$$\n\\begin{align*}\nE(F_{t}) \u0026= \\sum_{i=1}^{N}\\{\\exp(-y^{(i)}F_{t-1}(x^{(i)})) \\times \\exp(-y^{(i)}\\alpha_{t}f_{t}(x^{(i)}))\\} \\\\\n\u0026= \\sum_{i=1}^{N} \\gamma_{t}^{(i)} \\exp(-y^{(i)}\\alpha_{t}f_{t}(x^{(i)})) \\\\\n\u0026= \\sum_{i:y^{(i)}=f_{t}(x^{(i)})}\\gamma_{t}^{(i)}\\exp(-\\alpha_{t}) + \\sum_{i:y^{(i)}\\neq f_{t}(x^{(i)})}\\gamma_{t}^{(i)}\\exp(\\alpha_{t}) \\\\\n\u0026= \\sum_{i=1}^{N}\\gamma_{t}^{(i)}\\exp(-\\alpha_{t}) + \\sum_{i:y^{(i)}\\neq f_{t}(x^{(i)})}\\gamma_{t}^{(i)}(\\exp(\\alpha_{t})-\\exp(-\\alpha_{t})) \\\\\n\u0026= \\exp(-\\alpha_{t})\\sum_{i=1}^{N}\\gamma_{t}^{(i)} + (\\exp(\\alpha_{t})-\\exp(-\\alpha_{t}))\\sum_{i:y^{(i)}\\neq f_{t}(x^{(i)})}\\gamma_{t}^{(i)}\n\\end{align*}\n$$\n\n여기서 Error를 가장 작게 할 수 있는 $\\theta_{t}, \\alpha_{t}$를 찾기 위한 방법은 각 각 다음과 같다.\n\n1. 식에서 $\\theta_{t}$가 바꿀 수 있는 것은 $f_{t}$밖에 없다. 즉 $\\sum_{i:y^{(i)}\\neq f_{t}(x^{(i)})}\\gamma_{t}^{(i)}$를 조정하는 것이다.  \n   즉, $\\gamma_{t}^{(i)}$는 이전 분류기($F_{t-1}$)가 잘 분류했다면 $e$, 그렇지 않다면 $1 \\over e$가 되는데, 이들의 합이 최소가 되도록 하는 임계값 $\\theta_{t}$를 찾는 것이다.  \n   즉, 기존 분류기가 잘못 분류한 data에 대해서 더 중점적으로 분류할 수 있도록 가중치를 부여하여 다시 분류한다는 것이다.\n2. Error를 $\\alpha_{t}$에 대한 미분을 하여, 0이 되도록 하는 $\\alpha_{t}$를 찾으면 된다. 이 과정은 다음과 같다.\n\n$$\n\\alpha_{t} = \\frac{1}{2}\\ln\\frac{1-\\varepsilon_{t}}{\\varepsilon_{t}},\\quad \\varepsilon_{t} = \\frac{\\sum_{i:y^{(i)}\\neq f_{t}(x^{(i)})}\\gamma_{t}^{(i)}}{\\sum_{i}^{N}\\gamma_{t}^{(i)}}\n$$\n\n여기서 $\\varepsilon_{t}$를 자세히 보면, 분모는 decision stump의 최대 Error이고 분자는 현재 decision stump의 Error를 의미한다. 이것이 직접적으로 $\\alpha_{t}$에 영향을 미치는 것이다.\n\n따라서 이르 조금 더 정리하자면 다음과 같다.\n\n1. $\\varepsilon_{t} \\gt \\frac{1}{2} \\rArr \\alpha_{t} \\lt 0$  \n   $\\varepsilon_{t} \\gt \\frac{1}{2}$라는 것은 사실 $f_{t}$의 성능이 선택지 두 개지 하나를 Random하게 고르는 경우의 확률 $\\frac{1}{2}$보다 못하다는 것이다. 이 경우에 $\\alpha_{t}$를 음수로 설정하여 적용하는 것이 반대로 확률을 적용하는 것이고, 이것이 전체 성능을 높일 수 있기에 타당하다.\n2. $\\varepsilon_{t} = \\frac{1}{2} \\rArr \\alpha_{t} = 0$  \n   만약, 성능이 딱 $\\frac{1}{2}$라면, 더 이상 개선의 여지가 없어진다. 즉, $\\alpha_{t}$를 0으로 설정하여 적용하게 되면, $F_{t}=F_{t-1}$이 된다. 즉, 더 이상의 Model 중첩은 무의미하다는 것을 의미하므로 해당 단계에 도달하면 학습을 중단한다.\n3. $0 \\lt \\varepsilon_{t} \\lt \\frac{1}{2} \\rArr \\alpha_{t} \\gt 0$  \n   일반적인 경우로, 새롭게 만든 분류기가 기존 분류기($F_{t-1}$)를 보완할 만큼 잘 예측을 하고 있기에 $\\alpha_{t}$를 양수로 설정하여 적용한다.\n4. $\\varepsilon_{t} \\rarr 0 \\rArr \\alpha \\rarr \\infin$  \n   $\\varepsilon_{t}$가 0에 가까워지면, 즉, $f_{t}$가 모든 data를 정확하게 분류한다면, 사실상 기존 분류기들은 더 이상 의미가 없다. 하나의 $decision stump$로 완벽하게 분류되는 문제였기 때문이다. 즉, $F_{t} = f_{t}$가 된다.\n\n### Decision Tree\n\n앞 선 **AdaBoost**에서는 Decision Stump를 다루었지만, 더 다양한 분류기를 이용해서 Decision Tree를 구성하는 것도 가능하다. 실제 Stacking 또는 Bagging 등의 작업을 할 때에는 단순한 Decision Stump의 합 같은 형태가 아니라 Tree형태로 구성되는 경우가 많다(Decision을 할 때마다 가지치기를 하며 나뉘는 형태). 그리고 실제로도 이 형태가 인간의 사고 과정도 매우 유사하다. 따라서, 대게의 경우 성능도 좋은 뿐만 아니라 직관적이기 때문에 이러한 방식을 사용해서 여러 Model을 혼합하는 경우도 있다. 이 안에서 Decision을 수행할 때 복잡한 Deep Learning을 수행할 수도 있고, 단순하게 Decision Stump를 사용할 수도 있는 것이다.\n\n![ml-decision-tree](/images/ml-decision-tree.png)\n\n그렇다면, 이러한 Decision Tree를 어떻게 학습하는 게 좋을지를 조금만 살펴보도록 하겠다. 가정을 하나 해보자. 우리가 분류하고자 하는 Category가 10개이고, feature가 100개이다. 이때, 어떤 Feature를 이용한 어떤 Model을 사용한 것을 우선으로 적용해야할까? 이것이 사실 가장 중요한 문제이다. 이를 해결하기 위해서 여러 알고리즘(ID3, CART, 등)이 제시되었다. 하지만, 결국 핵심은 각 각의 단계에서 데이터를 가장 적절하게 나누는 것이 중요한 것이다. 따라서, Model(f)에 대해서 \u003cmark\u003e**얻을 수 있는 정보의 양**(**IG**, Information Gain)\u003c/mark\u003e이 많을 수록 좋은 Model이라고 칭하는 것이다. 이를 식으로 표현하면 다음과 같다.\n\n$$\nIG(\\mathcal{D}, f) = I(\\mathcal{D}) - \\sum_{j=1}^{J} \\frac{D_{j}}{D}I(\\mathcal{D}_{j})\n$$\n\n여기서, 또 그렇다면, I는 무엇인지 궁금할 수 있다. 이는 Impurity(정보의 혼탁도)를 의미하며, 이를 표현하는 지표는 아래와 같은 것들이 있다.\n\n1. Gini Impurity\n2. Entropy\n3. Classification Error\n\n위 중에서 우리가 [🔗 ML Base Knowledge(Information Theory)](/posts/ml-base-knowledge#Information-Theory)에서 다루었던 **Entropy**에 기반한 방법이 가장 즐겨서 사용되어진다.\n\n즉, Entropy에 기반한 설명을 하자면, 우리는 IG(정보 획득량)를 최대화하기 위한 선택을 하게 되면, 해당 결정의 Child들은 적은 Entropy를 가지게 되고 이 과정을 반복해 나가면서 최적화를 수행하는 것이다.\n\n즉, Decision Tree를 생성할 때에는 여러 가지 feature와 Model을 적용하며 각 Model이 가지는 IG를 기반으로 하여 Tree의 Root에서부터 Model을 선택하며 내려오는 것이다.\n\n## Cutting down a Compex Model\n\n또한, 좋은 Model을 만들기 위해서 아이러니하게도 일부 정보를 삭제하는 것이 도움이 될 때가 있다. 대게 Deep Learning 환경에서 많이 발생하는 경우인데, **over fitting**으로 인한 문제를 해결하기 위해서 일부 edge를 제거하는 **dropout**을 수행한다. 이러한 방법은 **over fitting**을 방지할 뿐만 아니라 학습의 속도 역시 개선할 수 있기 때문에 자주 사용되어진다. 실제로 model의 성능이 증가할 수 있는지에 대해 다룬 논문이 별도로 있으니 참고할 수 있다면 해보도록 하자. 만약 시간이 된다면 이에 대해서도 다룰 수 있도록 하겠다.\n\n- Frankle, Jonathan, and Michael Carbin. \"The lottery ticket hypothesis: Finding sparse, trainable neural networks.\" ICRL 2019\n\n## Reference\n\n- Tumbnail : Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=unsplash\u0026utm_medium=referral\u0026utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@markuswinkler?utm_source=unsplash\u0026utm_medium=referral\u0026utm_content=creditCopyText)\n- [🔗 CNN(Convolutional Neural Networks) 쉽게 이해하기](https://halfundecided.medium.com/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-cnn-convolutional-neural-networks-%EC%89%BD%EA%B2%8C-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-836869f88375)\n","slug":"ml-model-selection","date":"2022-11-08 16:07","title":"[ML] 7. Model Selection","category":"AI","tags":["ML","ModelSelection","CrossValidation","Boosting","AdaBoost","DecisionTree","NetworkPruning"],"desc":"여태까지 ML을 수행할 수 있는 여러 가지 방법론을 살펴보았다. 그렇다면, 어떤 Model을 선택하고, 학습과 추정을 해야할지 결정해야 한다. 따라서, 여기서는 어떤 것이 좋은 Model이고, 각 Model 간에 어떻게 비교를 수행할 것인지 그리고 더 나아가 Model을 혼합하는 방법에 대해서 알아볼 것이다.","thumbnailSrc":"https://euidong.github.io/images/ml-thumbnail.jpg"},"relatedPosts":[{"content":"\n## Intro\n\nMachine Learning은 data들로 부터 특정 pattern을 나타내는 function을 만드는 것이라고 할 수 있다. 즉, pattern은 data에 대한 간단한 요약본이라고 볼 수 있다.\n확률/통계 이론 및 선형대수, 미적분, 정보 이론 관련 기본 내용을 해당 포스팅에 정리한다. 여기서 다루는 내용은 대게 많이 추상적인 내용이며, 키워드 중심의 내용이다. 만약, 추가적인 설명이 필요하다면 키워드를 기반으로 더 검색을 하는 것이 좋을 것이다.\n\n## Probability/Statisics\n\n확률과 통계는 대게 거의 동의어처럼 사용되지만, Statistics는 대게 과거를 의미할 때 사용하는 반면 Probability는 미래를 의미하는 용도로 많이 사용되어진다.\n\n### Probability Space\n\n확률 공간을 정의하는 것은 확률을 이해하는 토대가 된다. 확률을 적용하기 위한 공간을 먼저 살펴보자.\n\n- Sample Space($\\Omega$)  \n  가능한 모든 결과값의 집합이다.  \n  ex. 동전을 두 번을 던져서 나올 수 있는 모든 결과값은 $\\Omega = $ $\\{ hh, ht, th, tt \\}$\n- Event($E$)  \n  Sample Space의 Subset이다. Sample Space에서 발생할 수 있는 event라는 의미로 볼 수 있다.  \n  ex. 동전을 두 번을 던져서 모두 같은 면이 나오는 Event는 $E = $ $\\{ hh, tt \\}$\n- Field($\\mathcal{F}$)  \n  Sample Space에서 발생 가능한 모든 Event들의 집합이다.  \n  ex 동전을 두 번 던져서 나오는 결과값의 Field는 $\\mathcal{F} = $ $\\{$ $\\emptyset$, $\\{hh\\}$, $\\{ht\\}$, $\\{th\\}$, $\\{tt\\}$, $\\{hh, ht\\}$, $\\{hh, th\\}$, $\\{hh, tt\\}$, $\\{ht, th\\}$, $\\{ht, tt\\}$, $\\{th, tt\\}$, $\\{hh, ht, th\\}$, $\\{hh, ht, tt\\}$, $\\{hh, th, tt\\}$, $\\{ht, th, tt\\}$, $\\{hh, ht, th, tt\\}$ $\\}$\n- $\\sigma$-field  \n  자신 내부의 원소를 포함하는 합집합을 모두 포함하는 셀 수 있는 field를 sigma field라고 한다.  \n  이 $\\sigma$-field는 일반적인 확률과 특정 domain에서의 확률을 정의하는데 필요하다.  \n  우리가 sample space($\\Omega$)와 $\\sigma$-field $\\mathcal{F} \\subset 2^{\\Omega}$가 주어질 때, 확률P가 다음과 같이 mapping한다고 하자. $P: \\mathcal{F} \\mapsto [0, 1]$ 이때 P는 다음과 같은 특징을 가진다.\n  - $A \\in \\mathcal{F}$인 모든 A에 대해서 $P(A) \\leq 0$ 이다.  \n    $P(\\emptyset) = 0, P(\\Omega) = 1$\n  - $\\{A_i\\}_{i \\in I}$이고, 서로 다른 모든 i, j에 대해 $ A_{i}\\cup A_{j} = \\emptyset$이라면, 아래 식을 만족한다.  \n    $$P(\\cup_{i \\in I}A_i) = \\sum_{i \\in I}P(A_i)$$\n\n### Important properties of Probability\n\n- **Joint Probability**  \n  두 Event의 Joint Probability는 두 Event의 합집합의 확률을 의미한다.\n  $P(A, B) = P(A \\cap B)$\n- **Marginal Probability**  \n  대게 두 개 이상의 Event가 있을 때, 각 각의 Event의 확률을 특정할 때 사용한다.\n  $P(A), P(B)$\n- **Independence**  \n  두 Event가 독립이라는 의미는 서로의 Event가 서로 영향을 받지 않는다는 의미이다. \u003cmark\u003e**주의할 것은 이것이 의미하는 것이 두 Event의 교집합이 없다는 의미가 아니다.**\u003c/mark\u003e  \n  예를 들어보면 다음과 같다. 우리가 위에서 예시로 사용한 두 개의 동전을 던진 결과를 보자. 두 개의 동전이 모두 앞면이 나오는 경우와 모두 뒷면이 나오는 경우는 서로 독립일까? 이는 독립이 아니다. 왜냐하면, 동전이 모두 앞면이 나오는 사건은 필연적으로 모두 뒷면이 나오는 사건은 반드시 일어나지 않을 것이라는 증거가 되기 때문이다. 반대로, 모두 앞면이 나오는 사건과 한 번만 앞면이 나오는 사건을 생각해보자. 하나의 사건이 일어났다고, 반드시 그 사건이 일어났거나 안일어났다는 관계를 밝혀낼 수 없다. 따라서, 이러한 경우 두 사건이 독립적이라고 한다.  \n  이를 수학적으로 표현하면, 다음과 같이 표현할 수 있다.  \n  $P(A, B)=P(A)P(B)$  \n  즉 위 공식이 성립하면 독립이며, 독립이라면 위의 식이 성립한다.\n- **Conditional Probability**  \n  두 Event가 있을 때, 하나의 Event가 발생했을 때 다른 하나의 Event가 발생할 확률을 의미한다. 따라서, 이는 다음과 같이 수식으로 표현할 수 있다.  \n  $P(A|B) = {{P(A, B)}\\over{P(B)}}, (P(B) \\neq 0)$  \n  여기서 independence 특성을 더 명확하게 확인할 수 있는데, 만약 A와 B가 독립이라면, $P(A|B) = P(A)$이다.  \n  즉, B가 발생했는지 여부는 A의 결과에 영향을 안준다는 것이다.\n- **Partition**  \n  Sample Space($\\Omega$)를 겹치지 않고, 모두 포함하는 Event의 집합을 의미한다. 따라서, 이를 식으로 다음과 같이 표현할 수 있다.  \n  $\\cup_{i=1}^{n}{P_i} = \\Omega$ 이고, $\\cap_{i=1}^{n}{P_i} = \\emptyset$\n- **Marginalization**  \n  전체 Sample space($\\Omega$)에 대하여 **B**가 이에 대한 partition일 때, 아래 공식이 성립한다.  \n  $P(A) = \\sum_{i=1}^{n}{P(A,B_i)} = \\sum_{i=1}^{n}{P(A|B_i)P(B_i)}$\n- **Bayes' Theorem**  \n  만약 $P(B) \\neq 0$라면, 아래 공식이 성립한다. 간단히 conditional probability를 풀어주면 아래 식을 얻을 수 있다.  \n  $P(A|B) = {P(B|A)P(A)\\over{P(B)}}$  \n  해당 식은 단순히 Joint Probability로 변환하고, 다시 반대 확률로 변경했을 뿐이다. 이 공식이 중요하다기 보다는 이 공식이 가지는 의미를 이해하는 것이 중요하다. 확률을 사건의 발생의 빈도로 이해하는 Frequentist Approach에서는 관측을 통해서 특정 데이터가 발생할 확률을 얻는다. 만약 우리가 원하는 확률이 관측을 통해서는 얻을 수 없는 데이터라고 하자. 이 경우에 우리는 확률의 역연산이 필요하다. 위의 공식을 보면 특이한 것이 보이는데, 바로 $P(A|B)$와 $P(A)$이다. 이는 전체 확률을 통해서 **Conditional Probability**를 찾는 것이다. 그렇기에 우리는 이를 역연산이라고 부르며, 우리가 가지고 있는 기존 **사전 확률**(Priority, 이전까지 맞을 거라고 생각한 확률)을 통해서 데이터가 주어졌을 때의 사건의 확률을 다시 계산해보는 것이다. 이 과정을 **Bayesian Update**라고 하는데 이 과정을 통해서 얻은 $P(A|B)$를 다시 다음 데이터에 대해서는 $P(A)$로써 활용하는 것이다. 이렇게 해서 우리는 점진적으로 $P(A)$를 찾아나갈 수 있다.\n\n### Random Variable\n\nRandom Variable이라는 것은 특정 사건을 수학적으로 표현하기 위해서 변형하는 과정을 의미한다. 우리는 이전 예시에서 두 개의 동전을 동시에 던져서 나온 결과를 Sample Space로 두었고, 이를 $\\Omega = $ $\\{ hh, ht, th, tt \\}$라고 표현했다. 하지만, 이와 같은 표기 방식은 수학적인 연산을 적용하기 어렵다. 따라서, 우리는 앞면이 나온 경우를 $X=1$, 뒷면이 나온 경우를 $X=-1$ 라고 하는 형태로 치환하는 것이다. 여기서 만들어진 X를 우리는 Random Variable이라고 부른다. 이런 치환을 통해서 우리는 확률을 Random Variable에 대한 함수로 표현할 수 있다.\n\n또, Random Variable을 정의하여 다음과 같은 값을 연속적으로 정의할 수 있다.\n\n- **Mean**  \n  Random Variable의 평균 또는 기댓값이라고 부른다.  \n  $\\mu_{X} = E[X] = \\sum_{x}{xP(X=x)}$\n- **Variance**  \n  평균에서 데이터가 떨어진 정도를 표현하는 값으로 분산이라고 부른다.  \n  $\\sigma_{X}^{2} = E[(X-\\mu_{X})^2] = E[X^2] -\\mu_{X}^{2}$\n- **Covariance**  \n  Random Variable X와 Y의 상관관계(Correlation)을 확인하는 척도로 사용한다.  \n  $cov(X, Y) = E[(X-\\mu_{X})(Y-\\mu_{Y})] = E[XY] -\\mu_{X}\\mu_{Y}$  \n  만약, 두 X와 Y가 서로 전혀 상관이 없다(Independent)면, $cov(X, Y) = 0$이다. 그 반대는 성립하지 않지만, 그럴 가능성이 굉장히 높아진다.\n- **Correlation Coefficient**  \n  Covariance보다 더 엄격한 상관관계를 확인하는 척도로 사용되는데, 단순히 Covariance를 각 표준편차($\\sigma$)로 나눈 것이다. 이로 인해 결과 값은 [-1, 1] 사이 값이 된다.  \n  $corr(X, Y) = {cov(X,Y)\\over{\\sigma_{X}\\sigma_{Y}}}$  \n  따라서, \u003cmark\u003e1일 수록 두 Random Variable의 상관성이 높으며 비례하는 관계라는 것을 의미하며, -1일 경우에는 상관이 높지만 반비례하는 관계라는 것을 의미한다. 반대로, 0인 경우는 상관 관계가 아주 낮음으로 독립일 가능성이 높다.\u003c/mark\u003e 그렇다고 100%는 아니지만, 단지 그럴 확률이 굉장히 높다는 것이다. 주의할 점은 Correlation Coefficient가 1이라고 X가 Y의 원인이 되는 것은 아니라는 것을 유의해야 한다. 단순히 X가 일어났을 때, Y가 일어날 확률이 높다는 것이다.  \n\n### Law of Large Numbers\n\n경험적 확률과 수학적 확률 사이의 관계를 나타내는 법칙으로, 전체 경우의 수와 이에 따른 확률(모집단)이 있을 때, 관측한 경우의 수와 이에 따른 확률(표본 집단)은 관측 데이터의 크기가 커질 수록 표본 평균이 모평균에 가까워짐을 의미한다.\n\n### 자주 사용되는 Probability Distribution Function\n\n특정 task의 경우 이미 정의된 확률 분포를 통해서 표현할 수 있는 경우가 있다. 따라서, 아래와 같은 대표적인 확률 분포는 알아두는 것은 중요하다.\n\n- **Bernoulli distribution**  \n  하나의 사건이 일어날 확률을 의미한다. 발생하는 경우를 X=1, 그렇지 않은 경우를 X=0으로 random variable로 치환하여 나타낸 확률 분포(probability distribution)이다. 대표적인 사건은 동전 던지기와 같은 두 개의 결과만 갖는 binary event을 표현할 때이다.  \n  따라서, 사건이 일어날 확률을 p라고 할 때, 다음과 같이 Random Variable에 대한 확률을 정의할 수 있다.  \n  $P(X=x) = p^{x}(1-p)^{1-x}$\n  복잡해보이지만, 실상은 X가 0 또는 1이므로, $P(X=0)=1-p$이고, $P(X=1)=p$이다.\n  - 평균\n    $E[X] = p$\n  - 분산  \n    $Var[X] = E[X^2] - \\mu_{X}^2 = p - p^2 = p(1-p)$\n- **Binomial Distribution**  \n  확률이 p인 사건을 n번 수행했을 때, x번 발생할 확률을 의미한다. 따라서, Random Variable X의 범위는 {0, 1, …, n}이 된다. 대표적인 사건은 동전 던지기를 여러 번 던졌을 때, 앞 면이 x번 나올 경우의 수이다.  \n  이에 따라 Random Variable에 대한 확률을 정의하면 다음과 같다.  \n  $P(X=x) = {n \\choose x}p^x(1-p)^{n-x}$  \n  이 또한 복잡해 보이지만, 사실은 독립적인 Bernoulli의 연속 수행으로 볼 수 있다.  \n  - 평균  \n    $E[X] = np$\n  - 분산  \n    $Var[X] = Var[\\sum_{i}X_i]=\\sum_iVar[X_i]=np(1-p)$\n- **Beta Distribution**  \n  $\\alpha, \\beta \u003e 0$를 만족하는 두 parameter를 이용한 probability distribution이다.  \n  이는 [0, 1]에서 continuous한 random variable를 이용할 수 있다. 이에 따른 확률은 다음과 같다.  \n  $P(X=x) \\propto x^{\\alpha-1}(1-x)^{\\beta-1}$  \n  이에 대한 의미를 이해하자면, 확률에 대한 확률 분포이다. 각 $\\alpha - 1$와 $\\beta - 1$를 성공 횟수, 실패 횟수라고 하자.  이는 이미 알고 있는 모집단(전체 집합)의 계산 결과이다. 그리고 random variable을 특정 event의 확률이라고 하자. 예를들면, 동전 던지기를 할 때, 앞면이 나올 확률이 $1\\over2$이라는 것을 이미 알고 있다. 따라서, 우리는 $\\alpha - 1$ = $\\beta - 1$ 라는 것을 알고 있는 것이다. 하지만, 실제로 동전 던지기를 5번 수행했을 때, 4번 앞면이 나왔다고 하자. 그렇다면, 우리가 추측한 해당 event의 확률은 $4\\over5$이 된다. 그렇다면, 실제로 해당 확률이 $4\\over5$일 확률을 얼마나 될까?  \n  이를 측정하기 위한 것이 Beta distribution인 것이다. 이에 따라, Beta distribution을 PDF로 표현하면 ${\\alpha\\over\\alpha+\\beta}$에서 높은 확률값을 가지는 것을 볼 수 있다.\n  - 평균  \n    $E[X] = {\\alpha\\over{\\alpha+\\beta}}$\n  - 분산  \n    $Var[X] = {\\alpha\\beta\\over{(\\alpha+\\beta)^2(\\alpha+\\beta+1)}}$\n\n  위의 평균과 분산을 보면 알 수 있듯이, 만약 이전 모집단에서의 평균값에 대한 믿음이 크다면, 각각  $\\alpha, \\beta$의 비율은 유지하면서 상수배를 수행하여 평균은 동일하지만 분산 값을 더 적게 만들어 뾰족한 형태의 분포를 완성할 수도 있다. 이 경우에는 평균과 맞지 않는 표본집합에서의 평균을 굉장히 확률이 낮은 확률로 식별하는 것이다.\n- **Gaussian Distribution**  \n  $\\mu, \\sigma^2$를 parameter로 갖는 probability distribution이다.\n\n  이는 $[-\\infin, \\infin]$를 구간으로 continuous한 random varible을 이용한다. 이에 따른 확률은 다음과 같다. (단일 random variable인 경우)\n  \n  $P(X) = {1\\over{\\sqrt{2\\pi\\sigma^2}}}\\exp(-{1\\over{2\\sigma^2}}(X-\\mu)^2)$\n\n  이 분포는 굉장히 많은 곳에 사용되는데 \u003cmark\u003e우리가 생각할 수 있는 대게의 자연 발생에 의한 현상들(ex. 사람 키의 분포)이 이 분포를 따르기 때문이다.\u003c/mark\u003e 그렇기에 다양한 환경에서 많이 사용되는 분포이다. 뿐만 아니라 (Lindeberg-Levy) **Central Limit Theoriem**에 따르면, 표본에서 얻은 표본 평균을 구하면 구할 수록 점점 Gaussian Distribution을 따라간다. 즉, $n \\rarr \\infin$이면, 표본 평균이 이루는 분포가 Gaussian이라는 것이다.\n  \n  추가적으로 알아볼 것은 바로 여러 개의 Random Variable로 Gaussian Distribution을 더 높은 차원으로 구성할 수 있다는 것이다. 이를 수행하면, Gaussian 분포가 평균과 분산을 포함하기 때문에 두 데이터의 경향성(Covariance)를 어느정도 파악할 수 있다.\n\n## Calculus\n\n일명 미적분학으로, 대게의 미적분 법칙은 모두 알고 있을 것이라고 생각하고 넘어간다.\n\n### Optimization\n\n정말 모두가 알고 있을 거 같지만, 그럼에도 중요하기 때문에 정리하고 넘어가자. 일반적으로 Optimization이란 최적값을 찾는 과정이다. 이 과정에서 대게 사용되는 것이 최솟값 또는 최댓값이다. 우리는 최솟값/최댓값을 미분을 통해서 구할 수 있다.\n\n여기서는 Convex라는 성질에 대해서 자세히 다루지 않는다. 시간이 있다면, 이에대한 개념도 반드시 숙지하기를 바란다.\n\n\u003e **최대/최소 구하기**\n\n모두가 알다시피 함수의 미분은 기울기를 의미한다. 만약 함수의 미분에 특정 값을 대입할 경우 이는 그 지점에서의 기울기를 의미한다.\n\n먼저, 함수의 미분에 대입한 값이 0인 경우에 해당 값(극값)이 가지는 성질을 기억해야 한다. 만약, 값이 0으로 하는 값을 기준으로 좌우 부호가 바뀐다면, 이는 정말 극대, 극소라는 의미를 가진다. 즉, 해당 구간에서 최소와 최대라는 의미를 가지는 것이다.\n\n이를 이해하기 위해서는 함수의 기울기의 부호가 바뀌었다는 의미를 살펴보아야 한다. 이는 함수의 값이 구간 내에서 가장 작은 값(극소) 또는 구간 내에서 가장 큰 값(극대)라는 것을 의미한다. 왜냐하면, 직관적으로 기울기가 0이 되기 전까지는 계속해서 증가/감소해왔다는 것을 알기 때문이다. 따라서, 우리는 기울기가 0인 지점을 모두 찾아 비교하면, 그 안에서 최대/최소를 찾을 수 있을 것이다.\n\n그런데 어떻게 하면, 기울기가 0인 지점이 극대인지 극소인지를 구분할 수 있을까? 이것은 바로 직전의 값을 미분 함수에 대입해보면 쉽게 알 수 있다. 하지만, 이것이 매번 그렇게 쉽게 판별되는 것은 아니다. 따라서, 우리는 이중 미분을 사용한다. 이중 미분 함수에 극값을 대입했을 때 양수라면 이는 극소를 의미하고, 음수인 경우는 극대를 의미한다. 이 또한, 직관적으로 기울기의 변화량이라는 이중 미분의 정의를 알면, 직관적으로 와닿을 수 있다.\n\n이렇게 해서 극대와 극소를 골라내고, 이중에서 가장 큰 값과 가장 작은 값을 찾아내면, 우리는 이것을 함수의 최적화를 수행했다고 한다.\n\n### Constraint Optimization\n\n여기서는 특별한 case를 위한 예시이다. 특정 조건이 주어졌을 때, 이를 만족하면서 특정 함수의 optimization을 수행하는 것이다.\n\n그러면 우리가 최적화하고자 하는 목적함수($\\mathcal{J}(\\bold{x})$)와 등식 제약 조건($h_{j}(\\bold{x})$), 부등식 제약 조건($g_{i}(\\bold{x})$)을 살펴보자.\n\n우리는 모든 최적화 문제를 다음과 같은 형태로 묘사할 수 있다.\n\n$$\n\\begin{align*}\n  \\text{minimize}   \\quad \u0026 \\mathcal{J}(\\bold{x}) \u0026\\\\\n  \\text{subject to} \\quad \u0026 g_{i}(\\bold{x}) \\leq 0, \u0026 i = 1, ..., M \\\\\n                          \u0026 h_{j}(\\bold{x}) = 0, \u0026 j = 1, ..., L\n\\end{align*}\n$$\n\nmaximization인 경우는 음수를 취해서 결과를 구한 후 변환 시에 다시 음수를 취해주면 된다. 그리고 부등호가 반대인 제약 조건인 경우에도 양변에 음수를 취해서 간단하게 뒤집는 것이 가능하다.\n\n이러한 문제를 풀기 위해서는 우리는 식을 **Lagrangian** 형태로 변환해야 한다.\n\n\u003e **Lagrangian**\n\n이는 조건부식에 있는 조건에 변수($\\nu$, $\\lambda$)를 곱한 값의 합과 원래 목적 함수($\\mathcal{J}(\\bold{x})$)의 합이다.\n\n$$\n\\mathcal{L}(\\bold{x}, \\boldsymbol{\\nu}, \\boldsymbol{\\lambda}) = \\mathcal{J}(\\bold{x}) + \\sum_{i=1}^{M}{\\nu_{i}g_{i}(\\bold{x})} + \\sum_{j=1}^{K}{\\lambda_{j}h_{j}(\\bold{x})}\n$$\n\n여기서 **Lagrangian** 함수의 optimization이 곧 목적함수의 optimization이다. 증명은 수행하지 않는다. 이에 대한 추가적인 설명이 필요한 경우에는 직접 찾아보아야할 것이다.  \n여기서 만약 등식만 있는 식인 경우에 우리는 간단히 모든 변수에 대해서 편미분이 0이 되는 등식을 이용해서, 최적 $\\bold{x}$를 찾을 수 있다. 위에 식에서 부등식 조건($g_{i}(\\bold{x})$)이 사라진다면, 우리는 미분을 통해서 처리해야하는 값은 총 x의 크기(N)와 L이다. 이는 우리가 편미분해서 구할 수 있는 식의 갯수와 똑같다. 즉, 우리가 모르는 변수는 N+M개 우리가 가진 등식은 N+M개이므로 연립해서 각 값을 구할 수 있는 것이다.\n\n하지만, 부등식인 경우에는 추가적으로 고려해줘야할 것이 있다.\n\n\u003e **KKT Condition**\n\n이는 우리가 최적값($\\bold{x}_{*}$)를 찾았을 때, 다음과 같은 $\\boldsymbol{\\nu_{*}}$, $\\boldsymbol{\\lambda_{*}}$가 존재해야 한다는 정리이다.\n\n1. **Optimality**  \n   $\\nabla\\mathcal{L} = \\nabla\\mathcal{J}(\\bold{x}_{*}) + \\sum_{i=1}^{M}{\\nu_{*(i)}\\nabla g_{i}(\\bold{x}_{*})} + \\sum_{j=1}^{L}{\\lambda_{*(j)}\\nabla h_{j}(\\bold{x}_{*})} = 0$  \n   위에서 보았던 최적화를 수행하는 식이다.\n2. **Feasibility**  \n   $g_{i}(\\bold{x}_{*}) \\leq 0,  i = 1, ..., M$  \n   $h_{j}(\\bold{x}_{*}) = 0,  j = 1, ..., L$  \n   조건이 만족하는지를 확인하는 것이다.\n3. **Complementary slackness**  \n   $\\nu_{*(i)}g_{i}(\\bold{x}_{*}) = 0, i = 1, ..., M\\quad(\\nu_{*(i)} \\geq 0)$  \n   위의 식은 다소 헷갈릴 수 있는데 가장 알아듣기 쉬운 형태는 아래이다.  \n   $g_{i}(\\bold{x}_{*}) \\lt 0\\text{, then } \\nu_{*(i)} = 0$  \n   $g_{i}(\\bold{x}_{*}) = 0\\text{, then } \\nu_{*(i)} \u003e 0$\n\n위의 식을 만족하는 $\\bold{x}_{*}$, $\\boldsymbol{\\nu_{*}}$, $\\boldsymbol{\\lambda_{*}}$를 찾으면, 그것이 최적값에서의 $\\bold{x}_{*}$이다.\n\n\u003e **Lagrangian Dual Problem**\n\n여기서 한 발 더 나아가면, Lagrangian에 다시 한번 Lagrangian을 취할 수 있다.\n\n우리가 만약 Lagrangian의 하한을 $\\mathcal{G}(\\boldsymbol{\\nu}, \\boldsymbol{\\lambda})$이라 하고,\n\n$$\n\\mathcal{G}(\\boldsymbol{\\nu}, \\boldsymbol{\\lambda}) = \\inf_{\\bold{x} \\in \\mathcal{X}}\\mathcal{L}(\\bold{x}, \\boldsymbol{\\nu}, \\boldsymbol{\\lambda})\n$$\n\n$\\boldsymbol{f}^{*}$을 최적값이라고 한다면, 아래 식이 성립한다.\n\n$$\n\\boldsymbol{f}^{*} \\geq \\min_{\\bold{x}}\\mathcal{L}(\\bold{x}, \\boldsymbol{\\nu}, \\boldsymbol{\\lambda}) := \\mathcal{G}(\\boldsymbol{\\nu}, \\boldsymbol{\\lambda})\n$$\n\n따라서, 우리는 $\\mathcal{G}$의 최댓값을 찾으면 해당 값이 최적해에 근사한다는 것을 알 수 있다.\n\n이는 우리가 풀고자 하는 문제의 형식을 다시 한 번 바꾸게 된다.\n\n$$\n\\begin{align*}\n  \\text{minimize}   \\quad \u0026 \\mathcal{G}(\\boldsymbol{\\nu}, \\boldsymbol{\\lambda}) \u0026\\\\\n  \\text{subject to} \\quad \u0026 \\boldsymbol{\\nu}_{i} \\geq 0, \u0026 i = 1, ..., M\n\\end{align*}\n$$\n\n이 식을 KKT condition을 이용하여 푸는 것이 기존 식보다 쉽게 풀 수 있는 경우가 많다. 따라서, 이러한 형태로 문제를 풀이할 수도 있다.\n\n## Information Theory\n\n### Entropy\n\n수학에서 정보의 불확실성(uncertainty)을 표현하기 위해서 물리의 entropy 라는 개념을 도입한 것이다. 즉 정보가 가지는 \"surprise\" 정도가 크다면, entropy가 큰 정보를 의미하고, 일반적인 정보라면 이는 entropy가 작은 정보인 것이다.\n\n수학적으로 다시 정의하자면, 다음과 같다.  \nsample space $\\Omega$에서 정의된 random variable $X$와 확률 $p_{X}(x)$이 주어질 때, Entropy를 $H(x)$라 하자.\n\n$$\nH(X) = -\\sum_{x \\in \\Omega}p(x)\\log_{2}p(x)\n$$\n\n위 식에서 log의 밑이 2인 것을 알 수 있는데 computer science에서는 정보가 bit단위로 저장되기 때문에 기본적으로는 2를 사용한다. 하지만, 상황에 따라서는 다른 밑을 사용할 수도 있다.\n\n헷갈릴 수 있는데 표기법이 굉장히 다양하니 유의해서 보도록 하자.\n\n$$\nH(X) = H_{p}(X) = H(p) = H_{X}(p) = H(p_{X})\n$$\n\n\u003e **최댓값과 최솟값**\n\nEntropy는 정보의 불확실성을 나타낸다고 했다. 즉, 정보가 확실할 수록 Entrophy는 0으로 수렴하며, 확실히 아는 정보의 경우 Entropy가 최솟값인 0이 된다.  \n반대로 Entropy의 최댓값의 경우 $|\\Omega| = n$이라고 할 때, $\\log_{2}{n}$이다. 이는 uniform distribution(모든 Random Variable의 확률이 같은 분포)일 경우이다.\n\n$$\n0 \\leq H(x) \\leq log_{2}{|\\Omega|}\n$$\n\n\u003e **$\\bold{\\log_{2}({1 \\over p_{X}(x)})}$의 평균**\n\nEntropy를 random variable x의 확률의 역수의 log를 취한 값으로 해석할 수도 있다.\n\n$$\n\\begin{align*}\nE[\\log_{2}(({1 \\over p_{X}(x)})] \u0026= \\sum_{x \\in X}p_{X}(x)\\log_{2}({1 \\over p_{X}(x)}) \\\\\n\u0026= -\\sum_{x \\in X}p_{X}(x)\\log_{2}(p_{X}(x)) \\\\\n\u0026= H(p_{X})\n\\end{align*}\n$$\n\n여기서 우리는 $\\log_{2}({1 \\over p_{X}(x)})$을 **정보량**이라고 정의한다. 식에서도 알 수 있지만, 정보량과 해당 정보량을 얻을 확률은 반비례한다.\n\n\u003e **Joint, Conditional Entropy**\n\nRandom Variable이 두 개 이상일 때, 이를 적용할 수 있다. 유도 과정은 $H(X)$가 Expectation과 어떤 관계였는지를 떠올려 보면 알 수 있다.\n\n- **Joint Entropy** : $H(X, Y) = -\\sum_{x \\in \\Omega_{X}}\\sum_{y \\in \\Omega_{Y}}p(x, y)\\log_{2}p(x, y)$\n- **Conditional Entropy** : $H(Y|X) = -\\sum_{x \\in \\Omega_{X}}\\sum_{y \\in \\Omega_{Y}}p(x, y)\\log_{2}p(y|x)$\n\n\u003e **properties**\n\n1. **Chain Rule**  \n   $H(X, Y) = H(Y|X) + H(X)$  \n   $H(X, Y) = H(X|Y) + H(Y)$\n2. **Conditional Entropy's Maximum**  \n   $H(Y|X) \\leq H(Y)$  \n   독립일 때 같아지며 그 외에는 항상 Conditional의 Entropy가 더 낮다. 의미를 이해하면 쉽다. 한 마디로 X라는 정보가 Y라는 정보가 발생할 확률에 대한 티끌이라도의 힌트를 준다면, 해당 불확실성은 감소하게 되는 것이다.\n3. **Joint Entropy's Maximum**  \n   $H(X, Y) \\leq H(X) + H(Y)$  \n   동일하게 독립일 때 같아지며, 그 외에는 항상 Joint의 Entropy가 더 낮다. 이 또한, 두 사건이 티끌이라도 겹치는 Event가 있다면, 각 Entropy를 더하는 것보다 당연히 작을 수 밖에 없는 것이다.\n4. **Concave**  \n   Entropy의 그래프는 항상 concave하다.\n\n\u003e **Coding**\n\n정보 이론이 활발하게 사용되는 예시 중에 하나가 바로 데이터의 Encoding/Decoding을 수행하여 bit data로 mapping할 때이다. variable length encoding을 알고 있다면, 이에 대한 이해가 쉬울 것이다. 쉽게 설명하면, 데이터를 bit sequence로 mapping할 때 모든 데이터에게 동일한 bit sequence의 길이만큼을 할당하는 게 아니라 빈도가 높은 데이터부터 짧은 bit sequence 길이를 할당하는 방식이다. 이때 bit sequence의 길이를 Entropy를 이용해서 구할 수 있다. 이 길이는 항상 해당 데이터의 Entropy보다는 커야 한다. 따라서, 해당 Entropy보다 큰 가장 작은 자연수가 해당 데이터의 Bit Sequence 길이의 최적값이다.\n\n### KL divergence(Relative Entropy)\n\nKullback-Leibler Divergence의 약자로, 우리가 구하고자하는 실제 확률(p)과 추측 확률(q) 사이의 오차를 계산할 때 사용하는 지표이다. 따라서, 동일한 Sample Space와 Random Variable에 대한 서로 다른 확률 분포를 비교한다고 생각할 수 있다.\n\n$$\nD(p||q) = KL(p||q) = \\sum_{x \\in \\Omega}p(x)\\log_{2}(p(x)/q(x)) = E_{p}[\\log_{2}({p(x) \\over q(x)})]\n$$\n\n아쉽게도 KL divergence는 거리와 같은 연산을 적용할 수 없다. 즉, 둘 사이의 역연산은 같지 않을 뿐만 아니라($D(p||q) \\neq D(q||p)$), 서로 다른 Random Variable의 KL divergence의 합이 Random Variable의 합의 KL divergence와는 다르다.\n\n### Mutual Information\n\nKL divergence를 활용하여 서로 다른 Random Variable X,Y의 연관성을 유추하는 것도 가능하다.\n\n$$\nI(X, Y) = D(p(x,y) || p(x)p(y))\n$$\n\n$I$값이 의미하는 것은 Y를 아는 것이 X의 추측을 얼마나 쉽게하는지에 대한 지표로 작용한다.\n\n증명 과정은 생략하지만, 위의 식을 정리하면 결국은 아래와 같아지기 때문이다.\n\n$$\n\\begin{align*}\n  I(X, Y) \u0026= H(X) - H(X|Y) \\\\\n  \u0026= H(Y) - H(Y|X)\n\\end{align*}\n$$\n\n### Cross Entropy\n\n우리가 특정 corpus(dataset)를 통해서 확률을 추정했다고 해보자. 그렇다면, 우리는 이 가설을 증명하기 위해서 다른 data에 대해서 해당 추측이 적절한지를 확인하여 정당성을 증명할 수 있다. 그러기 위해서 우리가 만든 확률에서 정보량을 추출하고, 이를 우리가 알고 있는 data의 공간에 넣었을 때의 확률을 추정하기 위해서 Cross Entropy를 사용할 수 있다.\n\n$$\nH_{q}(p) = \\sum_{x \\in \\Omega}q(x)\\log_{2}{1 \\over p(x)}\n$$\n\n간단하게 요약하면, 위 식은 틀릴 수 있는 정보를 갖고 구한 최적의 Entropy로, 정보량에 추측 정보량을 넣고, 확률에는 실제 확률을 넣는 방식이다.\n\n또한, 이는 다음과 같이 변형되기도 한다.\n\n$$\nH_{q}(p) = H(q) + D(q || p)\n$$\n\n또한, 특정 조건이 주어졌을 때의 Conditional Cross Entropy는 다음과 같다.\n\n$$\nH_{q}(p) = - \\sum_{y \\in \\Omega_{Y}}\\sum_{x \\in \\Omega_{X}}q(y,x)\\log_{2}p(y|x)\n$$\n\n하지만, 실제 구현 level에서는 이러한 Cross Entropy를 정석으로 구하는 것은 비용이 크다. 따라서, 이와 근사하는 식을 사용한다.\n\n$$\n\\begin{align*}\n  H_{q}(p) \u0026= - \\sum_{y \\in \\Omega_{Y}}\\sum_{x \\in \\Omega_{X}}q(y,x)\\log_{2}p(y|x) \\\\\n  \u0026= {1\\over{|T_{Y}|}}\\sum_{i=1..|T_{Y}|}{\\log_{2}p(y_{i}|x_{i})}\n\\end{align*}\n$$\n\n위 식을 이용할 때에는 실제 데이터와 비교에 사용해서는 안된다. 대신 두 개의 서로 다른 p,q가 있을 때, s라는 실제 분포에 어떤 것이 더 적절한지를 판명할 때 사용할 수 있다.\n\n## Reference\n\n- Tumbnail : Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=unsplash\u0026utm_medium=referral\u0026utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@markuswinkler?utm_source=unsplash\u0026utm_medium=referral\u0026utm_content=creditCopyText)\n","slug":"ml-base-knowledge","date":"2022-10-14 19:28","title":"[ML] 0. Base Knowledge","category":"AI","tags":["ML","Probability","Calculus","InformationTheory"],"desc":"Machine Learning은 data들로 부터 특정 pattern을 나타내는 function을 만드는 것이라고 할 수 있다. 즉, pattern은 data에 대한 간단한 요약본이라고 볼 수 있다.확률/통계 이론 및 선형대수, 미적분, 정보 이론 관련 기본 내용을 해당 포스팅에 정리한다. 여기서 다루는 내용은 대게 많이 추상적인 내용이며, 키워드 중심의 내용이다. 만약, 추가적인 설명이 필요하다면 키워드를 기반으로 더 검색을 하는 것이 좋을 것이다.","thumbnailSrc":"https://euidong.github.io/images/ml-thumbnail.jpg"},{"content":"\n## Intro\n\nMachine Learning은 특정 목표를 달성하기 위해서 데이터로 부터 pattern 또는 가정 등을 유도해내는 방법이다.\n이를 위한 가장 일반적인 방법은 여러 개의 확률분포와 이것의 parameter의 조합(probabilistic model)들 중에서 측정된 데이터들을 가장 잘 나타내는 하나를 찾아내는 것이다.\n그 중에서, 확률 분포를 결정한 상태에서 parameter를 찾아나가는 형태의 접근법을 우리는 Parametric Estimation이라고 한다. 그 외에도 Nonparametric, Semi-parametric 방식도 존재하지만 이는 여기서는 다루지 않는다.\n\n## Small Example\n\n간단한 예시를 통해서 Parametric Estimation의 흐름을 익혀보자.\n\n한 학급에서 학생들의 형제자매 수에 대한 예측을 하고 싶다고 하자.  \n그렇다면, 우리는 먼저 조사(관측)를 수행해야 한다. 이를 통해서 다음과 같은 데이터를 얻게 되었다고 하자.\n\n| x        | 1    | 2    | 3    | 4    | 5    | 6    | x$\\geq$7 |\n| :------- | :--- | :--- | :--- | :--- | :--- | :--- | :------- |\n| $p(X=x)$ | 17   | 59   | 15   | 6    | 2    | 0    | 1        |\n\n여기서 우리는 여러 사전 지식을 활용하여 해당 데이터를 보았을 때, 해당 분포가 Poisson 분포의 형태라는 것을 알 수 있다.  \n따라서, 우리는 해당 분포를 Poisson이라고 가정한 다음에는 단순히 해당 분포에 대입하며, 가장 적절한 parameter만 찾으면 된다.  \n\n이 과정과 단순히 각 x에서의 확률값을 구하는 방식이랑 무엇이 다른지를 알아야지 해당 과정의 의의를 알 수 있다.\n먼저, 우리가 하고자 하는 일이 형제자매의 평균 수를 구한다고 하자. 이때의 평균 값과 Poisson 분포에서의 확률값은 다를 수 밖에 없다.\n\n이렇게 확률 분포를 구하는 것의 의미는 이것말고도 보지 않은 데이터(unseen data)를 처리함에 있다. 우리가 만약 모든 가능한 경우의 수를 모두 알고 있고, 이를 저장할 공간이 충분하다면,\n이러한 확률 분포를 구할 필요가 없다. 하지만, 우리가 원하는 추측은 unseen data에 대해서도 그럴사해야 한다. 이를 위해서는 결국 확률 분포가 필요하다.\n\n위의 예시에서 만약, 형제자매가 3명인 경우의 데이터가 없다고 하자. 이 경우에도 확률분포를 통한 추측을 한다면, 우리는 유의미한 값을 구할 수 있는 것이다.\n\n## Parametric Estimation\n\n\u003e **정의**\n\nsample space $\\Omega$에서 통계 실험의 관측 결과를 통해서 얻은 sample $X_1$, $X_2$, ... , $X_n$이 있다고 하자. 각 sample에 대한 확률 분포를 우리는 $p_\\theta$라고 한다.\n여기서 $\\theta$는 특정 확률 분포에서의 parameter를 의미한다. 만약, bernoulli 라면, 단일 시행에 대한 확률이 될 것이고, binomial이라면, 단일 시행의 확률과 횟수가 해당 값이 될 것이다.\n\n\u003e **성능 평가**\n\n여기서 우리가 찾기를 원하는 것은 전체 sample space $\\Omega$를 모두 잘 표현할 수 있는 $\\theta_{*}$(실제 true $\\theta$)를 찾는 것이다.(이미 확률 분포의 형태(함수, ex. Bernoulli, Binomial)는 이미 정의되어 있다.)  \n그렇다면, 실제 $\\theta_*$와 추측을 통해 만든 $\\hat{\\theta}$ 사이의 비교를 위한 지표도 필요할 것이다. 즉, 우리가 만든 확률 분포의 예측 성능평가가 필요하다는 것이다. 이를 측정하기 위해서 우리는 **Risk**라는 것을 사용한다.  \n간단하게도 실제 $\\theta_*$와 $\\hat{\\theta}$의 Mean Square Error를 계산한다.\n\n$$\n\\begin{align*}\nRisk \u0026= E[(\\hat{\\theta} - \\theta_*)^2] = E[\\hat{\\theta}^2 - 2\\hat{\\theta}\\theta_* + \\theta_*^2] \\\\\n\u0026= E[\\hat{\\theta}^2] - 2\\theta_*E[\\hat{\\theta}] + \\theta_*^2 \\\\\n\u0026= E[\\hat{\\theta}^2] - 2\\theta_*E[\\hat{\\theta}] + \\theta_*^2 + (E^2[\\hat{\\theta}] - E^2[\\hat{\\theta}]) \\\\\n\u0026= (E[\\hat{\\theta}] - \\theta_*)^2 + E[\\hat{\\theta}^2] - E^2[\\hat{\\theta}] \\\\\n\u0026= {Bias}^2 + Var[\\hat{\\theta}]\n\\end{align*}\n$$\n\n해당 식을 분석해보면, 이와 같은 의미로 해석하는 것이 가능하다. 우리가 특정 확률 분포의 파라미터를 단 하나로 단정하고 Risk를 계산하는 경우는 Variance 값은 0이다. 즉, 해당 확률 분포가 가지는 Risk는 단순히 해당 parameter와 실제 parameter가 얼마나 찾이가 나는가를 의미한다.\n\n하지만, parameter를 특정하지 않고, 범위로 지정한다면, (예를 들어, 주사위를 던져 3이 나올 확률은 1/6 ~ 1/3이다.) 해당 확률의 평균과 Variance가 영향을 미칠 것이다.  \n다소 처음에는 헷갈릴 수 있지만, 해당 식에서 평균이 의미는 잘 확인하자. 특정 확률 분포를 가지도록 하는 $\\theta$가 $\\theta_*$ 에 얼마나 근접한지를 확인하기 위한 식이라는 것을 다시 한 번 기억하자.\n\n\u003e **Estimation**\n\n이제부터는 앞에서 살펴보았던, parameteric estimation에서 어떻게 $\\hat{\\theta}$를 구할 수 있는지를 다룰 것이다. 확률/통계 이론에서는 크게 3가지로 나눌 수 있다고 볼 수 있다. 각 각을 살펴보도록 하자.\n\n\u003cmark\u003e**1. MLE**\u003c/mark\u003e\n\nMaximum Likelihood Estimation의 약자이다. 여기서, Likelihood는 가능성이라는 뜻을 가지며, 확률/통계 이론에서 이는 확률을 해당 사건이 발생할 가능성으로 해석하는 것이다. 이를 이용해서 우리가 풀고자 하는 문제, 우리가 추측한 $\\theta$가 우리가 가진 Dataset를 만족시킬 가능성을 확인하기 위해 사용한다. 아래 수식을 보자.\n\n$$\n\\begin{align*}\n\\mathcal{L}(\\theta;\\mathcal{D}) \u0026= p(\\mathcal{D}|\\theta) = p(x_1, x_2, ..., x_n|\\theta) \\\\\n\u0026= \\prod_{i=1}^{n}{p(x_i|\\theta)}\n\\end{align*}\n$$\n\n(위 식을 이해하려면, 먼저 Dataset의 각 data들은 서로 independent하다는 사실을 기억하자.)  \n결국 $\\theta$가 주어졌을 때, Dataset일 확률을 구하는 것이다. 이를 다시 생각하면, $\\theta$가 얼마나 데이터셋의 확률을 잘 표현할 수 있는가와 같다.\n\n이것을 직관적으로 이해하려면 하나의 예시를 보면 좋다.\n\n![MLE example](/images/MLE-example.png)\n\n첫 번째 그래프는 같은 가우시안 분포 함수를 쓰면서, parameter만 다르게 한 경우이고, 아래는 실제 데이터의 분포라고 하자.(빨간색 선 하나 하나가 데이터를 의미)  \n이때, Likelihood를 각 각 구하면 각 x에서의 확률분포의 확률값을 모두 곱하면 된다. 그 경우 어떤 것이 제일 클지는 분명하다. 바로 파란색 분포일 것이다.  \n\n그렇다면, 우리가 원하는 것은 무엇인가? 바로 가장 높은 가능성을 가지게 하는 $\\theta$를 찾는 것이다. 따라서, 이를 식으로 표시하면 아래와 같다.\n\n$$\n\\hat{\\theta}_{MLE} = \\argmax_{\\theta}\\mathcal{L}(\\theta;\\mathcal{D})\n$$\n\n여기서 하나 문제가 있을 수 있다. 바로, 컴퓨터로 연산하게 되면 underflow가 발생하는 것이다. 특정 언어가 계산할 수 있는 소수점 범위를 벗어난다면, 제대로 된 결과를 얻을 수 없다. 이와 같은 문제를 **vanishing likelihood**라고 한다.  \n따라서, 우리는 log를 취했을 때와 log를 취하지 않았을 때의 경향성이 같음을 바탕으로 likelihood에 log를 취한 값을 이용하여 MLE를 구하는 것이 일반적이다. 이 방식을 maxmum log likelihood estimation 이라고 부른다.\n\n$$\n\\mathcal{l}(\\theta;\\mathcal{D}) = \\sum_{i=1}^{n}{\\log{(p(x_i|\\theta))}}\n$$\n\n이 방식을 이용하게 되면, 곱셈이 모두 덧셈으로 바뀌기 때문에 계산에서도 용이하다.\n\n여기까지 살펴보면, 하나의 의문이 들 수도 있다. 바로, $p(\\theta|\\mathcal{D})$도 측정 기준으로 사용할 수 있지 않냐는 것이다. 이 역시도 Dataset이 주어질 때, $\\theta$일 확률이라고 볼 수 있다.  \n어찌보면, 사람의 생각으로는 이게 더 당연하게 느껴질 수도 있다. 이는 바로 다음 MAP에서 다룰 것이다. 우선 MLE를 먼저한 이유는 이것이 더 구하기 쉽기 때문임을 기억해두자.\n\n```plaintext\n 🤔 증명\n\n (*해당 내용은 정보 이론에 기반한 MLE에 대한 추가적인 이해를 위한 내용입니다. 해당 내용은 자세히 알 필요까지는 없습니다.)\n\n 두 확률 분포 간 information Entropy의 차이를 나타내는 KL divergence의 최솟값을 구하는 것이 우리의 목표라고 정의할 수 있다.  \n 따라서, 우리가 결국 얻고자 하는 것은 확률 분포 함수가 주어졌을 때,  \n n이 무한대로 갈 때, 경험적 확률(empirical probability)에 가장 근사하는 parameter를 찾는 것이다.  \n 따라서, 우리는 KL divergence의 최솟값을 구하면 된다.\n```\n\n$$\n\\begin{align*}\n\\argmin_\\theta KL(\\tilde{p}||p_\\theta) \u0026= \\argmin_\\theta \\int\\tilde{p}(x)\\log{\\tilde{p}(x)\\over{p_\\theta(x)}}dx \\\\\n\u0026=\\argmin_\\theta[-\\int\\tilde{p}(x)\\log{\\tilde{p}(x)dx} - \\int\\tilde{p}(x)\\log{p_\\theta(x)dx}] \\\\\n\u0026= \\argmax_\\theta\\int{\\tilde{p}(x)\\log{p_\\theta(x)}dx} \\\\\n\u0026= \\argmax_\\theta\\sum_{i=1}^{n}{\\log{p_\\theta(x_i)}} \\\\\n\u0026= \\theta_{MLE}\n\\end{align*}\n$$\n\n\u003cmark\u003e**2. MAP**\u003c/mark\u003e\n\nMaximum A Posteriori의 약자이다. Posteriori는 사후 확률이라고도 부르며, dataset이 주어졌을 때, $\\theta$일 확률을 구하는 것이다.  \n이를 바로 구하는 것은 다소 어렵다. 왜냐하면, Dataset이 조건으로 들어가는 형태이기 때문이다. ($p(\\theta|\\mathcal{D})$)  \n따라서, 우리는 Bayes' Theorem에 따라서 이전에 배운 Likelihood와 parameter의 확률, 그리고 Dataset의 확률을 활용히여 풀어낼 것이다.\n\n$$\np(\\theta|\\mathcal{D}) = {p(\\mathcal{D}|\\theta)p(\\theta)\\over{p(\\mathcal{D})}}\n$$\n\n여기서 주의해서 볼 것은 바로 $p(\\theta|\\mathcal{D})$와 $p(\\theta)$의 관계이다. dataset이 주어질 때의 parameter의 확률을 구하기 위해서 원래 parameter의 확률이 필요하다는 것이다.  \n어찌보면 굉장히 모순되어 보일 수 있지만, 우리가 이것을 사전 확률(priori)로 본다면 다르게 볼 여지가 있다.  \n예를 들면, 우리가 수상한 주사위로 하는 게임에 참가한다고 하자. 이때, 우리는 수상한 주사위의 실제 확률은 알 수 없지만, 주사위 자체의 확률은 모두 1/6이라는 것을 알고 있다. 따라서, $p(\\theta={1\\over6}) = \\alpha, p(\\theta\\neq{1\\over6}) = \\beta$ 라고 할 수 있다. 만약 정말 수상해보인다면, 우리는 $\\alpha$가 점점 작아진다는 식으로 표현할 수 있고, 하나도 수상해보이지 않는 일반 주사위라면, $\\alpha=1, \\beta=0$으로 할 수도 있다. 이 경우에는 likelihood 값에 상관없이 다른 모든 값이 0이기 때문에 결국은 $p(\\theta|\\mathcal{D}) = p(\\theta)$ 가 되는 것을 알 수 있다.\n\n최종적으로, MAP도 결국은 Dataset을 얼마나 parameter가 잘 표현하는가에 대한 지표로 사용할 수 있다.\n따라서, 이를 최대로 만드는 parameter는 $\\theta_*$와 굉장히 근접할 것이다.\n\n$$\n\\begin{align*}\n\\hat{\\theta}_{MAP} \u0026= \\argmax_{\\theta}p(\\theta|\\mathcal{D}) \\\\\n\u0026= \\argmax_\\theta{p(\\mathcal{D}|\\theta)p(\\theta)\\over{p(\\mathcal{D})}} \\\\\n\u0026=\\argmax_\\theta{p(\\mathcal{D}|\\theta)p(\\theta)} \\\\\n\u0026=\\argmax_\\theta{[\\red{\\log{p(\\mathcal{D}|\\theta)}} + \\blue{\\log{p(\\theta)}}]}\n\\end{align*}\n$$\n\nMLE와 마찬가지로 이 또한 연산 및 **vanishing**을 막기 위해서 log를 취한다. 사실상 likelihood와 사전 확률의 합을 최대로 하는 $\\theta$를 찾는 것이다.\n\n\u003cmark\u003e**3. Bayesian Inference**\u003c/mark\u003e\n\n이제 마지막 방법으로 제시되는 Bayesian Inference이다. 이는 대게 Bayesian Estimation이라고 많이 불리는 것 같다. 이전까지 MLE, MAP는 결국 주어진 식을 최대로 하는 확정적 $\\theta$ 하나를 구하는 것을 목표로 했다.\n\nBayesian Inference는 Dataset이 주어졌을 때, $\\theta$의 평균값을 활용한다. 더 자세히 말하면, Posteriori(사후 확률)의 평균을 구하는 것이다.  \n이를 구하는 과정을 살펴보면 이해하는데 도움이 될 것이다. 한 번 살펴보자.\n\n$$\n\\begin{align*}\n\\hat{\\theta}_{BE}\u0026= E[\\theta|\\mathcal{D}] \\\\\n\u0026= {\\int_{0}^{1}{{\\theta}p(\\theta|\\mathcal{D})}d\\theta} \\\\\n\u0026= {\\int_{0}^{1}{\\theta}{{p(\\mathcal{D}|\\theta)p(\\theta)}\\over{p(\\mathcal{D})}}d\\theta} \\\\\n\u0026= {{\\int_{0}^{1}{\\theta}{p(\\theta)p(\\mathcal{D}|\\theta)}d\\theta}\\over{p(\\mathcal{D})}} \\\\\n\u0026= {{\\int_{0}^{1}{\\theta}{p(\\theta)\\prod_{i=1}^{n}{p(x_i|\\theta)}}d\\theta}\\over{p(\\mathcal{D})}} \\\\\n\u0026= {{\\int_{0}^{1}{\\theta}{p(\\theta)\\prod_{i=1}^{n}{p(x_i|\\theta)}}d\\theta}\\over{\\int_0^1{p(\\mathcal{D}|\\theta)p(\\theta)}d\\theta}} \\\\\n\u0026= {{\\int_{0}^{1}{\\theta}{p(\\theta)\\prod_{i=1}^{n}{p(x_i|\\theta)}}d\\theta}\\over{\\int_0^1{p(\\theta)\\prod_{i=1}^{n}p(x_i|\\theta)}d\\theta}} \\\\\n\\end{align*}\n$$\n\n이를 구하는 과정은 이전과는 다르게 상대값이 아닌 평균을 구해야하기 때문에 posteriori(사후 확률,$p(\\theta|\\mathcal{D})$)를 구해야 한다.\n\n하지만, 여기서 잡기술이 하나 존재한다. 바로 **Conjugate Prior**이다.\n\n바로 두 확률 분포 함수(likelihood, prior)에 의한 posterior의 형태가 정해진 경우가 있기 때문이다.\n\n| Prior $p(\\theta \\mid \\alpha)$  | Likelihood $p(\\mathcal{D} \\mid \\theta)$                 | Posterior $p(\\theta \\mid \\mathcal{D}, \\alpha)$                                                                                                                                                                                                                   | Expectation of Posterior                                                                                                                                                       |\n| :----------------------------- | :------------------------------------------------------ | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| Beta ($\\alpha, \\beta$)         | Benoulli ($\\sum _{i=1}^{n}x_{i}$)                       | Beta ($\\alpha +\\sum _{i=1}^{n}x_{i},\\,\\beta +n-\\sum _{i=1}^{n}x_{i}$)                                                                                                                                                                                            | ${{\\alpha + \\sum _{i=1}^{n}x_{i}}\\over{\\alpha + \\beta + n}}$                                                                                                                   |\n| Beta ($\\alpha, \\beta$)         | Binomial ($\\sum _{i=1}^{n}N_{i}, \\sum _{i=1}^{n}x_{i}$) | Beta ($\\alpha +\\sum _{i=1}^{n}x_{i},\\,\\beta +\\sum _{i=1}^{n}N_{i}-\\sum _{i=1}^{n}x_{i}$)                                                                                                                                                                         | ${{\\alpha + \\sum _{i=1}^{n}x_{i}}\\over{\\alpha + \\beta + \\sum _{i=1}^{n}N_{i}}}$                                                                                                |\n| Gaussian ($\\mu_0, \\sigma_0^2$) | Gaussian ($\\mu, \\sigma^2$)                              | Gaussian (${\\displaystyle {\\frac {1}{{\\frac {1}{\\sigma _{0}^{2}}}+{\\frac {n}{\\sigma ^{2}}}}}\\left({\\frac {\\mu_{0}}{\\sigma _{0}^{2}}}+{\\frac {\\sum_{i=1}^{n}x_{i}}{\\sigma ^{2}}}\\right),\\left({\\frac {1}{\\sigma_{0}^{2}}}+{\\frac {n}{\\sigma ^{2}}}\\right)^{-1}}$) | ${\\displaystyle {\\frac {1}{{\\frac {1}{\\sigma _{0}^{2}}}+{\\frac {n}{\\sigma ^{2}}}}}\\left({\\frac {\\mu_{0}}{\\sigma _{0}^{2}}}+{\\frac {\\sum_{i=1}^{n}x_{i}}{\\sigma ^{2}}}\\right)}$ |\n\n이를 이용하면, 우리는 간단하게 Posteriori의 평균을 구할 수 있다.\n\n## Reference\n\n- Tumbnail : Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=unsplash\u0026utm_medium=referral\u0026utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@markuswinkler?utm_source=unsplash\u0026utm_medium=referral\u0026utm_content=creditCopyText)\n  ","slug":"ml-parametric-estimation","date":"2022-10-15 11:25","title":"[ML] 1. Parametric Estimation","category":"AI","tags":["ML","MLE","MAP","Bayesian"],"desc":"Machine Learning은 특정 목표를 달성하기 위해서 데이터로 부터 pattern 또는 가정 등을 유도해내는 방법이다.이를 위한 가장 일반적인 방법은 여러 개의 확률분포와 이것의 parameter의 조합(probabilistic model)들 중에서 측정된 데이터들을 가장 잘 나타내는 하나를 찾아내는 것이다.그 중에서, 확률 분포를 결정한 상태에서 parameter를 찾아나가는 형태의 접근법을 우리는 Parametric Estimation이라고 한다. 그 외에도 Nonparametric, Semi-parametric 방식도 존재하지만 이는 여기서는 다루지 않는다.","thumbnailSrc":"https://euidong.github.io/images/ml-thumbnail.jpg"},{"content":"\n## Intro\n\nRegression(회귀)이라는 단어는 \"원래의 상태로 돌아간다\"로 돌아간다는 의미를 가진다. 결국 어떤 일련의 Event로 인해서 데이터에 Noise가 발생할 수 있어도 결국은 하나의 \"보편\"으로 시간이 지나면 수렴(회귀)할 것이라는 생각에 기반하는 것이다.  \n따라서, 우리는 이러한 \"보편\"을 찾기 위해서 우리가 알고 있는 독립 데이터 X를 통해서 알고자 하는 값 Y를 보편적으로 추론할 수 있다. 이 과정을 우리는 Regression이라고 부른다. 또한, X에 의해 독립적이지 않고 종속적인 Y의 관계가 Linear하게 표현될 때 이를 우리는 Linear Regression이라고 한다.  \n따라서, 해당 Posting에서는 Linear Regression을 바탕으로 Machine Learning이 어떻게 동작하는지를 이해하는 것이 목표이다.\n\n## Regression\n\n\u003e **정의**\n\n독립 변수 X로 부터 종속 변수 Y에 대응되는 함수 f를 생성하는 과정을 의미한다.\n\n$$\n\\bold{y} = f(\\bold{x}) + \\epsilon\n$$\n\n$$\nf(\\bold{x}) = \\bold{w}^{\\top}\\bold{x},\n(\\bold{w} = \\begin{bmatrix} w_{0} \\\\ w_{1} \\\\ w_{2} \\\\ \\vdots \\\\ w_{N} \\\\ \\end{bmatrix}, \\bold{x} = \\begin{bmatrix} 1 \\\\ x_{1} \\\\ x_{2} \\\\ \\vdots \\\\ x_{N} \\\\ \\end{bmatrix} )\n$$\n\n여기서 각 변수 $x$, $y$, $\\epsilon$, $w$은 다음과 같이 여러 이름으로 불려진다.\n\n- $x$ : input, 독립 변수, predictor, regressor, covariate\n- $y$ : output, 종속 변수, response\n- $\\epsilon$ : noise, 관측되지 않은 요소\n- $w$ : weight, 가중치, parameter\n\n\u003e \u003cmark\u003e**성능 평가(MSE)**\u003c/mark\u003e\n\n우리가 만든 Regression이 얼마나 데이터를 잘 반영하는지를 알고 싶을 때, 즉 평가하고자 할 때, 우리는 Mean Squared Error(MSE)를 사용한다. 이는 이전 포스팅인 [Parametric Estimation](/posts/ml-parametric-estimation)에서도 살펴보았었다.\n\n그렇다면, MSE를 최소로 하는 f(x)는 무엇일까? 이를 통해서 또, 하나의 식견을 넓힐 수 있다. 한 번 MSE 식을 정리해보자.\n\n$$\n\\begin{align*}\n\\Epsilon(f) \u0026= E[||\\bold{y}_*-f(\\bold{x})||^2] \\\\\n\u0026= \\int\\int||\\bold{y}_*-f(\\bold{x})||^2p(\\bold{x}, \\bold{y}_*)d\\bold{x}d\\bold{y}_* \\\\\n\u0026= \\int\\int||\\bold{y}_*-f(\\bold{x})||^2p(\\bold{x})p(\\bold{y}_* | \\bold{x})d\\bold{y}_*d\\bold{x} \\\\\n\u0026= \\int p(\\bold{x}) \\red{\\int||\\bold{y}_*-f(\\bold{x})||^2p(\\bold{y}_* | \\bold{x})d\\bold{y}_*}d\\bold{x}\n\\end{align*}\n$$\n\n여기서 중요한 것은 바로 빨간색으로 색칠한 부분이다. 우리가 바꿀 수 있는 값은 f(x)를 구성하는 w밖에 없다 즉, 위 식을 최소화하는 것은 빨간색 부분을 최소화하는 것과 같아진다.  \n따라서, 이 부분을 미분해서 최솟값을 구할 수 있는데 이를 확인해보자.\n\n$$\n\\begin{align*}\n\u0026{\\partial\\over{\\partial{f(\\bold{x})}}}({\\int||\\bold{y}_*-f(\\bold{x})||^2p(\\bold{y}_* | \\bold{x})d\\bold{y}_*}) = 0 \\\\\n\u0026{\\partial\\over{\\partial{f(\\bold{x})}}}({\\int||\\bold{y}_*^2p(\\bold{y}_* | \\bold{x})d\\bold{y}_*} - 2f(\\bold{x}){\\int\\bold{y}_*p(\\bold{y}_* | \\bold{x})d\\bold{y}_*} + f(\\bold{x})^2{\\int p(\\bold{y}_* | \\bold{x})d\\bold{y}_*}) = 0 \\\\\n\u0026-2{\\int\\bold{y}_*p(\\bold{y}_* | \\bold{x})d\\bold{y}_*} + 2f(\\bold{x}) = 0 \\\\\n\u0026f(\\bold{x}) = {\\int\\bold{y}_*p(\\bold{y}_* | \\bold{x})d\\bold{y}_*} = E[\\bold{y}_*|\\bold{x}]\n\\end{align*}\n$$\n\n즉, 우리가 구하고자 하는 Linear Regression 함수는 data x에 따른 실제 y 값의 평균을 의미한다. Regression의 정의를 생각했을 때, 어느정도 합리적이라는 것을 알 수 있다. \"보편\"적이다는 의미에서 \"평균\"을 쓰는 경우가 많이 있기 때문이다.\n\n위에서는 MSE를 이용해서 분석하였지만, MAE(Mean Absolute Error)를 활용하여 구할 수 있는데 이 경우에는 Regression의 형태가 또 달라진다. 즉, MSE를 최소화하는 방식은 우리가 \"보편\"적인 답을 구하는데 있어 \"평균\"을 활용한 것이고, MAE를 사용한다면, 또 다른 방식을 사용한다는 것을 알게 될 것이다.\n\n## MLE of Linear Regression\n\n이제 Linear Regression에서 $\\bold{w}$를 어떻게 찾아 나갈지에 대해서 살펴볼 것이다. 순서는 이전 Posting [Parametric Estimation](/posts/ml-parametric-estimation)에서 살펴봤던 것과 마찬가지로 MLE, MAP 순으로 살펴볼 것이다. 그리고 이것이 왜 MLE고, MAP랑 관련이 있는지도 살펴볼 것이다.\n\n들어가기에 앞 서, 표기법과 용어를 몇 개 정리할 필요가 있다.\n\n- $\\bold{x}, \\bold{y}, \\bold{w}$ 등 굵은 선 처리되어 있는 변수는 vector를 의미한다.\n- $\\bold{X}$ 등 굵고 대문자로 처리되어 있는 변수는 Matrix를 의미한다.\n- $\\bold{w^{\\top}}$, $\\bold{X}^{\\top}$ 에서 T는 Transpose를 의미한다.\n- feature : input 데이터의 각 각 분류 기준들을 의미한다. 수식으로는 $x_1, x_2, x_3$ 이런 식으로 표현된 input들 중에 각 각의 input을 feature라고 하며, 실제 예시로는 데이터 수집 시에 각 데이터의 column(나이, 성별, 등 등)이 될 것이다.\n\n위의 용어 정리에 의해서 다음과 같은 사실을 다시 한 번 확인하자.\n\n먼저, 단일 Linear Regression이다.\n\n$$\n\\hat{y} = f(\\bold{x}) = \\bold{w}^{\\top}\\bold{x} = \\bold{x}^{\\top}\\bold{w}\n$$\n\n이번에는 여러 개의 데이터를 한 번에 추측한 결과값 $\\hat{\\bold{y}}$ 이다.\n\n$$\n\\hat{\\bold{y}} = \\bold{X}\\bold{w}\n$$\n\n각 의미를 곱씹어보면 어떻게 생겼을지 어렵풋이 짐작이 올 것이다.\n\n\u003e **basis function**\n\n여기서 또 하나 짚어볼 것은 바로 $\\bold{x}$를 변형하는 방법이다. 바로, 우리는 데이터로 입력 받은 데이터를 바로 사용할 수도 있지만, 해당 input 값을 제곱해서 사용해도 되고, 서로 더해서 사용해도 되고, 나누어서 사용할 수도 있다. 예를 들어서 우리가 구하고 싶은 값이 대한민국 인구의 평균 나이라고 하자. 이때, 우리가 사용하는 데이터의 값이 가구 단위로 조사되어 부,모,자식1, 자식2, ... 로 분류되어 나이가 적혀있다고 하자. 이때 우리가 필요한 것은 결국 전체 인구의 나이 데이터임으로 모두 하나의 feature로 합쳐버릴 수도 있다.\n\n이러한 과정을 위해서 우리는 basis function($\\phi(\\bold{x})$)이라는 것을 이용한다. 단순히 input data를 합성해서 하나의 input을 생성하는 것이다.\n\n따라서, 우리는 필요에 따라 input data를 가공하여 사용하며 여러 $\\phi$를 적용하여 나타낼 경우 linear regression은 다음과 같은 형태가 된다.\n\n$$\nf(\\bold{x}) = \\bold{w}^{\\top}\\boldsymbol{\\phi}(\\bold{x})\n$$\n\n대표적인 Basis function을 살펴보자.\n\n- Polynomial basis : 하나의 input feature에 대해서 n-제곱형태의 vector로 변환하는 형식이다. 따라서, 다음과 같이 표기 된다.  \n  $\\boldsymbol{\\phi}(\\bold{x}) = \\begin{bmatrix} 1 \\\\ x \\\\ x^{2} \\\\ \\vdots \\\\ x^{n} \\\\ \\end{bmatrix}$, $\\bold{w}^{\\top}\\boldsymbol{\\phi}(\\bold{x}) = w_{0} + w_{1}x + w_{2}x^{2} + ... + w_{n}x^{n}$  \n  대게 이러한 형태로 변형한 Linear Regression을 Polinomial Regression이라고 부르는데, 이를 통한 결과 값이 마치 다항식의 형태를 띄기 때문이다. 하지만, feature의 값이 polynomial이 되었더라도 $\\bold{w}$가 선형임을 잊어서는 안된다.  \n  이를 사용하게 되면, 우리는 1차원의 input 공간에서 선형으로는 나눌 수 없던 분류를 수행할 수 있다.\n- Gaussian basis : 가우시안 분포로 변환하는 것으로 특정 feature를 gaussian으로 변환하게 되면, 데이터의 경향성이 파악된다. 이는 후에 더 자세히 다룰 기회가 온다.  \n- Spline basis: 특정 구간마다 다른 Polynomial 형태의 feature를 적용하도록 하는 방식이다. 대게 구간마다 다른 확률 분포를 적용하고자 할 때 사용한다.\n- Fourier basis, Hyperbolic tangent basis, wavelet basis 등 여러 가지 방식이 존재한다.\n\n\u003e **Design Matrix**\n\n마지막으로, 이렇게 만들어진 $\\phi(\\bold{x})$를 하나의 Matrix로 합친 것을 Design Matrix라고 한다. N개의 데이터를 L개의 서로 다른 basis function으로 변환한 데이터를 행렬로 표현하면, 다음과 같다.\n\n$$\n\\Phi =\n  \\begin{bmatrix}\n    \\phi_1({\\bold{x_1}})  \u0026 \\phi_2(\\bold{x_1})  \u0026 \\cdots  \u0026 \\phi_L(\\bold{x_1})  \\\\\n    \\phi_1({\\bold{x_2}})  \u0026 \\phi_2(\\bold{x_2})  \u0026 \\cdots  \u0026 \\phi_L(\\bold{x_2})  \\\\\n    \\vdots                \u0026 \\vdots              \u0026 \\ddots  \u0026 \\vdots              \\\\\n    \\phi_1({\\bold{x_N}})  \u0026 \\phi_2(\\bold{x_N})  \u0026 \\cdots  \u0026 \\phi_L(\\bold{x_N})  \\\\\n  \\end{bmatrix}\n$$\n\n이를 통해서 표현한 모든 데이터에 대한 Linear Regression은 다음과 같다.\n\n$$\n\\hat{\\bold{y}} = \\Phi\\bold{w}\n$$\n\n자 이제부터 우리는 본론으로 들어와서 우리의 Linear Regression의 Weight(Parameter, $\\bold{w}$)를 어떻게 추정할 수 있을지를 알아보자.\n\n우리는 최종적으로 우리의 Linear Regression이 정답과 매우 유사한 값을 내놓기를 원한다. 따라서, 이때 우리는 Least Square Error를 사용할 수 있다. 이는 모든 데이터에서 얻은 예측값(Linear Regression의 output)과 실제 y의 값의 Square Error의 합을 최소화하는 것이다.\n\n$$\n\\varepsilon_{LS}(\\bold{w}) = {1\\over2}\\sum_{n=1}^{N}(y_n - \\bold{w}^{\\top}\\boldsymbol{\\phi}(\\bold{x_n}))^2 = {1\\over2}||\\bold{y}_* - \\Phi\\bold{w}||^2\n$$\n\n이제 $\\argmin_{\\bold{w}}\\varepsilon_{LS}(\\bold{w})$을 풀기 위해서 미분을 해보자.\n\n$$\n\\begin{align*}\n\u0026{\\partial\\over\\partial\\bold{w}}{1\\over2}||\\bold{y}_* - \\Phi\\bold{w}||^2 = 0 \\\\\n\u0026\\Phi^{\\top}(\\bold{y}_* - \\Phi\\bold{w}) = 0 \\\\\n\u0026\\Phi^{\\top}\\Phi\\bold{w} = \\Phi^{\\top}\\bold{y_*} \\\\\n\u0026\\bold{w} = (\\Phi^{\\top}\\Phi)^{-1}\\Phi^{\\top}\\bold{y_*} \\\\\n\u0026\\bold{w} = \\Phi^{\\dagger}\\bold{y_*}\n\\end{align*}\n$$\n\n이를 통해서, 위와 같은 식을 얻을 수 있다.\n\n---\n\n그럼 이 식이 왜 MLE랑 관련이 있는 것일까? 그것은 다음의 과정을 통해서 증명할 수 있다.\n\n우리는 각 data마다 존재하는 error(noise, $y_* - \\hat{y}$, $\\varepsilon$)가 그 양이 많아짐에 따라 정규 분포를 따른다는 것을 알 수 있다. (Central Limit Theorem)\n\n$$\n\\begin{align*}\n\\varepsilon \u0026= y_* - \\hat{y} = y_*-\\phi(\\bold{x}) \\\\\ny_* \u0026= \\phi(\\bold{x}) + \\varepsilon\n\\end{align*}\n$$\n\n이를 좌표 평면 상에서 나타내면 다음과 같다고 할 수 있다.\n\n![gaussian-error](/images/gaussian-error.jpeg)\n\n또한, $\\varepsilon$의 확률을 정의하면 다음과 같은 확률을 얻을 수 있다.\n\n$$\n\\begin{align*}\np(\\varepsilon) \u0026= {1\\over{\\sqrt{2\\pi}\\sigma}}\\exp{[-{\\varepsilon^2\\over{2\\sigma^2}}]} \\\\\np(\\varepsilon) \u0026= {1\\over{\\sqrt{2\\pi}\\sigma}}\\exp{[-{(y_*-\\phi(\\bold{x}))^2\\over{2\\sigma^2}}]}\n\\end{align*}\n$$\n\n여기서 우리는 $p(\\varepsilon)$을 $p(y_*|\\bold{x}; \\theta)$라고 볼 수 있다. ($\\theta = (\\bold{w}, \\phi, \\sigma)$)\n\n우리는 이를 이용해서 Likelihood를 구할 수 있다.\n\n$$\n\\begin{align*}\n\\mathcal{L} \u0026= \\log{p(\\bold{y}_*|\\bold{X}; \\theta)} = \\sum_{i=1}^{N}{\\log{p(y_{*(i)}|\\bold{x}_{(i)}; \\theta)}} \\\\\n\u0026= N\\log{{1\\over{\\sqrt{2\\pi}\\sigma}}} + \\sum_{i=1}^{N}{-{(y_*-\\phi(\\bold{x}))^2\\over{2\\sigma^2}}} \\\\\n\u0026= N\\log{{1\\over{\\sqrt{2\\pi}\\sigma}}} - {1\\over{\\sigma^2}}\\red{{1\\over{2}}\\sum_{i=1}^{N}{(y_*-\\phi(\\bold{x}))^2}}\n\\end{align*}\n$$\n\n우리가 변경할 수 있는 데이터는 $\\phi(\\bold{x})$ 밖에 없다. 따라서, 빨간색을 제외한 부분은 Likelihood의 최댓값을 구할 때, 고려하지 않아도 되는 상수로 볼 수 있다. 그렇다면, 우리는 Likelihood의 최댓값을 구하기 위해서 빨간색 표시된 부분을 최소화해야 한다는 것을 알 수 있다. 그리고, 이는 우리가 앞에서 살펴봤던, Least Squared Error와 같다.\n\n\u003cmark\u003e즉, $\\bold{w}_{LS}=\\bold{w}_{MLE}$ 라는 것이다.\u003c/mark\u003e\n\n## MAP of Linear Regression\n\n이번에는 Linear Regression에서 $\\bold{w}$를 찾아나가는 과정에서 MAP를 활용하는 과정을 알아볼 것이다.\n\n\u003e **overfitting**\n\n우리가 MLE를 통해서 Linear Regression을 찾는 것이 충분하다고 생각할 수 있다. 하지만, 우리는 어쩔 수 없이 **overfitting**이라는 문제에 직면하게 된다.\n\n![over-fitting-example](/images/over-fitting-example.jpg)\n\n**overfitting**이란 데이터를 통해서 구할 수 있는 분포가 학습에 사용된 데이터에 대해서는 에러가 거의 없는 형태로 예측하지만, 그 외에 데이터에 대해서는 에러가 크게 발생하는 경우를 의미한다. 위의 예시에서 처럼 데이터가 전체 Sample space보다 턱없이 적은 경우에 발생하기 쉽다.\n\n이러한 문제는 사실 basis function을 잘 선택하면 해결할 수 있다. 하지만, 우리가 어떻게 매번 적절한 basis function을 찾기 위해서 iteration을 반복하는 것이 올바를까? 그리고 이는 실제 적합한 값을 찾기 위한 수학적 식도 존재하지 않는다.\n\n\u003e **Regularization**\n\n따라서, 우리는 **regularization**을 수행한다. 위의 overfitting된 그래프를 보면 하나의 insight(번뜩이는 idea?)를 얻을 수 있다. 바로, 급격한 기울기의 변화는 overfitting과 유사한 의미로 볼 수 있다는 것이다. 즉, 그래프의 형태가 smooth 해야한다는 것이다.\n\n따라서, 우리는 하나의 error에 대해서 다음과 같이 재정의해서 smoothing(regularization)을 수행할 수 있다.\n\n$$\n\\varepsilon = {1\\over2}||\\bold{y}_* - \\Phi\\bold{w}||^2 + {\\lambda\\over{2}}||\\bold{w}||^2\n$$\n\n$\\bold{w}$의 L2 norm을 error에 추가하여 $\\bold{w}$의 크기가 작아지는 방향으로 예측을 할 수 있도록 하는 것이다. (물론 L1 norm을 사용할 수도 있다. 이 또한, 후에 다룰 것이니 여기서는 넘어가겠다. 추가로 이렇게 L2 norm을 이용하면 **Ridge Regression**, L1 norm을 이용하면 **Lasso Regression**이라고 한다.)\n\n자 이제 위의 식을 미분해서 최소값이 되게 하는 $\\bold{w}$를 찾아보자. 과정은 연산이 그렇게 어렵지 않으므로 넘어가고 결과는 아래와 같다.\n\n$$\n\\bold{w}_{ridge} = (\\lambda I + \\Phi^{\\top}\\Phi)^{-1}\\Phi^{\\top}\\bold{y}_*\n$$\n\n---\n\n그럼 이 역시 MAP를 통해서 해석해보도록 하자.\n\n위에서 살펴본 바와 같이 우리는 w값이 작을 확률이 높을 수록 좋은 성능을 가질 것이라는 Prior를 얻을 수 있다.\n\n즉,$p(\\bold{w})$가 zero-mean gaussian(표준정규분포)형태를 이루기를 바랄 것이다.\n\n$$\np(\\bold{w}) = \\mathcal{N}(\\bold{w}|0, \\Sigma)\n$$\n\n그리고, 이전에 MLE를 구할 때, Likelihood를 다음과 같이 정의했다.\n\n$$\n\\begin{align*}\np(\\bold{y}_*|\\bold{X}; \\theta) \u0026= \\mathcal{N}(\\bold{y}_*-\\Phi\\bold{w}, \\sigma I) \\\\\np(\\bold{y}_*|\\Phi, \\bold{w}) \u0026= \\mathcal{N}(\\bold{y}_*-\\Phi\\bold{w}, \\sigma I)\n\\end{align*}\n$$\n\n따라서, 우리는 이를 이용해서 posterior를 추론할 수 있다.\n\n$$\np(\\bold{w}|\\bold{y}_*, \\Phi) = {{p(\\bold{y}_*| \\Phi, \\bold{w})p(\\bold{w})}\\over{p(\\bold{y}_*|\\Phi)}}\n$$\n\n여기서 MAP를 구할 때에는 Lemma 정리(두 정규분포의 conditional Probability를 구하는 공식)를 이용하면 편하다. 따로 연산은 수행하지 않지만 결과 값은 아래와 같다.\n\n$$\n\\bold{w}_{MAP} = (\\sigma^2\\Sigma^{-1}+\\Phi^{\\top}\\Phi)^{-1}\\Phi^{\\top}\\bold{y}\n$$\n\n여기서 만약 우리가 $\\Sigma = {\\sigma^2\\over{\\lambda}}I$라고 가정하면, 위의 MAP 식은 Ridge Regression과 동일해지는 것을 알 수 있다.\n\n즉, Ridge Regression은 MAP의 한 종류라고 볼 수 있는 것이다.\n\n$$\n\\bold{w}_{ridge} \\in {(\\bold{w}_{MAP}, \\Sigma)}\n$$\n\n## Gradient Descent\n\n여태까지 우리는 Loss를 정의하고, 이 Loss가 최솟값을 갖는 $\\bold{w}$를 찾는 것을 목표로 하였다. 하지만, 우리가 다루는 모든 Loss가 미분이 항상 쉬운 것은 아니다. 뿐만 아니라, Loss의 미분 값이 5차원 이상의 식으로 이루어진다면, 우리는 이를 풀 수 없을 수도 있다. 5차원 이상의 polynomial에서는 선형대수적인 해결법(근의 방정식)이 없다는 것이 증명되어있다.(Abel-Ruffini theorem)\n\n따라서, 우리는 Loss가 0이 되는 지점을 찾기 위해서, w의 값을 점진적으로 업데이트하는 방식을 활용한다. 이때, 우리는 w의 값이 계속해서 Loss를 감소시키기를 원한다. 따라서, 우리는 현재 $\\bold{w}$에서 Gradient를 현재 $\\bold{w}$에 빼준다. 이를 우리는 **Gradient Descent**라고 한다.\n\n$$\n\\bold{w}_{t+1} = \\bold{w}_{t} - \\gamma((\\nabla L)(\\bold{w}_{t}))^{\\top}\n$$\n\n여기서 $\\gamma$는 step size(learning rate)라고 하며, 기울기값을 얼마나 반영할지를 의미한다.\n\n---\n\n이제부터는 Gradient Descent를 더 효과적으로 진행하기 위한 3가지의 기술들을 추가적으로 제시한다.\n\n\u003e **1. optimize stepsize**\n\nstepsize($\\gamma$)가 특정 상수로 제시된 게 아니라 변수로 표현된 이유는 linear regression마다 적절한 $\\gamma$가 다르기 때문이다. 하나의 예시를 들어보자.\n\n![loss-divergence](/images/loss-divergence.jpg)\n\n위는 Loss function이 convex할 때, 최솟값을 찾아나가는 과정이다. 만약, $\\gamma$가 크다면, Loss가 특정값으로 수렴하는 것이 아니라 발산하는 것을 알 수 있다. 이를 막기 위해 $\\gamma$를 굉장히 작은 수로 하는 경우에는 Loss의 최솟값을 찾기도 전에 특정 지점에서 멈춰버릴 수도 있다. 또한, Loss의 graph형태는 data마다 달라지기 때문에 절대적인 $\\gamma$역시 존재하지 않는다.\n\n따라서, 우리는 매 update마다 적절한 $\\gamma$를 찾을려고 노력한다. 여기서는 자세히 다루지 않지만 후에 더 다룰 기회가 있을 것이다. 간단히 프로그래밍적으로(systemical) 생각하면, 업데이트 이후 loss가 만약 그전 Loss보다 커진다면, 이를 취소하고 더 작은 $\\gamma$를 사용하도록 하고, 업데이트 된 후의 Loss와 그전 Loss가 같다면, 진짜 수렴하는지를 확인하기 위해서 $\\gamma$를 키워볼 수도 있다.\n\n\u003e **2. momentum**\n\n우리가 Gradient Descent를 진행하다보면, 다음과 같은 현상을 자주 마주하게 된다.\n\n![momentum-example-1](/images/momentum-example-1.jpg)\n\n우리가 찾고자 하는 Loss를 찾아가는 과정에서 매 업데이트마다 반대방향으로 기울기가 바뀌는 경우이다.(진동한다) 이는 최종으로 찾고자 하는 값을 찾는 과정이 더 오래 걸리게 한다. 따라서, 우리는 이러한 진동을 막기 위해서 Momentum을 사용한다. 즉, 이전 차시에서의 gradient를 저장해두고, 이를 더해서 진동하는 것을 막는 것이다.\n\n$$\n\\bold{w}_{i+1} = \\bold{w}_{i} - \\gamma_{i}((\\nabla L)(\\bold{w}_{i}))^{\\top} + \\alpha \\Delta \\bold{w}_i ,( \\alpha \\in [0, 1] )\n$$\n\n$$\n\\Delta \\bold{w}_i = \\bold{w}_{i} - \\bold{w}_{i-1} = \\alpha \\Delta \\bold{w}_{i-1} - \\gamma_{i-1}((\\nabla L)(\\bold{w}_{i-1}))^{\\top}\n$$\n\n즉, 그림으로 표현하면, 다음과 같다.\n\n![momentum-example-2](/images/momentum-example-2.jpg)\n\n이전 변화량과 현재 변화량을 합하여 이동하기 때문에 위에 새로 추가된 것처럼 진동하지 않고, 진행하는 것을 볼 수 있다.\n\n\u003e **3. Stochastic Gradient Descent**\n\n우리의 Gradient Descent의 가장 큰 문제는 바로 Global Minimum을 찾을 거라는 확신을 줄 수 없다는 것이다. 아래 그림을 보자.\n\n![gradient-descent-example](/images/gradient-descent-example.jpg)\n\n여기서 우리는 초기 w 값을 어떻게 정하냐에 따라서, **local minimum**을 얻게 되거나 **global minimum**을 얻게 된다. 즉, 초기값이 결과에 굉장히 큰 영향을 준다는 것이다.\n\n이를 해결할 수 있으며, 학습 효율도 높일 수 있는 것이 Stochastic Gradient Descent이다. 원리는 Loss를 구하기 위해서 전체 데이터(모집단)를 사용했었는데 그러지말고 일부 데이터를 랜덤하게 추출(sampling)해서(표본 집단) 이들을 통해서 Loss function을 구하기를 반복하자는 것이다.\n\n이 방식을 통해서 구한 Gradient의 평균이 결국은 전체 batch의 평균과 같다는 것은 Central Limit Theorem(중심 극한 정리)에 의해 증명이 된다. 따라서, 우리는 이를 통한 gradient descent도 특정 minimum을 향해 나아가고 있음을 알 수 있다.\n\n그렇지만, 표본 집단을 이용한 평균을 구했을 때에 우리는 noise에 의해서 local minimum으로만 수렴하는 현상을 막을 수 있다. 즉, gradient descent를 반복하다보면, 다른 local minimum으로 튀어나가기도 하며 global minimum을 발견할 확률을 높일 수 있는 것이다.\n\n## Reference\n\n- Tumbnail : Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=unsplash\u0026utm_medium=referral\u0026utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@markuswinkler?utm_source=unsplash\u0026utm_medium=referral\u0026utm_content=creditCopyText)\n- [Probabilistic interpretation of linear regression clearly explained](https://towardsdatascience.com/probabilistic-interpretation-of-linear-regression-clearly-explained-d3b9ba26823b), Lily Chen\n","slug":"ml-linear-regression","date":"2022-10-17 09:46","title":"[ML] 2. Linear Regression","category":"AI","tags":["ML","LinearRegression","BasisFunction","Regularization","GradientDescent","Momentum","StochasticGradientDescent"],"desc":"Regression(회귀)이라는 단어는 \"원래의 상태로 돌아간다\"로 돌아간다는 의미를 가진다. 결국 어떤 일련의 Event로 인해서 데이터에 Noise가 발생할 수 있어도 결국은 하나의 \"보편\"으로 시간이 지나면 수렴(회귀)할 것이라는 생각에 기반하는 것이다.  따라서, 우리는 이러한 \"보편\"을 찾기 위해서 우리가 알고 있는 독립 데이터 X를 통해서 알고자 하는 값 Y를 보편적으로 추론할 수 있다. 이 과정을 우리는 Regression이라고 부른다. 또한, X에 의해 독립적이지 않고 종속적인 Y의 관계가 Linear하게 표현될 때 이를 우리는 Linear Regression이라고 한다.  따라서, 해당 Posting에서는 Linear Regression을 바탕으로 Machine Learning이 어떻게 동작하는지를 이해하는 것이 목표이다.","thumbnailSrc":"https://euidong.github.io/images/ml-thumbnail.jpg"},{"content":"\n## Intro\n\n이전까지 우리는 input data가 들어왔을 때, continuos한 output을 얻는 것을 목표로 했다. 하지만 현실에서는 대게 정확한 수치보다는 특정 분류로 나누는 것이 효과적인 경우가 많다. 예를 들어, spam 필터링, object detection, 등 등. 따라서, 해당 포스팅에서는 classification을 위해서 사용할 수 있는 logistic regression에 대해서 살펴볼 것이다.\n\n## Classification\n\n**Classification**이란 결국 특정 input이 들어왔을 때, 이를 하나의 Class라는 output을 내보내는 것이다. 즉, output은 연속적이지 않고, descret하다. 대게 Classification에서는 Class의 갯수를 K라고 표기하고, $C_k$는 k 번째 Class라는 의미로 사용되어진다.\n\n그렇다면, 어떻게 Class를 나눌 수 있는 것일까? 매우 단순하게도 이는 **Decision Boundary**라는 선을 그어서 해결 할 수 있다.\n\n![decision-boundary](/images/decision-boundary.jpg)\n\n위의 예시처럼 우리는 선을 하나 그어서 $\\red{\\text{x}}$와 $\\blue{\\text{o}}$를 구분할 수 있다. 이를 통해서 우리는 Class 1에 해당할 것이라고 예측하는 구간 $R_1$이 만들어지고, Class 2라고 예측하는 구간 $R_2$를 구성할 수 있다.\n\n즉, classification을 수행하기 위해서 해야할 일은 기존의 Regression 과정과 마찬가지로 선을 찾는 것이다.\n\n결국 찾고자 하는 것이 선이라면, 이것을 Linear Regression으로 해결할 수 있을 것이다. 따라서, 우리는 다음과 같은 식으로 간단히 Linear Regression을 바꿔서 생각할 수 있다.\n\n- 예측값($\\hat{y}$, $h(\\bold{x})$)  \n  $h(\\bold{x}) = \\text{sign}(\\bold{w}^{\\top}\\bold{x}) = \\begin{cases} +1 \u0026 \\bold{w}^{\\top}\\bold{x} \\geq 0 \\\\ -1 \u0026 \\text{otherwise}\\end{cases}$\n- Least Squared Error(LS, MLE)  \n  실제로 parameter를 구할 때에는 sign을 취하지 않는데, sign을 취하게 되면 모두 LS는 결국 오답의 갯수 정도로 취급된다. 즉, 얼마나 예측이 잘못되었는지를 반영할 수 없다는 것이다. 따라서, 이는 기존 Linear Regression의 LS를 구하는 방법과 동일하게 수행한다.  \n  $\\argmin_{w} {1\\over2}\\sum_{n=1}^{N}{(y_n - (\\bold{w}^{\\top}\\bold{x}))^2}$\n\n이렇게 Linear Regression을 적용하면 문제가 없을 거 같다. 하지만, 실제로는 문제가 있다. 바로, 데이터가 불균형할 때이다. 만약 데이터가 decision boundary를 기준으로 대칭(symmetric)인 형태로 존재한다면, 문제가 없다. 하지만, 비대칭(asymmetric)인 경우 제대로 동작하지 않는다. 왜냐하면, linear regression은 최적에서 데이터의 평균을 반영하는데 불균형한 경우 데이터의 평균이 Decision Boundary가 되는 것은 문제가 있다.\n\n![linear-in-classification](/images/linear-in-classification.jpg)\n\n## Logistic Regression\n\n위에서 제시한 문제를 해결하기 위해서 Classification에서는 Linear Regression이 아닌 Logistic Regression을 활용한다. 이를 이해하기 위해서 기반이 될 요소들을 먼저 살펴보자.\n\n\u003e **Discriminant Function**\n\n판별함수(Discriminant Function, Score Function) 등으로 불리는 해당 함수는 특정 data가 특정 class에 속할 가능성(likelihood, probability, score)을 나타내는 함수이다. 즉, input으로 data를 받고, output으로 class에 속할 확률을 내보낸다.\n\n이를 통해서 우리는 다음과 같은 과정을 할 수 있다.\n\n만약, $f_k(\\bold{x}) \\gt f_j(\\bold{x})$이라면, $\\bold{x}$의 class는 $C_k$이다.\n\n따라서, 우리는 다음과 같은 식으로 여러 개의 Class가 있는 공간에서 data를 분류할 수 있다.\n\n$$\nh(\\bold{x}) = \\argmax_{k}f_{k}(\\bold{x})\n$$\n\n그렇다면, Discriminant Function으로 어떤 값을 쓰면 좋을까? 이에 대한 해결책을 Bayes Decision Rule에서 제시한다.\n\n\u003e **Bayes Decision Rule**\n\n만약 우리가 특정 data가 특정 Class에 속할 확률을 구한다고 하자. 우리는 먼저 Likelihood를 생각할 수 있다. $P(x|C = k), P(x|C = j)$를 구하여 각 Class에 속할 확률을 비교할 수 있을까?  \n물론 비교는 가능하다 하지만, 반쪽짜리 비교라고 할 수 있다. 만약, class k에 속하는 데이터보다 class j에 속하는 데이터가 훨씬 많다고 하자. 그러면, 일반적으로 class j가 발생할 확률 자체가 높다. 하지만, likelihood는 이러한 경향을 반영하지 않는다. 간단한 예시를 들어보자.\n\n```plaintext\n 🤔 어떤 동물의 털에 존재하는 색의 갯수가 주어졌을 때, 고양이일 확률과 호랑이일 확률이라고 하자.\n\n  그리고, input data는 털에 존재하는 색의 수라고 하자. (호랑이는 대게 3가지 색, 백호 = 2가지 색, 고양이는 매우 다양)\n  그렇다면, P(털의 색 = 3|C = 호랑이), P(털의 색 = 3|C = 고양이)를 비교했을 때, 우리는 당연히 전자가 크다고 생각할 것이다.\n  하지만, 여기서 우리가 고려하지 않은 것이 있다. 바로 전체 고양이와 호랑이의 비율이다. \n  상대적으로 고양이가 호랑이보다 압도적으로 많다는 것을 고려했을 때, 고양이의 확률이 더 높을 수도 있다. \n\n  즉, 어떤 동물의 털에 존재하는 색의 갯수가 주어졌을 때, 고양이일 확률은 \n  P(C=고양이|털의 색=3) =  P(털의 색 = 3|C = 고양이)P(C=고양이)이다. (분모는 생략함.)\n```\n\n즉, Bayes Rule에 기반하여 우리가 원하는 output은 Posterior라는 것을 명확히 알 수 있다.\n\n$$\n\\begin{align*}\np(C_{k}|\\bold{x}) \u0026= {{p(\\bold{x}| C_{k}) p(C_{k})}\\over{\\sum_{j=1}^{K}{p(\\bold{x}|C_{j})p(C_{j})}}} \\\\\n\u0026\\propto p(\\bold{x}| C_{k}) p(C_{k})\n\\end{align*}\n$$\n\n위의 경우 Class간의 상대 비교에 사용하는 지표로 이를 사용하기 때문에, 분모(Normalization Factor, 확률의 총합이 1이 되도록 하는 역할)를 제외하여도 상관없기에 대게 복잡한 분모 계산을 제외하고 표현하는 것이 일반적이다.\n\n또한, 앞선 예시에서 얻을 수 있는 insight는 편향된 데이터일수록 MLE를 사용할 수 없다는 것이다. 위에서 Linear Regression이 Classification에 부적함한 경우도 데이터의 편향이 있을 경우이다. 이 역시 Linear Regression이 결국은 MLE에 기반하기 때문인 것이다.\n\n우리는 각 Class 자체의 확률(Prior)과 Likelihood를 이용할 수 있는 Discriminant Function을 구해야 한다는 것이다.\n\n\u003e **Logistic Regression**\n\n자 이제 드디어 Logistric Regression을 시작해보자. 우리는 Discriminant Function을 먼저 지정해야 한다. 여러 가지 방법이 있지만, 가장 대표적으로 사용되는 방법은 **Softmax**를 활용하는 것이다. **Softmax**를 활용하여 식을 나타내면 아래와 같다.\n\n$$\np(y_n = k | \\bold{x}_n, \\bold{w}) = {{\\exp(\\bold{w}_{k}^{\\top}\\bold{x}_n)}\\over{\\sum_{j=1}^{K}{\\exp(\\bold{w}_{j}^{\\top}\\bold{x}_n)}}}\n$$\n\n만약, class가 2개인 Binary Classification인 경우에 **Softmax**는 다음과 같아진다. 특히 이를 **Sigmoid**(**Logit**)라고 정의한다.\n\n$$\np(y_n = k | \\bold{x}_n, \\bold{w}) = {1\\over{1+\\exp(-y_{n}\\bold{w}^{\\top}\\bold{x}_{n})}}\n$$\n\n이를 유도하는 과정은 생략하지만, 여타 다른 블로그를 더 참고하면 좋다.\n\n이를 Linear Regression과 비교해서 살펴보자.\n\n![logistic-vs-linear](/images/logistic-vs-linear.jpg)\n\nLinear Regression은 특정값을 향해 나아가고 있다. 해당 방식을 보면 x가 대상의 특성을 강하게 가지고 있다면, 명확하게 구분할 수 있는데, 이는 **sigmoid**($\\sigma$) 함수가 [0, 1] 범위 내에서 정의되기 때문에 Regression 과정에서 극단 데이터(outlier)가 가지는 영향력이 Linear Regression보다 극단적으로 적다는 것을 알 수 있다.\n\n자 이것이 가지는 의미를 이전에 살펴본 **Bayes Decision Rule**에 기반해서 생각해보자. **sigmoid**($\\sigma$)는 결국 극단적인 데이터이든, 애매한 데이터이든 거의 비슷한 값으로 변환한다. 그렇다는 것은 기존에는 평균을 구하는데에 input(x)의 값이 큰 영향을 미쳤다면, **sigmoid**($\\sigma$)에서는 특정 class에 속하는 x의 갯수가 많은 영향을 주는 것을 알 수 있다. 이를 통해서 **sigmoid**($\\sigma$)가 완벽하지는 않지만, **Bayes Decision Rule**을 반영했다는 것을 알 수 있다.\n\n마지막으로, MLE를 통해서 Logistic Regression의 parameter를 추정해보자. (MAP는 기존에 살펴본 Linear Regression과 동일하게 regularizer를 더해주는 방식이기 때문에 생략한다.)\n\n$$\n\\begin{align*}\n\\argmax_{w}\\log{p(\\mathcal{D}|\\bold{w})} \u0026= \\argmax_{w}\\sum_{n=1}^{N}{\\log p(y_{n}|\\bold{x}_{n}, \\bold{w})} \\\\\n\u0026= \\argmax_{w}\\sum_{n=1}^{N}{\\log ({1\\over{1+\\exp(-y_{n}\\bold{w}^{\\top}\\bold{x}_{n})}}) } \\\\\n\u0026= \\argmax_{w}\\sum_{n=1}^{N}{-\\log (1+\\exp(-y_{n}\\bold{w}^{\\top}\\bold{x}_{n})) } \\\\\n\u0026= \\argmin_{w}\\sum_{n=1}^{N}{\\log (1+\\exp(-y_{n}\\bold{w}^{\\top}\\bold{x}_{n})) } \\\\\n\\end{align*}\n$$\n\n## Gradient Descent/Ascent\n\n위의 복잡한 식을 봤으면 알겠지만, 안타깝게도 일반식으로 $\\bold{w}_{MLE}, \\bold{w}_{MAP}$ 등을 구할 수는 없다. 따라서, 우리가 믿을 것은 Gradient를 이용한 방식이다.\n\n\u003e **Gradient Descent**\n\n먼저, 위에서 봤겠지만, Loss는 다음과 같다.\n\n$$\n\\mathcal{L} = \\sum_{n=1}^{N}{\\log(1+\\exp(-y_{n}\\bold{w}^{\\top}\\bold{x}_{n}))}\n$$\n\n이제 이를 미분해서 Gradient를 구하면 다음과 같다.\n\n$$\n\\nabla_{\\bold{w}}\\mathcal{L}(\\bold{w}) = \\sum_{n=1}^{N}{{{-y_{n}\\exp(-y_{n}\\bold{w}^{\\top}\\bold{x}_{n})}\\over{1+\\exp(-y_{n}\\bold{w}^{\\top}\\bold{x}_{n})}}\\bold{x}_{n}}\n$$\n\n따라서, Gradient Descent 방식은 다음과 같이 진행된다.\n\n$$\n\\bold{w}_{t+1} = \\bold{w}_{t} - \\alpha\\nabla_{\\bold{w}}\\mathcal{L}(\\bold{w}_{t})\n$$\n\n\u003e **Gradient Ascent**\n\n위의 방식이 가장 일반적이지만, 우리가 sigmoid의 class값으로 $y \\in \\{-1, 1\\}$ 대신 $y \\in \\{0, 1\\}$을 사용했을 경우 다른 식으로도 접근이 가능하다.\n\n이 경우에는 Loss라기 보기 어렵지만, 다른 형태의 optimization 형태가 만들어진다. (여기서 $\\sigma$는 sigmoid 함수를 의미한다.)\n\n$$\n\\argmax_{\\bold{w}} \\sum_{n=1}^{N}y_{n}\\log{\\sigma(\\bold{w}^{\\top}\\bold{x}_{n}) + (1-y_{n})\\log{(1-\\sigma(\\bold{w}^{\\top}\\bold{x}_{n}))} }\n$$\n\n이를 똑같이 미분하여 사용하지만, 반대로 이 경우에는 maximization 이기 때문에 Gradient Ascent를 수행해야 한다.\n\n우선 미분 결과 얻는 Gradient는 다음과 같다.\n\n$$\n\\nabla_{\\bold{w}}\\mathcal{L}(\\bold{w}) = \\sum_{n=1}^{N}{[y_{n} - \\sigma(\\bold{w}^{\\top}\\bold{x}_{n})]\\bold{x}_{n}}\n$$\n\n굉장히 간단하게 정리가 되어지는 것을 볼 수 있다.\n\n$$\n\\bold{w}_{t+1} = \\bold{w}_{t} - \\alpha\\nabla_{\\bold{w}}\\mathcal{L}(\\bold{w}_{t})\n$$\n\n따라서, 아래와 같이 Gradient Ascent를 활용하여 계산하는 것도 충분히 가능하다.\n\n\u003e **Newton Method**\n\n이러한 형태로 넘어오게 되면, 굉장히 많은 연산이 각 update마다 필요하다는 것을 알 수 있다. 따라서, 우리는 이 과정을 축약할 방법을 찾게 된다. 그 아이디어는 바로 gradient를 업데이트 할 때, linear 하게 update하는 것이 아니라 Quadratic하게 update하는 것이다. 이를 위한 방법론이 **Newton Method**이다. 이 방식을 Logistic Regression에 적용하였을 때, 이를 IRLS(Iterative Re-weighted Least Squared) Algorithm 이라고 부른다.\n\n![newton-method](/images/newton-method.jpg)\n\n위 그래프에서 f(x)가 Loss 라고 할 때, 우리는 $x_k$에서 직선형의 gradient를 사용하는 것보다 quadratic 형태를 사용하는 것이 더 빠르게 수렴값을 찾을 수 있다는 것을 알 수 있다.\n\n이를 사용하기 위해서는 다음 2가지에 대한 사전 이해가 필요하다.\n\n- Taylor Series  \n  smooth한 형태를 가진 x에 대한 함수를 x에 대한 급수의 형태로 변환한 것이다. 따라서 이를 식으로 나타내면 다음과 같다.  \n  $T_{\\infin}(x) = \\sum_{k=0}^{\\infin}{f^{(k)}(x_{0})\\over{k\\!}}(x-x_{0})^{k} $  \n  즉, sine 함수와 같은 형태의 그래프도 x의 급수 형태로 변환이 가능하다는 것이다. Newton Method에서는 무한대까지는 사용하지 않고, 대게 K=2까지를 쓴다.\n- Hessian Matrix  \n  특정 함수 $f(\\bold{x})$를 각 feature에 대해서 이중 편미분한 결과를 저장한 행렬이다. 식은 다음과 같다.  \n  $\n  H = \\nabla^{2}f(x) =\n  \\left[\n    \\begin{array}{ccc}\n      \\dfrac{\\partial^{2} f(\\mathbf{x})}{\\partial x_{1}^{2}} \u0026 \\cdots \u0026 \\dfrac{\\partial^{2} f(\\mathbf{x})}{\\partial x_{1} \\partial x_{D}} \\\\\n      \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\n      \\dfrac{\\partial^{2} f(\\mathbf{x})}{\\partial x_{D} \\partial x_{1}} \u0026 \\cdots \u0026 \\dfrac{\\partial^{2} f(\\mathbf{x})}{\\partial x_{n}^{2}}\n    \\end{array}\n  \\right]\n  $\n\n이를 이용해서, Newton Method의 결과값을 정리하면 결과는 다음과 같다.\n\n$$\n\\bold{w}^{(k+1)} = \\bold{w}^{(k)} - [\\nabla^{2}\\mathcal{J}(\\bold{w}^{(k)})]^{-1}\\nabla\\mathcal{J}(\\bold{w}^{(k)})\n$$\n\n자 이제 이것을 실제로 Logistic Regression 식에 대입해보자.\n\n$$\n\\begin{align*}\n  \\nabla\\mathcal{J}(w) \u0026= - \\sum_{n=1}^{N}(y_{n}-\\hat{y}_{n})x_{n} \\\\\n  \\nabla^{2}\\mathcal{J}(w) \u0026= \\sum_{n=1}^{N}\\hat{y}_{n}(1-\\hat{y}_{n})\\bold{x}_{n}\\bold{x}_{n}^{\\top}\n\\end{align*}\n$$\n\n여기서, 아래와 같이 변수를 정의하면,\n\n$$\nS =\n  \\begin{bmatrix}\n    \\hat{y}_{1}(1-\\hat{y}_1)  \u0026 \\cdots  \u0026 0                         \\\\\n    \\vdots                    \u0026 \\ddots  \u0026 \\vdots                     \\\\\n    0                         \u0026 \\cdots  \u0026 \\hat{y}_{N}(1-\\hat{y}_N)  \\\\\n  \\end{bmatrix},\n\n\\bold{b} =\n  \\begin{bmatrix}\n    {{y_{1} - \\hat{y}_{1}}\\over{\\hat{y}_{1}(1-\\hat{y}_{1})}} \\\\\n    \\vdots \\\\\n    {{y_{N} - \\hat{y}_{N}}\\over{\\hat{y}_{N}(1-\\hat{y}_{N})}}\n  \\end{bmatrix}\n$$\n\n결과적으로 다음과 같은 형태를 얻을 수 있다.\n\n$$\n\\begin{align*}\n\\bold{w}_{k+1} \u0026= \\bold{w}_{k} + (XS_{k}X^{\\top})^{-1}XS_{k}\\bold{b}_{k} \\\\\n\u0026= (XS_{k}X^{\\top})^{-1}[(XS_{k}X^{\\top})\\bold{w}_{k} + XS_{k}\\bold{b}_{k}] \\\\\n\u0026= (XS_{k}X^{\\top})^{-1}XS_{k}[X^{\\top}\\bold{w}_{k} + \\bold{b}_{k}]\n\\end{align*}\n$$\n\n이는 결코 계산 과정이 단순하다고는 할 수 없지만, 빠르게 수렴할 수 있기 때문에 가치있는 방법이다.\n\n## Reference\n\n- Tumbnail : Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=unsplash\u0026utm_medium=referral\u0026utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@markuswinkler?utm_source=unsplash\u0026utm_medium=referral\u0026utm_content=creditCopyText)\n","slug":"ml-logistic-regression","date":"2022-10-18 09:58","title":"[ML] 3. Logistic Regression","category":"AI","tags":["ML","LogisticRegression","Classification","SigmoidFunction","SoftmaxFunction","NewtonMethod"],"desc":"이전까지 우리는 input data가 들어왔을 때, continuos한 output을 얻는 것을 목표로 했다. 하지만 현실에서는 대게 정확한 수치보다는 특정 분류로 나누는 것이 효과적인 경우가 많다. 예를 들어, spam 필터링, object detection, 등 등. 따라서, 해당 포스팅에서는 classification을 위해서 사용할 수 있는 logistic regression에 대해서 살펴볼 것이다.","thumbnailSrc":"https://euidong.github.io/images/ml-thumbnail.jpg"},{"content":"\n## Intro\n\n우리는 Classification을 하기 위해서 Logistic Regression을 수행하였다. 그 결과 결국 Classification도 결국은 선을 긋는 것이라는 결론을 내리게 되었다. 하지만, 여기서 그치지 않고 하나 더 고민해 볼 수 있는 것이 있다. 바로 주어진 데이터에 대해서 완벽하게 구분하는 decision boundary가 여러 개 있을 때, 어떤 것이 가장 좋은 것일까? 이것에 대한 아이디어를 제시하는 것이 SVM이다. 해당 Posting에서는 이에 대해서 살펴보도록 하겠다.\n\n## (Hard Margin) SVM\n\nSoft Vector Machine의 약자로, 위에서 제시한 문제를 해결하기 위해서 Margin이라는 것을 도입하였다.\n\n\u003e **Margin**\n\n**Margin**이란 decison boundary와 가장 가까운 각 class의 두 점 사이의 거리를 2로 나눈 값이다.\n\n![svm-1](/images/svm-1.jpg)\n\n위의 그림은 똑같은 데이터 분포에서 대표적인 decision boundary 두 개를 제시한 것이다. 여기서 우리는 굉장히 많은 decision boundary를 그릴 수 있다. 그 중에서도 파란색 실선이 직관적으로 가장 적절한 decision boundary가 될 것이라고 짐작할 수 있다. 그 이유는 필연적으로 data는 noise에 의한 오차가 발생할 수 있는데 실제 데이터의 오차의 허용 범위를 우리는 **margin**(=capability of unexpected noise)만큼 확보할 수 있다는 의미로 이를 해석할 수 있다. 따라서, 이 margin을 크게 하면 할 수록 좋은 성능을 가지는 선을 그을 수 있을 것이라는 결론을 내릴 수 있다.\n\n이것이 SVM의 핵심 아이디어이다.\n\n그렇다면, margin을 수학적으로 정의해보자. 우리가 decision boundary를 $f(\\bold{x}) := \\bold{w}^{\\top}\\bold{x} + b = 0$이라고 한다면, 점($\\bold{x}_{i}$)과 vector 직선 vector 사이의 거리 공식을 통해서 ${{|f(\\bold{x}_{i})|}\\over{||\\bold{w}||^{2}}}$라는 것을 알 수 있다.\n\n따라서 margin은 수학적으로 다음과 같다.\n\n$$\n\\min_{i}{{|f(\\bold{x}_{i})|}\\over{||\\bold{w}||^{2}}}\n$$\n\n```plaintext\n 🤔 Canonical(법칙까지는 아니지만 사실상 표준화된) SVM\n\n SVM에서는 f(x) = 0인 등식 형태를 같는다. 즉 f(x)에 어떤 값을 곱해도 똑같다는 것이다.\n 그런데 margin의 크기를 구할 때에는, w와 b에 어떤 값이 곱해진다면 이 값이 굉장히 달라지게 된다.\n 따라서, 일반적으로 우리는 margin에서의 |f(x)| = 1이 될 수 있도록 설정한다. \n 이렇게 하면 계산이 굉장히 쉬워진다.\n```\n\n![svm-2](/images/svm-2.jpg)\n\n따라서, 우리는 위의 그림과 같은 형태로 $\\bold{x}^{-}$와 $\\bold{x}^{+}$를 찾을 수 있는 것이다.\n\n이제 마지막으로 margin을 정의해보자.\n\n$$\n\\begin{align*}\n\\rho \u0026= {1\\over2}\\{ {{|f(\\bold{x}^{+})|}\\over{||\\bold{w}||^{2}}} - {{|f(\\bold{x}^{-})|}\\over{||\\bold{w}||^{2}}}  \\} \\\\\n\u0026= {1\\over2}{1\\over{||\\bold{w}||^{2}}}\\{\\bold{w}^{\\top}\\bold{x}^{+} - \\bold{w}^{\\top}\\bold{x}^{-}\\} \\\\\n\u0026= {1\\over{||\\bold{w}||^{2}}}\n\\end{align*}\n$$\n\n\u003e **Optimization**\n\n그렇다면, 이제 우리는 문제를 해결할 준비가 된 것이다. 우리가 하고자 하는 것은 margin을 최대화하면서도, 모든 data를 오류없이 분류하는 것이다. 이는 다음과 같은 Constraint Optimization 형태로 변환할 수 있다.\n\n$$\n\\begin{align*}\n  \\text{maximize}   \\quad \u0026 {1\\over{||\\bold{w}||^{2}}} \u0026\\\\\n  \\text{subject to} \\quad \u0026 y_{i}(\\bold{w}^{\\top}\\bold{x}_{i} + b) \\geq 1, \u0026 i = 1, ..., N\n\\end{align*}\n$$\n\nConditional Optimization은 이전 Posting([[ML] 0. Base Knowledge](/posts/ml-base-knowledge))에서 다룬바 있다. 해당 내용에 대해 미숙하다면 한 번 살펴보고 오도록 하자.\n\n위 내용을 숙지하였다면, 위의 폼이 다소 바뀌어야 한다는 것을 알 것이다. 해당 형태를 바꾸면서, minimize 형태를 미분이 간편할 수 있도록 바꾸도록 하겠다.\n\n$$\n\\begin{align*}\n  \\text{minimize}   \\quad \u0026 {1\\over2}||\\bold{w}||^{2} \u0026\\\\\n  \\text{subject to} \\quad \u0026 1 - y_{i}(\\bold{w}^{\\top}\\bold{x}_{i} + b) \\leq 0, \u0026 i = 1, ..., N\n\\end{align*}\n$$\n\n우선 lagrangian은 다음과 같다.\n\n$$\n\\mathcal{L} = {1\\over2}||\\bold{w}||^{2} + \\sum_{i=1}^{N}\\alpha_{i}(1 - y_{i}(\\bold{w}^{\\top}\\bold{x}_{i} + b))\n$$\n\n이것에 KKT Condition을 적용하여 정리하면 다음과 같은 등식을 얻을 수 있다.\n\n$$\n\\bold{w} = \\sum_{i=1}^{N}\\alpha_{i}y_{i}\\bold{x}_{i}\n$$\n\n$$\n\\sum_{i=1}^{N}\\alpha_{i}y_{i} = 0\n$$\n\n이를 $\\mathcal{L}$에 대입하여 식을 정리하면, 다음과 같다.\n\n$$\n\\mathcal{L} = -{1\\over2}\\sum_{i=1}^{N}\\sum_{j=1}^{N}\\alpha_{i}\\alpha_{j}y_{i}y_{j}\\bold{x}_{i}^{\\top}\\bold{x}_{j} + \\sum_{i=1}^{N}\\alpha_{i}\n$$\n\n이제 이것을 이용해서 Dual Problem을 정의하면 다음과 같다.\n\n$$\n\\begin{align*}\n  \\text{maximize}   \\quad \u0026 -{1\\over2}\\sum_{i=1}^{N}\\sum_{j=1}^{N}\\alpha_{i}\\alpha_{j}y_{i}y_{j}\\bold{x}_{i}^{\\top}\\bold{x}_{j} + \\sum_{i=1}^{N}\\alpha_{i} \u0026\\\\\n  \\text{subject to} \\quad \u0026 \\sum_{i=1}^{N}\\alpha_{i}y_{i} = 0, \u0026 \\\\\n  \u0026 \\alpha_{i} \\geq 0, \u0026 i = 1, ..., N\n\\end{align*}\n$$\n\n이 식에서 눈여겨 볼점은 바로 constraint 부분이다. 이 과정을 통해서 결론적으로 constraint 부분이 부등식에서 등식이 되었다. 이는 연산 과정을 매우 간단하게 한다. 뿐만 아니라 $\\bold{x}_{i}^{\\top}\\bold{x}_{j}$는 한 번 계산하면, 전체 과정에서 계속해서 재사용할 수 있기 때문에 컴퓨팅 시에는 굉장한 이점을 발휘할 수 있다. 따라서, 실제로 값을 구할 때에는 이것을 이용하여 값을 구하는 것이 가장 일반적이다.\n\n## (Soft Margin) SVM\n\nSVM의 모든 절차를 살펴본 것 같지만, 우리가 간과한 사실이 하나 있다. 바로 그것은 우리는 data가 하나의 선을 통해서 완벽하게 나뉘어진다고 가정했다. 하지만, 실제 데이터는 그렇지 않을 가능성이 크다. 따라서, 우리는 어느 정도의 오차를 허용할 수 있도록 해야 한다. 이를 slack($\\zeta$)이라고 한다.\n\n![svm-2](/images/svm-2.jpg)\n\n이를 적용하면, 우리의 목적함수와 제약 조건을 변경해야 한다. 이를 변경하는 방법은 두 가지가 존재하는데 각 각 slack variable의 L2-norm을 목적함수에 더하는 방식과 L1-norm을 더하는 방식이다.\n\n\u003e **L2-norm Optimization**\n\n먼저 L2-norm을 더하는 방식을 알아보자\n$$\n\\begin{align*}\n  \\text{minimize}   \\quad \u0026 {1\\over2}||\\bold{w}||^{2} + C\\sum_{i=1}^{N}\\zeta_{i}^{2} \u0026\\\\\n  \\text{subject to} \\quad \u0026 1 - y_{i}(\\bold{w}^{\\top}\\bold{x}_{i} + b) - \\zeta_{i} \\leq 0, \u0026 i = 1, ..., N\n\\end{align*}\n$$\n\n여기서 $C$는 margin 최대화와 slackness 정도의 상대값을 의미한다. 만약, slackness보다 margin의 최대화가 중요하다면, C값은 커지고 반대라면 이 값은 작아진다.\n\n우선 lagrangian을 먼저 구하면 다음과 같다.\n\n$$\n\\mathcal{L} = {1\\over2}||\\bold{w}||^{2} + {C\\over2}\\sum_{i=1}^{N}\\zeta_{i}^{2} + \\sum_{i=1}^{N}\\alpha_{i}(1 - \\zeta_{i} - y_{i}(\\bold{w}^{\\top}\\bold{x}_{i} + b))\n$$\n\nKKT condition을 이용하여 주요 값들을 구하면 다음과 같은 등식을 얻을 수 있다.\n\n$$\n\\bold{w} = \\sum_{i=1}^{N}\\alpha_{i}y_{i}\\bold{x}_{i}\n$$\n\n$$\n\\sum_{i=1}^{N}\\alpha_{i}y_{i} = 0\n$$\n\n$$\n\\boldsymbol{\\zeta} = {\\alpha\\over{C}}\n$$\n\n마지막으로 이를 Dual Problem으로 재정의하면 다음과 같아진다.\n\n$$\n\\begin{align*}\n  \\text{maximize}   \\quad \u0026 -{1\\over2}\\sum_{i=1}^{N}\\sum_{j=1}^{N}\\alpha_{i}\\alpha_{j}y_{i}y_{j}(\\bold{x}_{i}^{\\top}\\bold{x}_{j} + {1\\over{C}}\\delta_{ij}) + \\sum_{i=1}^{N}\\alpha_{i} \u0026\\\\\n  \\text{subject to} \\quad \u0026 \\sum_{i=1}^{N}\\alpha_{i}y_{i} = 0, \u0026 \\\\\n  \u0026 \\alpha_{i} \\geq 0, \u0026 i = 1, ..., N\n\\end{align*}\n$$\n\n여기서 $\\delta_{ij}$는 단위행렬이다. 기존 hard margin svm과 비교했을 때, ${1\\over{C}}\\delta_{ij}$ 외에는 바뀌지 않는 것을 알 수 있다.\n\n\u003e **L1-norm Optimization**\n\n그 다음은 L1-norm이다.\n$$\n\\begin{align*}\n  \\text{minimize}   \\quad \u0026 {1\\over2}||\\bold{w}||^{2} + C\\sum_{i=1}^{N}\\zeta_{i} \u0026\\\\\n  \\text{subject to} \\quad \u0026 1 - y_{i}(\\bold{w}^{\\top}\\bold{x}_{i} + b) - \\zeta_{i} \\leq 0, \u0026 \\\\\n  \u0026 \\zeta_{i} \\geq 0 \u0026 i = 1, ..., N\n\\end{align*}\n$$\n\n여기서는 slack variable이 반드시 0보다 크거나 같다는 것을 주의하자.\n\nlagrangian은 다음과 같다.\n\n$$\n\\mathcal{L} = {1\\over2}||\\bold{w}||^{2} + C\\sum_{i=1}^{N}\\zeta_{i} + \\sum_{i=1}^{N}\\alpha_{i}(1 - \\zeta_{i} - y_{i}(\\bold{w}^{\\top}\\bold{x}_{i} + b)) -  \\sum_{i=1}^{N}\\beta_{i}\\zeta_{i}\n$$\n\nKKT condition을 이용하여 주요 값들을 구하면 다음과 같은 등식을 얻을 수 있다.\n\n$$\n\\bold{w} = \\sum_{i=1}^{N}\\alpha_{i}y_{i}\\bold{x}_{i}\n$$\n\n$$\n\\sum_{i=1}^{N}\\alpha_{i}y_{i} = 0\n$$\n\n$$\n\\sum_{i=1}^{N}\\beta_{i} = C\n$$\n\n마지막으로 이를 Dual Problem으로 재정의하면 다음과 같아진다.\n\n$$\n\\begin{align*}\n  \\text{maximize}   \\quad \u0026 -{1\\over2}\\sum_{i=1}^{N}\\sum_{j=1}^{N}\\alpha_{i}\\alpha_{j}y_{i}y_{j}\\bold{x}_{i}^{\\top}\\bold{x}_{j} + \\sum_{i=1}^{N}\\alpha_{i} \u0026\\\\\n  \\text{subject to} \\quad \u0026 \\sum_{i=1}^{N}\\alpha_{i}y_{i} = 0, \u0026 \\\\\n  \u0026 0 \\leq \\alpha_{i} \\leq C, \u0026 i = 1, ..., N\n\\end{align*}\n$$\n\n결국 기존 Hard margin과 비교했을 대는 마지막 constraint에 $\\alpha_{i} \\leq C$가 추가된 것 밖에 없다.\n\n---\n\n마지막으로 여기서 하나의 insight를 더 얻을 수 있다.  \nL1-norm의 optimization으로 돌아가보자.\n\n$$\n\\begin{align*}\n  \\text{minimize}   \\quad \u0026 {1\\over2}||\\bold{w}||^{2} + C\\sum_{i=1}^{N}\\zeta_{i} \u0026\\\\\n  \\text{subject to} \\quad \u0026 1 - y_{i}(\\bold{w}^{\\top}\\bold{x}_{i} + b) - \\zeta_{i} \\leq 0, \u0026 \\\\\n  \u0026 \\zeta_{i} \\geq 0 \u0026 i = 1, ..., N\n\\end{align*}\n$$\n\n목적 함수의 slack variable에 constraint의 값을 대입하여, 다음과 같이 변환이 가능하다.\n\n$$\n\\min {C^{\\prime}\\over2}||\\bold{w}||^{2} + \\sum_{i=1}^{N}max\\{ 0, 1 - y_{i}(\\bold{w}^{\\top}\\bold{x}_{i} + b) \\}\n$$\n\n이 형태는 logistric regression에 regularization을 수행한 것과 동일한 형태를 가지게 된다. 즉, 이전 logistic regression에서 regularization을 다루지 않았는데, 결국은 soft margin svm의 L1-norm 목적함수가 logistic regression 중에서도 hinge function이라는 것을 이용했을 때의 regularization이 되는 것이다.\n\n## Generalization\n\n여태까지 살펴본 Regression을 통해서 우리는 General한 Classification 방식을 지정할 수 있다. 우선 아래 식을 살펴보자.\n\n- Linear Regression(Quadratic Loss)  \n  $\\min {C^{\\prime}\\over2}||\\bold{w}||^{2} + \\sum_{i=1}^{N}{1\\over2}(1 - y_{i}(\\bold{w}^{\\top}\\phi(\\bold{x}_{i})) )^{2}$\n- Logit Regresion(Log Loss)  \n  $\\min {C^{\\prime}\\over2}||\\bold{w}||^{2} + \\sum_{i=1}^{N}\\log( 1 + \\exp[-y_{i}(\\bold{w}^{\\top}\\phi(\\bold{x}_{i})]) )$\n- Binary SVM(Hinge Loss)  \n  $\\min {C^{\\prime}\\over2}||\\bold{w}||^{2} + \\sum_{i=1}^{N}max\\{ 0, 1 - y_{i}(\\bold{w}^{\\top}\\phi(\\bold{x}_{i})) \\}$\n\n여태까지 나온 식들을 살펴보면 위와 같다. 우리는 여기서 아래와 같은 일반적인 형태의 Classification을 제시할 수 있다.\n\n- General Classification  \n  $\\min {C^{\\prime}\\over2}||\\bold{w}||^{2} + \\sum_{i=1}^{N}\\varepsilon\\log( 1 + \\exp[-y_{i}(\\bold{w}^{\\top}\\phi(\\bold{x}_{i})]) )$\n\n여기서 $\\varepsilon$이 1이면 바로 logistic regression이 되고, $\\varepsilon$이 0에 수렴할 수록 SVM이 된다. 아래 그림을 보면 이를 알 수 있다.\n\n![compare-regressions](/images/compare-regressions.jpg)\n\n## Reference\n\n- Tumbnail : Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=unsplash\u0026utm_medium=referral\u0026utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@markuswinkler?utm_source=unsplash\u0026utm_medium=referral\u0026utm_content=creditCopyText)\n","slug":"ml-svm","date":"2022-10-18 17:29","title":"[ML] 4. SVM","category":"AI","tags":["ML","SVM","GeneralClassifier"],"desc":"우리는 Classification을 하기 위해서 Logistic Regression을 수행하였다. 그 결과 결국 Classification도 결국은 선을 긋는 것이라는 결론을 내리게 되었다. 하지만, 여기서 그치지 않고 하나 더 고민해 볼 수 있는 것이 있다. 바로 주어진 데이터에 대해서 완벽하게 구분하는 decision boundary가 여러 개 있을 때, 어떤 것이 가장 좋은 것일까? 이것에 대한 아이디어를 제시하는 것이 SVM이다. 해당 Posting에서는 이에 대해서 살펴보도록 하겠다.","thumbnailSrc":"https://euidong.github.io/images/ml-thumbnail.jpg"},{"content":"\n## Intro\n\n이전 Posting에서는 SVM에 대해서 알아보았다. 일반적인 Logistic Regression에서는 softmax function을 통해서 여러 class를 구분할 수 있었지만, SVM의 경우 구분 선이 결국은 hyperplane으로만 표현 가능하다. 이를 해결하기 위한 SVM에서의 여러 해결책을 알아보자.\n\n## Multiclass in SVM\n\n가장 쉽게 생각할 수 있는 것은 SVM을 결합해서 Multiclass를 구분할 수 있다는 idea이다. 아래에서 곧바로 제시할 아이디어들이 이에 대한 내용이다.\n\n\u003e **1. OvR SVM**\n\nOne vs Rest 의 약자로 다양한 별명이 존재한다. (One vs All, OVA, One Against All, OAA)  \n이름에서부터 느껴지다시피 하나의 class와 그 외에 모든 class를 하나로 묶어서 SVM을 총 class 갯수만큼 만들어서 각 decision boundary로 부터 거리가 양의 방향으로 가장 큰 class를 선택하는 방식이다.\n\n$$\n\\argmax_{k \\in [K]}(\\bold{w}_{(k)}^{\\top}\\phi(\\bold{x})+ b_{(k)})\n$$\n\n![svm-ovr](/images/svm-ovr.jpg)\n\n이 방식은 하나의 큰 문제를 갖고 있는데, 그것은 과도한 데이터 불균형을 유발한다는 것이다. 이러한 문제는 class의 수가 많아질 수록 더 심해진다.\n\n\u003e **2. OvO SVM**\n\nOne vs (Another) One의 약자로, 해당 방식은 1대1로 비교하면서 각 SVM에서 선택한 class 중에서 가장 많은 선택을 받은 class를 최종한다. OvR과는 다르게 각 각의 class를 1대1로 비교하기 때문에 데이터의 불균형에 대한 위협은 덜하다. 하지만, 해당 과정을 수행하기 위해서는 총 K(K-1)/2개의 SVM이 필요하다.\n\n![svm-ovo](/images/svm-ovo.jpg)\n\n또한, 그림에서 \"?\"로 표시된 부분을 어떤 class로 선택할지에 대한 기준이 없다. 왜냐하면, 각 영역에서 한 표씩만 받기 때문이다.\n\n\u003e **3. DAG SVM**\n\n앞 서 보았던 OvO와 OvR의 문제를 해결하기 위해서 장단점을 취하기 위해서 둘을 결합한 방식이다. 계층 형태로 SVM을 구성하기 때문에 OvO보다는 적은 SVM을 사용하면서, OvO에서의 과도한 데이터 불균형을 해결한다.\n\n![svm-multiclass-comparing](/images/svm-multiclass-comparing.jpg)\n\n\u003e **4. WW SVM**\n\nmulticlass 구분을 SVM 최적화 과정에 적용하기 위해서 목적 함수의 형태를 변형하여 구현한 방법으로 자세히 다루지 않지만, 궁금하다면 해당 [🔗 link](https://www.csie.ntu.edu.tw/~cjlin/papers/multisvm.pdf)를 통해서 확인할 수 있다.\n\n## Kernel Method\n\n이전까지는 실제로 SVM의 형태를 변형시키거나 SVM을 여러 개 활용하여 multiclass classification을 수행하기 위한 방법을 보았다.\n\n또 다른 방법이 존재한다. 바로 input 공간을 확장하는 것이다. 즉, 더 많은 유의미한 feature를 수집하거나 기존 feature를 가공하여 새로운 feature로 활용하는 것이다. 시스템적으로 해결할 수 있는 방법은 기존 feature를 가공하여 새로운 feature를 활용하는 것이다. 아래의 예시를 보자.\n\n![feature-transposing](/images/feature-transposing.jpg)\n\n왼쪽 공간에서는 SVM은 decision vector를 적절하게 선택하는 것이 어렵다. 하지만, 기존 x 데이터에 절대값을 취하여 나타내어 데이터에 추가하면, 쉽게 decision boundary를 결정하는 것을 볼 수 있다. 그렇다면, 이러한 여러 변환 함수를 적용해보며 여러 feature를 더 추출하는 것이 좋은 해결책을 가져다 줄 것이다.\n\n그렇다면, 우리의 Soft margin SVM의 Dual Problem을 다시 한 번 살펴보자.\n\n$$\n\\begin{align*}\n  \\text{maximize}   \\quad \u0026 -{1\\over2}\\sum_{i=1}^{N}\\sum_{j=1}^{N}\\alpha_{i}\\alpha_{j}y_{i}y_{j}\\bold{x}_{i}^{\\top}\\bold{x}_{j} + \\sum_{i=1}^{N}\\alpha_{i} \u0026\\\\\n  \\text{subject to} \\quad \u0026 \\sum_{i=1}^{N}\\alpha_{i}y_{i} = 0, \u0026 \\\\\n  \u0026 0 \\leq \\alpha_{i} \\leq C, \u0026 i = 1, ..., N\n\\end{align*}\n$$\n\n이것을 feature 변환(basis function을 취한다.)을 통해서 다음과 같이 변형한다는 것이다.\n\n$$\n\\begin{align*}\n  \\text{maximize}   \\quad \u0026 -{1\\over2}\\sum_{i=1}^{N}\\sum_{j=1}^{N}\\alpha_{i}\\alpha_{j}y_{i}y_{j}\\red{\\boldsymbol{\\phi}^{\\top}(\\bold{x}_{i})\\boldsymbol{\\phi}(\\bold{x}_{j})} + \\sum_{i=1}^{N}\\alpha_{i} \u0026\\\\\n  \\text{subject to} \\quad \u0026 \\sum_{i=1}^{N}\\alpha_{i}y_{i} = 0, \u0026 \\\\\n  \u0026 0 \\leq \\alpha_{i} \\leq C, \u0026 i = 1, ..., N\n\\end{align*}\n$$\n\n하지만, 우리가 새로운 feature를 생성할 수록, 그리고 기존 feature를 복잡하게 사용할 수록 $\\boldsymbol{\\phi}(\\bold{x}_{i})$를 연산하는 비용이 커질 수 밖에 없다.  \n\n따라서, 우리는 일종의 trick을 하나 사용하도록 한다. 바로, 매 bayese update 마다 변하지 않고 재사용되는 값인 $\\boldsymbol{\\phi}^{\\top}(\\bold{x}_{i})\\boldsymbol{\\phi}(\\bold{x}_{j})$를 다른 값으로 대체하면 어떨까? 그렇게 하면 우리는 $\\boldsymbol{\\phi}(\\bold{x}_{i})$를 계산하고 구성하는 수고를 덜 수 있다.\n\n이것이 kernel method(trick)의 핵심 아이디어이다.\n\n가장 대표적인 예시로 아래와 같은 복잡한 $\\phi$ 가 주어졌을 때,\n\n$$\n\\boldsymbol{\\phi}(x) = \\exp[{{-x^{2}}\\over{2\\sigma^{2}}}](1, \\sqrt{1\\over{1!\\sigma^{2}}}x, \\sqrt{1\\over{2!\\sigma^{4}}}x^{2}, \\sqrt{1\\over{3!\\sigma^{6}}}x^{3}, \\cdots)\n$$\n\n아래의 (RBF) kernel로 대체가 가능해진다.\n\n$$\n\\kappa(x,x^{\\prime}) = \\exp(-{{(x - x^{\\prime})}\\over{2\\sigma^{2}}}) = \\boldsymbol{\\phi}^{\\top}(x)\\boldsymbol{\\phi}(x^{\\prime})\n$$\n\n대게 우리가 표현하고자 하는 형태의 $\\boldsymbol{\\phi}$는 이미 특정 kernel 함수로 매핑되고 있으니 직접 $\\boldsymbol{\\phi}$를 계산하기 전에 찾아보는 것이 도움이 될 것이다.[🔗 link](https://dataaspirant.com/svm-kernels/#t-1608054630726)\n\n## Reference\n\n- Tumbnail : Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=unsplash\u0026utm_medium=referral\u0026utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@markuswinkler?utm_source=unsplash\u0026utm_medium=referral\u0026utm_content=creditCopyText)\n- A Comparison of Methods for Multi-class Support Vector Machines, Chih-Wei Hsu and Chih-Jen Lin, \u003chttps://www.csie.ntu.edu.tw/~cjlin/papers/multisvm.pdf\u003e\n- SEVEN MOST POPULAR SVM KERNELS, \u003chttps://dataaspirant.com/svm-kernels/#t-1608054630726\u003e\n","slug":"ml-multiclass-classification-in-svm","date":"2022-10-18 23:19","title":"[ML] 5. Multiclass Classification in SVM","category":"AI","tags":["ML","SVM","KernelMethod"],"desc":"이전 Posting에서는 SVM에 대해서 알아보았다. 일반적인 Logistic Regression에서는 softmax function을 통해서 여러 class를 구분할 수 있었지만, SVM의 경우 구분 선이 결국은 hyperplane으로만 표현 가능하다. 이를 해결하기 위한 SVM에서의 여러 해결책을 알아보자.","thumbnailSrc":"https://euidong.github.io/images/ml-thumbnail.jpg"},{"content":"\n## Intro\n\n우리는 Linear Regression, Logistic Regression, SVM을 거치며 data로 부터 유의미한 pattern을 발견하는 과정을 알아보았다. 이 과정은 우리에게 명확한 식 하나를 제시하였고, 모든 과정을 우리가 제어할 수 있게 하였다. 하지만, 실제 데이터를 우리가 모두 명확하게 이해할 수 있는 형태로 분류할 수 있는 것인지는 의문이 들 수 있다. 그렇다면, 우리가 이해하지는 못하지만, 알아서 최적의 결과를 가져오게 할 수 있는 방법이 있을까? 이런 마법같은 일에 대한 아이디어를 제시하는 것이 Neural Network이다.\n  게 알지 못하지만 input이 들어왔을 때, 이를 처리해서 output을 전달하는 시스템을 우리의 신체에서 찾게 된다. 바로 우리 몸을 이루는 신경망이다. 예시로 우리는 눈을 통해 빛이라는 input을 받으면, 우리 눈과 뇌에서 무슨 일이 발생하는지는 모르지만 결과적으로 우리는 물체를 볼 수 있다. 이 과정을 추측의 과정에 도입하면 어떻게 될까?\n\n## Perceptron\n\nPerception(인지 능력) + Neuron(신경 세포)의 합성어이다. 중고등학교 생명 수업을 들었다면, 우리의 모든 신경은 뉴런이라는 단위 세포로 이루어진다는 것을 배웠을 것이다. 즉, 우리의 신경 세포를 컴퓨터 공학에서 활용하기 위해서, 수학적으로 변환한 것이다. 형태를 먼저 살펴보자.\n\n$$\ny = sign(\\bold{w}^{\\top}\\bold{x} + b)\n$$\n\n![nn-perceptron-1](/images/nn-perceptron-1.jpg)\n\n대단한 것을 기대했다면 실망하겠지만, simple한 것이 최고라는 연구의 진리에 따라서 위의 식은 꽤나 합리적이다. 우리가 Linear Regression과 Logistic Regression을 배웠으니 알 것이다. 이는 사실 Linear Regression을 이용해서 우리가 Classification을 수행할 때 사용했던 식이다. 즉, perceptron 하나는 input을 선형으로 구분할 수 있도록 하는 decision boundary를 찾는 것과 같다.\n\n\u003e **Optimization**\n\n그렇다면, 해당 perceptron을 통해서 모든 데이터를 구분하기 위해서는 다음을 만족하는 $\\bold{w}$를 찾아야 한다.\n\n$$\ny_{n} =\n\\begin{cases}\n1  \u0026\\text{ if  } \\bold{x}_{n} \\in \\mathcal{C}_{1} \\\\\n-1 \u0026\\text{ if  } \\bold{x}_{n} \\in \\mathcal{C}_{2} \\\\\n\\end{cases}\n$$\n$$\ny_{n}\\bold{w}^{\\top}\\bold{x}_{n} \\gt 0, \\forall n\n$$\n\n결국 Loss 함수는 perceptron의 잘못된 classification 결과를 최소화하는 것이다.\n\n$$\n\\mathcal{J}(\\bold{w}) = - \\sum_{n \\in \\mathcal{M}(\\bold{w})}{y_{n}\\bold{w}^{\\top}\\bold{x}_{n}} \\quad( \\mathcal{M}(\\bold{w}) = \\{ n : y_{n}\\bold{w}^{\\top}\\bold{x}_{n} \\} )\n$$\n$$\n\\nabla_{\\bold{w}}\\mathcal{J}(\\bold{w}) = - \\sum_{n \\in \\mathcal{M}(\\bold{w})}{y_{n}\\bold{x}_{n}}\n$$\n\n따라서, 우리가 사용할 수 있는 Gradient Descent식은 다음과 같다.\n\n$$\n\\bold{w}_{t+1} = \\bold{w}_{t} + \\alpha\\sum_{n \\in \\mathcal{M}(\\bold{w})}{y_{n}\\bold{x}_{n}}\n$$\n\n간단한 예시로 AND, OR Gate를 percentron을 통해 표현해보자.\n\n![nn-and-gate](/images/nn-and-gate.jpg)\n![nn-or-gate](/images/nn-or-gate.jpg)\n\n하지만, 우리가 다루는 데이터는 항상 완벽하게 선으로 나뉘어지지는 않는다. 하나의 perceptron으로는 아래의 XOR조차도 구분해낼 수 없다.\n\n![nn-multi-line-example](/images/nn-multi-line-example.jpg)\n\n## Multilayer Perceptron\n\n위의 문제를 해결하기 위해서 나온 것이 perceptron을 다층으로 쌓아서 해결하는 방법이다. 이제는 하나의 신경세포였던 perceptron을 진짜 신경망처럼 연결해보자는 것이다.\n\n먼저 추상적인 예시를 생각해보자. 우리가 XOR Gate를 만들기 위해서는 어떤 Gate를 결합해야할까?\n\n$$\na \\oplus b = ab + \\bar{a}\\bar{b}\n$$\n\n우리는 AND Gate 2개 연산을 수행하고, 해당 결과값을 이용해서 OR Gate 연산을 수행하면 XOR Gate를 표현할 수 있다는 것을 알고 있다. 그렇다면, 각 Gate는 우리가 perceptron으로 나타낼 수 있었는데 그냥 이것을 gate로 표현하듯이 똑같이 나타내면 풀 수 있지 않을까?\n\n그래서 직접 수행해보면 다음과 같은 값을 구할 수 있다.\n\n![nn-xor-gate](/images/nn-xor-gate.jpg)\n\n```plaintext\n 🤔 Insight\n\n 위의 과정을 보다보면 놀라운 것을 하나 발견할 수 있다. 바로 왼 쪽 그림의 변화이다. \n 첫번째, 두 개의 perceptron을 통해서 만들어진 output이 이루는 결과값의 형태로 feature를 변환하면, \n 하나의 perceptron으로 decision boundary를 그릴 수 있다는 것이다. \n 이는 마치 이전 linear regression에서 배웠던 basis function(ϕ)이 했던 역할이다.\n\n 그렇다면, 이를 더욱 확장해보자. \n 만약 해당 Layer가 더 깊어진다고 해도, 출력 직전의 layer는 단순히 이전 모든 layer는 입력 데이터를 가공해서\nfeature를 변환하는 하나의 basis function(ϕ)를 취한 것으로 이해할 수 있다.\n```\n\n결론적으로 우리는 더 복잡하고, 어려운 문제의 경우에도 더 깊게 신경망을 구성하면 결국은 문제를 풀 수 있다는 것이다.\n\n\u003e **Universal Approximation Theorem**\n\n위와 같은 깊은 신경망 구조를 이용하자는 주장도 있지만, 이와 유사하게 넓은 신경망을 쓰자는 주장도 존재했다.  \n\n![nn-universal-approx-theorem-1](/images/nn-universal-approx-theorem-1.jpg)\n\n만약, 우리가 하나의 Layer와 output에서 최종 output perceptron만 갖고 처리를 한다면, 결국 여러 perceptron의 weighted 합으로 볼 수 있다. 그 경우 우리는 계단 함수의 weighted 합으로 생각할 수 있는데 perceptron이 많아질 수록 촘촘해지며 정답과 유사한 추론이 가능해진다.(마치 적분의 개념과 유사하다. 물론 이는 추상적인 설명이기 때문에 실제로는 계단함수의 합이기 때문에 좀 다르다.)\n\n![nn-universal-approx-theorem-2](/images/nn-universal-approx-theorem-2.jpg)\n\n위의 그림을 보면 이해할 수 있다. 하지만, 이 방식은 결국 모든 함수 형태를 기억하는 것이다.(**memorizer**) 이것은 input data가 많아질 수록 복잡도가 급격하게 증가하기 때문에 학습과 예측과정에 굉장히 많은 시간을 소모한다.\n\n\u003e **Multilayer Optimization(Backpropagation)**\n\n그렇다면, 넓은 신경망이 한계가 있으니 선택지는 input과 output 사이의 layer(**hidden layer**)의 갯수를 늘려서 깊은 신경망을 만드는 것이다. 하지만, 우리가 사용하고 있는 perceptron은 sign함수로 감싸져있기 때문에 미분 시에 기울기가 0이라는 문제를 갖는다. 또한, 그렇다고 정답의 갯수를 이용하기에는 각 perceptron의 영향을 전달하기에 부족하다는 것이 명확하다. 따라서, 우리는 perceptron에 있는 정답을 판별하는 함수 sign을 다른 함수로 대체하기로 한다.\n\n![nn-perceptron-2](/images/nn-perceptron-2.jpg)\n\n여기서 이 함수를 우리는 **activation function**이라고 부르고 대표적으로는 같은 종류가 있다.\n\n- **sigmoid**  \n  우리가 가장 쉽게 생각할 수 있는 함수이다. logistic regression에서 사용해본만큼 기울기값을 효과적으로 가질 수 있다.\n- **tanh**  \n  sigmod와 굉장히 유사한 함수이다. 따라서, 비슷한 용도로 사용될 수 있다.\n- **ReLU**  \n  출력 시점에서는 사용하지 않지만, 각 각의 hidden layer에서 이를 사용하는 경우가 많다. 왜냐하면, sigmoid 함수는 출력값의 형태가 [0, 1], tanh는 [-1, 1]이기 때문에 반복해서 적용하면, gradient가 사라지는 현상이 발생할 수 있다. 따라서, 기울기를 있는 그대로 적용할 수 있는 이러한 형태를 출력 이전에는 많이 사용한다.\n- **Leaky ReLU**  \n  ReLU가 음수값을 완전히 무시하는데 Leaky ReLU는 이러한 데이터가 조금이라도 의미 있는 경우에 사용할 수 있다.\n- **ELU**  \n  Leaky ReLU와 비슷한 이유이다.\n\n  ![activation-functions](/images/activation-functions.png)\n  \n자료가 보이지 않는다면 [🔗 wikipedia](https://en.wikipedia.org/wiki/Activation_function)를 참고하자.\n\n---\n\n자 이제 실제로 어떻게 optimization을 수행할지를 알아보도록 하자.\n\n먼저, Loss는 가장 마지막 layer(output layer)의 output과 실제 값과의 차이가 될 것이다. 따라서, 다음과 같이 정의할 수 있다.\n\n(아래서 $\\bold{h}_{L}$은 L번째 layer의 output을 의미한다.)\n\n$$\n\\begin{align*}\n\\mathcal{L} \u0026= \\sum_{n=1}^{N}{\\ell(y_n, \\bold{h}_L)} \\\\\n\u0026= \\sum_{n=1}^{N}{(y_{n} - \\bold{h}_{L})^2} \\\\\n\u0026= \\sum_{n=1}^{N}{(y_{n} - \\sigma(\\bold{w}_{L}^{\\top}\\bold{h}_{L-1} + b_{L-1}))^2} \\\\\n\u0026= \\sum_{n=1}^{N}{(y_{n} - \\sigma(\\bold{w}_{L}^{\\top}\\sigma(\\bold{w}_{L-1}^{\\top}\\bold{h}_{L-2} + b_{L-2}) + b_{L-1}))^2} \\\\\n\u0026= ...\n\\end{align*}\n$$\n\n여기서 중요한 것은 우리는 전체 $\\bold{W}$를 학습시켜야 한다는 것이다. 우리는 출력층만 학습하는 게 아니라 전체 모든 layer의 $\\bold{w}_{i}$를 업데이트해야 한다는 것이다.\n\n그러기 위해서는 우리는 ${{\\partial\\mathcal{L}}\\over{\\partial \\bold{w}_{i}}}$를 모두 구해야 한다는 것이다. 아마 가장 습관적으로 하는 행위는 숫자가 작은 값부터 편미분하면서 진행하는 것이다. 하지만, 그렇게 하지말고 반대 순서로 미분을 하라는 것이 **backpropagation**의 main idea이다.\n\n$$\n{{\\partial\\mathcal{L}}\\over{\\partial \\bold{w}_{L}}} = \\sum_{n=1}^{N}\\{({\\partial \\bold{h}_L \\over \\partial \\bold{w}_{L}} )\\times\\red{-2(y_{n} - \\sigma(\\bold{w}_{L}^{\\top}\\bold{h}_{L-1} + b_{L-1}))}\\}\n$$\n\n$$\n{{\\partial\\mathcal{L}}\\over{\\partial \\bold{w}_{L-1}}} = \\sum_{n=1}^{N}\\{({\\partial \\bold{h}_{L} \\over \\partial \\bold{w}_{L-1} })\\times\\red{-2(y_{n} - \\sigma(\\bold{w}_{L}^{\\top}\\bold{h}_{L-1} + b_{L-1}))}\\}\n$$\n\n즉, 다음과 같은 chain rule을 이용하는 것이다.\n\n$$\n\\begin{align*}\n{{\\partial\\mathcal{L}}\\over{\\partial \\bold{w}_{L}}} \u0026= \\red{ {{\\partial\\mathcal{L}}\\over{\\partial \\bold{h}_{L}}} } {{\\partial\\bold{h}_{L}}\\over{\\partial \\bold{w}_{L}}} \\\\\n{{\\partial\\mathcal{L}}\\over{\\partial \\bold{w}_{L-1}}} \u0026= \\red{ {{\\partial\\mathcal{L}}\\over{\\partial \\bold{h}_{L}}} } {{\\partial\\bold{h}_{L}}\\over{\\partial \\bold{w}_{L-1}}} \\\\\n\u0026= \\red{ {{\\partial\\mathcal{L}}\\over{\\partial \\bold{h}_{L}}} } {{\\partial\\bold{h}_{L}}\\over{\\partial \\bold{h}_{L-1}}} {{\\partial\\bold{h}_{L-1}}\\over{\\partial \\bold{w}_{L-1}}} \\\\\n\u0026= \\blue{ {{\\partial\\mathcal{L}}\\over{\\partial \\bold{h}_{L-1}}} } {{\\partial\\bold{h}_{L-1}}\\over{\\partial \\bold{w}_{L-1}}} \\\\\n{{\\partial\\mathcal{L}}\\over{\\partial \\bold{w}_{L-2}}} \u0026= \\blue{ {{\\partial\\mathcal{L}}\\over{\\partial \\bold{h}_{L-1}}} } {{\\partial\\bold{h}_{L}}\\over{\\partial \\bold{w}_{L-2}}} \\\\\n\\end{align*}\n$$\n\n우리는 빨간색과 파란색 부분의 연산을 재활용할 수 있다는 것이다. 또한, ${{\\partial\\bold{h}_{l}}\\over{\\partial \\bold{w}_{l}}}$은 굉장히 쉬운 연산이기에 우리가 신경 써서 계산해야 할 값은 매단계를 연결해줄 $ {{\\partial\\bold{h}_{l}}\\over{\\partial \\bold{h}_{l-1}}}$이다.\n\n![ml-backpropagation](/images/ml-backpropagation.jpg)\n\n## Loss Function\n\n우선 KL-Divergence, Entropy, Cross Entropy에 대한 약간의 이해가 필요하니 이전 Posting([🔗 Base Knowledge](posts/ml-base-knowledge))을 살펴보고 오자.\n\n위에서는 자연스럽게 Loss를 계산할 때, Squared Error를 사용하였다. 하지만 경우에 따라서는 다양한 함수를 사용할 수 있다. multiclass classification에서는 **Cross Entropy Loss**를 사용한다.\n\n우선 Cross Entropy Loss는 대게 L2 Loss(Squared Error)와 같이 비교되어진다. 우선 우리가 이전 [🔗 Parametric Estimation](posts/ml-parametric-estimation)에서 MLE를 다룰 때, KL-Divergence를 통해서 MLE가 최적 parameter를 찾을 것이라는 걸 증명한 적이 있다. 그렇다면, 우리가 [🔗 Logistic Regression](/posts/ml-logistic-regression)에서 Squared Error를 통해서 Loss를 구했던 공식을 확인해보자.(Gradient Asecent Part)\n\n여기서 우리는 다음과 공식을 봤었다.\n\n$$\n\\argmax_{\\bold{w}} \\sum_{n=1}^{N}y_{n}\\log{\\sigma(\\bold{w}^{\\top}\\bold{x}_{n}) + (1-y_{n})\\log{(1-\\sigma(\\bold{w}^{\\top}\\bold{x}_{n}))} }\n$$\n\n이 공식을 Cross Entropy를 통해서 설명할 수 있다.\n\n$$\n\\begin{align*}\nH_{q}(p) \u0026= - \\sum_{x \\in \\Omega}q(x)\\log_{2}p(x) \\\\\n\u0026= \\sum_{n=1}^{N}{[-y_{n}\\log\\hat{y}_{n} - (1- y_{n})\\log(1-\\hat{y}_{n})]}\n\\end{align*}\n$$\n\n즉, 여기서 우리가 얻을 수 있는 insight는 Cross Entropy는 sigmoid를 취한 binary classification에서 Squared Error와 같고, 이러한 Cross Entropy를 Squared Error가 할 수 없는 Multiclass에는 적용할 수 있을 것이라는 점이다. 왜냐하면, multiclass classification에 사용되는 Softmax Function을 이용해서 Sigmoid function을 유도하기 때문이다. 잠시 까먹었을까봐 Softmax 함수를 다시 적는다.\n\n$$\n\\hat{y}_{k} = {{\\exp(\\bold{w}_{k}^{\\top}\\bold{x})}\\over{\\sum_{i=1}^{K}{\\exp(\\bold{w}_{i}^{\\top}\\bold{x})}}}\n$$\n\n따라서, Cross Entropy Loss를 대입하여 다음과 같은 Loss를 얻을 수 있다.\n\n$$\n\\mathcal{L} = \\sum_{n=1}^{N}\\sum_{k=1}^{K}[-y_{k,n}\\log\\hat{y}_{k,n}],\\quad y_{k,n} = p(x_{n} \\in C_{k}| x_{n})\n$$\n\n여기서 $y_{k,n}$은 one-hot encoding된 데이터로, 정답인 class만 1이고 나머지는 모두 0으로 되어 있다. 따라서, multiclass classification에서는 위와 같은 Loss를 주로 사용한다.\n\n이 두가지 뿐만 아니라 여러가지 Loss Function이 이미 존재한다. 예전에 잠깐 설명했던 L1 Loss부터 시작해서 NLLLoss, KLDivLoss 등등 존재하며, data의 특성과 output의 형태에 따라서 우리는 스스로 Loss Function을 새로 정의할 수도 있다.\n\n## Reference\n\n- Tumbnail : Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=unsplash\u0026utm_medium=referral\u0026utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@markuswinkler?utm_source=unsplash\u0026utm_medium=referral\u0026utm_content=creditCopyText)\n- activation function, wikipedia, \u003chttps://en.wikipedia.org/wiki/Activation_function\u003e\n","slug":"ml-nn","date":"2022-10-20 09:00","title":"[ML] 6. Neural Network","category":"AI","tags":["ML","NeuralNetwork","Perceptron","Backpropagation","CrossEntropyLoss"],"desc":"우리는 Linear Regression, Logistic Regression, SVM을 거치며 data로 부터 유의미한 pattern을 발견하는 과정을 알아보았다. 이 과정은 우리에게 명확한 식 하나를 제시하였고, 모든 과정을 우리가 제어할 수 있게 하였다. 하지만, 실제 데이터를 우리가 모두 명확하게 이해할 수 있는 형태로 분류할 수 있는 것인지는 의문이 들 수 있다. 그렇다면, 우리가 이해하지는 못하지만, 알아서 최적의 결과를 가져오게 할 수 있는 방법이 있을까? 이런 마법같은 일에 대한 아이디어를 제시하는 것이 Neural Network이다.  게 알지 못하지만 input이 들어왔을 때, 이를 처리해서 output을 전달하는 시스템을 우리의 신체에서 찾게 된다. 바로 우리 몸을 이루는 신경망이다. 예시로 우리는 눈을 통해 빛이라는 input을 받으면, 우리 눈과 뇌에서 무슨 일이 발생하는지는 모르지만 결과적으로 우리는 물체를 볼 수 있다. 이 과정을 추측의 과정에 도입하면 어떻게 될까?","thumbnailSrc":"https://euidong.github.io/images/ml-thumbnail.jpg"},{"content":"\n## Intro\n\nMachine Learning은 주어진 data를 가장 잘 설명할 수 있는 pattern(Model)을 찾는 것이 목표라고 하였다. 그렇다면, \"data가 가지는 여러가지 정보(feature)들 중에서 어떤 feature를 중점적으로 보고 이용할 수 있을까?\" 그리고, \"만약 여러 feature들이 서로 연관이 있다면 이를 연산의 최적화를 위해 이용할 수 있지 않을까?\" 라는 접근이 가능하다. 여기서 Graphical Model은 이러한 관계를 시각적으로 표현할 수 있으며, 이를 통해서 연산 최적화에 대한 insight를 얻을 수 있다.\n\n## Relation\n\n각 feature들 즉, Random Variable들 간의 관계는 크게 세 가지 종류가 있다.\n\n1. **Correlation(상관관계)**  \n   쉽게 생각하면 두 Random Variable이 있을 때, 서로가 값 추정에 영향을 준다는 것이다. 즉, 특정 Random Variable의 값이 관측되었을 때, Random Variable이 가지는 값의 범위가 제한되고, 확률이 변화한다.  \n   즉, $X$와$Y$가 서로 Correlation이 존재한다면, $P(X) \\neq P(X|Y)$  \n   그렇기에 두 Random Variable이 서로 독립(independence)이라면, Correlation이 존재하지 않는 것이다.  \n2. **Causality(인과관계)**  \n   쉽게 Correlation과 헷갈릴 수 있지만, Causality는 원인과 결과가 나타나는 관계를 의미한다. 쉬운 예시로 X라는 사건과 Y라는 사건이 빈번하게 같이 발생한다고, 쉽게 X라는 사건이 Y의 원인이라고 말할 수는 없는 것과 같은 원리이다. 또한, 중요한 특징 중에 하나는 방향이 분명하다는 것이다. 원인과 결과는 대게 분리되기 때문에 원인이 되는 사건과 결과가 되는 사건이 분명이 구분된다. 결론적으로, Causality를 가지는 두 사건은 서로 Correlation이 있는 것은 자명하지만, Correlation이 존재한다고 Causality를 단정할 수 있는 것은 아니다. 즉, Correlation이 Causality를 포함하는 개념이다. 그렇기에 서로 독립이라면, Causality도 존재하지 않는 것이다.\n3. **Independence(독립)**  \n   위에 제시된 두 가지는 dependence 관계를 나타낸다. 이는 두 Random Variable의 값이 서로의 값에 영향을 전혀 주지 않음을 의미한다.  \n   즉, $X$와 $Y$가 서로 독립하다면, $P(X) = P(X|Y), P(Y) = P(Y|X)$이다.  \n   (결과적으로 Independence가 아니라면 최소한의 Correlation이 존재한다.)\n\n이러한 관계를 어떻게 활용할 수 있을지를 고민해보자. 우리가 집중적으로 살펴볼 것은 **Independence**이다. 만약, 우리가 구하고자 하는 결과값($Y$)가 존재할 때, 특정 feature($X_{1}$)가 서로 독립한다고 하자. $P(Y|X_{1})=P(Y)$에 의해서 $X_{1}$는 전혀 쓸모가 없는 정보임을 알 수가 있다. 이렇게 명확한 independence를 안다면 해당 feature를 Learning 및 Estimation에서 제거하는 것은 쉬울 것이다. 하지만, 우리는 이러한 관계를 명확하게 밝히기 어려울 때가 많다. 그렇다면 결국 우리가 Machine Learning을 통해서 구하고자 하는 식인 아래 식을 어떻게 하면 좀 더 최적화할 수 있을까?\n\n$$\nP(Y|X_{1}, X_{2}, \\cdots, X_{N}) = \\frac{P(Y, X_{1}, X_{2}, \\cdots, X_{N})}{P(X_{1}, X_{2}, \\cdots, X_{N})}\n$$\n\n여기서의 핵심은 바로 **Joint Probability**에 있다. 우리는 결국 좋든 싫든 **Joint Probability**를 구해야 한다.\n\n$$\n\\begin{align*}\nP(X_{1}, X_{2}, \\cdots, X_{N}) \u0026= P(X_{1} | X_{2}, X_{3}, \\cdots, X_{N}) \\times P(X_{2}, X_{3}, \\cdots, X_{N})\\\\\n\u0026= P(X_{1} | X_{2}, X_{3}, \\cdots, X_{N}) \\times P(X_{2} |, X_{3}, X_{4}, \\cdots, X_{N}) \\times P(X_{3}, X_{4}, \\cdots, X_{N}) \\\\\n\u0026= \\prod_{i=1}^{N} P(X_{i} | X_{i+1}, X_{i+2}, \\cdots, X_{N})\n\\end{align*}\n$$\n\n위에 제시한 **Probability Chain Rule**에 의해서 우리는 Joint Probability는 각각의 Random Variable 의 Conditional Probability라고 할 수 있다. 그렇다면, 우리는 Random Variable이 N개 있고, 각 Random Variable의 dimension이 L이라고 할 때, 다음과 같아짐을 알 수 있다.\n\n$$\nL^{N} \\times L^{N-1} \\times \\cdots \\times L^{1} = O(L^{N})\n$$\n\n이러한 연산을 어떻게 하면 좀 더 최적화할 수 있을까? Hint는 Conditional Probability 각 각의 변수의 양을 줄이는 것이다. 우리가 어떤 관계가 있을 때, 이 Random Variable의 갯수를 줄일 수 있을까? 바로 변수 간 Conditional Independence가 이에 대한 해답을 제시한다.\n\n### Conditional Independence\n\nConditional Independence는 Conditional Probability처럼 특정 정보(다른 Random Variable의 값)가 주어졌을 때, 두 Random Variable이 서로 독립이라는 것이다.\n\n쉽게 예를 들어 설명한다면, \"과음\"과 \"빨간 얼굴\" 사이의 관계라고 할 수 있다. 일반적으로 우리는 \"빨간 얼굴\"인 사람이 \"과음\"을 했을 것이라고 판단할 것이다. 즉, \"빨간 얼굴\"과 \"과음\" 사이에는 관계가 존재한다(dependency). 하지만, \"혈중 알코올 농도\"라는 정보가 주어진다면 어떨까? \"혈중 알코올 농도\"가 주어진다면, 사실 \"빨간 얼굴\"은 더 이상 \"과음\" 여부를 판단하는 기준에 영향을 1도 주지 않을 것이다. 이때에는 \"과음\"과 \"빨간 얼굴\"은 independence하다. 우리는 이런 경우를 다음과 같이 표현할 수 있다.\n\n$$\n\\text{과음} \\not\\!\\perp\\!\\!\\!\\perp \\text{빨간 얼굴}\n$$\n$$\n\\text{과음} \\perp\\!\\!\\!\\!\\perp \\text{빨간 얼굴} |\\ \\text{혈중 알코올 농도}\n$$\n\n즉, 확률에 적용하면 다음과 같다.\n\n$$\nP(\\text{과음} | \\text{빨간 얼굴, 혈중 알코올 농도}) = P(\\text{과음} | \\text{혈중 알코올 농도})\n$$\n\n여기서 우리가 하고 싶었던 것이 나왔다. 바로 \"빨간 얼굴\"이라는 Random Variable이 없어졌다. 즉, \"과음\"과 \"빨간 얼굴\" 사이의 관계 같은 것을 찾을 수 있다면, 우리는 계산 과정을 단순화할 수 있다.\n\n즉, 이것이 우리가 **Graph**를 통해서 찾고자 하는 것이다.\n\n## Graphical Model\n\n**Graphical Model**은 **Graph**를 이용해서 Random Variable들의 관계를 표현하고, 이를 통해서 **Joint Probability**를 계산하는 방법이다. **Graph**를 그리는 방법은 기본적으로 Random Variable 하나 하나가 Graph의 Node가 되고, 각 Node간의 관계가 Edge가 된다. 그런데, 이 관계가 Correlation이냐, Causality냐에 따라서 두 가지 종류로 나뉘게 된다. \u003cmark\u003e**Correlation**은 일반적으로 관계의 방향이 없기에 **Undirected Graph**\u003c/mark\u003e로 표현하고, \u003cmark\u003e**Causality**는 관계의 방향이 있기에 **Directed Graph**\u003c/mark\u003e로 표현한다. 이는 아래에서 더 자세히 다루도록 하겠다.\n\n### Markov Random Field(Undirected Graphical Model, Correlation)\n\n**Markov Random Field**(MRF)라고 불리며, **Correlation**를 표현한 Graph이다. 각 Node는 Random Variable을 의미하며, Edge는 Correlation를 의미한다. 즉, 두 Node가 Edge로 연결되어 있다면, 두 Random Variable은 Independence하지 않다는 것이다.\n\n![ml-undirected-graph-1](/images/ml-undirected-graph-1.jpg)\n\n여기서 중요한 것은 Random Variable을 대표하는 Node와 Correlation을 대표하는 Edge이기 때문에, Graph $G=(V, E)$에서 Random Variable의 집합 $X = \\{X_{1}, X_{2}, \\cdots, X_{|V|}\\}$이고, $\\{1,2, \\cdots, |V|\\}$가 주어질 때 반드시 아래에 제시된 **Markov Property들**을 만족해야 한다.\n\n1. \u003cmark\u003e**Pairwise Markov Property**\u003c/mark\u003e  \n   인접하지 않은 Node 두 개는 다른 모든 Node가 주어질 때 conditionally independent하다.  \n   (아래에서 \\는 포함하지 않는다는 의미이다.)\n   $$\n   X_{i} \\perp\\!\\!\\!\\!\\perp X_{j} | X_{S\\backslash\\{i, j\\}}\n   $$\n2. \u003cmark\u003e**Local Markov Property**\u003c/mark\u003e  \n   한 Node에 인접한 모든 Node(Neighbors)가 주어질 때, 해당 Node는 다른 모든 Node와 conditionally independent하다.  \n   (아래에서 $\\mathcal{N}_{i}$는 Node i와 인접한 모든 Node를 의미한다.)\n   $$\n   X_{i} \\perp\\!\\!\\!\\!\\perp X_{S\\backslash \\mathcal{N}_{i}} | X_{\\mathcal{N}_{i}}\n   $$\n3. \u003cmark\u003e**Global Markov Property**\u003c/mark\u003e  \n   만약, Node들의 Subset으로 이루어진 $A, B$가 특정 subset $C$가 주어질 때, 서로 conditionally independent하다면, $A, B$에 속하는 어떤 subset이라도 서로 independent하다.  \n   (subset간의 conditionally independent를 확인하기 위해서는 특정 Subset들간에 이어지는 모든 경로를 차단할 수 있는 subset이 있는지를 확인한다.)  \n   $$\n   \\begin{align*}\n   X_{A} \u0026\\perp\\!\\!\\!\\!\\perp X_{B} | X_{C} \\\\\n   X_{\\text{subset of }A} \u0026\\perp\\!\\!\\!\\!\\perp X_{\\text{subset of }B} | X_{C} \\\\\n   \\end{align*}\n   $$  \n   ![ml-global-markov-property](/images/ml-global-markov-property.jpg)\n\n따라서, 우리는 이전 그림에서 Conditional Independence를 활용할 수 있다. $X_{1}, X_{4}$의 경우 다른 모든 Random Variable과 correlation이 존재하지만, $X_{2}, X_{3}$의 경우 $X_{1}, X_{4}$만 알면 된다. 즉, $X_{2} \\perp\\!\\!\\!\\!\\perp X_{3} | X_{1}, X_{4}$이다. 따라서, 우리는 이 관계를 확률 식에서 녹여낼 수 있다.\n\n$$\n\\begin{align*}\nP(X_{1}, X_{2}, X_{3}, X_{4}) \u0026= P(X_{2}|X_{1},\\cancel{X_{3}},X_{4})P(X_{1}, X_{3}, X_{4}) (\\because X_{2} \\perp\\!\\!\\!\\!\\perp X_{3} | X_{1}, X_{4}) \\\\\n\u0026= P(X_{2}|X_{1},X_{4})P(X_{1}, X_{3}, X_{4})\n\\end{align*}\n$$\n\n또한, 우리는 Graph를 통해서 Joint Probability를 다음과 같이 정의할 수 있다.\n\n$$\nP(\\cap_{i=1}^{N}X_{i}) = \\frac{1}{Z} \\prod_{C \\in \\mathcal{C}} \\psi_{C}(\\cap_{X_{j}\\in C}X_{j})\n$$\n\n식이 다소 난해하다. 하나 하나 해석을 해보도록 하자. 먼저, $P(\\cap_{i=1}^{N}X_{i})$이다. 이는 Joint Probability를 표현하는 방법 중의 하나로 단순히 이를 정리하면, $P(\\cap_{i=1}^{N}X_{i})=P(X_{1} \\cap X_{2} \\cap \\cdots \\cap X_{N})=P(X_{1}, X_{2}, \\cdots, X_{N})$이다. 다음은 $C$와 $\\mathcal{C}$이다. 둘 다 아마 집합일 것이라는 것은 $\\in$ 기호 덕분에 알 수 있을 것이다. 그렇다면, 어떤 데이터를 담고 있는 집합일까? 이는 Random Variable들로 이루어진 부분 집합이다. 이를 \u003cmark\u003e**Clique($C$)**\u003c/mark\u003e라고 한다. Clique는 Graph에서 Node들의 부분 집합으로, Graph에서 **Fully Connected Node**의 집합을 의미한다. 이것이 가지는 의미는 사실상 하나의 Node로 합칠 수 있다는 것이다.(이를 Graph 상에서의 인수분해(**factorization**)라고도 한다.) Clique에 속하는 Node끼리는 서로 완벽하게 연결되어 있기 때문에 이 중에 하나의 Node라도 다른 Node와 연결을 가진다면, 이에 속하는 모든 Node가 이 관계로 연결된다는 것이다. 추가적으로 Clique들 중에서 다른 Clique에 속하지 않는 Clique들을 \u003cmark\u003e**Maximal Clique($\\mathcal{C}$)**\u003c/mark\u003e라고 한다. 아래 그림에서는 Maximal Clique를 빨간색으로 표기한 것이다.\n\n![ml-max-clique](/images/ml-max-clique.jpg)\n\n마지막으로 $\\psi$이다. 이는 \u003cmark\u003e**Clique Potential Function**\u003c/mark\u003e로, 각 Clique의 Node(Random Variable)를 parameter로 사용하는 함수로 확률과 비슷한 성질을 가지지만 확률처럼 합이 1이 아닐 수도 있고, 값 자체가 음수일 수도 있다. 즉, 이를 구할 때에는 각 Random Variable의 경우의 수와 해당 경우의 상대적 확률로 이루어진 table을 작성하고, 이를 표현할 수 있는 함수를 찾아낸 것이 $\\psi$이다. 대게의 경우 $\\psi$는 해당 Parameter로 이루어진 Condition Probability 또는 Joint Probability가 되는 경우가 많다. 하지만, 그렇지 않은 경우에도 $\\psi$로 표현이 가능하다.(이에 대한 엄밀한 증명은 여기서 다루지 않을 뿐만 아니라 중요하지 않다.) 여기서 \u003cmark\u003e$Z$\u003c/mark\u003e의 의미를 마지막으로 짚어보자면, 단순한 normalization이다. $\\psi$가 운좋게도 Joint Probability, Conditional Probability로 쉽게 구해진다면 $Z=1$이다. 하지만, 그렇지 않을 경우에는 이들의 합이 1이 아니기 때문에 Normalization이 필요한 것이다.\n\n$$\n\\begin{align*}\nZ \u0026= \\sum_{X_{1}}\\sum_{X_{2}} \\cdots \\sum_{X_{N}}{\\prod_{C \\in \\mathcal{C}} \\psi_{C}(\\cap_{X_{j}\\in C}X_{j})} \\\\\n\u0026= \\sum_{X_{1}, X_{2}, \\cdots, X_{N}}{\\prod_{C \\in \\mathcal{C}} \\psi_{C}(\\cap_{X_{j}\\in C}X_{j})}\n\\end{align*}\n$$\n\n결론적으로 의미를 따지자면, 위에서 구한 **Maximal Clique**에 특정 함수를 취한 $\\psi$가 인수분해(**factorization**)에서 하나의 인자(**factor**)가 되는 것이다. 따라서, 이를 **factor function**이라고도 부른다.\n\n자, 마지막으로 우리가 4개의 Random Variable 4개($A, B, C, D$)가 있을 때, Graph로 그릴 수 있는 형태를 네 개 정도 가정하여 예시들을 살펴볼 것이다.\n\n![ml-undirected-graph-2](/images/ml-undirected-graph-2.jpg)\n\n1. $A, B, C, D$가 선형으로 이루어진다.  \n   여기서는 **Maximal Clique**가 3개이다($\\{\\{A, B\\}, \\{ B, C\\}, \\{ C, D\\}\\}$). 따라서, 이를 통해서 Joint Probability를 추정하면 다음과 같다.  \n   $$\n   P(A, B, C, D) = \\frac{1}{Z} \\times \\psi_{1}(A, B) \\times \\psi_{2}(B, C) \\times \\psi_{3}(C, D)\n   $$  \n   여기서 직접적으로 한 번 $P(A, B, C, D)$를 추정해보자.  \n   $$\n   \\begin{align*}\n   P(A, B, C, D) \u0026= P(A| B, C, D) \\times P(B | C, D) \\times P(C, D) \\\\\n   \u0026= P(A|B) \\times P(B|C) \\times P(C, D)\n   \\end{align*}\n   $$  \n   즉, 이렇게 일렬로 된 Graph에서는 마지막 $\\psi$를 제외하고는 모두 Conditional Probability이고, 마지막 $\\psi$는 Joint Probability이다. 그리고, $Z$는 1이라는 것을 알 수 있다.\n2. $A, B, C, D$가 모두 완벽하게 연결되어 있다.  \n   이 경우에는  **Maximal Clique**가 1개이다($\\{\\{A, B, C, D\\}\\}$). 따라서, Joint Probability를 다음과 같이 추정할 수 있다.  \n   $$\n   P(A, B, C, D) = \\frac{1}{Z} \\times \\psi(A, B, C, D)\n   $$  \n   결론적으로 Clique가 하나기 때문에 줄일 수 있는 변수가 없다. 즉, $\\psi$가 Joint Probability이고, $Z$는 1이다.\n3. **Maximal Clique**가 2개이다($\\{\\{A, B, D\\}\\, \\{A, C, D\\}\\}$). 따라서, 다음과 같이 정리된다.  \n   $$\n   \\begin{align*}\n   P(A, B, C, D) \u0026= P(B|A, C, D) \\times P(A, C, D) \\\\\n   \u0026= P(B|A,D) \\times P(A, C, D) \\\\\n   \u0026= \\frac{1}{Z} \\times \\psi_{1}(A, B, D) \\times \\psi_{2}(A, C, D) \\\\\n   \\end{align*}\n   $$\n4. **Maximal Clique**가 4개이다($\\{\\{A, B\\}, \\{ A, C\\}, \\{ B, D\\}, \\{ C, D\\}\\ \\}$).  \n   $$\n   \\begin{align*}\n   P(A, B, C, D) \u0026= P(A|B, C, D) \\times P(B|C, D) \\times P(C, D) \\\\\n   \u0026= P(A|B, C) \\times P(B|D) \\times P(C, D) \\\\\n   \u0026= \\frac{P(A, B, C)}{P(B, C)} \\times P(B|D) \\times P(C, D) \\\\\n   \u0026= \\frac{P(B, C| A)}{P(A)P(B, C)} \\times P(B|D) \\times P(C, D) \\\\\n   \u0026= \\frac{P(B|A)P(C|A)}{P(A)P(B, C)} \\times P(B|D) \\times P(C, D) \\\\\n   \u0026= \\frac{1}{P(B,C)} \\times P(A, B) \\times P(C|A) \\times P(B|D) \\times P(C, D) \\\\\n   \u0026\\neq \\frac{1}{Z} \\times \\psi_{1}(A, B) \\times \\psi_{2}(A, C) \\times \\psi_{3}(B, D) \\times \\psi_{4}(C, D) \\\\\n   \\end{align*}\n   $$  \n   이것이 바로 $\\psi$를 확률 함수라고 부르지 않는 이유이다.  \n   우리가 $\\psi$를 확률 함수 형태로 표현하기 위해서는 **Chordal graph**(4개 이상의 Node로 이루어진 Cycle에서는 중간에 반드시 Cycle을 이루는 Edge가 아닌 Edge가 존재하는 Graph) 형태를 가져야 한다는 것이다. $\\psi$가 확률 함수로 표현되지 않는다고 우리가 하고자 하는 일에 영향을 주지는 않으니 그런가보다 하고 넘어가도 무방하다.\n\n여기서 우리는 **factorization**이라는 개념을 익혔고, 이것이 가능하기 위해서는 Chordal graph가 주어진 상황에서 Markov Property를 만족해야 함을 확인했다. 그리고, 우리는 이러한 **factorization** 형태를 좀 더 명확하게 나타내기 위해서 다음과 같은 형태로 표현하고, 이를 \u003cmark\u003e**factor graph**\u003c/mark\u003e라고 정의한다. 따라서, 각 **factor**(인수)는 **Maximal Clique** 단위로 생성된다.\n\n![ml-factor-graph-1](/images/ml-factor-graph-1.jpg)\n\n### Bayesian Network(Directed Graphical Model, Causality)\n\n**Bayesian Network**라고 불리며, **Causality**를 표현한 Graph이다. 각 Node는 Random Variable을 의미하며, Edge는 Causality(원인($C$) -\u003e 결과($R$))를 의미한다. 그렇기에 굉장히 명확하게 표현이 될 수 있다. 왜냐하면, $P(R, C) = P(C|R)P(R)$임을 명백하게 드러낸다. 그렇기에 우리는 해당 Graph가 주어지는 순간 Joint Probability를 다음과 같이 유추할 수 있는 것이다.\n\n![ml-bayesian-network](/images/ml-bayesian-network.jpg)\n\n즉, 이것을 식으로 나타내면 다음과 같다.\n\n$$\nP(\\cap_{i=1}^{N}X_{i}) = \\prod_{i \\in \\{1, 2, \\cdots, N\\}} P(X_{i}| \\cap_{j \\in \\text{Parents}(X_{i})} X_{j})\n$$\n\n이러한 점 때문에 Bayesian Network에서는 Cycle이 존재할 수 없다. 왜냐하면, Cycle이 존재한다는 것은 각 Random Varaible이 서로 원인과 결과가 되는 것이 때문에 사실상 하나의 사건이라는 의미를 내포하는 것이다. 그렇기에 이는 사실상 존재할 수 없다.\n\n여기서도 마찬가지로 Conditional Independence를 찾을 수 있다. 뿐만 아니라 Marginal Independence에 대한 힌트도 얻을 수 있다. 이때 우리는 \u003cmark\u003e**D-Seperation**\u003c/mark\u003e이라는 방법을 활용한다. 이를 위해서는 자신과 주변 2개의 Node가 이룰 수 있는 관계 3가지를 정의해야 한다.\n\n![ml-bayesian-network-2](/images/ml-bayesian-network-2.jpg)\n\n1. **head-to-tail**  \n   이 경우에는 $X \\rightarrow Y \\rightarrow Z$의 관계를 의미한다. 따라서, $X$와 $Z$는 $Y$가 주어질 때, 서로 Independent하다.  \n   $$\n   \\begin{align*}\n   P(X, Z | Y) \u0026= \\frac{P(X,Y,Z)}{P(Y)}\\\\\n   \u0026= \\frac{P(X)P(Y|X)P(Z|Y)}{P(Y)}\\\\\n   \u0026= \\frac{P(X, Y)}{P(Y)} \\times P(Z|Y) \\\\\n   \u0026= P(X | Y)P(Z | Y)\n   \\end{align*}\n   $$\n2. **tail-to-tail**  \n   이 경우에는 $X \\leftarrow Y \\rightarrow Z$의 관계를 의미한다. 따라서, $X$와 $Z$는 $Y$가 주어질 때, 서로 Independent하다.  \n   $$\n   \\begin{align*}\n   P(X, Z | Y) \u0026= \\frac{P(X, Y, Z)}{P(Y)} \\\\\n   \u0026= \\frac{P(X|Y)P(Y)P(Z|Y)}{P(Y)} \\\\\n   \u0026= P(X | Y)P(Z | Y)\n   \\end{align*}\n   $$\n3. **head-to-head**  \n   이 경우에는 $X \\rightarrow Y \\leftarrow Z$의 관계를 의미한다. 따라서, $X$와 $Z$는 서로 Independent하다.  \n   즉, Conditional Independence가 아니라 Marginal Independence이다.  \n   $$\n   \\begin{align*}\n   P(X, Z) \u0026= \\sum_{Y} P(X, Y, Z) \\\\\n   \u0026= \\sum_{Y} P(X)P(Y|X,Z)P(Z) \\\\\n   \u0026= P(X)P(Z)\\sum_{Y} P(Y|X,Z) \\\\\n   \u0026= P(X)P(Z)\n   \\end{align*}\n   $$\n\n이 관계에서 중요한 것은 $X,Z$간 edge가 존재해서는 안된다는 점이다. 위의 관계를 활용하면, 인접한 관계에서의 Conditional Independence는 판별이 가능하다.하지만, \u003cmark\u003e**D-Seperation**\u003c/mark\u003e을 통해서 이를 더 넓은 범위로 확장할 수 있다. 세 Node의 집합 $A, B, C$가 주어질 때, $A \\perp\\!\\!\\!\\!\\perp B | C$이기 위해서는 다음 조건을 만족해야 한다.\n\n1. A에서 B로 가는 경로가 하나 이상 존재한다.(여기서 경로는 방향을 신경쓰지 않고 연결 여부에 따라 결정한다.)\n2. 모든 경로에 대해서, C에 속하는 Node가 적어도 하나 head-to-tail 또는 tail-to-tail 관계를 중계할 수 있어야 한다.\n3. 모든 경로에 대해서, C에 속하는 Node는 head-to-head 관계를 중계하면 안되며, head-to-head 관계를 중계하는 Node의 자손이여도 안된다.\n\n즉, $A, B, C$가 이러한 조건을 모두 만족할 때, 우리는 $C$가 $A, B$를 Block했다고 하며, $A \\perp\\!\\!\\!\\!\\perp B | C$이다.\n\n예를 들어 아래와 같은 두 경우를 예를 들어볼 수 있다.\n\n![ml-d-seperation](/images/ml-d-seperation.jpg)\n\n왼쪽의 경우 C의 parent가 A에서 B로 가는 경로에서 head-to-head를 중계하고 있다. 따라서, A와 B는 Conditionally Independence를 만족하지 않는다. 반면, 오른쪽의 경우 C가 A에서 B로 가는 경로에서 head-to-tail 관계를 중계하고 있으므로, A와 B는 Conditionally Independence를 만족한다. 여기서 재밌는 점은 A와 B는 두 경우 모두 Marginal Independence를 만족한다는 점이다. 왜냐하면, A에서 B로 가는 경로가 순방향만으로는 이루어지지 않기 때문이다.\n\n마지막으로, Bayesian Network도 **factorization**이 가능하다 A, B의 **Causality**가 $P(A|B)P(B)$를 의미한다는 점을 활용해서 우리는 다음과 같은 형태로 정의하는 것이 가능하다.\n즉, 초기 시작 점은 자신만을 가지는 factor를 가지고, head-to-head 관계는 하나로 통일하며, 나머지 관계(head-to-head, 등)는 별도로 factor를 분리한다. 즉, 다음과 같은 형태를 가진다.\n\n![ml-factor-graph-2](/images/ml-factor-graph-2.jpg)\n\n```plaintext\n 🤔 Markov Blankets\n\n Markov Blanket은 특정 Node에 대한 정보(관계)가 있는 모든 Node를 의미한다. \n 즉, 특정 Random Variable의 확률이 궁금하다면, 이 Markov Blanket만 가지면 된다. \n 그 중에서도 가장 작은 크기로 모든 필요한 정보를 담은 subset을 Markov Boundary라고 한다. \n Markov Boundary는 Markov Random Field에서는 Neighbor이고,\n Bayesian Network에서는 Parent, Child, Co-Parent이다.\n```\n\n![ml-markov-boundary](/images/ml-markov-boundary.jpg)\n\n### Factor Graph\n\n앞 서 본 두 가지 Graph 표현 방법은 각 각 장단점을 가지고 있다.\n\n1. Markov Random Field는 Joint Probability를 Potential이라는 임의의 변수를 통해서 추정하는 것이 가능하다. 따라서, 명확성이 떨이지지만, Conditional Independence를 파악하는 것은 더 분명하고 쉽다.\n2. Bayesian Network는 Joint Probability를 명확하게 판별할 수 있다. 하지만, Conditional Independence를 판별하는 것이 더 어렵고 복잡하다.\n\n이러한 장단점을 모두 살릴 수 있는 방법으로 제시된 것이 Factor Graph이다. 위에서 각 각 Factor Graph를 표현하는 방법에 대해서는 제시하였으므로 여기서는 다루지 않는다. Factor Graph는 근본적으로 Graph의 요소들을 인수분해(Factorization)하여 인수(Factor)로 분리해낸 것이다. 그렇기에 더 명확한 구분이 가능하다. 각 Node는 Factor와 기존 Node에 해당하는 값이 두 개 다 존재하고, Factor는 꽉 찬 네모, 기존 Node(Variable)는 비어있는 동그라미로 표현하는 것이 일반적이다.\n\n그리고, 여기서는 Joint Probability를 다음과 같이 정의한다.\n\nVariable Node는 $\\{X_{1},X_{2}, \\cdots, X_{N}\\}$이고, Factor Node가 $\\{f_{1},f_{2}, \\cdots, f_{M}\\}$일 때, $f_{j}$와 이웃한 Variable Node의 집합을 $\\mathcal{N}_{j}$라고 하자.\n\n$$\nP(X_{1}, X_{2}, \\cdots, X_{N}) = \\prod_{j=1}^{M}{f_{j}(\\cap_{X \\in \\mathcal{N}_{j}} X)}\n$$\n\n이렇게 표현하는 것은 확실히 Markov Random Field에서는 명확하다. 하지만, Bayesian Network에서는 표현할 수 있는 정보를 어느정도 잃었다고 볼 수도 있다. 어차피 Conditional Probability인데, 다르게 표현한 것이기 때문이다. 하지만, 이를 이용하게 되면 기존에 문제였던 Conditional Independence를 쉽게 파악할 수 있다. 왜냐하면 Factor Graph에서는 Conditional Independence를 확인하기 위해서 해당 집합으로 이어지는 모든 경로에서 중간에 하나라도 Variable Node가 껴있는지만 확인해도 충분하다.\n\n![ml-factor-graph-3](/images/ml-factor-graph-3.jpg)\n\n따라서, 앞으로의 과정에서는 Factor Graph를 Main으로 하여 설명을 진행하도록 하겠다.\n\n## Message Passing\n\n우리는 앞의 Graph 표현을 통해서 Feature를 Factor로 압축하는 과정을 익혔다. 이 역시 엄청난 계산 효율을 가져온다. 하지만, 이를 더 효과적으로 활용할 수 있는 방법이 있다. 그것은 Message Passing 방법이다. 우선 우리가 해결하고자하는 문제를 정의해보자. 우리는 Joint Probability($P(X_{1}, X_{2}, \\cdots, X_{N})$)가 주어졌을 때, 다음 값을 구하고 싶을 수 있다.\n\n1. \u003cmark\u003e**Marginalization**\u003c/mark\u003e  \n   Marginal Probability는 Joint Probability에서 구하고자 하는 Random Variable을 제외한 모든 경우의 수를 더한 것이다.\n   $$\n   \\begin{align*}\n   P(X_{i}) \u0026= \\sum_{X_{j}}P(X_{i}, X_{j}) \\\\\n   \u0026= \\sum_{X_{j}, X_{k}}P(X_{i}, X_{j}, X_{k}) \\\\\n   \u0026= \\cdots \\\\\n   \u0026= \\sum_{X_{-i}}P(X_{1}, X_{2}, \\cdots, X_{N})\n   \\end{align*}\n   $$  \n   즉, 이를 일반적인 방법으로 풀고자하면 Random Variable($X_{i}$)이 각 각 $\\mathbb{R}^{L}$로 정의된다고 할 때, $L^{N-1}$번의 합연산이 필요하다.\n2. \u003cmark\u003e**Maximization**\u003c/mark\u003e  \n   Joint Probability의 최댓값을 갖게 하는 경우의 수($\\hat{X}$)를 구하고자 한다면 다음을 구해야 한다.  \n   $$\n   \\hat{X} = \\argmax_{X_{1}, X_{2}, \\cdots, X_{N}} P(X_{1}, X_{2}, \\cdots, X_{N})\n   $$  \n   이 또한 무식하게 풀고자하면, $L^{N-1}$번의 max 연산이 필요하다.\n\n그렇다면, 이를 한 번 가장 간단한 형태인 일자형 Factor Graph로 표현해보자.\n\n![ml-bp-1](/images/ml-bp-1.jpg)\n\n여기서 $P(X_{2})$를 알고 싶다고 해보자. 그 경우 다음과 같이 식이 정리되는 것을 볼 수 있다.\n\n$$\n\\begin{align*}\nP(X_{2}) \u0026= \\sum_{X_{1}}P(X_{1},X_{2}) \\\\\n\u0026= \\sum_{X_{1}, X_{3}, X_{4}, X_{5}}P(X_{1}, X_{2}, X_{3}, X_{4}, X_{5}) \\\\\n\u0026= \\sum_{X_{1}}\\sum_{X_{3}}\\sum_{X_{4}}\\sum_{X_{5}}P(X_{1}, X_{2}, X_{3}, X_{4}, X_{5}) \\\\\n\u0026= \\sum_{X_{1}}\\sum_{X_{3}}\\sum_{X_{4}}\\sum_{X_{5}}f_{a}(X_{1}, X_{2})f_{b}(X_{2}, X_{3})f_{c}(X_{3}, X_{4})f_{d}(X_{4}, X_{5}) \\\\\n\u0026= (\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))(\\sum_{X_{3}}\\sum_{X_{4}}\\sum_{X_{5}}f_{b}(X_{2}, X_{3})f_{c}(X_{3}, X_{4})f_{d}(X_{4}, X_{5})) \\\\\n\u0026= (\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))(\\sum_{X_{3}}\\sum_{X_{4}}f_{b}(X_{2}, X_{3})f_{c}(X_{3}, X_{4})\\sum_{X_{5}}f_{d}(X_{4}, X_{5})) \\\\\n\u0026= (\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))(\\sum_{X_{3}}f_{b}(X_{2}, X_{3})\\sum_{X_{4}}f_{c}(X_{3}, X_{4})\\sum_{X_{5}}f_{d}(X_{4}, X_{5}))\n\\end{align*}\n$$\n\n이것이 의미하는 바는 무엇일까? 이는 단순하게 순서를 바꾸어 재조합하는 것만으로 Computing을 줄일 수 있음을 보여줬다. 먼저, 앞의 $\\sum$연산만 단독으로 할 때, $L$번의 연산이 필요하고, 뒤에 연속해서 나오는 3번의 $\\sum$을 구하기 위해서는 결국 $L^{3}$의 연산이 필요하다. 즉, $L + L^{3}$의 합연산으로 marginalization 결과를 구할 수 있다는 것이다. 그렇기에 더 효율적인 연산이 가능한 것이다. 이는 특히 Graph의 중앙에 있는 값을 구할 때 더 도드라지게 나타난다. 전체 marginalization 결과를 나타내면 다음과 같다.\n\n$$\n\\begin{align*}\nP(X_{1}) \u0026= \\sum_{X_{2}}f_{a}(X_{1}, X_{2})\\sum_{X_{3}}f_{b}(X_{2}, X_{3})\\sum_{X_{4}}f_{c}(X_{3}, X_{4})\\sum_{X_{5}}f_{d}(X_{4}, X_{5}) \\rightarrow L^{4} \\\\\nP(X_{2}) \u0026= (\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))(\\sum_{X_{3}}f_{b}(X_{2}, X_{3})\\sum_{X_{4}}f_{c}(X_{3}, X_{4})\\sum_{X_{5}}f_{d}(X_{4}, X_{5})) \\rightarrow L^{3} + L \\\\\nP(X_{3}) \u0026= (\\sum_{X_{2}}f_{b}(X_{2}, X_{3})\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))(\\sum_{X_{4}}f_{c}(X_{3}, X_{4})\\sum_{X_{5}}f_{d}(X_{4}, X_{5})) \\rightarrow 2L^{2} \\\\\nP(X_{4}) \u0026= (\\sum_{X_{3}}f_{c}(X_{3}, X_{4})\\sum_{X_{2}}f_{b}(X_{2}, X_{3})\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))(\\sum_{X_{5}}f_{d}(X_{4}, X_{5})) \\rightarrow L^{3} + L \\\\\nP(X_{5}) \u0026= \\sum_{X_{4}}f_{d}(X_{4}, X_{5})\\sum_{X_{3}}f_{c}(X_{3}, X_{4})\\sum_{X_{2}}f_{b}(X_{2}, X_{3})\\sum_{X_{1}}f_{a}(X_{1}, X_{2}) \\rightarrow L^{4}\n\\end{align*}\n$$\n\n이것이 끝이 아니다. 우리는 중복된 연산을 별도로 저장해두어서 더 빠른 연산을 수행하는 것도 가능하다. 예를 들어 다음과 같은 과정이라고 할 수 있다.\n\n$$\n\\begin{align*}\nP(X_{2}) \u0026= \\underbrace{(\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))}_{\\red{\\mu_{a\\rightarrow2}(X_{2})}}(\\sum_{X_{3}}f_{b}(X_{2}, X_{3})\\sum_{X_{4}}f_{c}(X_{3}, X_{4})\\sum_{X_{5}}f_{d}(X_{4}, X_{5})) \\\\\nP(X_{3}) \u0026= \\underbrace{(\\sum_{X_{2}}f_{b}(X_{2}, X_{3})\\red{\\mu_{a\\rightarrow2}(X_{2})})}_{\\red{\\mu_{b\\rightarrow3}(X_{3})}}(\\sum_{X_{4}}f_{c}(X_{3}, X_{4})\\sum_{X_{5}}f_{d}(X_{4}, X_{5})) \\\\\nP(X_{4}) \u0026= \\underbrace{(\\sum_{X_{3}}f_{c}(X_{3}, X_{4})\\red{\\mu_{b\\rightarrow3}(X_{3})})}_{\\red{\\mu_{c\\rightarrow4}(X_{4})}}(\\sum_{X_{5}}f_{d}(X_{4}, X_{5})) \\\\\nP(X_{5}) \u0026= \\underbrace{\\sum_{X_{4}}f_{d}(X_{4}, X_{5})\\red{\\mu_{c\\rightarrow4}(X_{4})}}_{\\red{\\mu_{d\\rightarrow5}(X_{5})}}\n\\end{align*}\n$$\n\n![ml-bp-2](/images/ml-bp-2.jpg)\n\n즉, 이전 Marginalization에서 계산했던 $\\mu_{\\text{factor}\\rightarrow\\text{variable}}(X_{\\text{variable}})$를 저장해서, 다음 Marginalization 연산 시에 사용할 수 있기 때문에 전체 Marginalization을 구하는데에도 더 빠른 연산이 가능하다. 이 방식은 역으로 진행하는 것도 가능한데 다음과 같다.\n\n$$\n\\begin{align*}\nP(X_{4}) \u0026= (\\sum_{X_{3}}f_{c}(X_{3}, X_{4})\\sum_{X_{2}}f_{b}(X_{2}, X_{3})\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))\\underbrace{(\\sum_{X_{5}}f_{d}(X_{4}, X_{5}))}_{\\blue{\\mu_{d\\rightarrow4}(X_{4})}} \\\\\nP(X_{3}) \u0026= (\\sum_{X_{2}}f_{b}(X_{2}, X_{3})\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))\\underbrace{(\\sum_{X_{4}}f_{c}(X_{3}, X_{4})\\blue{\\mu_{d\\rightarrow4}(X_{4})})}_{\\blue{\\mu_{c\\rightarrow3}(X_{3})}} \\\\\nP(X_{2}) \u0026= (\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))\\underbrace{(\\sum_{X_{3}}f_{b}(X_{2}, X_{3})\\blue{\\mu_{c\\rightarrow3}(X_{3})})}_{\\blue{\\mu_{b\\rightarrow2}(X_{2})}} \\\\\nP(X_{1}) \u0026= \\underbrace{\\sum_{X_{2}}f_{a}(X_{1}, X_{2})\\blue{\\mu_{b\\rightarrow2}(X_{2})}}_{\\blue{\\mu_{a\\rightarrow1}(X_{1})}}\n\\end{align*}\n$$\n\n![ml-bp-3](/images/ml-bp-3.jpg)\n\n이를 합쳐서 표현하면 다음과 같은 형태를 가지는 것을 알 수 있다.\n\n$$\n\\begin{align*}\nP(X_{1}) \u0026= \\blue{\\mu_{a\\rightarrow1}(X_{1})} \u0026= \\red{\\mu^{-}(X_{1})}\\blue{\\mu^{+}(X_{1})} \\\\\nP(X_{2}) \u0026= \\red{\\mu_{a\\rightarrow2}(X_{2})}\\blue{\\mu_{b\\rightarrow2}(X_{2})}\u0026= \\red{\\mu^{-}(X_{2})}\\blue{\\mu^{+}(X_{2})} \\\\\nP(X_{3}) \u0026= \\red{\\mu_{b\\rightarrow3}(X_{3})}\\blue{\\mu_{c\\rightarrow3}(X_{3})}\u0026= \\red{\\mu^{-}(X_{3})}\\blue{\\mu^{+}(X_{3})} \\\\\nP(X_{4}) \u0026= \\red{\\mu_{c\\rightarrow4}(X_{4})}\\blue{\\mu_{d\\rightarrow4}(X_{4})}\u0026= \\red{\\mu^{-}(X_{4})}\\blue{\\mu^{+}(X_{4})} \\\\\nP(X_{5}) \u0026= \\red{\\mu_{d\\rightarrow5}(X_{5})}\u0026= \\red{\\mu^{-}(X_{5})}\\blue{\\mu^{+}(X_{5})} \\\\\n\u0026\\therefore P(X_{i}) = \\red{\\mu^{-}(X_{i})}\\blue{\\mu^{+}(X_{i})} \\\\\n\\end{align*}\n$$\n\n![ml-bp-4](/images/ml-bp-4.jpg)\n\n$\\mu^{+}$와 $\\mu^{-}$의 방향이 헷갈릴 수 있는데, 이는 자신($X_{i}$)을 기준으로 큰 쪽에서 왔는지 작은 쪽에서 왔는지를 표시한다고 생각하면 쉽다. 따라서, $\\mu$는 다음과 같이 정의되어질 수 있다.\n\n$$\n\\begin{align*}\n\\mu^{-}(X_{1}) \u0026= 1,\\, \\mu^{+}(X_{N}) = 1 \\text{이고,}\\\\\n\\mu^{-}(X_{i}) \u0026= \\sum_{X_{i-1}}f_{i}(i-1, i)\\mu^{-}(X_{i-1}) \\\\\n\\mu^{+}(X_{i}) \u0026= \\sum_{X_{i+1}}f_{i}(i, i+1)\\mu^{+}(X_{i+1}) \\\\\n\\end{align*}\n$$\n\n여기서 $\\mu$가 바로 \u003cmark\u003e**Message**\u003c/mark\u003e를 의미한다. 즉, 우리가 마치 운동장에서 사람 수를 세기 위해서 앞 사람이 말한 수 + 1을 반복하면서 진행하는 것처럼 Message를 전달하며 전체 확률을 구해나가는 것이다. 이러한 방법을 **Message Passing**이라고 하며, 이 방법을 통해서 우리는 Marginal Probability를 더 효과적으로 구할 수 있다. 왜냐하면, $\\mu^{-}(X_{i})$를 구하기 위한 연산량이 $(i-1) \\times L$이라는 것과, $mu^{+}(X_{i})$를 구하기 위한 연산량이 $(N-i) \\times L$이라는 것을 알고 있다. 따라서, 각 각의 Marginalization을 구하기 위한 연산량이 $L^{N-1}$에서 $(N-1)L$로 줄어들었다.\n\n여기까지 우리는 Line으로 되어있는 가장 간단한 Factor Graph에서의 \u003cmark\u003e**Sum-Product Belief Propagation**\u003c/mark\u003e을 알아본 것이다. 이제부터 우리는 더 복잡한 상황에서의 Belief Propagation(BP)을 살펴볼 것이다. Belief Propagation과 Message Passing은 대게 비슷한 의미로 사용되어 진다(일부는 Message Passing 후에 데이터를 가공하는 작업을 분리하고 이를 통합하여 Belief Propagation이라고 하기도 한다.)\n\n### Sum-Product Belief Propagation\n\n합의 곱을 통해서 Marginal Probability를 구하는 방법으로, 앞 서 보았던 Linear Factor Graph 뿐만 아니라 Tree형태의 Factor Graph에서도 사용할 수 있다. 물론 Cycle이 존재하는 Factor Graph가 존재할 수도 있지만, 이 경우에 대해서는 특별한 알고리즘을 별도로 적용하는 것이 일반적이다. 따라서, 여기서는 Tree형태의 Factor Graph에서 일반적으로 적용할 수 있는 방법을 제시한다.\n\n우선 아래 그림을 통해서 대략적인 이해를 해보도록 하자.\n\n![ml-sum-product-bp-1](/images/ml-sum-product-bp-1.jpg)\n\n우리는 위에서 Line Factor Graph에서 어떻게 Marginal Probability를 어떻게 구하는지를 보았다. Tree 구조에서도 동일하게 결국 Marginal Probability를 자신과 이웃한 Factor Node들로 부터 전달된 Message의 곱이라고 할 수 있다. 단지 다른 점은 이웃한 factor가 복수 개라는 것이다.  \n(factor 또는 variable에 해당하는 Node 중에서 index가 i인 Node와 인접한 Node(Node i가 factor라면 variable, variable이라면 factor이다.)들의 index 집합을 $\\mathcal{N}_{i}$ 라고하고, 값은 종류의 Node의 index를 모아둔 집합 I가 있을 때 $X_{I} = \\{X_{i}\\}_{i \\in I}$라고 하자.)\n\n$$\nP(X_{i}) = \\prod_{p \\in \\mathcal{N}_{i}}\\mu_{p \\rightarrow i}(X_{i})\n$$\n\n그렇다면, 여기서 $\\mu_{p \\rightarrow i}(X_{i})$를 각 각 어떻게 구할 수 있을까? 그러기 위해서 빨간색 부분을 자세히 봐보자.\n\n![ml-sum-product-bp-2](/images/ml-sum-product-bp-2.jpg)\n\n여기서도 기존 Linear Factor Graph와 다른 점은 Factor Node역시 여러 개의 Variable Node와 연결된다는 점이다. 이 부분만 떼어서 자세히 보면 다음과 같다.\n\n![ml-sum-product-bp-3](/images/ml-sum-product-bp-3.jpg)\n\n그렇기에 이전 Variable Node로 부터 오는 Message들과 factor 값을 함께 곱하는 과정이 필요하다. 여기서, Varaible Node에서 factor Node로 오는 Message를 $\\nu$라고 정의한다면, 다음과 같이 표현할 수 있다. 여기서 주의할 점은 Factor Node와 이웃한 Variable Node 중에서 Message를 전달할 Variable Node는 연산에서 제외해야 한다는 점이다.\n\n$$\n\\mu_{u \\rightarrow i}(X_{i}) = \\sum_{X_{\\mathcal{N}_{u}\\backslash\\{i\\}}}f_{u}(X_{\\mathcal{N}})\\prod_{j \\in \\mathcal{N}\\backslash\\{i\\}}{\\nu_{j \\rightarrow u}(x_{j})}\n$$\n\n그리고 마지막으로 $\\nu$를 구하는 과정은 다음과 같다.\n\n![ml-sum-product-bp-4](/images/ml-sum-product-bp-4.jpg)\n\n$$\n\\nu_{j \\rightarrow u}(X_{j}) = \\prod_{v \\in \\mathcal{N}_{j}\\backslash\\{u\\}}\\mu_{v \\rightarrow j}(X_{j})\n$$\n\n따라서, Marginal Probability($P(X_{i})$)를 구하고자 할 때 우리는 Leaf Node에서 부터 시작해서 차례차례 값을 구하면서, $\\mu_{\\mathcal{N}_{i} \\rightarrow i}$를 모두 구할 때까지 연산을 수행해야 한다.\n\n```plaintext\n 🤔 Loopy Sum-Product BP\n\n 우리는 Sum-Product BP를 Tree에서만 쓸 수 있다고 제한하였지만, \n 사실 Cycle이 존재하는 Factor Graph에서도 동일한 BP를 사용할 수 있다.\n 하지만, 이 경우에는 비례 관계를 통해서 나타낼 수 밖에 없기 때문에\n 결과값에 대해서 100% 확신할 수는 없다.\n```\n\n### Max Product Belief Propagation\n\nBelief Propagation은 앞 서 살펴보았던 Marginal Probability를 구할 때에도 사용할 수 있지만, Maximization 문제를 풀 때에도 사용할 수 있다. 마찬가지로 가장 간단한 예시인 Linear Factor Graph를 가정해보자.\n\n![ml-bp-1](/images/ml-bp-1.jpg)\n\n$$\nP(X_{1}, X_{2}, X_{3}, X_{4}, X_{5}) = f_{a}(X_{1}, X_{2})f_{b}(X_{2}, X_{3})f_{c}(X_{3}, X_{4})f_{d}(X_{4}, X_{5})\n$$\n\n이 경우에 $P(X_{1}, X_{2}, X_{3}, X_{4}, X_{5})$를 최대로 만드는 $\\hat{x_{1}}, \\hat{x_{2}}, \\hat{x_{3}}, \\hat{x_{4}}, \\hat{x_{5}}$를 찾아보자.  \n\n$$\n\\begin{align*}\n\u0026\\max_{X_{1}, X_{2}, X_{3}, X_{4}, X_{5}} f_{a}(X_{1}, X_{2})f_{b}(X_{2}, X_{3})f_{c}(X_{3}, X_{4})f_{d}(X_{4}, X_{5})\\\\\n\u0026= \\max_{X_{1}}\\{f_{a}(X_{1}, X_{2})\\max_{X_{2}}\\{\\max_{X_{3}}\\{f_{b}(X_{2}, X_{3}) \\max_{X_{4}}\\{f_{c}(X_{3}, X_{4})\\max_{X_{5}}\\{f_{d}(X_{4}, X_{5})\\}\\}\\}\\}\\}\\\\\n\u0026= \\max_{X_{2}}\\{\\max_{X_{1}}\\{f_{a}(X_{1}, X_{2})\\} \\max_{X_{3}}\\{f_{b}(X_{2}, X_{3}) \\max_{X_{4}}\\{f_{c}(X_{3}, X_{4})\\max_{X_{5}}\\{f_{d}(X_{4}, X_{5})\\}\\}\\}\\}\\\\\n\u0026= \\max_{X_{3}}\\{\\max_{X_{2}}\\{f_{b}(X_{2}, X_{3})\\max_{X_{1}}\\{f_{a}(X_{1}, X_{2})\\}\\} \\max_{X_{4}}\\{f_{c}(X_{3}, X_{4})\\max_{X_{5}}\\{f_{d}(X_{4}, X_{5})\\}\\}\\}\\\\\n\u0026= \\max_{X_{4}}\\{\\max_{X_{3}}\\{f_{c}(X_{3}, X_{4})\\max_{X_{2}}\\{f_{b}(X_{2}, X_{3})\\max_{X_{1}}\\{f_{a}(X_{1}, X_{2})\\}\\}\\}\\max_{X_{5}}\\{f_{d}(X_{4}, X_{5})\\}\\}\\\\\n\u0026= \\max_{X_{5}}\\{f_{d}(X_{4}, X_{5})\\max_{X_{4}}\\{\\max_{X_{3}}\\{f_{c}(X_{3}, X_{4})\\max_{X_{2}}\\{f_{b}(X_{2}, X_{3})\\max_{X_{1}}\\{f_{a}(X_{1}, X_{2})\\}\\}\\}\\}\\}\\\\\n\\end{align*}\n$$\n\nMarginalization과 굉장히 유사하다고 하다. 이를 이전에 사용한 Tree 구조에 반영해도 동일하다.\n\n![ml-sum-product-bp-1](/images/ml-sum-product-bp-1.jpg)\n\n단, 여기서 Message와 최종 결과를 다음과 같이 재정의하면 끝난다.\n\n$$\n\\begin{align*}\n\\max P(X_{1}, X_{2}, \\cdots, X_{N}) \u0026= \\max_{X_{i}}\\{\\prod_{p\\in\\mathcal{N}_{i}}\\mu_{p \\rightarrow i}(X_{i})\\} \\\\\n\\mu_{u \\rightarrow i}(X_{i}) \u0026= \\max_{\\mathcal{N}_{u}\\backslash\\{i\\}}\\{f_{u}(\\mathcal{N}_{i})\\prod_{j \\in \\mathcal{N}_{u}\\backslash\\{i\\}}\\nu_{j \\rightarrow u}(X_{j})\\} \\\\\n\\nu_{j \\rightarrow u}(X_{j}) \u0026= \\prod_{v\\in\\mathcal{N}_{j}\\backslash\\{u\\}}\\mu_{v \\rightarrow j}(X_{j})\n\\end{align*}\n$$\n\n추가적으로 Max Sum Belief Propagation을 소개하겠다. 이는 Maximization 문제를 풀 때, $\\log$를 취한 결과도 동일하다는 점을 활용하여 문제를 푸는 것이다. 따라서, 다음과 같이 식이 조금 변화한다. 이 방식을 쓰면, 너무 작은 probability로 인한 문제를 피할 수 있다.\n\n$$\n\\begin{align*}\n\\max \\red{\\log} P(X_{1}, X_{2}, \\cdots, X_{N}) \u0026= \\max_{X_{i}}\\{\\red{\\sum_{p\\in\\mathcal{N}_{i}}}\\mu_{p \\rightarrow i}(X_{i})\\} \\\\\n\\mu_{u \\rightarrow i}(X_{i}) \u0026= \\max_{\\mathcal{N}_{u}\\backslash\\{i\\}}\\{\\red{\\log} f_{u}(\\mathcal{N}_{i}) + \\red{\\sum_{j \\in \\mathcal{N}_{u}\\backslash\\{i\\}}}\\nu_{j \\rightarrow u}(X_{j})\\} \\\\\n\\nu_{j \\rightarrow u}(X_{j}) \u0026= \\red{\\sum_{v\\in\\mathcal{N}_{j}\\backslash\\{u\\}}}\\mu_{v \\rightarrow j}(X_{j})\n\\end{align*}\n$$\n\n## Construction from Data\n\n앞에서는 Graph를 통해서 연산 과정을 Optimization하는 방법을 알아보았다면, 여기서는 실제 관측 data를 이용해서 어떻게 Graph를 구조화할 수 있는지에 대해서 알아볼 것이다. 이를 수행하기 위해 많은 Algorithm이 존재하지만 가장 기본이 될 수 있는 Algorithm인 **Chow-Liu Algorithm**만 살펴보도록 하겠다.\n\n### Chow-Liu Algorithm\n\n제일 먼저 구해야할 것은 **Joint Probability**이다. 이는 Empirical distribution을 이용하여 구할 수 있다. 아래는 feature가 N개인 총 K개의 data가 있을 때, 다음과 같이 **Joint Probability**를 구한 것이다.\n\n$$\np(X_{1}=x_{1}, X_{2}=x_{2}, \\cdots, X_{N}=x_{n}) = \\frac{1}{K} \\sum_{k=1}^{K} \\mathbb{1}[x^{(k)}=(x_{1}, x_{2}, \\cdots, x_{n})]\n$$\n\n위와 같이 **Joint Probability**가 주어졌을 때, **Chow-Liu Algorithm**에서는 **Second Order Conditional Probability**(총 두개의 Random Variable로 구성된 Conditional Probability. 즉, Condtion도 하나이고, 확률을 구하고자 하는 변수도 하나이다.)와 **Marginal Probability**로 Graph를 가정하고 **Bayesian Network**를 구성한다. 이 경우에는 형태가 Tree 형태로 만들어지기 때문에 결론적으로 head-to-head 관계가 만들어지지 않는다.(각 각의 node는 하나의 parent만 갖기 때문이다.)\n\n![ml-chow-liu-1](/images/ml-chow-liu-1.jpg)\n\n따라서, 위와 같은 Graph로 추정했다면, 확률은 다음과 같아진다.\n\n$$\np(x_{1}, x_{2}, \\cdots, x_{n}) = p(x_{6}|x_{5})p(x_{5}|x_{2})p(x_{4}|x_{2})p(x_{3}|x_{2})p(x_{2}|x_{1})p(x_{1})\n$$\n\n여기서 이제 우리는 다음과 같은 문제만 풀면 끝이다. Empirical distribution으로 구한 Joint Probability($p$)와 우리가 추정한 Graph에서의 Joint Probability($p_{\\intercal}$)사이의 차이가 최소가 되도록 하면 된다. 이를 위해서 사용하는 것이 **KL Divergence**이다. 따라서, 우리가 구하고 싶은 **Bayesian Network**는 다음과 같이 구할 수 있다.\n\n$$\n\\argmin_{\\intercal\\text{:tree}} KL(p||p_{\\intercal})) = \\argmin_{\\intercal\\text{:tree}} \\sum_{x^{(k)} \\in \\mathcal{D}}p(x^{(k)})\\log \\frac{p(x^{(k)})}{p_{\\intercal}(x^{(k)})}\n$$\n\n그렇다면, 좀 더 면밀하게 $p_{\\intercal}$을 정의해보자.\n\n$$\n\\begin{align*}\np_{\\intercal}(x_{1}, x_{2}, \\cdots, x_{N}) \u0026= \\prod_{i=1}^{N}p(x_{i}|x_{\\text{parent}(i)})\\, (\\because \\text{Bayesian Network Definition})\\\\\n\u0026= p(x_{root})\\prod_{(i,j) \\in E}p(x_{j}|x_{i})\n\\end{align*}\n$$\n\n여기서 V는 node의 집합을 의미하고, E는 edge를 저장하며 각 tuple(i,j)는 (parent, child)를 의미한다. 그리고, Tree에서는 단 하나의 Node만 Root이고 parent가 없기 때문에 해당 Root만 marginal Probability를 가지는 것을 알 수 있다.\n\n$$\n\\begin{align*}\np_{\\intercal}(x_{1}, x_{2}, \\cdots, x_{N}) \u0026= p(x_{root})\\prod_{(i,j) \\in E}p(x_{j}|x_{i})\\\\\n\u0026= p(x_{root})\\prod_{(i,j) \\in E} \\frac{p(x_{j},x_{i})}{p(x_{i})}\\\\\n\u0026= \\red{p(x_{root})}\\prod_{(i,j) \\in E} \\frac{p(x_{j},x_{i})\\red{p(x_{j})}}{p(x_{i})p(x_{j})}\\\\\n\u0026= \\prod_{i\\in V}p(x_{i}) \\prod_{(i,j) \\in E} \\frac{p(x_{j},x_{i})}{p(x_{i})p(x_{j})}\\\\\n\\end{align*}\n$$\n\n마지막이 좀 애매할 수 있는 tree이기 때문에 가능한 것이다. 특정 node로 가는 path는 단 하나이기 때문에 $j$로 끝나는 edge도 하나일 수 밖에 없다. 따라서, $p(x_{root})\\prod_{(i,j) \\in E} p(x_{j}) = \\prod_{i=V}p(x_{i})$일 수 있는 것이다.\n\n이것이 정의되면, 우리는 이제 최적의 Tree인 $\\intercal_{*}$를 찾을 수 있다.\n\n$$\n\\begin{align*}\n\\intercal_{*} \u0026= \\argmin_{\\intercal\\text{:tree}} KL(p||p_{\\intercal})\\\\\n\u0026= \\argmin_{\\intercal\\text{:tree}} \\sum_{x^{(k)} \\in \\mathcal{D}}p(x^{(k)})\\log \\frac{p(x^{(k)})}{p_{\\intercal}(x^{(k)})}\\\\\n\u0026= \\argmin_{\\intercal\\text{:tree}} \\sum_{x^{(k)} \\in \\mathcal{D}}\\cancel{p(x^{(k)})\\log{p(x^{(k)})}} -p(x^{(k)})\\log{p_{\\intercal}(x^{(k)})}\\\\\n\u0026= \\argmax_{\\intercal\\text{:tree}} \\sum_{x^{(k)} \\in \\mathcal{D}}p(x^{(k)})\\log{p_{\\intercal}(x^{(k)})}\\\\\n\u0026= \\argmax_{\\intercal\\text{:tree}} \\sum_{x^{(k)} \\in \\mathcal{D}}p(x^{(k)})\\log({\\prod_{i\\in V}p(x_{i}^{(k)}) \\prod_{(i,j) \\in E} \\frac{p(x_{j}^{(k)},x_{i}^{(k)})}{p(x_{i}^{(k)})p(x_{j}^{(k)})}})\\\\\n\u0026= \\argmax_{\\intercal\\text{:tree}} \\sum_{x^{(k)} \\in \\mathcal{D}}\\sum_{i\\in V}p(x^{(k)})\\log(p(x_{i}^{(k)})) + \\sum_{x^{(k)} \\in \\mathcal{D}}\\sum_{(i,j) \\in E} p(x^{(k)})\\log({\\frac{p(x_{j}^{(k)},x_{i}^{(k)})}{p(x_{i}^{(k)})p(x_{j}^{(k)})}})\\\\\n\u0026= \\argmax_{\\intercal\\text{:tree}} \\sum_{i\\in V}\\sum_{x^{(k)} \\in \\mathcal{D}}p(x^{(k)})\\log(p(x_{i}^{(k)})) + \\sum_{(i,j) \\in E}\\sum_{x^{(k)}_{i}, x^{(k)}_{j}} p(x^{(k)}_{i}, x^{(k)}_{j})\\log({\\frac{p(x_{j}^{(k)},x_{i}^{(k)})}{p(x_{i}^{(k)})p(x_{j}^{(k)})}})\\, (\\because \\text{marginalization})\\\\\n\u0026= \\argmax_{\\intercal\\text{:tree}} \\cancel{\\sum_{i\\in V}-H(X_{i})} + \\sum_{(i,j) \\in E}I(X_{i}, X_{j})\\, (\\because H(X_{i})\\text{는 constant이다.})\\\\\n\u0026= \\argmax_{\\intercal\\text{:tree}}\\sum_{(i,j) \\in E}I(X_{i}, X_{j})\\\\\n\\end{align*}\n$$\n\n마지막 marginalization은 헷갈린다면, 해당 Posting의 Sum-Product BP 부분을 다시 보고오도록 하자.\n\n자, 이제 우리가 얻은 결론은 다음과 같다. 결국, 최적의 Tree는 $I(X_{i}, X_{j})$가 최대가 되는 Tree이다. I(Mutual Information)이 헷갈린다면, [Information Theory](/posts/ml-base-knowledge#Information-Theory) 정리해놓은 Posting을 다시 보고 오자. 결국, $X_{i}, X_{j}$간의 모든 Mutual Information을 구해서 weighted graph를 구축한다음에 Kruskal Algorithm을 통해서 최적 Tree를 찾으면 되는 것이다.\n\n따라서, 과정은 다음과 같다.\n\n1. 가능한 모든 (i,j) 쌍에 대하여 $I(X_{i}, X_{j})$를 구하여, Weighted Graph를 구성한다.\n2. Kruskal Algorithm을 수행한다.\n   1. weight의 내림차순으로 Edge를 정렬한다.\n   2. 하나씩 Edge를 뽑으면서, Cycle이 생기는지 확인하여 생기면 버리고, Cycle이 생기지 않으면 Tree에 추가한다.(Cycle 여부는 동일한 Node가 두 개 다 존재하는지 확인)\n   3. 모든 Node를 뽑았다면 종료하고, 그렇지 않다면 2번을 반복 시행한다.\n\n이렇게 Graph를 만들게 되면, 우리는 Joint Probability를 이전에 배운 Optimization 방법을 통해서 쉽게 구할 수 있다. 그리고, 이를 Model에 직접 적용할 수 있다. 예를 들면, 우리가 Classification을 수행할 때이다.\n\n$$\n\\argmax_{\\mathcal{l} \\in \\{0,1,2,\\cdots, 9\\}} p_{\\mathcal{l}} \\times p(x^{\\text{new}}|\\mathcal{l}^{\\text{new}}=\\mathcal{l}) \\propto \\argmax_{\\mathcal{l} \\in \\{0,1,2,\\cdots, 9\\}} p_{\\mathcal{l}} \\times p_{\\intercal}(x^{\\text{new}})\n$$\n\n위와 같이 추정하여 계산을 획기적으로 줄일 수 있다.\n\n## Reference\n\n- Tumbnail : Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=unsplash\u0026utm_medium=referral\u0026utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@markuswinkler?utm_source=unsplash\u0026utm_medium=referral\u0026utm_content=creditCopyText)\n- Medium[Chullin], Graphical Model이란 무엇인가요?, \u003chttps://medium.com/@chullino/graphical-model%EC%9D%B4%EB%9E%80-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80%EC%9A%94-2d34980e6d1f\u003e\n- Wiki, Markov Random Field, \u003chttps://en.wikipedia.org/wiki/Markov_random_field\u003e\n- Adaptive Computation and Machine Learning, Thomas G. Dietterich\n- \u003chttps://cedar.buffalo.edu/~srihari/CSE574/Chap8/Ch8-PGM-Inference/Ch8.3.2-FactorGraphs.pdf\u003e\n","slug":"ml-graphical-model","date":"2022-11-14 13:08","title":"[ML] 8. Graphical Model","category":"AI","tags":["ML","GraphicalModel","ConditionalIndependence","MarkovRandomField","BayesianNetwork","FactorGraph","D-Seperation","Factorization","MarkovProperty","MessagePassing","BeliefPropagation","Chow-LiuAlgorithm"],"desc":"Machine Learning은 주어진 data를 가장 잘 설명할 수 있는 pattern(Model)을 찾는 것이 목표라고 하였다. 그렇다면, \"data가 가지는 여러가지 정보(feature)들 중에서 어떤 feature를 중점적으로 보고 이용할 수 있을까?\" 그리고, \"만약 여러 feature들이 서로 연관이 있다면 이를 연산의 최적화를 위해 이용할 수 있지 않을까?\" 라는 접근이 가능하다. 여기서 Graphical Model은 이러한 관계를 시각적으로 표현할 수 있으며, 이를 통해서 연산 최적화에 대한 insight를 얻을 수 있다.","thumbnailSrc":"https://euidong.github.io/images/ml-thumbnail.jpg"},{"content":"\n## Intro\n\n이전까지의 Posting에서는 Supervised Learning 즉, 이미 Labeling이 완료된 데이터에 의한 Learning을 중점적으로 다루었다. 지금부터는 Unsupervised Learning에 대해서 조금 더 살펴보도록 하겠다. 대표적인 Unsupervised Learning은 Clustering, Feature Selection(or Dimensionality Reduction), Generative Model 등이 존재한다. 이들에 대해서 차근차근 살펴보도록 하고, 해당 Posting에서는 가장 대표적이라고 할 수 있는 Clustering을 먼저 살펴보면서 Unsupervised Learning에 대한 계략적인 이해를 해보도록 하겠다.\n\n## Clustering\n\nClustering은 unlabeled data를 data간 유사성 또는 거리 지표 등을 활용하여 미리 지정한 수 만큼의 partitioning하는 작업을 의미한다. 즉, 우리가 학습을 진행함에 있어 data는 label이 존재하지 않기 때문에 우리는 data간의 관계에서 정보를 추출해서 이를 분류해내는 것이 목표인 것이다.\n\n이를 수행하기 위한 방법은 크게 두 가지로 나눌 수 있다.\n\n1. **Non-Parametric Approach**  \n   이름 그대로 확률적 분포를 가정한 후, Parameter를 찾아가는 방식이 아닌 직관적인 방법(Huristic Approach)을 활용하는 방법이다. 그렇기에 확률적인 해석이 뒷받침되기 보다는 Algorithm을 통해서 이를 설명한다. 대표적인 방법이 K-Means Clustering이다.\n2. **Parametric Approach**  \n   확률적 분포를 가정한 후, Parameter를 찾아가는 방식으로, 대표적인 방법이 Gaussian 분포를 가정하고 찾아나가는 Gaussian Mixture Model(GMM, or MoG, Mixture of Gaussian)이 있다.\n\n따라서, Clustering을 대표하는 K-means Clustering과 GMM을 각 각 살펴보도록 하겠다.\n\n### K-Means Clustering\n\nK-Means Clustering은 K개의 평균값을 통한 Clustering으로 해석하면 의미 파악이 쉽다. 즉, K개의 Partition을 만들기 위해서 K개의 평균값을 찾아 이를 기반으로 더 가까운 평균값에 속하는 Partition에 data를 분배하는 방식이다.\n\n그렇다면, 우리가 구해야할 값은 각 data가 어느 Partition에 속하는지에 대한 정보($\\bold{r}\\leftarrow\\text{one hot vector}$)와 각 Partition의 평균값($\\mu$)이다. 즉, K-means Clustering에서는 기존 data들을 통해서 K개의 평균값(K-means)을 찾아서(**Learning**) 이후에 추가로 들어올 data에 대해서도 똑값은 K-means를 통해서 Partition을 찾을 수 있다(**Inference**).또는 모든 data를 저장해두었다가 K-means를 다시 계산하는 방법도 있다(Online K-means).\n\n그렇다면, $\\boldsymbol{\\mu}(=\\{\\mu_{1}, \\mu_{2}, \\cdots, \\mu_{K}\\})$와 $\\bold{R}$(모든 data의 $\\bold{r}$로 이루어진 Matrix)을 어떻게 구할 수 있을까? 이에 대한 해답은 다음과 같은 Cost Function을 제시하는 것으로 해결할 수 있다.\n\n$$\n\\mathcal{L} = \\min_{\\boldsymbol{\\mu}}\\min_{\\bold{R}} \\sum_{i \\in \\{1,2, \\cdots, N\\}}\\sum_{k \\in \\{1, 2, \\cdots, K\\}}\\bold{R}_{ik}||x_{i} - \\mu_{k}||^{2}\n$$\n\n현재 data의 point로 부터 가장 가까운 평균을 선택하는 경우를 최대화해야 해당 값이 가장 작아질 수 있다는 것을 알 수 있다. \u003cmark\u003e즉, 여기서는 평균과의 거리를 유사성의 지표로 사용한 것이다.\u003c/mark\u003e 여기서는 Euclidean distance(L2-norm)를 사용했지만, Manhatan distance(L1-norm)을 활용할 수도 있고 아예 다른 지표를 활용할 수도 있다. 중요한 것은 Cost Function이 아래와 같은 form을 가진다는 것이다.\n\n$$\n\\mathcal{L} = \\min_{\\boldsymbol{\\mu}}\\min_{\\bold{R}} \\sum_{i \\in \\{1,2, \\cdots, N\\}}\\sum_{k \\in \\{1, 2, \\cdots, K\\}}\\bold{R}_{ik}\\times(\\text{Similarity measure})\n$$\n\n그렇다면, 실제로 위에서 제시한 Cost Function을 활용하여 어떻게 $\\boldsymbol{\\mu}$와 $\\bold{R}$을 구할 수 있을까? minimize하고자하는 요소가 두 개이기 때문에 미분을 하기도 다소 난해하다. 따라서, 여기서는 EM Algorithm이라는 방식을 제시한다. 이에 대해서는 다음 Posting에 대해서 자세히 다루겠지만, 간단히 설명하자면 하나의 Variable을 Random하게 지정하고, 다른 Variable의 최적값을 구한 후 이를 다시 대입하고 반대 Variable을 최적값으로 구하기를 반복하면서 더 이상 Variable이 유의미하게 변경되지 않을 때까지 반복해서 구한 값이 최적값과 근사한다는 점을 활용한 Algorithm이다. 지금은 다소 엉뚱할 수 있지만, 지금은 해당 방법을 사용하도록 하겠다. 증명이 궁금하다면, 해당 Posting([🔗 [ML] 10. EM Algorithm](/posts/ml-em-algorithm))을 참고하자.\n\n따라서, 우리가 수행할 과정은 다음과 같다.\n\n1. $\\boldsymbol{\\mu}$를 랜덤하게 초기화한다.\n2. Assignment step: $\\boldsymbol{\\mu}$가 주어졌을 때, $\\bold{R}$을 구한다.  \n   $$\n   R_{ik} = \\begin{cases}\n    1 \u0026 \\text{if}\\quad k = \\argmin_{k}||x_{i} - \\mu_{k}||^{2} \\\\\n    0 \u0026 \\text{otherwise}\n   \\end{cases}\n   $$\n3. Update step: $\\bold{R}$이 주어졌을 때, $\\boldsymbol{\\mu}$를 구한다.  \n   우리가 분류한 $R$을 활용하여 각 k에 속하는 data의 평균을 통해서 $\\boldsymbol{\\mu}$를 구한다.\n   $$\n   \\mu_{k} = \\frac{\\sum_{i=1}^{N}R_{ik}x_{i}}{\\sum_{i=1}^{N}R_{ik}}\n   $$\n4. 특정값으로 $\\boldsymbol{\\mu}$가 수렴할 때까지 2번, 3번 과정을 반복한다.\n\n아래는 이 과정을 그림을 통해서 표현한 것이다.\n\n![ml-clustering-1](/images/ml-clustering-1.jpg)\n\nK-means 방식은 위와 같은 Iteration 절차를 많이 수행하지 않아도 몇번의 수행만으로 수렴한다는 것을 관측할 수 있다. 또한, Assignment 시에는 $O(KND)$의 시간이 소모되고, Update 시에는 $O(N)$ 만큼의 시간이 소모되기 때문에 무겁지 않고, 굉장히 간단하다는 장점을 갖고 있다. 하지만, 이 방법은 Global Optimal을 찾을 것이라는 확신을 줄 수 없다. 그렇기에 초기값을 어떻게 잡느냐에 따라서 결과가 크게 변할 수도 있다. 뿐만 아니라, outlier data에 대해서도 굉장히 민감하게 반응한다는 단점이 있다. 예를 들어, 아래 사진에서 왼쪽보다 오른쪽이 더 성공적인 Clustering이라고 말할 수 있을 것이다.\n\n![ml-clustering-2](/images/ml-clustering-2.jpg)\n\n이를 해결하기 위한 방법으로 다음과 같은 방법들이 제시되었다.\n\n1. **K-means++**: 초기값을 잘 설정하기 위한 방법으로, 초기값을 잘 설정하면 수렴하는 속도가 빨라지고, Global Optimal에 수렴할 가능성이 높아진다.\n2. **K-mendoids**: K-means에서는 중심점을 data의 평균으로 설정했지만, K-mendoids에서는 중심점을 data의 중간값으로 설정한다. 이렇게 하면 outlier에 민감하지 않게 된다.\n\n\u003e \u003cmark\u003e**Soft K-means**\u003c/mark\u003e\n\n마지막으로 K-means Clustering에서 확률적인 접근을 시도한 방법 또한 소개하겠다. 앞 서 본 (Hard)K-means에서는 $\\bold{R}_{ik}$를 0 또는 1로 보았다. 하지만, 이를 확률적으로 표현하는 것에 대해서 생각해 볼 수 있다. 즉, 다음과 같이 soft-max function을 활용한다면 표현이 가능할 것이다.\n\n$$\n\\bold{R}_{ik} = \\frac{\\exp(-\\beta||x_{i}-\\mu_{k}||^{2})}{\\sum_{l \\in {1, 2, \\cdots, K}} \\exp(-\\beta||x_{i}-\\mu_{l}||^{2})}\n$$\n\n이렇게 확률적으로 표현하게 되면, 우리는 추가적인 정보를 활용할 수 있다. 대표적으로 특정 Cluster로 해당 확률이 편향되어 있을 수록 더 좋은 분류일 것이라는 사전 지식(Prior)을 활용할 수 있다. 따라서, 우리는 다음과 같이 Cost Function을 변경할 수 있다.\n\n$$\n\\mathcal{L} = \\min_{\\boldsymbol{\\mu}}\\min_{\\bold{R}} \\sum_{i \\in \\{1,2, \\cdots, N\\}}\\sum_{k \\in \\{1, 2, \\cdots, K\\}}\\bold{R}_{ik}||x_{i} - \\mu_{k}||^{2} - \\frac{1}{\\beta}\\sum_{i \\in \\{1,2, \\cdots, N\\}}\\sum_{k \\in \\{1, 2, \\cdots, K\\}}\\bold{R}_{ik}\\log\\bold{R}_{ik}\n$$\n\n뒷 부분에 새로 추가된 $-\\frac{1}{\\beta}\\sum_{i \\in \\{1,2, \\cdots, N\\}}\\sum_{k \\in \\{1, 2, \\cdots, K\\}}\\bold{R}_{ik}\\log\\bold{R}_{ik}$는 $R_{ik}$가 확률이 되었기 때문에 사실상 Entropy를 의미한다. Entropy는 균형잡힌 분포일 수록 커지고, skew된 경우에는 작아지기 때문에 적절한 지표라고 할 수 있다. $\\beta$는 이러한 prior를 얼마나 사용할지에 대한 hyperparameter이다. $\\beta$가 클 수록 사실상 Hard K-means와 동일한 결과를 얻게 되고, $\\beta$가 작을 수록 Entropy를 더 중요시하는 결과를 얻게 된다.\n\n### Gaussian Mixture Model\n\nGaussian Mixture Model, 일명 GMM은 Finite Mixture Model의 일종이다. Finite Mixture Model은 우리가 추정하고자 하는 확률 분포가 다양한 확률 분포 몇 개의 조합으로 이루어진 분포라고 가정하고, 해당 확률 분포의 Parameter를 학습(Learning) 단계에서 찾아내고, 이를 이용해서 새로운 data에 대해서 추정(Inference)하는 방식이다.\n\n$$\np(x) = \\sum_{k \\in \\{1, 2, \\cdots, K\\}}p(x, z=k) = \\sum_{k \\in \\{1, 2, \\cdots, K\\}}p(x|z=k)p(z=k) = \\sum_{k \\in \\{1, 2, \\cdots, K\\}}p_{k}(x)p(z=k)\n$$\n\n여기서 $z$는 관측할 수 없는 latent(hidden) variable로 data가 몇 번째 확률 분포에 속할 것인지를 의미한다. 따라서, $p(z=k)$ k번째 분포에 속할 확률이라고 볼 수 있다. 대게 이것이 어느정도로 확률 분포를 섞는지를 의미하기 때문에 mixing parameter라고도 부른다.\n\n이에 따라 GMM은 각 $p_{k}(x)$가 Gaussian Distribution이라고 가정하는 Finite Mixture Model인 것이다.\n\n![ml-gmm-graphical-form](/images/ml-gmm-graphical-form.jpg)\n\n그렇다면, 우리는 다음과 같이 Graphical Model 형태로 Finite Mixture Model을 생성할 수 있다. 여기서 $\\pi,\\, \\mu,\\, \\Sigma$는 Parameter를 의미한다.\n\n- $\\pi_{k} = p(z = k)$\n- $\\mu_{k} = E[x|z=k]$ 즉, Gaussian의 기댓값을 의미한다.\n- $\\Sigma_{k} = Cov[x|z=k]$ 즉, Gaussian의 분산을 의미한다.\n\n이를 통해서 우리는 위에서 제시한 확률을 다음과 같이 재정의할 수 있다. (Joint Probability를 Bayesian Network로 푼 식이다. 모르겠다면, [🔗 [ML] 8. Graphical Model](/posts/ml-graphical-model#Graphical-Model)에서 Bayesian Network를 다시 살펴보고 오자.)\n\n$$\n\\begin{align*}\np(x) \u0026= \\sum_{k \\in \\{1, 2, \\cdots, K\\}}p(x, z=k) \\\\\n\u0026= \\sum_{k \\in \\{1, 2, \\cdots, K\\}}p(z=k| \\pi_{k})p(x|z=k, \\mu_{k}, \\Sigma_{k}) \\\\\n\u0026= \\sum_{k \\in \\{1, 2, \\cdots, K\\}}\\pi_{k}\\mathcal{N}(x|\\mu_{k}, \\Sigma_{k})\n\\end{align*}\n$$\n\n여기서 우리가 실제로 추측(Inference)을 할 때에는 $p(z|x)$가 필요하다. 이는 우리가 posterior를 활용해서 구할 수 있다.\n\n$$\n\\begin{align*}\n\\hat{k} \u0026=\\argmax_{k}p(z=k|x) \\\\\n\u0026= \\argmax_{k}\\frac{p(x|z=k)p(z=k)}{p(x)} \\\\\n\u0026= \\argmax_{k}p(x|z=k)p(z=k)\\\\\n\u0026= \\argmax_{k}\\pi_{k}\\mathcal{N}(x|\\mu_{k}, \\Sigma_{k})\n\\end{align*}\n$$\n\n학습(Learning)을 할 때에는 결국 $\\pi,\\, \\mu,\\, \\Sigma$ 이 세 개의 parameter 값을 찾는 것이 중요하다. 이것은 우리가 Parametric Estimation에서 줄기차게 했던 MLE를 이용하면 된다. 이를 위한 Likelihood는 다음과 같다.\n\n$$\n\\begin{align*}\n\\mathcal{L}(\\pi,\\, \\mu,\\, \\Sigma) \u0026= \\log{p(\\mathcal{D} | \\pi,\\, \\mu,\\, \\Sigma)} \\\\\n\u0026= \\log{\\prod_{i=1}^{N}{p(x_{i} | \\pi,\\, \\mu,\\, \\Sigma)}} \\\\\n\u0026= \\sum_{i=1}^{N}{\\log{p(x_{i}| \\pi,\\, \\mu,\\, \\Sigma)}} \\\\\n\u0026= \\sum_{i=1}^{N}{\\log{\\sum_{k=1}^{K}{\\pi_{k}\\mathcal{N}(x_{i}|\\mu_{k}, \\Sigma_{k})}}}\n\\end{align*}\n$$\n\n하지만, 이것을 단순한 Optimization Technique으로는 풀 수 없다. 왜냐하면, 단순한 미분으로 각 parameter를 구할 수 없기 때문이다. 따라서, EM Algorithm을 이용해서 풀어야 한다. (이것은 [🔗 [ML] 10. EM Algorithm](/posts/ml-em-algorithm)에서 다룬다.)\n\n따라서, 아래 그림과 같이 임의의 $\\pi,\\, \\mu,\\, \\Sigma$를 가정한 상태에서 data에 알맞는 최적의 Cluster set을 구하고, data에 cluster가 label된 상태에서 최적의 $\\pi,\\, \\mu,\\, \\Sigma$를 구하는 과정을 반복하는 것이다.\n\n![ml-gmm-1](/images/ml-gmm-1.jpg)\n\n그렇다면, 이를 실제로 어떻게 하는지를 알아보도록 하겠다. 하지만, 그냥 모든 Gaussian 형태를 위한 방법을 사용하면 다소 식이 복잡해지기 때문에 isotropic Gaussian(모든 방향에서 분산이 동일한 Gaussian)을 가정으로 하겠다.\n\n또한, 다음과 같은 요소를 추가로 정의하자.\n\n1. $z_{i} \\in \\{1, 2, \\cdots, K\\}$ : $i$번째 data가 속하는 cluster의 index  \n   $z_{ik} = \\begin{cases} 1 \u0026 \\text{if } z_{i} = k \\\\ 0 \u0026 \\text{otherwise} \\end{cases}$\n2. $\\theta_{k} = (\\pi_{k},\\, \\mu_{k},\\, \\Sigma_{k})$ : $k$번째 cluster를 위한 parameter의 집합  \n   $\\theta = (\\pi,\\, \\mu,\\, \\Sigma)$ : parameter의 집합  \n\n앞 서 말한 바와 같이 이제 우리는 $\\theta$를 구하는 과정에서 $z_{i}$에 해당하는 정보도 알고 있다. 따라서, Likelihood 식도 변형되어야 한다.\n\n$$\n\\begin{align*}\n\\mathcal{L}(\\theta) \u0026= \\log{p(\\mathcal{D} | \\theta)} \\\\\n\u0026= \\sum_{i=1}^{N}{\\log{p(x_{i}, z_{i}| \\theta)}} \\\\\n\u0026= \\sum_{i=1}^{N}{\\log{p(z_{i} | \\theta) \\times p(x_{i}| z_{i}, \\theta)}} \\\\\n\u0026= \\sum_{i=1}^{N}{\\log{(\\prod_{k=1}^{K}{\\pi_{k}^{z_{ik}}} \\times \\prod_{k=1}^{K}{\\mathcal{N}(x_{i}|\\mu_{k}, \\Sigma I)^{z_{ik}}})}} \\\\\n\u0026= \\sum_{i=1}^{N}{\\sum_{k=1}^{K}\\log{({\\pi_{k}}{\\mathcal{N}(x_{i}|\\mu_{k}, \\Sigma I)})^{z_{ik}}}} \\\\\n\u0026= \\sum_{i=1}^{N}{\\sum_{k=1}^{K}z_{ik}\\log{({\\pi_{k}}{\\mathcal{N}(x_{i}|\\mu_{k}, \\Sigma I)})}} \\\\\n\\end{align*}\n$$\n\n\u003c!-- TODO: 여기 부분 EM algorithm 복습한 이후에 다시 점검(p.28~31) --\u003e\n\n이에 따라서 다음과 같이 우리는 정리할 수 있다.\n\n- **E-step**  \n  $$\n  r_{ik} = p(z_{i} = k | x_{i}, \\theta) = \\frac{p(z_{i} = k, x_{i} | \\theta)}{p(x_{i} | \\theta)} = \\frac{p(z_{i} = k, x_{i} | \\theta)}{\\sum_{l=1}^{K}{p(z_{i} =l, x_{i} | \\theta)}} = \\frac{\\pi_{k}{\\mathcal{N}(x_{i}|\\mu_{k}, \\Sigma I)}}{\\sum_{l=1}^{K}{\\pi_{l}{\\mathcal{N}(x_{i}|z_{i} = l, \\mu_{l}, \\Sigma_{l} I)}}}\n  $$\n- **M-step**  \n  $$\n  \\begin{align*}\n  \\mu_{k} \u0026= \\frac{\\sum_{i=1}^{N}{r_{ik}x_{i}}}{\\sum_{i=1}^{N}{r_{ik}}} \\\\\n  \\Sigma_{k} \u0026= \\frac{1}{D}\\frac{\\sum_{i=1}^{N}{r_{ik}||x_{i} - \\mu_{k}||^{2}}}{\\sum_{i=1}^{N}{r_{ik}}} \\\\\n  \\pi_{k} \u0026= \\frac{1}{N}\\sum_{i=1}^{N}{r_{ik}} \\\\\n  \\end{align*}\n  $$\n\n이렇게 식을 정리하고 나면, 하나의 insight를 얻을 수 있다. 그것은 바로 K-means Clustering은 사실 GMM의 하나의 special case라는 것이다. 만약, 우리가 $\\pi_{k},\\, \\Sigma_{k}$를 모두 같은 값으로 설정하면, $\\pi_{k} = \\frac{1}{K}$이고 $\\Sigma_{k} = \\Sigma$가 된다고 하자. 이때 EM algorithm을 살펴보면 다음과 같다.\n\n- **E-step**  \n  $$\n  r_{ik} = \\begin{cases} 1 \u0026 k = \\argmax_{l\\in \\{1, 2, \\cdots, K\\}} p(x_{i}|z_{i} = l, \\mu_{l}, \\Sigma) \\\\ 0 \u0026 \\text{otherwise} \\end{cases}\n  $$  \n  이는 사실상 K-means Clustering에서 중심과의 거리를 통해서 구했던 것과 매우 유사한 식이다.\n- **M-step**  \n  $$\n  \\begin{align*}\n  \\mu_{k} \u0026= \\frac{\\sum_{i=1}^{N}{r_{ik}x_{i}}}{\\sum_{i=1}^{N}{r_{ik}}} \\\\\n  \\pi_{k} \u0026= \\frac{1}{N}\\sum_{i=1}^{N}{r_{ik}}\n  \\end{align*}\n  $$  \n  $\\pi_{k}$가 추가되기는 했지만, $\\mu_{k}$를 구하는 식은 완전 동일하다.\n\n## Reference\n\n- Tumbnail : Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=unsplash\u0026utm_medium=referral\u0026utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@markuswinkler?utm_source=unsplash\u0026utm_medium=referral\u0026utm_content=creditCopyText)\n","slug":"ml-clustering","date":"2022-11-23 09:19","title":"[ML] 9. Clustering","category":"AI","tags":["ML","UnsupervisedLearning","Clustering","K-means","GMM"],"desc":"이전까지의 Posting에서는 Supervised Learning 즉, 이미 Labeling이 완료된 데이터에 의한 Learning을 중점적으로 다루었다. 지금부터는 Unsupervised Learning에 대해서 조금 더 살펴보도록 하겠다. 대표적인 Unsupervised Learning은 Clustering, Feature Selection(or Dimensionality Reduction), Generative Model 등이 존재한다. 이들에 대해서 차근차근 살펴보도록 하고, 해당 Posting에서는 가장 대표적이라고 할 수 있는 Clustering을 먼저 살펴보면서 Unsupervised Learning에 대한 계략적인 이해를 해보도록 하겠다.","thumbnailSrc":"https://euidong.github.io/images/ml-thumbnail.jpg"}]},"__N_SSG":true},"page":"/posts/[slug]","query":{"slug":"ml-model-selection"},"buildId":"7YkH3ZSfLE_PLxr1wR4Mz","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>