{"pageProps":{"posts":[{"content":"\n## **Reference**\n\n![<img src=\"/images/default.jpg\" width=\"190\" />](/images/default.jpg)\n\nDavid A. Patterson, John L. Hennessy,Â Computer Organization and Design\n\në³¸ Postingì€ ë‹¤ìŒ êµì œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì±•í„° ë³„ë¡œ ì •ë¦¬ í•œ ë‚´ìš©ì…ë‹ˆë‹¤. ì•„ë˜ë¶€í„°ëŠ” í¸ì˜ë¥¼ ìœ„í•´ \"-ë‹¤\"ë¡œ í‘œí˜„í•©ë‹ˆë‹¤.\n\n---\n\nìš°ë¦¬ê°€ ì›í•˜ëŠ” ê²ƒì€ ê°•í•œ performanceë¥¼ ë°œíœ˜í•˜ë©´ì„œë„, ê°€ìš©ì„±(availability, ëŠê¹€ ì—†ì´ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì˜ ì •ë„)ê°€ ë†’ì€ computerë¥¼ ë§Œë“œëŠ” ê²ƒì´ë‹¤. ì´ë¥¼ ìœ„í•´ì„œ, ìš°ë¦¬ëŠ” ë‹¨ìˆœíˆ í•˜ë‚˜ì˜ processorë¥¼ ì •êµí•˜ê²Œ ë§Œë“¤ê¸°ë³´ë‹¤ëŠ” ë™ë“±í•œ ê¸°ëŠ¥ì„ í•˜ëŠ” ì—¬ëŸ¬ ê°œì˜ processorë¥¼ ì—°ê²°í•˜ì—¬ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ë” íš¨ìœ¨ì ì´ë¼ëŠ” ê²ƒì´ë¼ëŠ” ê²ƒì„ ì•Œì•„ëƒˆë‹¤. (ì´ë¥¼ softwareê°€ ì˜ í™œìš©í•  ìˆ˜ë§Œ ìˆë‹¤ë©´, ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë  ê²ƒì´ë‹¤.)\n\n- í•˜ë‚˜ì˜ ì¥ì¹˜ë¥¼ ë™ì‘ì‹œí‚¤ëŠ” ë°©ì‹ë³´ë‹¤ ì ì€ ì—ë„ˆì§€ë¡œ ê°™ì€ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤. (ë™ì‹œì— ì‹¤í–‰ì‹œí‚¤ê¸° ë•Œë¬¸ì— ë” ì§§ì€ ì‹œê°„ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.)\n- nê°œì˜ processorì—ì„œ í•˜ë‚˜ê°€ ì‹¤íŒ¨í•˜ì—¬ë„ n-1ê°œëŠ” ì •ìƒ ì‘ë™í•˜ê¸° ë•Œë¬¸ì— ì „ì²´ ì‹œìŠ¤í…œì€ ë¬¸ì œ ì—†ì´ ë™ì‘í•œë‹¤. (Redundant, ì¶”ê°€ìì›ì„ í†µí•´ì„œ ê°€ìš©ì„±ì„ í–¥ìƒì‹œí‚´)\n\nì´ì— ë”°ë¼ ìš°ë¦¬ëŠ” multi-processorë¥¼ ì‚¬ìš©í•œë‹¤. \nì´ëŠ” multi-processorê°€ ì–´ë–»ê²Œ ì¡´ì¬í•˜ëŠëƒì— ë”°ë¼ì„œ ë‹¤ìŒê³¼ ê°™ì€ í˜•íƒœë¡œ ë‚˜ëˆˆë‹¤.\n\n1. **Multicore Microprocessor** : í•˜ë‚˜ì˜ IC(ì§‘ì  íšŒë¡œ) ì¹©ì— ì—¬ëŸ¬ ê°œì˜ processor(core)ê°€ ì¡´ì¬í•œë‹¤.\n2. **Multiple Processor** : ICì¹©ì˜ ê°¯ìˆ˜ë¥¼ ëŠ˜ë¦°ë‹¤.\n3. **Cluster System** : Machine(Computer) ìì²´ì˜ ê°¯ìˆ˜ë¥¼ ëŠ˜ë¦°ë‹¤.\n\në”°ë¼ì„œ, ê°œì¸ PCì—ì„œëŠ” Multiple Multicore Microprocessorë¥¼ ì§€ì›í•˜ê³ , ìˆëŠ” ìƒí™©ì´ê³ , Datacenterì™€ ê°™ì€ í™˜ê²½ì—ì„œëŠ” ì´ëŸ¬í•œ Machineë“¤ì´ ì—¬ëŸ¬ ê°œ ì¡´ì¬í•˜ëŠ” Cluster Systemì´ë¼ê³  ìƒê°í•˜ë©´ ë˜ê² ë‹¤.\n\në˜í•œ, ì´ìš©í•˜ëŠ” ë°©ì‹ì— ë”°ë¼ í¬ê²Œ ë‘ ê°€ì§€ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆë‹¤. \n\n1. Task Level Parallelism(=Process Level Parallelism) : ë™ì‹œì— ë…ë¦½ëœ ì—¬ëŸ¬ programì„ ì‹¤í–‰ì‹œí‚¤ëŠ” ë°©ì‹\n2. Parallel Processing Program : ë™ì‹œì— ì—¬ëŸ¬ ê°œì˜ processorë¥¼ ì´ìš©í•˜ì—¬ í•˜ë‚˜ì˜ programì„ ì‹¤í–‰ì‹œí‚¤ëŠ” ë°©ì‹\n\n## Parallel Processing Programì˜ êµ¬í˜„\n\ní•˜ë‚˜ì˜ ì‘ì—…ì„ ë” ë¹ ë¥´ê²Œ ì²˜ë¦¬í•˜ê¸° ìœ„í•˜ì—¬ multiple processorë¥¼ ì‚¬ìš©í•˜ëŠ” softwareë¥¼ ì‘ì„±í•˜ëŠ” ê²ƒì€ ì–´ë µë‹¤. ì´ëŠ” processorì˜ ìˆ˜ê°€ ëŠ˜ì–´ë‚  ìˆ˜ë¡ ì‹¬í•´ì§„ë‹¤. multiprocessor programì„ ì´ìš©í•  ê²½ìš°ì—, ìˆ˜ê°€ ëŠ˜ì–´ë‚  ìˆ˜ë¡ ìš°ë¦¬ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì‘ì—…ì— ëŒ€í•œ ë¶€ë‹´ì„ ê°€ì§ˆ ìˆ˜ ë°–ì— ì—†ë‹¤.\n\n1. **Scheduling** : process ë˜ëŠ” threadë¥¼ schedulingí•˜ì—¬ ì–´ë–¤ ê²ƒì„ ë¨¼ì € ì‹¤í–‰ì‹œí‚¬ì§€ì— ëŒ€í•œ scheduling ì—­ì‹œ í° ë¶€ë‹´ì´ë‹¤.\n2. **Partitioning** : Memoryì˜ êµ¬ê°„ì„ ê° processorì—ê²Œ ì–´ë–»ê²Œ ë‚˜ëˆ„ê³  ì„œë¡œ ë…ë¦½ë˜ê²Œ ì¡´ì¬í•˜ê¸° ìœ„í•œ ê´€ë¦¬ë¥¼ ìˆ˜í–‰í•˜ëŠ” ê²ƒ ì—­ì‹œ í° ë¶€ë‹´ì´ ëœë‹¤.\n3. **Balancing the Load** : ì‘ì—…ì„ ê° processorì—ê²Œ ê· ë“±íˆ ë¶„ë°°í•˜ëŠ” ê²ƒ ì—­ì‹œ ì–´ë µë‹¤.\n4. **Time to Synchronize** : ì—¬ëŸ¬ ê°œê°€ ë™ì‹œì— í•˜ë‚˜ì˜ processë¥¼ ì‹¤í–‰ì‹œí‚¤ë©´, ì½ê³  ì“°ê¸°ì—ì„œ ì¶©ëŒì´ ë°œìƒí•˜ëŠ” ê²ƒì— ì˜í•œ ë¬¸ì œê°€ ë°œìƒí•˜ê³  ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ì„œ ì‹œê°„ì„ ì‚¬ìš©í•  ìˆ˜ ë°–ì— ì—†ë‹¤.\n5. **Overhead for Communication** : ê° processorê°„ì˜ ì˜ì‚¬ì†Œí†µì— ë„ˆë¬´ í° ë¹„ìš©ì´ ë°œìƒí•˜ëŠ” ê²½ìš° ì˜¤íˆë ¤ í•˜ë‚˜ì˜ processorê°€ ì‹¤í–‰ì‹œí‚¤ëŠ” ê²ƒë³´ë‹¤ ë” ë§ì€ ì‹œê°„ì„ ìš”êµ¬í•  ìˆ˜ë„ ìˆë‹¤.\n\nì´ ëª¨ë“  ê²ƒì„ softwareì—ì„œ ì œëŒ€ë¡œ ê´€ë¦¬í•  ìˆ˜ ìˆì„ ë•Œ, ê·¸ì œì„œì•¼ ìš°ë¦¬ëŠ” multi processor ì‹œìŠ¤í…œì„ ì œëŒ€ë¡œ í™œìš©í•  ìˆ˜ ìˆëŠ” ê²ƒì´ë‹¤.\n\nìš°ë¦¬ê°€ processorì˜ ê°¯ìˆ˜ë¥¼ ëŠ˜ë¦¼ìœ¼ë¡œì¨ ì–»ì„ ìˆ˜ ìˆëŠ” í˜œíƒì€ ê° processorì— ì „ë‹¬ë˜ëŠ” ì‘ì—…ì˜ ìˆ˜ë¥¼ ê· ë“±í•˜ê²Œ ë‚˜ëˆ„ì–´, ê¸°ì¡´ì— í•˜ë‚˜ì˜ processorê°€ í•  ìˆ˜ ì—†ë˜ ì¼ì„ ì²˜ë¦¬(weak scaling)í•˜ê±°ë‚˜, ê¸°ì¡´ì˜ ë¬¸ì œë¥¼ ë” ë¹ ë¥´ê²Œ ì²˜ë¦¬(strong scaling)í•  ìˆ˜ ìˆë‹¤.\n\n## Data Stream, Instruction Stream\n\nprocessorë“¤ë¡œ ë“¤ì–´ì˜¤ëŠ” dataì˜ ì–‘ì„ ì˜ë¯¸í•˜ëŠ” **Data Stream**ê³¼ instructionì˜ ì–‘ì„ ì˜ë¯¸í•˜ëŠ” **Instruction Stream**ì— ë”°ë¼ì„œ, ìš°ë¦¬ëŠ” ê° processorë“¤ì„ ë‹¤ì–‘í•œ ì´ë¦„ìœ¼ë¡œ ë¶€ë¥¸ë‹¤.\n\n1. **SISD**(Single Instruction Stream, Single Data Stream) : ëŒ€ê²Œ single processorì¼ ê²½ìš° ì´ì™€ ê°™ì€ í˜•íƒœë¥¼ ì±„íƒí•œë‹¤.\n2. **MIMD**(Multiple Instrunction Stream, Multiple Data Stream) : Multiple Processor Systemì—ì„œëŠ” ë‹¹ì—°íˆ ì´ì™€ ê°™ì€ ì‹œìŠ¤í…œì„ ì±„íƒí•œë‹¤.\n3. **MISD**(Multiple Instrunction Stream, Single Data Stream) : ì˜ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” í˜•íƒœì´ë‹¤. ëŒ€ê²ŒëŠ” Dataì˜ ì²˜ë¦¬ê°€ ë” ë§ì´ ë°œìƒí•˜ê¸° ë•Œë¬¸ì´ë‹¤.\n4. **SIMD**(Single Instruction Stream, Multiple Data Stream) : í•˜ë‚˜ì˜ Instructionì„ ì´ìš©í•˜ì—¬ ë³µí•©ì ì¸ ì—¬ëŸ¬ ê°œì˜ ë°ì´í„°ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬í•˜ëŠ” vector ì—°ì‚° ë“±ì„ ë¹ ë¥´ê²Œ ì²˜ë¦¬í•  ìˆ˜ ìˆë‹¤.   \n   1. vector ì—°ì‚° í•˜ë‚˜ê°€ for loop í•˜ë‚˜ë¥¼ ì˜ë¯¸í•  ìˆ˜ ìˆë‹¤. ì´ëŠ” processor partì˜ ê° pipeline ë‹¨ê³„ì—ì„œ fetchì™€ decodeì— ì˜í•œ ë¹„ìš©ì„ í¬ê²Œ ê°ì†Œì‹œí‚¬ ìˆ˜ ìˆë‹¤.\n   2. í•˜ë‚˜ì˜ vector ì—°ì‚°ì€ ë‚´ë¶€ì—ì„œ ê°ê°ì´ ë…ë¦½ì ìœ¼ë¡œ ìˆ˜í–‰ë˜ê¸° ë•Œë¬¸ì—, data hazardë¥¼ checkí•˜ëŠ” ë¹„ìš©ì´ ë°œìƒí•˜ì§€ ì•ŠëŠ”ë‹¤. ğŸ‘‰ ë”°ë¼ì„œ, vectorì˜ ê° ìš”ì†Œë¥¼ ëª¨ë‘ ê²€ì‚¬í•˜ëŠ” ê²ƒì´ ì•„ë‹Œ vector ì™¸ë¶€ ê°„ì˜ data hazard ìœ ë¬´ë§Œ í™•ì¸í•˜ë©´ ëœë‹¤.\n   3. Main Memoryì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ê²½ìš°ì—ë„ ê° ìš”ì†Œë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ê²ƒì´ ì•„ë‹Œ í•œ ë²ˆì— ê°€ì ¸ì˜¬ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ë§¤ìš° ë¹ ë¥´ë‹¤.\n   4. Loopë¥¼ í‘œí˜„ì´ vector ì—°ì‚°ìœ¼ë¡œ ëŒ€ì²´ë˜ê¸° ë•Œë¬¸ì—, Loop Branchê°€ ì¤„ì–´ë“ ë‹¤.   \n\n## Hardware Multithreading\n\nprogrammerì˜ ì…ì¥ì—ì„œ MIMDëŠ” hardware multithreadingì²˜ëŸ¼ ë™ì‘í•œë‹¤ê³  ìƒê°í•˜ê²Œ í•œë‹¤. ì´ëŠ” processorì˜ ì‚¬ìš©ì„±ì„ ìµœëŒ€í™”í•˜ê¸° ìœ„í•´ì„œ, íŠ¹ì • threadê°€ stall ë˜ì—ˆì„ ë•Œ, ë‹¤ë¥¸ threadë¥¼ ìˆ˜í–‰í•˜ë„ë¡ í•˜ëŠ” ë°©ì‹ì´ë‹¤. ì¦‰, í•˜ë‚˜ì˜ processorì—ì„œ ì—¬ëŸ¬ ê°œì˜ threadë¥¼ ì‹¤í–‰ì‹œí‚¨ë‹¤ëŠ” ê²ƒì´ë‹¤. ê·¸ëŸ¬ê¸° ìœ„í•´ ì‚¬ì‹¤ìƒ ì—¬ëŸ¬ processorê°€ ì¡´ì¬í•˜ëŠ” multiprocessor í™˜ê²½ì—ì„œ ì„œë¡œê°„ ì‹¤í–‰ í™˜ê²½ì„ ì„œë¡œ ê³µìœ í•´ì•¼ í•œë‹¤. ì´ë¥¼ ì‹¤í˜„í•˜ë ¤ë©´, ê° threadì˜ ë…ë¦½ëœ ìƒíƒœë¥¼ ë³µì‚¬í•  ìˆ˜ ìˆì–´ì•¼ í•œë‹¤. ì¦‰, ê° ê°ì˜ register fileê³¼ PCê°€ ì¡´ì¬í•´ì•¼ í•œë‹¤. ì´ë“¤ ê°„ì˜ Memory ê³µìœ  ê°™ì€ ê²½ìš°ëŠ” ì´ì „ì— ë³´ì•˜ë˜ Virtual Memory ì •ë³´ë¥¼ ê³µìœ í•˜ì—¬ ìˆ˜í–‰í•˜ê²Œ ëœë‹¤. ê·¸ë¦¬ê³  ë¬´ì—‡ë³´ë‹¤ ì¤‘ìš”í•œ ê²ƒì€ ì´ ì‹¤í–‰í•˜ëŠ” threadë¥¼ ë°”ê¾¸ëŠ” ì‹œê°„ì  ë¹„ìš©ì´ ì‘ì•„ì•¼ í•œë‹¤. ì´ë¥¼ ìœ„í•´ì„œ, processê°€ ì•„ë‹Œ threadë¥¼ ë°”ê¾¸ëŠ” ê²ƒì´ë‹¤. processë¥¼ ë°”ê¾¸ëŠ” ê²ƒë³´ë‹¤ëŠ” ë¹„ìš©ì´ í›¨ì”¬ ì ê¸° ë•Œë¬¸ì´ë‹¤. \n\nthreadë¥¼ ë³€ê²½ ì‹œì— ì–´ë–¤ ë°©ë²•ì„ íƒí•  ê²ƒì¸ê°€ ì—­ì‹œ ì¤‘ìš”í•œë°, ì•„ë˜ì™€ ê°™ì€ ë°©ë²•ë¡ ì´ ì¡´ì¬í•œë‹¤.\n\n> **1. Fine Grained Multithreading**\n\nthreadì˜ ëª…ë ¹ì–´ë¥¼ round robine ë°©ì‹ì„ ì´ìš©í•˜ì—¬ ë§¤ë²ˆ ë°”ê¾¸ë©´ì„œ ì‹¤í–‰ì‹œí‚¤ëŠ” ë°©ì‹ì´ë‹¤. ë³€ê²½í•œ thread ì—­ì‹œ stallì´ ëœ threadë¼ë©´, ê±´ë„ˆë›°ê³  ë‹¤ìŒ threadë¥¼ ì‹¤í–‰ì‹œí‚¨ë‹¤.\n\n- ì¥ì  : stall ê¸°ê°„ì´ ì§§ë˜ ê¸¸ë˜ ì´ë¡œ ì¸í•œ ì†ì‹¤ì„ ê°ì¶”ê³ , ê·¸ ë™ì•ˆ ë‹¤ë¥¸ threadë¥¼ ì‹¤í–‰ì‹œí‚¬ ìˆ˜ ìˆë‹¤.\n- ë‹¨ì  : ì‹¤í–‰ ì¤€ë¹„ê°€ ëœ ìƒíƒœ(stallì´ ì•„ë‹Œ ìƒíƒœ)ì—ì„œë„ ë‹¤ìŒ ì°¨ë¡€ê°€ ì˜¬ ë•Œê¹Œì§€ ë°˜ë“œì‹œ ê¸°ë‹¤ë ¤ì•¼ í•˜ê¸° ë•Œë¬¸ì— í•˜ë‚˜ì˜ threadì— ëŒ€í•œ ì²˜ë¦¬ ì†ë„ê°€ dramaticí•˜ê²Œ ì¤„ì–´ë“ ë‹¤.\n\n> **2. Coarse Grained Multithreading**\n\ní•˜ë‚˜ì˜ threadì— ëŒ€í•œ Instructionë§Œ ì²˜ë¦¬í•˜ë‹¤ê°€ stallì´ ë°œìƒí–ˆì„ ë•Œì—ë§Œ threadë¥¼ ë³€ê²½í•˜ë„ë¡ í•˜ëŠ” ë°©ì‹ì´ë‹¤.\n\n- ì¥ì  : í•˜ë‚˜ì˜ threadì— ëŒ€í•œ ì²˜ë¦¬ ì†ë„ì˜ ì†ì‹¤ì´ ì ê³ , switchingì„ ë¹¨ë¦¬ í•˜ëŠ” ê²ƒì— ëŒ€í•œ ë¶€ë‹´ì´ ì ë‹¤.\n- ë‹¨ì  : í•˜ë‚˜ì˜ threadì— ëŒ€í•œ Instructionë§Œ ì²˜ë¦¬í•˜ê¸° ë•Œë¬¸ì—, threadë¥¼ ë³€ê²½í•˜ëŠ” ê²ƒì— ëŒ€í•œ ë¹„ìš©ì´ í¬ë‹¤. (long pipeline setup time) ë”°ë¼ì„œ, ì§§ì€ ê¸°ê°„ì˜ stallì¸ ê²½ìš°ì—ëŠ” í•´ë‹¹ stallì´ ëë‚˜ê¸¸ ê¸°ë‹¤ë¦°ë‹¤.\n\n> **3. Simultaneous Multithreading(SMT)**\n\nThread Levelì—ì„œ Parallelismê³¼ Instruction Levelì—ì„œì˜ Parallelismì„ ë™ì‹œì— ìˆ˜í–‰í•˜ëŠ” ë°©ì‹ì´ë‹¤. Multiple Instruction ì‹œìŠ¤í…œì—ì„œëŠ” ë” ë§ì€ functional unit(register, pc, etc)ì´ ìˆê¸° ë•Œë¬¸ì— ì´ë¥¼ Multi Threadingì—ì„œë„ ì ì ˆíˆ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤ëŠ” ì ‘ê·¼ë²•ì—ì„œ ë‚˜ì™”ë‹¤. ì—¬ê¸°ì„œëŠ” register renamingê³¼ dynamic schedulingì„ ì´ìš©í•˜ì—¬ multiple threadì—ì„œ ì—¬ëŸ¬ ê°œì˜ Instructionì„ ë¹ˆí‹ˆì—†ì´ ë°°ì¹˜í•  ìˆ˜ ìˆë‹¤. ì˜ì¡´ì„±ì€ dynamic schedulingì´ í•´ê²°í•˜ê³ , register renamingì„ í†µí•´ í•„ìš”ì— ë”°ë¼ ì—¬ë¶„ì˜ registerë¥¼ ë¶ˆëŸ¬ì™€ì„œ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ê°€ëŠ¥í•´ì¡Œë‹¤. ì´ë¥¼ í†µí•´ì„œ ìœ„ì˜ ë‘ ë°©ì‹ìœ¼ë¡œ í•  ìˆ˜ ì—†ì—ˆë˜, multi processorë¥¼ ìµœëŒ€í•œìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” íš¨ê³¼ë¥¼ ë³¼ ìˆ˜ ìˆë‹¤.\n\n![multi-threading](/images/multi-threading.png)\n\n## GPU(Graphic Processing Unit)\n\ngame ì‚°ì—… ë° ê·¸ë˜í”½ ë¶„ì•¼ì˜ í° ì„±ì¥ì— í˜ì—…ì–´ graphic ì²˜ë¦¬ì— ëŒ€í•œ processorì˜ ì„±ëŠ¥ í–¥ìƒì´ í•„ìš”í–ˆë‹¤. ì¦‰, ê¸°ì¡´ micro processorì™€ ê²‰ì•„ ë‹¤ìš©ë„ë¡œ ì‚¬ìš©ë˜ëŠ” ê²ƒì´ ì•„ë‹Œ graphic ì—°ì‚°ë§Œì„ ë¹ ë¥´ê²Œ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” processorë¥¼ ë¶„ë¦¬í•  í•„ìš”ê°€ ìƒê¸´ ê²ƒì´ë‹¤. ì´ê²ƒë§Œì„ ìœ„í•´ì„œ ë§Œë“¤ì–´ì§„ ê²ƒì´ GPUì´ë‹¤.\n\nGPUëŠ” ì• ì„œ ì„¤ëª…í•œ Multi Threading ê¸°ìˆ ì„ ì ê·¹ ë„ì…í–ˆê¸° ë•Œë¬¸ì— Memory ì ‘ê·¼ì— ë”°ë¥¸ Latencyê°€ ì„±ëŠ¥ì— í° ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•ŠëŠ”ë‹¤. ê·¸ëŸ° ë§Œí¼ ë°˜ëŒ€ë¡œ ë†’ì€ Bandwidthë¥¼ ê°€ì§„ ì €ì¥ ì¥ì¹˜ë¥¼ í•„ìš”ë¡œ í•œë‹¤.\n\ní›„ì—ëŠ” ì´ ì¥ì¹˜ê°€ ìˆ˜í–‰í•˜ëŠ” vector ì—°ì‚°ì´ ì—¬ëŸ¬ ìš©ë„ë¡œ ì‚¬ìš©ë¨ì— ë”°ë¼ ì´ë¥¼ ìœ„í•œ programming languageë“¤ë„ ë§Œë“¤ì–´ì¡Œë‹¤. ëŒ€í‘œì ì¸ ê²ƒì´ NVidiaê°€ Cë¥¼ í†µí•´ì„œ ë§Œë“  CUDAì´ë‹¤.","slug":"architecture-parallel-processors","date":"2022-05-02 20:22","title":"6. Parallel Processors","category":"Computer Architecture","tags":["Computer Organization And Design","Multi Processors","Multi Threading","MTU"],"thumbnailSrc":"https://euidong.github.io/images/default.jpg"}],"params":{"subject":"Multi Processors"}},"__N_SSG":true}