{"pageProps":{"recentPosts":[{"content":"\n## Intro\n\nSDN Lullaby는 SDN/NFV 환경에서 효율적인 VNF 배치에 관하여 작성한 논문이다. 이 논문에서는 VNF 배치 문제를 DRL을 이용하여 해결하였다. 이를 위해서, 해당 논문에서는 상용 Cloud Data Center에서 주로 사용되던 VM Consolidation 방식을 활용하였고, 이 과정에서 추가적인 구현을 더해서 VNF 배치 문제를 해결하였다. 해당 Posting에서는 이를 구현 및 작성하는 과정에서 겪은 문제를 기반으로 한 회고록이다.\n\n## Description\n\n우선 해당 프로젝트를 통해서 해결하고자 했던 문제부터 정의하자면, 간단하게 SDN/NFV 환경에서 수 많은 VNF가 Virtual Machine(VM)의 형태로 존재하게 되는데 이를 Network Performance와 Energy Efficiency를 모두 고려하여 효율적으로 배치하는 것이 굉장히 어렵고, Rule based 방식으로는 한계가 있는 NP-Hard 문제라는 것이다. 이를 해결하기 위해서 해당 논문에서는 DRL 방식 중에서 PPO를 활용한 해결책을 제시하였고, 성능은 Rule based 방식보다 System Load가 낮은 경우에는 더 성능이 좋았지만, 높은 경우는 오히려 성능이 떨어졌다.\n\n자세한 설명은 `CNSM 2023` 에 오늘(2023/07/11) 제출하였기 때문에 결과가 나오면 추가로 업데이트하도록 하겠다. 일단은 구현에 대한 모든 내용은 Github [SDN Lullaby](https://github.com/euidong/sdn-lullaby)에서 볼 수 있다.\n\n## Process\n\n해당 프로젝트의 시작은 연구실에서 진행 중인 프로젝트 중 외국인 학생에게 할당되어있던 파트가 통채로 나에게 넘어오면서 시작된다. 프로젝트를 이어 받아서 유지, 보수하는 것으로 얘기가 되고 있었는데 사실상 구현이 거의 되어있지 않다는 것을 알게 되었다. 결국 그 학생은 이미 떠나갔고, 결국 나는 이를 처음부터 구현해야하는 상황에 놓여졌다. 이것이 4월 20일 나에게 주어진 미션이였다.\n\n우선 큰 흐름에서는 기존 외국인 학생이 제시한 방향인 강화학습을 활용한 VM Consolidation으로 가닥을 잡았다. 하지만, 실제 요구사항에 대한 정의가 애매했기에 이 부분은 랩미팅과 기존 자료들을 통해서 얻을 수 있었다.\n\n초기에는 여러 다른 논문을 찾아보면서, 어떤 구현이 가장 타당한지에 대한 조사를 진행하였다. 이 과정에서 VM Consolidation은 **Server Selection**, **VM Selection**, **VM Placement** 3단계로 나누어진다는 것을 알게 되었다. 즉, 어떤 서버에서 VM을 옮길지를 먼저 선택한 후에 해당 Server에서 어떤 VM을 선택할지를 결정한 후, 마지막으로 해당 VM을 어느 Server로 옮길지를 결정하는 것이다. 하지만, 해당 논문들을 읽으면서 든 생각은 왜 첫 번째 단계인 **Server Selection**이 왜 필요한가였다. 사실 결론적으로 원하는 것은 VM을 선택하고자 하는 것다. 즉, Server Selection은 선택하고자 하는 VM을 제한하는 역할을 수행한다. 이는 잘못된 추론을 하는 경우에 명백하게 편향적인 선택이 될 수 밖에 없다. 따라서, 해당 프로젝트에서는 과감하게 해당 단계를 생략하고 두 단계로 진행하는 것을 목표로 하였다. (**VM Selection**, **VM Placement**)\n또한, 알고리즘을 선택하는 과정에서는 처음에는 강화학습 중에서도 기본적인 SARSA, Q-Learning을 적용하여 해당 문제를 푸는 것을 목표로 하였다. 하지만, Server의 상태(State)를 강화학습의 Input으로 주는 과정에서 문제가 발생했다. Input으로 전달해야할 정보는 Server의 상태, VM의 상태, 전체 Server를 포함하는 Edge의 상태 등이 있었는데 이를 모두 하나의 State로 정의하는데에는 한계가 있었기 때문이다. 이는 VM의 수와 Server의 수가 늘어남에 따라 제곱으로 State와 Action의 갯수가 늘어나기 때문에 이를 모두 하나의 Table로 표현하는 단순한 SARSA, Q-Learning으로는 한계가 있다는 것을 깨달았다. 따라서, 이를 해결하기 위해서 두 가지 선택지 중에서 하나를 골라야했다.\n\n1. State를 압축할 수 있는 방법을 찾는다.\n2. Deep Learning을 적용하여, Table을 Network로 추정하자.\n\n랩미팅 과정에서 교수님은 1번을 강조하셨다. State를 압축할 수 있는 방법을 찾는다. 굉장히 간단한 알고리즘만으로도 해결이 가능할 것이라고 얘기하셨다. 하지만, 초기에는 이에 대한 감을 잡지 못했기 때문에 결론적으로는 2번을 선택했다. 사실 State가 많아진다면, 간단한 DQN(Deep Q Network)만 활요하더라도 어느정도 성능을 챙길 수 있을 것이라고 생각했고, State를 압축할 방법이 당시로서는 생각하기 어려웠다.\n\n따라서, DQN을 활용하여 문제를 해결하는 것을 바로 시도하였다. 여기서도 결국 문제에 부딪히게 된다. 바로 State를 모두 활용하는 것까지는 좋은데 Output의 크기가 계속 변화하면 어떻게 할 것인지에 대한 문제를 해결할 수 없었다. 즉, 우리가 원하는 VM Consolidation은 결국 어떤 VM을 어떤 Server로 옮길지를 결정해야 한다. 그렇다면, 매 사건마다 Server와 VM의 갯수가 달라질 수가 있다는 것이다. 일반적으로는 Server의 갯수가 변화하는 일은 흔치 않지만, VM은 매번 바뀔 것이다. 따라서, 우리가 고를 VM의 갯수를 해당 System에서는 Input State가 주어지기 전까지는 알 수 없기 때문에 Deep Learning Model의 Output의 크기를 알 수가 없다는 것이다. 즉, Input과 Output의 크기를 정해놓고 시작하는 일반적인 Deep Learning Model로는 한계가 있다는 것이다. 이를 해결하기 위해서 결국 RNN을 활용하기로 결정한다. 즉, RNN에 Input으로 주어지는 데이터가 (Batch size, Sequence length, Input size)의 형태로 주어졌을 때, output의 형태는 (Batch size, Sequence length, Output size)와 같다. 여기서 Sequence length는 변화하지 않는데, 내가 하고자 하는 작업이 사실은 VM/Server의 정보가 주어졌을 때, 하나의 VM/Server를 선택하는 일이기 때문에 VM/Server의 수만큼 Sequence를 만들고, 여기서 나오는 Output size를 1로 고정한다면, 결국 어떤 크기의 VM/Server 수가 들어오더라도 그만큼의 Output을 보장받을 수 있었다. 따라서, 이를 활용해서 초기에는 LSTM에 기반한 DQN 모델을 구현하였다. 여기서 RNN(LSTM을 포함한)은 사실 Sequence를 거치면서 값을 누적하기 때문에, 우리의 원래 의도랑은 다르게 어느 위치에 Input 데이터를 넣느냐가 영향을 미칠 것이라는 것을 생각해서 이를 완화시키기 위해서 Bi-Direction으로 LSTM을 구성하였다. 이렇게 구성한 모델은 아래와 같다.\n\n![sdn-lullaby-arch-1](/images/sdn-lullaby-arch-1.png)\n\n이를 실험하기 위해서, Emulation 환경도 구현을 해서 실험을 한 결과 서버 4개 정도에서 정상적으로 Consolidation이 진행되는 것을 확인했다. 하지만, 실제로 서버 갯수가 8개를 넘기자 전체적으로 성능이 떨어지는 것을 관측했다. 또한, 학습 과정에서 VM의 갯수가 Episode마다 유동적으로 변화하기 때문에 Batch 단위의 학습을 하기 위해서, Memory에 저장하는 과정에서 Episode Length마다 별도의 공간에 따로 저장하였다. 그리고, 학습을 진행할 때에는 Random하게 Length를 하나 선택해서 Episode를 추출했는데, 어떤 Length를 선택하냐에 따라서도 값의 변화가 크기 때문에 이 구조가 variance를 더 크게 할 것이라는 결론에 도달했다. 따라서, 이 문제를 해결하기 위해서 다음과 같은 해결책을 생각했다.\n\n1. Self Attention 구조 적용(LSTM -> Self Attention)\n2. Zero Padding 추가\n\n앞 서 제시했던 Bi Direction을 활요한 LSTM은 설계 자체가 Hidden Value를 순서대로 추출해나가면서 이득을 취하는 것인데 해당 구조에서는 각 요소의 특징을 입력으로 받아서 어떤 요소를 선택할지에 관한 문제이기 때문에 Self Attention 구조가 더 적절하다는 판단을 했다. 또한, zero padding을 추가하여 모든 데이터를 한 번에 저장하였다. 또한, 추가적으로 불가능한 Action의 선택을 방지하기 위해서 추가적인 preprocessing을 추가하였다. 즉, 옮길 수 있는 서버가 없는 VM인 경우, 선택한 VM을 옮길 수 없는 경우는 미리 filtering을 수행하여 해당 데이터를 zero 로 marking하였다. 이를 통해서, 불가능한 Action을 선택하는 것을 방지하였다. 따라서, 이를 반영하여 변경된 구조는 다음과 같다.\n\n![sdn-lullaby-arch-2](/images/sdn-lullaby-arch-2.png)\n\n하지만, 전체적인 성능 개선이 이루어지지 않았고, 따라서 이를 해결하기 위해서 `AlphaStar`라는 논문을 참고하였다. 해당 구조에서는 아래와 같은 구조를 보여준다.\n\n![alphastar](/images/alphastar.jpeg)\n\n여기서는 Encoding Layer를 두고, 이후에 LSTM을 통해서 Sequence 정보를 입력받고, 후에 이를 기반으로 Action을 선택하는 구조를 갖고 있다. 또한, 여기서 특정 Unit을 선택하기 위해서 Self Attention과 Attention을 혼합하여 사용하는 것을 보고 내가 위에서 VM/Server Selection에 Attention Mechanism을 사용하는 것이 일반적인 해결책이라는 것을 알게 되었다. 어쨌든, 이름 참고하여 다음과 같은 구조를 구현했다. 여기서는 DQN이 아닌 PPO를 적용하였다.\n\n![sdn-lullaby-arch-3](/images/sdn-lullaby-arch-3.png)\n\n해당 구조를 통한 실험 역시 실행하였지만, 전체적인 성능 역시 변화하지 않았다. 그래서 결론적으로 최종적으로 두 가지 구조를 변형하여 구현을 마무리하였다. 먼저, 기존 DQN 구조에서 input layer를 추가하여 PPO 구조로 변경하는 것, 그리고 불가능한 Action에 대한 filtering을 preprocessing이 아닌 postprocessing으로 수행하는 것이다. Preprocessing을 수행하는 경우에는 결론적으로 정보의 손실이 발생하게 되는데 이로 인한 손해를 보지말고 차라리 최종 선택 단계에서 불가능한 Action을 선택할 확률을 0이 되도록 postprocessing하는 방식으로 변경하였다. 따라서, 최종 구조는 다음과 같다.\n\n![sdn-lullaby-arch-4](/images/sdn-lullaby-arch-4.png)\n\n해당 최종 구조를 통해서 결론적으로 에너지 효율성과 네트워크 처리 능력까지 향상하는 결과를 얻을 수 있었다. (이는 논문과 Github에 업로드된 자료를 확인하도록 하자.)\n\n## Opinion\n\n결론적으로 나의 첫 번째 Full Paper 논문이 였기에 아쉬움도 많이 남지만, 애착도 그만큼이나 남을 것으로 생각하고 있다. 먼저 총평을 하자면, 나름 만족할만한 프로젝트였다고 생각한다. 우선 랩 미팅마다 매주 progress를 발표하고, 논의하는 과정 자체가 굉장히 유의미했다고 생각한다. 그 때 작성한 자료들이 지금 작성하고 있는 글 그리고 얼마 전에 제출한 논문을 작성하는데 많은 도움을 주었다. 따라서, progress를 주 단위나 작업 단위로 정리하는 것은 굉장히 중요하다는 것을 다시 한 번 느꼈다. 그리고, 실제로 Deep Learning과 Reinforcement Learning을 활용하여 Project를 직접 구현한 것은 이번이 처음이기 때문에 굉장히 많은 걱정을 하였는데 많은 사람들의 도움을 받고 여러 책곽 논문의 도움을 받아서 결국 성공적으로 마무리했다는 것이 중요한 경험으로 남을 거 같다. 또한, 문제를 정의하는 것이 가장 중요하고, 여러 논문을 찾는 사전 준비 단계가 반 이상이라는 것을 깨달았다. 이 과정이 탄탄해야 막힘없이 진행이 가능한데 이를 초기에는 간과한 거 같아서 앞으로는 초반 준비 단계에서 자료 찾고 읽는 것에 굉장히 집중해야겠다는 생각이 들었다. 그리고, 구현하는 과정에서도 관련 자료가 있으면 계속해서 읽어보는 것이 전체적인 구현의 질을 높일 수 있다는 것을 다시 한 번 상기할 수 있는 기회였다.\n\n해당 프로젝트를 하면서, 만족했던 점은 다음과 같다.\n\n1. 이때까지 프로젝트를 진행하면서, 내가 항상 가지는 마인드는 \"어떠한 판단을 하였다면, 이에 대한 근거를 항상 제시할 수 있어야 한다.\" 였는데 이는 해당 프로젝트에서는 꽤나 잘 지켜진 거 같아서 만족한다.\n2. 정리를 굉장히 잘 해두었다. 발표 자료 및 자료 조사 내용 정리를 굉장히 잘 해두었고, 이를 통해서 논문 작성에도 큰 도움을 받았다.\n\n아쉬웠던 점은 다음과 같다.\n\n1. DRL은 처음 적용하다보니 여러 알고리즘을 실험해보고 싶었는데 결과적으로는 DQN, PPO 밖에 적용하지 못했다.\n2. 실험 결과를 내는 과정에서 시간이 굉장히 오래 걸렸다. 이는 실험을 진행하면서, 여러가지 문제가 발생했기 때문인데 이를 미리 예측하고 대비하지 못한 것이 아쉽다.\n3. 최종 구현의 Performance에 미련이 남는다. 결론적으로는 Baseline 시스템과 비교했을 때, 조금 좋은 부분이 있고, 어떤 부분에서는 매우 뒤떨어지기도 하는데 이에 대해서 General한 성능 향상이 있었다면 더 좋았겠다는 생각이 든다.\n\n## Reference\n\n- For Thumbnail: <a href=\"https://www.flaticon.com/free-icons/lullaby\" title=\"lullaby icons\">Lullaby icons created by Freepik Flaticon</a>\n- For Thumbnail: <a href=\"https://www.flaticon.com/free-icons/data-server\" title=\"data server icons\">Data server icons created by The Chohans Brand - Flaticon</a>\n- Arulkumaran, Kai, Antoine Cully, and Julian Togelius. \"Alphastar: An evolutionary computation perspective.\" Proceedings of the genetic and evolutionary computation conference companion. 2019.\n","slug":"sdn-lullaby","date":"2023-07-11 15:51","title":"SDN Lullaby","category":"Memoir","tags":["SDN","NFV","VNF","SFC","VM Consolidation","DRL"],"desc":"SDN Lullaby는 SDN/NFV 환경에서 효율적인 VNF 배치에 관하여 작성한 논문이다. 이 논문에서는 VNF 배치 문제를 DRL을 이용하여 해결하였다. 이를 위해서, 해당 논문에서는 상용 Cloud Data Center에서 주로 사용되던 VM Consolidation 방식을 활용하였고, 이 과정에서 추가적인 구현을 더해서 VNF 배치 문제를 해결하였다. 해당 Posting에서는 이를 구현 및 작성하는 과정에서 겪은 문제를 기반으로 한 회고록이다.","thumbnailSrc":"https://euidong.github.io/images/sdn-lullaby.png"},{"content":"\n## Intro\n\nClustering과 같은 Unsupervised Learning으로 Feature Selection 또는 Feature Extraction 등 여러가지 이름으로 불리는 Dimensionality Reduction 기법에 대해서 다룰 것이다. 특정 data에서 유의미한 정보를 얻기 위해서 우리는 data 전체를 볼 필요가 없다. 따라서, feature들을 최소한으로 줄이면서 유의미한 정보를 얻을 수만 있다면 굉장히 효율적인 inferencing과 learning을 할 수 있다.\n\n## Dimensionality Reduction\n\n가장 AI가 활발하게 연구되고 있는 분야는 Vison과 Natural Language 분야일 것이다. 그리고 이들 분야의 공통점은 data의 크기가 굉장히 크다는 것이다. 예를 들어, 숫자를 표현하는 하나의 이미지가 $1920\\times1080$ 정도의 화질이고, 검은 색 또는 흰색으로 구분하는 bitmap 형식이라고 하자. 이 때 우리가 각 image에 존재하는 숫자를 classification하고 싶은 경우, data에 사용되는 feature가 $1920\\times1080=2,073,600$이다. 상당히 큰 숫자이고, 화질이 커질 수록 그리고 색이 생길 수록 이 값은 커질 것이다. Natural Language 분야에서도 마찬가지이다. 영어 단어의 종류만 따져도 170,000개가 넘는다. 즉, 이들 각 각을 단순 one-hot encoding으로 표현한다면, data에 사용되는 feature의 수는 170,000개가 넘는다. 이렇게 feature의 수가 많아지면, 우리는 data를 효율적으로 학습시키기가 매우 어려워진다. 이를 해결하기 위해서는 feature의 수를 줄이는 것이 반드시 필요하다.\n\n이를 위해서, 우리는 하나의 insight가 필요하다. data에서 필요한 부분이 눈으로 보이는 것이 아닐 수도 있다는 점이다. 예를 들어 우리가 $10\\times10$ 크기의 bitmap에 숫자가 쓰여있다고 하자.\n\n![ml-observed-dim](/images/ml-observed-dim.png)\n\n이때 우리가 갖는 경우의 수는 $2^{100}$개일 것이다. 여기서 숫자 형태로 존재하지 않는 data가 사실은 더 많음에도 불구하고 우리는 이 경우의 수도 고려하는 dimension에서 inferencing과 learning을 수행하는 것이다. 이는 매우 비효율적이라고 할 수 있다. 따라서, 우리는 실제로 관측한 observed dimensionality보다는 더 훌륭한 true dimensionality를 찾아내는 것이 필요하다. 이를 위해서, 다양한 Dimensionality Reduction 관련 방법들이 존재한다. 그 중에서 PCA가 가장 일반적으로 많이 사용되고 있는 방법이다.\n\n## Principal Component Analysis\n\nPrincipal Component Analysis(PCA)는 핵심이 되는 principal component(basis, 기저, 차원 축)를 재정의하여 차원을 줄이는 방법이다. 그렇다면, 어떤 basis가 좋은 basis인지를 알 수 있을까? 아마도 좋은 basis는 이전 basis에서 가지고 있던 정보들을 최대한 보존할 수 있다면 좋다고 할 수 있을 것이다. 그렇다면, 여기서 어떻게 information을 많이 보관할 수 있을지에 대한 통찰이 필요하다.\n\n![ml-pca-1](/images/ml-pca-1.png)\n\n위의 그림을 봤을 때, 왼쪽과 오른쪽 중 어떤 basis가 더 좋은 basis일지를 보자. 차원을 옮긴다는 것은 기존 basis에서의 data를 새로운 basis로 projection하는 것이다. 다시 말해, 해당 축에 직각으로 data를 내려보내는 것이다. 그렇게 했을 때, 왼쪽 그림이 오른쪽 그림보다 더 넓게 data가 퍼지는 것을 알 수 있다. 즉, 차원 이동 시에 충돌로 인해 사라지는 data의 수가 더 적다는 것을 의미한다. 이에 따라 더 많은 정보를 포함하는 것은 data를 최대한 넓게 퍼트릴 수 있는 basis를 가지는 것이라고 할 수 있다. <mark>**따라서, PCA는 기존 basis보다 적은 수의 새로운 basis로 옮기는 과정에서 기존 dimension에서의 정보를 최대한 포함하기 위해서 variance가 최대가 되는 basis를 찾는 것이 목표이다.**</mark> 그럼 이를 수학적으로 표현해볼 것이다. 우선은 이해를 위해서 새로운 basis의 수를 1이라고 가정하고 우리는 sample mean과 variance를 이용해서 이를 추론할 것이다. (해당 basis가 $u_{1}$이다.)\n\n$$\n\\begin{align*}\nVar[u_{1}^{\\top}x] &= E[(u_{1}^{\\top}x - E[u_{1}^{\\top}x])^{2}] \\\\\n&= E[(u_{1}^{\\top}x - u_{1}^{\\top}\\bar{x})^{2}] \\quad (\\bar{x} = E[x] = \\frac{1}{N}\\sum_{n\\in[N]}x_{n}) \\\\\n&=\\frac{1}{N}\\sum_{n\\in[N]}(u_{1}^{\\top}x_{n} - u_{1}^{\\top}\\bar{x})^{2} \\\\\n&=\\frac{1}{N}\\sum_{n\\in[N]}(u_{1}^{\\top}x_{n} - u_{1}^{\\top}\\bar{x})^{\\top}(u_{1}^{\\top}x_{n} - u_{1}^{\\top}\\bar{x}) \\\\\n&=\\frac{1}{N}\\sum_{n\\in[N]}(u_{1}^{\\top}(x_{n}-\\bar{x})(x_{n} -\\bar{x})^{\\top}u_{1}) \\\\\n&=u_{1}^{\\top} \\times \\{\\frac{1}{N}\\sum_{n\\in[N]}(x_{n}-\\bar{x})(x_{n} -\\bar{x})^{\\top}\\} \\times u_{1} \\\\\n&=u_{1}^{\\top} S u_{1} \\quad (S = \\frac{1}{N}\\sum_{n\\in[N]}(x_{n}-\\bar{x})(x_{n} -\\bar{x})^{\\top})\n\\end{align*}\n$$\n\n결국 우리가 얻고자 하는 다른 basis에서의 variance를 구하기 위해서 우리는 기존 차원에서의 모든 data들의 covariance($S_{ij} = Cov[x_{i}, x_{j}]$)를 구해야한다.\n\n자 이제 이를 maximization하는 답을 찾아볼 것이다. 그러기 위해서, 우선 basis의 크기 역시 variance의 영향을 미치기 때문에 이를 unit vector로 제한해야 한다. 이를 종합하면 결론적으로 dimension을 1로 바꾸는 PCA는 다음과 같은 형태로 표현할 수 있다.\n\n$$\n\\begin{align*}\n\\text{maximize }&\\quad u_{1}^{\\top} S u_{1} \\\\\n\\text{subject to }&\\quad u_{1}^{\\top}u_{1} = 1\n\\end{align*}\n$$\n\n위의 maximization problem을 해결해보자. 그러면 다음과 같은 lagrange function을 얻을 수 있다.\n\n$$\n\\mathcal{L} = u_{1}^{\\top} S u_{1} + \\lambda(1-u_{1}^{\\top}u_{1})\n$$\n\n이를 미분하면 다음과 같다.\n\n$$\n\\begin{align*}\n\\frac{\\partial\\mathcal{L}}{\\partial u_{1}} &= 2S u_{1} - 2\\lambda u_{1} = 0 \\\\\nS u_{1} &= \\lambda u_{1}\n\\end{align*}\n$$\n\n즉, 우리가 찾고자 하는 basis는 S matrix의 eigenvector 중 하나의 eigenvector인 것이다. 간단하게 eigenvector와 eigenvalue가 뭔지를 설명하자면, 위처럼 동일한 vector에 대해서, matrix와 vector의 곱이 scalar와 vector과 동일하게 하는 scalar(eigenvalue)와 vector(eigenvector)를 의미한다. (후에 시간이 되면 해당 개념을 다루겠지만, 여기서는 eigenvalue와 eigenvector에 대한 개념은 생략한다.)\n\n그리고 우리가 구한 식을 maximization 식에 한 번 대입하면 다음과 같은 결과를 얻을 수 있다.\n\n$$\n\\begin{align*}\n\\text{maximize }& \\quad u_{1}^{\\top} S u_{1} \\\\\n\\text{maximize }& \\quad u_{1}^{\\top} \\lambda u_{1} \\\\\n\\text{maximize }& \\quad \\lambda u_{1}^{\\top} u_{1} \\\\\n\\text{maximize }& \\quad \\lambda\n\\end{align*}\n$$\n\n따라서, eigenvalue 중 가장 큰 값을 가질 때의 eigenvector가 우리가 구하고자 하는 basis가 된다는 것을 알 수 있다. 또한, 결론적으로 $u_{1}^{\\top} S u_{1} = \\lambda$이기 때문에 $\\lambda$가 variance가 된다는 것도 포인트 중 하나이다.\n\n또한 최종적으로 이를 확장해서 이제 M개의 basis를 사용하는 PCA를 다음과 같이 표현할 수 있다.\n\n$$\n\\begin{align*}\n\\text{maximize }\\quad& \\sum_{i \\in [M]} u_{i}^{\\top} S u_{i} \\\\\n\\text{subject to }\\quad& u_{i}^{\\top}u_{j} = \\delta_{ij} \\quad \\forall i,j \\in [M] \\\\\n&(\\delta_{ij} = \\begin{cases} 1 & i=j \\\\ 0 & i \\neq j \\end{cases})\n\\end{align*}\n$$\n\n따라서, PCA는 data의 covariance matrix에 대한 eigenvalue decomposition을 통해 얻은 eigenvalue 중에 큰 값을 가지는 것을 총 M개 뽑고, 이에 상응하는 eigenvector들을 찾는 것이다. 그리고, 이에 따라서 우리가 가지는 M개의 basis의 eigenvalue($\\lambda$)의 합은 우리가 옮긴 차원에서 갖고 있는 총 variance를 의미한다.\n\n### Other Approaches\n\n위에서 우리는 PCA를 variance를 최대로 하는 basis를 찾는 것으로 정의했다. 하지만, 관점을 바꿔서 문제를 projection error, 기존 data와 projected data 사이의 거리를 최소화할 수 있는 basis를 찾는 것으로 정의할 수도 있다. 이 또한 생각하기에 합리적이라고 생각할 수 있는데 이를 실제로 수학적으로 나타내면 어떻게 되는지 알아보겠다.\n\n먼저, 우리가 총 D개의 unit vector가 있고, 이 중에 임의의 M개의 vector를 basis로 하는 차원으로 reduction을 한다고 해보자. 그렇다면, 우리는 다음과 같이 N개의 data들 중 하나인 $x_{n}$를 표현할 수 있을 것이다.\n\n$$\n\\begin{align*}\n  x_{n} &= \\sum_{i=1}^{D}\\{(x_{n}^{\\top}u_{i})u_{i}\\} \\\\\n  &= \\sum_{i=1}^{M}\\{(x_{n}^{\\top}u_{i})u_{i}\\} + \\sum_{i = M+1}^{D}\\{(x_{n}^{\\top}u_{i})u_{i}\\}\n\\end{align*}\n$$\n\n그리고 우리는 옮겨진 data($\\tilde{x}_{n}$)를 다음과 같이 표현할 수 있다.\n\n$$\n\\begin{align*}\n  \\tilde{x}_{n} &= \\sum_{i=1}^{M}\\{(x_{n}^{\\top}u_{i})u_{i}\\} + \\sum_{i = M+1}^{D}\\{(\\bar{x}^{\\top}u_{i})u_{i}\\}\n\\end{align*}\n$$\n\n여기서 의문이 들 수 있다. $\\sum_{i=M+1}^{D}$ 부분이 와닿지 않을 것이다. 왜냐하면, 우리는 projected data가 실제로는 $\\sum_{i=1}^{M}$ 부분만을 가지기 때문이다. 뒷 부분이 추가된 이유는 해당 M차원 data를 D차원의 공간에 표현할 때, 어느 부분을 중점으로 할지를 정한 것이다. 따라서, 앞 서 보았던 전체 data의 평균만큼을 남은 모든 방향에 더해준 것이다. 이 값은 모든 projected data에 동일하게 더해지는 상수값이라고 봐도 무방하다. 이래도 이해가 조금 어렵다면 아래 그림을 통해 이해할 수 있다.\n\n![ml-pca-3](/images/ml-pca-3.png)\n\n위와 같이 3개의 vector는 1차원에서는 동일한 vector이다. 하지만, projected data와 원래 data간의 적절한 거리를 구하기 위해서는 중앙에 있는 형태로 basis로 옮겨야 한다. 이를 위해서 필요한 것이 뒤의 요소이다. 따라서, 우리는 아래식과 같이 두 projected data와 원래 data간의 거리를 구할 수 있다.\n\n$$\n\\begin{align*}\n  x_{n} - \\tilde{x}_{n} &= (\\sum_{i=1}^{M}\\{(x_{n}^{\\top}u_{i})u_{i}\\} + \\sum_{i = M+1}^{D}\\{(x_{n}^{\\top}u_{i})u_{i}\\}) - (\\sum_{i=1}^{M}\\{(x_{n}^{\\top}u_{i})u_{i}\\} + \\sum_{i = M+1}^{D}\\{(\\bar{x}^{\\top}u_{i})u_{i}\\}) \\\\\n  &= \\sum_{i = M+1}^{D}\\{(x_{n}^{\\top}u_{i})u_{i}\\} - \\sum_{i = M+1}^{D}\\{(\\bar{x}^{\\top}u_{i})u_{i}\\} \\\\\n  &= \\sum_{i = M+1}^{D}\\{(x_{n}^{\\top}u_{i} - \\bar{x}^{\\top}u_{i})u_{i}\\}\n\\end{align*}\n$$\n\n따라서, 우리가 구하고자하는 최종 목적함수를 mean squared error라고 한다면 다음과 같이 정의할 수 있다.\n\n$$\n\\begin{align*}\n\\mathcal{J} &= \\frac{1}{N}\\sum_{n=1}^{N}||x_{n} - \\tilde{x}_{n}||^2 \\\\\n&= \\frac{1}{N}\\sum_{n=1}^{N}(\\sum_{i = M+1}^{D}x_{n}^{\\top}u_{i} - \\bar{x}^{\\top}u_{i})^{\\top}(\\sum_{i = M+1}^{D}x_{n}^{\\top}u_{i} - \\bar{x}^{\\top}u_{i}) \\\\\n&= \\frac{1}{N}\\sum_{n=1}^{N}\\sum_{i = M+1}^{D}(x_{n}^{\\top}u_{i} - \\bar{x}^{\\top}u_{i})^{2}u_{i}^{\\top}u_{i} \\\\\n&= \\sum_{i = M+1}^{D}\\frac{1}{N}\\sum_{n=1}^{N}(x_{n}^{\\top}u_{i} - \\bar{x}^{\\top}u_{i})^{2}\\\\\n&= \\sum_{i=M+1}^{D} u_{i}^{\\top} S u_{i}\\quad (\\because \\text{앞 서 살펴본 첫 번째 관점과 동일})\n\\end{align*}\n$$\n\n따라서, 우리는 다음과 같은 결론에 도달할 수 있다.\n\n$$\n\\begin{align*}\n\\text{minimize }\\quad& \\sum_{i=M+1}^{D} u_{i}^{\\top} S u_{i} \\\\\n\\text{subject to }\\quad& u_{i}^{\\top}u_{j} = \\delta_{ij} \\quad \\forall i,j \\in [M] \\\\\n&(\\delta_{ij} = \\begin{cases} 1 & i=j \\\\ 0 & i \\neq j \\end{cases})\n\\end{align*}\n$$\n\n기존 식과 다른 점이라면, maximization이 minimization으로 바뀌었고, 범위가 $[1, M]$에서 $[M+1, D]$로 바뀌었다는 점이다. 그리고, 우리는 다음과 같은 통찰을 얻을 수 있다. eigenvalue들 중에서 가장 큰 값부터 M번째로 큰 값을 구하는 것과 M+1부터 시작해서 가장 작은 eigenvalue를 찾는 과정은 동일하므로 두 식은 사실상 동일하다.\n\n![ml-pca-4](/images/ml-pca-4.png)\n\n### Very High Dimensional Data\n\n일반적으로 우리가 PCA를 구하기 위해서 eigenvector를 구하는 비용은 O($D^3$)이다. 하지만, 차원이 data의 수보다 큰 경우에 약간의 꼼수를 쓸 수 있다. 간단하게 S를 (M x M) matrix에서 (N x N) matrix로 변환하여 사용하는 것이다. 이를 이용하면, O($N^3$)로 시간 복잡도를 바꾸는 것이 가능하다. 식은 아래를 참고 하자. 아래에서 사용하는 $X$는 각 행이 $(x_{n} - \\bar{x})^{\\top}$인 matrix이다.\n\n$$\n\\begin{align*}\n  Su_{i} &= \\lambda_{i}u_{i} &\\\\\n  \\frac{1}{N}X^{\\top}Xu_{i} &= \\lambda_{i}u_{i} &\\leftarrow X^{\\top}X \\in R^{D\\times D} \\\\\n  X \\times \\frac{1}{N}X^{\\top}Xu_{i} &= X \\times \\lambda_{i}u_{i}& \\\\\n  \\frac{1}{N}XX^{\\top}(Xu_{i}) &= \\lambda_{i}(Xu_{i})& \\\\\n  \\frac{1}{N}XX^{\\top}(v_{i}) &= \\lambda_{i}(v_{i}) &\\leftarrow XX^{\\top} \\in R^{N\\times N}\\\\\n\\end{align*}\n$$\n\n## Probabilistic PCA\n\nPCA를 통해서 data를 다른 차원으로 옮기는 과정을 수행했다. 사실 이것으로 끝나기는 조금 아쉽다. 왜냐하면, 우리는 현재 가지고 있는 data에 대응하는 차원으로의 이동을 수행한 것이다. 즉, 우리가 실제로 inferencing 단계에서 unseen data를 보게 되었을 때 제대로 동작할지는 미지수라고 할 수 있다. 이를 극복하기 위해서, continueous한 형태를 만들어야 한다. 이를 위해서, PCA를 확률적으로 해석하는 것이 필요하다. 하지만, 여기서는 자세히 다루지 않는다. 후에 더 자세히 다루도록 하겠다.\n\n## Kernel PCA\n\n여태까지 앞에서 살펴봤던 PCA는 새로운 basis가 기존 Dimenalality에서 linear하게 만들었다. 하지만, 우리가 다루는 data가 사실은 그렇지 않은 형태일 가능성이 높다. 우리가 관측한 특징들에 의한 좌표 공간에서 선형 형태로 data가 존재하는게 아니라 더 복잡한 곡선 형태를 가질 수 있다. 가장 일반적인 data가 원형으로 이루어진 data 분포이다. 원형으로 반지름이 0.5이하인 data와 반지름이 1인 data를 구분하고 싶다고 하자. 일반적인 x, y 공간에서 linear basis를 이용해서 이를 적절하게 나누려면, dimensionality reduction에서는 정보를 모두 거의 균일하게 잃을 수 밖에 없다.\n\n![ml-kernel-pca-1](/images/ml-kernel-pca-1.png)\n\n하지만, 우리는 일반적으로 중심과 떨어진 정도($x^{2} + y^{2}$)와 같은 기존 feature를 non-linear하게 조합하여 활용하면 더 효과적인 구분이 가능할 것이라는 것을 알 수 있다. (아래 그림은 다른 방식을 사용한 것이지만, 원의 중심과 비슷하다.)\n\n![ml-kernel-pca-2](/images/ml-kernel-pca-2.png)\n\n따라서, 우리는 기존 차원에서 선형으로 basis를 변경하는 것이 아니라 비선형으로 basis를 찾고 싶은 것이다. 기존 차원과 비교했을 때 비선형의 basis를 통해서 만들어지는 차원을 manifold라고 하며, 아래 왼쪽 위와 같은 manifold를 발견만 한다면, Dimensionality reduction을 기존 linear 방식과 비교했을 때 더 효과적으로 수행할 수 있다.\n\n![ml-kernel-pca-3](/images/ml-kernel-pca-3.png)\n\n자 그렇다면 이 또한 어떻게 수학적으로 표현할 수 있을까? 이전에 썼던 Maximum Variance 방식을 이용할 것이다. 우선 우리가 data($x$)를 non-linear 공간으로 차원 이동시킨 값을 $\\phi(x)$라고 정의하고, $\\sum_{i=1}^{N}\\phi(x_{i})=0$이 되는 상황이라고 가정을 해보자.(그렇지 않으면 굉장히 수식이 복잡해지기 때문에 우선 이렇게 가정을 할 것이다.)\n\n$$\n\\begin{align*}\nVar[u_{1}^{\\top}\\phi(x)] &= E[(u_{1}^{\\top}\\phi(x) - E[u_{1}^{\\top}\\phi(x)])^{2}] \\\\\n&= E[(u_{1}^{\\top}\\phi(x) - u_{1}^{\\top}\\bar{\\phi}(x))^{2}]\\quad (\\bar{\\phi}(x) = E[\\phi(x)] = \\frac{1}{N}\\sum_{n \\in [N]}\\phi(x_{n})) \\\\\n&= E[(u_{1}^{\\top}\\phi(x))^2] \\\\\n&= \\frac{1}{N}\\sum_{n \\in [N]}(u_{1}^{\\top}\\phi(x_{n}))^{2} \\\\\n&= u_{1}^{\\top}\\frac{1}{N}\\{\\sum_{n \\in [N]}\\phi(x_{n})\\phi(x_{n})^{\\top}\\}u_{1} \\\\\n&= u_{1}^{\\top}\\bar{S}u_{1} \\quad (\\bar{S} = \\frac{1}{N}\\sum_{n \\in [N]}\\phi(x_{n})\\phi(x_{n})^{\\top})\n\\end{align*}\n$$\n\n따라서, 우리는 결론상 이전과 마찬가지로 다음과 같은 식을 얻을 수 있다.\n\n$$\n\\begin{align*}\n\\text{maximize}\\quad& \\sum_{i \\in [M]}u_{i}^{\\top}\\bar{S}u_{i} \\\\\n\\text{subject to}\\quad& u_{i}^{\\top}u_{j} = \\delta_{ij}\\quad \\forall i,j \\in [M] \\\\\n\\end{align*}\n$$\n\n이를 푸는 과정은 앞에서 살펴봤으니 정리를 하자면, 결국 다음과 같은 eigenvalue, eigenvector를 찾는 것이다.\n\n$$\n\\bar{S}u_{i} = \\lambda_{i}u_{i}\n$$\n\n하지만, 이를 푸는 것은 굉장히 곤혹스럽다. 왜냐하면, 우리는 모든 data에 대해서 차원 변환 함수인 $\\phi$를 적용해주어야 하기 때문에 연산의 복잡도는 급격하게 증가하게 된다. 따라서, 우리는 이를 차원 변환 함수 $\\phi$의 연산 과정을 효과적으로 줄이는 방법을 제시한다. 이것이 kernel 함수이다. 이는 앞 서 살펴봤었던, [🔗 5. Multiclass Classification](/posts/ml-multiclass-classification-in-svm#Kernel-Method)의 Kernel Method와 동일하다. 간단하게 설명하자면, $\\phi(x_{i})^{\\top}\\phi(x_{j})$의 결과와 동일한 $\\kappa(x_{i}, x_{j})$의 연산을 활용해서 총 2번의 차원 변환과 곱셈 연산을 두 개의 변수를 받는 하나의 함수로 대체한다는 idea이다. 이를 통해서, 연산 비용을 획기적으로 줄일 수 있다. 따라서, 우리는 기존 식에서 $\\phi$를 없애고, kernel 만으로 이루어진 형태로 바꿀 것이다.\n\n이를 위해서, 우리는 먼저 $u_{i}$를 다시 표현해보자.\n\n$$\n\\begin{align*}\n\\bar{S}u_{i} &= (\\frac{1}{N}\\sum_{n \\in [N]}\\phi(x_{n})\\phi(x_{n})^{\\top})u_{i} \\\\\n&= \\frac{1}{N}\\sum_{n \\in [N]}\\{\\phi(x_{n})\\times (\\phi(x_{n})^{\\top}u_{i})\\} \\\\\n&= \\frac{1}{N}\\sum_{n \\in [N]} <\\phi(x_{n}), u_{i}>\\phi(x_{n})\\quad(<\\phi(x_{n}), u_{i}> = \\phi(x_{n})^{\\top}u_{i})  \\\\\n\\\\\n\\lambda_{i}u_{i} &= \\bar{S}u_{i} \\\\\n\\lambda_{i}u_{i} &= \\frac{1}{N}\\sum_{n \\in [N]} <\\phi(x_{n}), u_{i}>\\phi(x_{n}) \\\\\nu_{i} &= \\sum_{n \\in [N]} \\frac{<\\phi(x_{n}), u_{i}>}{N\\lambda_{i}}\\phi(x_{n}) \\\\\n\\therefore u_{i} &= \\sum_{n \\in [N]} \\alpha_{in}\\phi(x_{n})\n\\end{align*}\n$$\n\n해당 과정을 통해서, 우리가 얻고자 하는 basis는 임의의 상수 $\\alpha_{in}$에 의해서 정의된다는 것을 알 수 있다. 따라서, 이제부터 문제는 $\\alpha_{in}$을 모든 N과 M에 대해서 찾기만 하면 되는 것이다. 이제 기존 식을 다시 정리해보도록 하자.\n\n$$\n\\begin{align*}\n\\bar{S}u_{i} &= \\lambda_{i}u_{i} \\\\\n(\\frac{1}{N}\\sum_{n \\in [N]}\\phi(x_{n})\\phi(x_{n})^{\\top})(\\sum_{m \\in [N]} \\alpha_{in}\\phi(x_{m})) &= \\lambda_{i}(\\sum_{n \\in [N]} \\alpha_{in}\\phi(x_{n})) \\\\\n\\phi(x_{\\ell})^{\\top}\\times (\\frac{1}{N}\\sum_{n \\in [N]}\\phi(x_{n})\\phi(x_{n})^{\\top})(\\sum_{m \\in [N]} \\alpha_{im}\\phi(x_{m})) &= \\phi(x_{\\ell})^{\\top}\\times \\lambda_{i}(\\sum_{n \\in [N]} \\alpha_{in}\\phi(x_{n})) \\\\\n\\frac{1}{N}\\sum_{n \\in [N]}\\phi(x_{\\ell})^{\\top}\\phi(x_{n})\\phi(x_{n})^{\\top}\\sum_{m \\in [N]} \\alpha_{im}\\phi(x_{m}) &= \\lambda_{i}\\sum_{n \\in [N]} \\alpha_{in}\\phi(x_{\\ell})^{\\top}\\phi(x_{n}) \\\\\n\\frac{1}{N}\\sum_{n \\in [N]}\\phi(x_{\\ell})^{\\top}\\phi(x_{n})\\sum_{m \\in [N]} \\alpha_{im}\\phi(x_{n})^{\\top}\\phi(x_{m}) &= \\lambda_{i}\\sum_{n \\in [N]} \\alpha_{in}\\phi(x_{\\ell})^{\\top}\\phi(x_{n}) \\\\\n\\frac{1}{N}\\sum_{n \\in [N]}\\kappa(x_{\\ell}, x_{n})\\sum_{m \\in [N]} \\alpha_{im} \\kappa(x_{n}, x_{m}) &= \\lambda_{i}\\sum_{n \\in [N]} \\alpha_{in}\\kappa(x_{\\ell}, x_{n}) \\\\\n\\sum_{n \\in [N]}\\kappa(x_{\\ell}, x_{n})\\begin{bmatrix} \\kappa(x_{n}, x_{1}) \\\\ \\kappa(x_{n}, x_{2}) \\\\ \\vdots \\\\ \\kappa(x_{n}, x_{N}) \\end{bmatrix}^{\\top}\\begin{bmatrix}\\alpha_{i1} \\\\ \\alpha_{i2} \\\\ \\vdots \\\\ \\alpha_{iN} \\\\\\end{bmatrix} &= N\\lambda_{i} \\begin{bmatrix} \\kappa(x_{\\ell}, x_{1}) \\\\ \\kappa(x_{\\ell}, x_{2}) \\\\ \\vdots \\\\ \\kappa(x_{\\ell}, x_{N}) \\end{bmatrix}^{\\top}\\begin{bmatrix}\\alpha_{i1} \\\\ \\alpha_{i2} \\\\ \\vdots \\\\ \\alpha_{iN} \\\\\\end{bmatrix} \\\\\n\\begin{bmatrix} \\kappa(x_{\\ell}, x_{1}) \\\\ \\kappa(x_{\\ell}, x_{2}) \\\\ \\vdots \\\\ \\kappa(x_{\\ell}, x_{N}) \\end{bmatrix}^{\\top}\\begin{bmatrix} \\kappa(x_{1}, x_{1}) & \\kappa(x_{1}, x_{2}) & \\cdots & \\kappa(x_{1}, x_{N}) \\\\\\kappa(x_{2}, x_{1}) & \\kappa(x_{2}, x_{2}) & \\cdots & \\kappa(x_{2}, x_{N}) \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\kappa(x_{N}, x_{1}) & \\kappa(x_{N}, x_{2}) & \\cdots & \\kappa(x_{N}, x_{N}) \\end{bmatrix}\\begin{bmatrix}\\alpha_{i1} \\\\ \\alpha_{i2} \\\\ \\vdots \\\\ \\alpha_{iN} \\\\\\end{bmatrix} &= N\\lambda_{i} \\begin{bmatrix} \\kappa(x_{\\ell}, x_{1}) \\\\ \\kappa(x_{\\ell}, x_{2}) \\\\ \\vdots \\\\ \\kappa(x_{\\ell}, x_{N}) \\end{bmatrix}^{\\top}\\begin{bmatrix}\\alpha_{i1} \\\\ \\alpha_{i2} \\\\ \\vdots \\\\ \\alpha_{iN} \\\\\\end{bmatrix} \\\\\n\\begin{bmatrix} \\kappa(x_{1}, x_{1}) & \\kappa(x_{1}, x_{2}) & \\cdots & \\kappa(x_{1}, x_{N}) \\\\\\kappa(x_{2}, x_{1}) & \\kappa(x_{2}, x_{2}) & \\cdots & \\kappa(x_{2}, x_{N}) \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\kappa(x_{N}, x_{1}) & \\kappa(x_{N}, x_{2}) & \\cdots & \\kappa(x_{N}, x_{N}) \\end{bmatrix}\\begin{bmatrix}\\alpha_{i1} \\\\ \\alpha_{i2} \\\\ \\vdots \\\\ \\alpha_{iN} \\\\\\end{bmatrix} &= N\\lambda_{i} \\begin{bmatrix}\\alpha_{i1} \\\\ \\alpha_{i2} \\\\ \\vdots \\\\ \\alpha_{iN} \\\\\\end{bmatrix} \\\\\nK\\alpha_{i} &= N\\lambda_{i} \\alpha_{i} \\\\\n\\end{align*}\n$$\n\n결국 또 다른 eigenvalue problem을 만들 수 있게 된다. 하지만, 여기서 $\\alpha_{i}$의 크기는 1이 아니다. 따라서, $\\alpha_{i}$를 정규화해주어야 한다.\n\n$$\n\\begin{align*}\nu_{i}^{\\top}u_{i} &= \\sum_{n \\in [N]} \\alpha_{in}\\phi(x_{n})\\sum_{m \\in [N]} \\alpha_{im}\\phi(x_{m}) \\\\\n&= \\sum_{n \\in [N]}\\alpha_{in} \\sum_{m \\in [N]}\\alpha_{im}\\phi(x_{n})\\phi(x_{m}) \\\\\n&= \\sum_{n \\in [N]}\\alpha_{in} \\sum_{m \\in [N]}\\alpha_{im}\\kappa(x_{n}, x_{m})\\\\\n&= \\sum_{n \\in [N]}\\alpha_{in} \\begin{bmatrix} \\kappa(x_{n}, x_{1}) \\\\ \\kappa(x_{n}, x_{2}) \\\\ \\vdots \\\\ \\kappa(x_{n}, x_{N}) \\end{bmatrix}^{\\top}\\begin{bmatrix}\\alpha_{i1} \\\\ \\alpha_{i2} \\\\ \\vdots \\\\ \\alpha_{iN} \\\\\\end{bmatrix}\\\\\n&= \\begin{bmatrix}\\alpha_{i1} \\\\ \\alpha_{i2} \\\\ \\vdots \\\\ \\alpha_{iN} \\\\\\end{bmatrix}^{\\top} \\begin{bmatrix} \\kappa(x_{1}, x_{1}) & \\kappa(x_{1}, x_{2}) & \\cdots & \\kappa(x_{1}, x_{N}) \\\\\\kappa(x_{2}, x_{1}) & \\kappa(x_{2}, x_{2}) & \\cdots & \\kappa(x_{2}, x_{N}) \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\kappa(x_{N}, x_{1}) & \\kappa(x_{N}, x_{2}) & \\cdots & \\kappa(x_{N}, x_{N}) \\end{bmatrix}  \\begin{bmatrix}\\alpha_{i1} \\\\ \\alpha_{i2} \\\\ \\vdots \\\\ \\alpha_{iN} \\\\\\end{bmatrix}\\\\\n&= \\alpha_{i}^{\\top}K\\alpha_{i} \\\\\n&= \\alpha_{i}^{\\top}N\\lambda_{i} \\alpha_{i}\\quad(\\because K\\alpha_{i} = N\\lambda_{i} \\alpha_{i}) \\\\\n&= N\\lambda_{i}\\alpha_{i}^{\\top}\\alpha_{i} = 1 \\\\\n\n\\therefore ||\\alpha_{i}||^{2} &= \\frac{1}{N\\lambda_{i}}\n\\end{align*}\n$$\n\n따라서, 결론적으로 우리는 nonlinear PCA를 수행하기 위해서 아래의 조건을 만족하는 $\\lambda_{i}$를 큰값부터 시작하여 M번째까지에서의 $\\alpha_{i}$를 구하는 것이다.\n\n$$\n\\begin{align*}\nK\\alpha_{i} &= N\\lambda_{i} \\alpha_{i} \\\\\n||\\alpha_{i}||^{2} &= \\frac{1}{N\\lambda_{i}}\n\\end{align*}\n$$\n\n그리고, 마지막으로 data를 우리가 구한 basis로 projection한 결과는 다음과 같이 구할 수 있다.\n\n$$\n\\begin{align*}\n<u_{i}, \\phi(x)> &= \\sum_{i\\in[N]}\\alpha_{in}\\phi(x)^{\\top}\\phi(x_{n}) \\\\\n&= \\sum_{i\\in[N]}\\alpha_{in}\\kappa(x, x_{n}) \n\\end{align*}\n$$\n\n즉, 이 또한 이전에 계산했던 kernel을 활용해서 그대로 활용할 수 있다.\n\n자 이제 마지막으로 해줘야 할 것은 우리가 맨 처음 가정했던 $\\sum_{i\\in[N]}\\phi(x_{i}) = 0$ 부분이다. 사실 대게의 일반적인 변환에서는 이렇게 이동하는 것이 더 드물 것이다. 따라서, 우리는 강제로 평균을 0으로 맞춰주는 과정을 수행해야 한다. 평균이 0이 되는 차원 변환 함수를 $\\tilde{\\phi}$라고 하고, 이때의 Kernel Matrix를 $\\tilde{K}$라고 하자. 그렇다면, 우리는 아래와 같이 적용하면, 강제로 평균을 0으로 만들 수 있다.\n\n$$\n\\tilde{\\phi}(x_{n}) = \\phi(x_{n}) - \\frac{1}{N}\\sum_{i\\in[N]}\\phi(x_{i})\n$$\n\n또한, $\\tilde{\\kappa}, \\tilde{K}$는 다음과 같이 구할 수 있다.\n\n$$\n\\begin{align*}\n\\tilde{\\kappa}(x_{n}, x_{m}) &= \\tilde{\\phi}(x_{n})^{\\top}\\tilde{\\phi}(x_{m}) \\\\\n&= (\\phi(x_{n}) - \\frac{1}{N}\\sum_{i\\in[N]}\\phi(x_{i}))^{\\top}(\\phi(x_{m}) - \\frac{1}{N}\\sum_{j\\in[N]}\\phi(x_{j})) \\\\\n&= \\phi(x_{n})^{\\top}\\phi(x_{m}) - \\frac{1}{N}\\sum_{i\\in[N]}\\phi(x_{i})^{\\top}\\phi(x_{m}) - \\frac{1}{N}\\sum_{j\\in[N]}\\phi(x_{n})^{\\top}\\phi(x_{j}) + \\frac{1}{N^{2}}\\sum_{i\\in[N]}\\sum_{j\\in[N]}\\phi(x_{i})^{\\top}\\phi(x_{j}) \\\\\n&= \\kappa(x_{n}, x_{m}) - \\frac{1}{N}\\sum_{i\\in[N]}\\kappa(x_{i}, x_{m}) - \\frac{1}{N}\\sum_{j\\in[N]}\\kappa(x_{j}, x_{n}) + \\frac{1}{N^{2}}\\sum_{i\\in[N]}\\sum_{j\\in[N]}\\kappa(x_{i}, x_{j})\n\\\\\n&\\text{위의 식을 일반화하여 행렬로 표현하면 아래와 같다.}\n\\\\\n\\tilde{K} &= K - 1_{N}K - K1_{N} + 1_{N}K1_{N}\\quad(1_{N} = \\frac{1}{N}\\begin{bmatrix}1 & 1 & \\cdots 1 \\\\ 1 & 1 & \\cdots & 1 \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 1 & 1 & \\cdots & 1\\end{bmatrix})\n\\end{align*}\n$$\n\n## Auto Encoder\n\n우리가 PCA에서 마지막에 살펴본 Kernel PCA의 한계는 data마다 kernel 함수를 어떻게 적용해야할지를 알 수 없다는 것이다. 그래서, 이를 위한 여러 Heuristic 방법들이 존재하지만 항상 완벽할 수는 없다. 그렇다면, 이 $\\phi$를 스스로 학습하는 방법을 알아볼 것이다.\n\n먼저, **Encoding**이란 data의 특징(feature)을 활용하여 이를 변형하는 것을 의미한다. 또한, 이 과정에서 중요한 것은 **Encoding**을 통해 얻은 결과를 이용해서 다시 원본 data를 복구할 수  있어야 한다.(복구하는 과정은 **Decoding**이라고 한다.) 이를 통해서, 우리는 압축을 하기도 하고, 관측 data로부터 숨겨진 feature를 추출하기도 한다. 여기서는 Dimensionality Reduction이 Encoding이라고 보는 것이다.\n\n여기서 **Auto Encoder**는 **Encoding**을 통해서 Dimensionality Reduction을 수행하고, 이를 통해 얻은 결과로 원래 data를 **Decoding**할 수 있을 때가지 반복하는 것이다. 이 모든 과정의 결과로 원래 data와 Decoding된 data 간의 차이가 일정 임계값 이하로 떨어졌다면, 우리는 이제 이 Encoder를 $\\phi$의 대용으로 쓸 수 있다. 그리고 이 $\\phi$를 안다면, 이를 근사하는 kernel function도 찾을 수 있다.\n\n![ml-auto-encoder-1](/images/ml-auto-encoder-1.png)\n\n이러한 방식은 굉장히 많은 분야에서 넓게 사용되고 있다. 이들을 간단하게 살펴보도록 하자.\n\n1. <mark>**CNN**</mark>  \n   결국 CNN은 너무 큰 image data를 처리하기 위해서 어쩔 수 없이 Dimensionality Reduction을 수행해야 한다. 따라서, 이를 감소시키기 위해서 Auto Encoder를 사용하여 true dimension을 찾을 수 있다.\n2. <mark>**Semi-Supervised Learning**</mark>  \n   label이 존재하는 data는 굉장히 희귀하며, 이 labeling 비용이 매우 많이 든다. 따라서, label이 존재하는 data와 존재하지 않는 data를 동시에 활용하는 방법이 필요한 경우가 많다. 이때 auto encoding을 활용하게 되면, 일단 labeled, unlabeled data를 모두 활용하여 먼저 true dimension을 구한 뒤에 여기서 labeled data를 활용하여 classifier를 학습할 수 있다. 이것이 unlabed data를 활용하여 더 높은 적중률을 보여줄 수 있다.  \n   ![ml-auto-encoder-2](/images/ml-auto-encoder-2.png)\n\n그리고, 마지막으로 Auto Encoding의 성능을 올리기 위한 방법으로 Masking과 같은 data augmentation을 활용하는 것이다. 기존 data의 일부분을 masking하고도 실제 원본 data를 복구해낼 수 있도록 하는 것이다.\n   \n\n## Reference\n\n- Tumbnail : Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n- Kernel PCA, <https://sebastianraschka.com/Articles/2014_kernel_pca.html>\n","slug":"ml-dimensionality-reduction","date":"2022-12-04 14:19","title":"[ML] 11. Dimensionality Reduction","category":"AI","tags":["ML","PCA","KernelPCA","AutoEncoder"],"desc":"Clustering과 같은 Unsupervised Learning으로 Feature Selection 또는 Feature Extraction 등 여러가지 이름으로 불리는 Dimensionality Reduction 기법에 대해서 다룰 것이다. 특정 data에서 유의미한 정보를 얻기 위해서 우리는 data 전체를 볼 필요가 없다. 따라서, feature들을 최소한으로 줄이면서 유의미한 정보를 얻을 수만 있다면 굉장히 효율적인 inferencing과 learning을 할 수 있다.","thumbnailSrc":"https://euidong.github.io/images/ml-thumbnail.jpg"},{"content":"\n## Intro\n\n주어지는 data에 항상 feature, label이 정확하게 매칭되지는 않는다. 이럴 경우 우리는 각 data에 대한 label과 주어진 data와 label을 잘 설명할 수 있는 probability distribution을 모두 구해야 한다. 여기서 label과 probability distribution을 동시에 구하기 위해서는 어떻게 해야할지에 대한 방법 중에서 대표적인 EM Algorithm에 대해서 살펴보도록 하겠다.\n\n## Problem\n\n여태까지 우리가 살펴봤던 supervised learning에서는 학습(learning) 시에는 feature와 label이 모두 동시에 주어지고, 예측/추론(inference)을 수행할 때에는 feature만 존재하는 data가 주어졌다. 따라서, 학습 시에 feature 정보들을 특정 pattern에 녹여냈을 때, label값을 얻는지를 확인할 수 있었다. 하지만, label이 주어지지 않은 data를 학습시킬 때에는 어떻게 해야할까? 우리는 label이 있어야 해당 data가 가진 실제 결과값을 알고 probability distribution을 얼마나 수정할지를 알 수 있었다. 하지만, 이 값을 모르니 probability distribution을 만들 수 없다. 정확한 probability distribution이 있다면, 반대로 label을 생성하는 것도 가능할 것이다. 하지만, 우리는 아무것도 알 수 없다.\n\n이렇게 답답한 상황에서 우리는 다음과 같은 아이디어를 발상해낼 수 있다. 만약, 대략적인 label을 안다면, 이것을 이용해서 최적의 확률 분포를 찾고, 이 확률 분포에 맞는 label을 다시 생성하고 이를 기반으로 다시 확률 분포를 찾는다면 어떨까? 이렇게 반복하면 꽤나 그럴싸한 분포를 만들 수 있지 않을까? 이 과정을 예를 들자면, 다음과 같다.\n\n각 기 다른 나라(label)의 동전 3종류(500원, 100cent, 100엔)를 구분하고 싶다고 하자. 이때, 알 수 있는 정보는 무게(feature) 밖에 없다고 가정하겠다. 이때 우리는 어떻게 구분할 수 있을까? 우리가 길 거리에서 무작위로 동전을 수집했다고 하자. 각 동전은 흠집도 있을 것이고 공장마다 조금씩 무게가 차이있을 수 있다. 그 결과 다음과 같은 분포가 나왔다고 하자.\n\n![ml-em-algorithm-1](/images/ml-em-algorithm-1.jpg)\n\n그래서 우리는 확률 분포가 아마 Gaussian distribution이라고 생각할 것이다. 따라서, 임의의 Gaussian Distribution을 따르는 세 개의 분포를 아래와 같이 가정해보는 것이다.\n\n![ml-em-algorithm-2](/images/ml-em-algorithm-2.jpg)\n\n그렇다면, 우리는 이 분포에 따라 가장 적절한 label을 생성할 수 있다. 아래와 같이 생성할 수 있다.\n\n![ml-em-algorithm-3](/images/ml-em-algorithm-3.jpg)\n\n그러면 결과적으로 우리는 다음과 같은 label된 data를 갖게 되는 것이다.\n\n![ml-em-algorithm-4](/images/ml-em-algorithm-4.jpg)\n\n이렇게 labeling data를 이용해서 우리는 더 효과적인 확률 분포 변수를 찾아보면 아래와 같이 이전과는 사뭇 다른 분포를 가진다는 것을 알 수 있다.\n\n![ml-em-algorithm-5](/images/ml-em-algorithm-5.jpg)\n\n결과적으로 해당 분포가 이전에 임의로 추정했던 분포보다 더 적절하다는 것을 알 수 있다. 이 과정을 계속해서 반복하면 어떻게 될까?\n\n![ml-em-algorithm-6](/images/ml-em-algorithm-6.jpg)\n\n반복을 통해서 우리는 그럴싸한 확률분포를 습득했다. 대략 머릿속으로는 그럴 수 있을 것 같다는 생각이 들 것이다. 그렇다면, 이것이 어떻게 가능하며 수학적으로 표현이 가능할까? 이를 이제부터 자세히 알아보도록 하겠다.\n\n## Base Knowledge\n\n본론으로 들어가기에 앞 서 우리는 두 가지 정의를 알아야 EM Algorithm을 증명하고 설명할 수 있다.\n\n1. Jensen’s Inequality\n2. Gibb's Inequality\n\n이 두 가지를 모두 안다면 바로 다음으로 넘어가는 것이 좋다. 하지만, 알지 못한다면 이 정의에 대해서 먼저 알아보고 가도록 하자.\n\n### Jensen’s Inequality\n\n일반적으로 우리는 다음 성질을 만족하는 집합을 Convex set이라고 한다.\n\n$$\n\\lambda x + (1-\\lambda)y \\in C,\\quad \\forall x, y \\in C \\text{ and } \\forall\\lambda\\in[0,1]\n$$\n\n즉, 집합에서 random으로 고른 두 수 사이의 수도 집합에 포함되는 집합이라는 것이다. convex set이라고 불리는 이유는 결국 이러한 집합을 2, 3 차원상에 그려보면 볼록하게 튀어나오는 형태라는 것을 알 수 있기 때문이다.\n\n또한, 아래와 같은 조건을 만족하는 함수(f)를 Convex function이라고 한다.\n\n$$\nf(\\lambda x + (1-\\lambda)y) \\leq \\lambda f(x) + (1-\\lambda)f(y),\\quad \\forall x,y \\in C(\\text{Convex set}) \\text{ and } \\forall\\lambda \\in [0,1]\n$$\n\n아래로 볼록한 함수에서는 위와 같은 과정이 너무나 당연하게도 성립한다. 사잇값의 함수값보다 함수값의 사잇값이 더 크기 때문이다.\n\n![ml-convex-function](/images/ml-convex-function.jpg)\n\n반대로 concave(위로 볼록) 함수인 경우에는 반대로 다음과 같이 정의된다.\n\n$$\nf(\\lambda x + (1-\\lambda)y) \\geq \\lambda f(x) + (1-\\lambda)f(y),\\quad \\forall x,y \\in C(\\text{Convex set}) \\text{ and } \\forall\\lambda \\in [0,1]\n$$\n\n여기서 Jensen's Inequality는 다음과 같은 수식이 convex에서 성립한다는 것이다.\n\n$$\nE[f(X)] \\geq f(E[X])\n$$\n\nconvex function에서는 어찌보면 당연해보인다. 그렇지만 이는 EM Algorithm에서 토대로 사용되는 아이디어이기 때문에 반드시 기억하자. 반대로 Concave function인 경우에는 다음과 같다.\n\n$$\nE[f(X)] \\leq f(E[X])\n$$\n\n### Gibb's Inequality\n\nKL divergence 식에 Jensen's Inequality를 적용하여 KL divergence가 항상 0보다 크거나 같고, KL divergence가 0이 되기 위해서는 두 확률분포가 같아야 한다는 것을 증명한 것이다.\n\n이에 대한 증명을 간단하게 하면 다음과 같다.\n\n$$\n\\begin{align*}\nKL(p||q) &= \\sum_{i}{p_{i}\\log\\frac{p_{i}}{q_{i}}} \\\\\n&= -\\sum_{i}p_{i}\\log{\\frac{q_{i}}{p_{i}}} \\\\\n&= E_{p}[-\\log{\\frac{q_{i}}{p_{i}}}] \\geq -\\log{E_{p}[\\frac{q_{i}}{p_{i}}]}\\, (\\because \\text{Jensen's Inequality}) \\\\\n&= -\\log{\\sum_{i}p_{i}\\frac{q_{i}}{p_{i}}} = -\\log{1} = 0\\\\\n\\therefore KL(p||q) &\\geq 0\n\\end{align*}\n$$\n\n## EM Algorithm\n\n우리는 parametric estimation 방법을 사용하기 위해서 다음과 같은 Likelihood를 계산했다.\n\n$$\n\\begin{align*}\n\\mathcal{L}(\\theta) &= \\log p(D| \\theta) \\\\\n\\mathcal{L}(\\theta) &= \\log \\prod_{x\\in D} p(x| \\theta) \\\\\n&= \\sum_{x\\in D} \\log{p(x|\\theta)}\n\\end{align*}\n$$\n\n그렇지만 우리가 이 값을 구하는 것이 어렵다는 것을 위에서 제시했다. 따라서, 이를 다음과 같이 바꿔서 풀어보자는 것이다.\n\n$$\n\\begin{align*}\n\\mathcal{L}(\\theta) &= \\sum_{x\\in D} \\log{p(x|\\theta)} \\\\\n&= \\sum_{x\\in D} \\log{\\int_{z \\in K}p(x, z|\\theta)} dz\n\\end{align*}\n$$\n\n이렇게 바꾸게 된다고 무슨 이득이 있을까? 단순히 식이 더 복잡해보인다. 하지만, 이 식을 다음과 같이 바꿀 수 있다.\n\n$$\n\\begin{align*}\n\\mathcal{L}(\\theta) &= \\sum_{x\\in D} \\log{p(x|\\theta)} \\\\\n&= \\sum_{x\\in D} \\log{\\int_{z \\in K} p(x, z|\\theta)} dz \\\\\n&= \\sum_{x\\in D} \\log{\\int_{z \\in K} p(x, z|\\theta) \\frac{p(z|x, \\theta^{\\prime})}{p(z| x, \\theta^{\\prime})} dz} \\\\\n&= \\sum_{x\\in D} \\log{\\int_{z \\in K} p(z|x, \\theta^{\\prime}) \\frac{p(x, z|\\theta)}{p(z| x, \\theta^{\\prime})} dz} \\\\\n&= \\sum_{x\\in D} \\log{E_{z|x, \\theta^{\\prime}}{[\\frac{p(x, z|\\theta)}{p(z| x, \\theta^{\\prime})}]}} \\geq \\sum_{x\\in D} E_{z|x, \\theta^{\\prime}}{[\\log{\\frac{p(x, z|\\theta)}{p(z| x, \\theta^{\\prime})}}]}\\,(\\because \\text{Jensen's Inequality}) = \\mathcal{F}(p_{z|x, \\theta^{\\prime}}, \\theta)\n\\end{align*}\n$$\n\n이를 통해서 우리는 아래와 같은 과정을 수행해볼 수 있다.\n\n$$\n\\begin{align*}\n\\mathcal{L}(\\theta) - \\mathcal{F}(p_{z|x, \\theta^{\\prime}}, \\theta) &= \\sum_{x\\in D} \\log{p(x|\\theta)} - \\sum_{x\\in D}\\{\\int_{z|x, \\theta^{\\prime}}{p(z|x,\\theta^{\\prime})\\log{\\frac{p(x, z|\\theta)}{p(z| x, \\theta^{\\prime})}}}\\} \\\\\n&= \\sum_{x\\in D} \\log{p(x|\\theta)} - \\sum_{x\\in D}\\{\\int_{z|x, \\theta^{\\prime}}{p(z|x,\\theta^{\\prime})\\log{\\frac{p(z|x, \\theta)p(x|\\theta)}{p(z| x, \\theta^{\\prime})}}}\\} \\\\\n&= \\sum_{x\\in D} \\log{p(x|\\theta)} - \\sum_{x\\in D}\\{\\int_{z|x, \\theta^{\\prime}}{p(z|x,\\theta^{\\prime})\\log{p(x|\\theta)}} + \\int_{z|x, \\theta^{\\prime}}{p(z|x,\\theta^{\\prime})\\log{\\frac{p(z|x, \\theta)}{p(z| x, \\theta^{\\prime})}}}\\} \\\\\n&= \\sum_{x\\in D}\\{\\int_{z|x, \\theta^{\\prime}}{p(z|x,\\theta^{\\prime})\\log{\\frac{p(z|x, \\theta^{\\prime})}{p(z| x, \\theta)}}}\\} \\\\\n&= \\sum_{x\\in D}{KL(p_{z|x, \\theta^{\\prime}}, p_{z|x, \\theta})}\n\\end{align*}\n$$\n\n우리가 원하는 것은 결국 해당 값의 minization이다. 따라서, 우리는 모든 $x$에 대해서 KL-divergence의 최솟값을 구해야 한다(모든 사건은 독립이기 때문이다). KL-divergence는 0과 같거나 큰 수이고, KL-divergence는 $p_{z|x, \\theta^{\\prime}} = p_{z|x, \\theta}$일 때, 0이므로 이를 만족할 수 있는 값을 찾는 것이 중요하다.\n\n따라서, 우리는 다음과 같은 insight를 얻을 수 있다.\n\n1. $\\mathcal{F}(p_{z|x, \\theta^{(t-1)}}, \\theta^{(t)}) \\leq \\mathcal{L}(\\theta^{(t)})$ 아래 식에 의해서 이를 증명할 수 있다.  \n   $\\mathcal{F}(p_{z|x, \\theta}, \\theta^{(t)}) \\leq \\mathcal{L}(\\theta^{(t)}) (\\because \\text{Jensen's Inequality})$\n2. $\\mathcal{L}(\\theta^{(t)}) = \\mathcal{F}(p_{z|x, \\theta^{(t)}}, \\theta^{(t)})$ 바로 위에서 살펴보았 듯이 $p_{z|x, \\theta^{\\prime}} = p_{z|x, \\theta}$일 때, 등식이 성립한다. (Gibb's Inequality)\n3. $\\mathcal{F}(p_{z|x, \\theta^{(t)}}, \\theta^{(t)}) \\leq \\mathcal{F}(p_{z|x, \\theta^{(t)}}, \\theta^{(t+1)})$  \n   여기서 $\\theta^{(t+1)}$은 다음과 같이 구할 수 있다.  \n   $\\theta^{(t+1)} = \\argmax_{\\theta}{\\mathcal{F}(p_{z|x, \\theta^{(t)}}, \\theta)}$\n4. $\\mathcal{F}(p_{z|x, \\theta^{(t)}}, \\theta^{(t+1)}) \\leq \\mathcal{L}(\\theta^{(t+1)})$  \n   이는 1번과 동일한 식이다.\n5. $\\mathcal{L}(\\theta^{(t)}) \\leq \\mathcal{L}(\\theta^{(t+1)})$\n\n결론적으로, 5번에 의해서 우리는 매단계가 이전보다 같거나 크다는 것을 알 수 있다. 또한, 각 단계를 차례대로 설명한다면 다음과 같다.\n\n1. 이전 확률과 현재 parameter의 추정치를 이용해서 구한 $\\mathcal{F}(p_{z|x, \\theta^{(t-1)}}, \\theta^{(t)})$는 $\\theta^{(t)}) \\leq \\mathcal{L}(\\theta^{(t)})$보다 작다는 것을 Jensen's Inequality에 의해서 알 수 있다.\n2. 우리는 이제 $\\mathcal{F}(p_{z|x, \\theta}, \\theta^{(t)})$를 최대화하기 위해서 $p_{z|x, \\theta}$를 $p_{z|x, \\theta^{(t)}}$로 업데이트 한다. 그렇다면, 이 결과는 앞 서 보았듯이 이 값은 $\\mathcal{L}(\\theta^{(t)})$와 동일한 결과를 갖는다.\n3. 여기서 우리가 얻은 $ \\mathcal{F}(p_{z|x, \\theta^{(t)}}, \\theta)$를 최대화할 수 있는 $\\theta^{(t+1)}$를 구한다면, 이는 당연하게도 $\\mathcal{F}(p_{z|x, \\theta^{(t)}}, \\theta^{(t)})$ 보다 크다.\n4. 이렇게 얻은 새로운 parameter에 의한 결과는 역시 당연하게도 1번과 같은 결론에 도달하게 된다.\n5. 결국 우리는 1~4번 까지의 과정을 거치면서 $\\mathcal{L}(\\theta)$를 계속해서 증가시킬 수 있다.\n\n결국 우리가 해야할 것은 다음값을 매차시마다 구하는 것이다.\n\n$$\n\\theta^{(t+1)} = \\argmax_{\\theta}{\\mathcal{F}(p_{z|x, \\theta^{(t)}}, \\theta)}\n$$\n\n이를 위해서 먼저 우리는 $\\mathcal{F}(p_{z|x, \\theta^{(t)}}, \\theta)$의 식을 좀 더 정리해볼 것이다.\n\n$$\n\\begin{align*}\n\\mathcal{F}(p_{z|x, \\theta^{\\prime}}, \\theta) &= \\sum_{x\\in D} E_{z|x, \\theta^{\\prime}}{[\\log{\\frac{p(x, z|\\theta)}{p(z| x, \\theta^{\\prime})}}]} \\\\\n&= \\sum_{x\\in D}\\{\\int_{z|x, \\theta^{\\prime}}{p(z|x,\\theta^{\\prime})\\log{\\frac{p(x, z|\\theta)}{p(z| x, \\theta^{\\prime})}}}\\}\\\\\n&= \\sum_{x\\in D}\\{\\int_{z|x, \\theta^{\\prime}}{p(z|x,\\theta^{\\prime})\\log{p(x, z|\\theta)}} + \\int_{z|x, \\theta^{\\prime}}{p(z|x, \\theta^{\\prime})}{\\log{\\frac{1}{p(z|x, \\theta^{\\prime})}}}\\} \\\\\n&= \\sum_{x\\in D}\\{\\int_{z|x, \\theta^{\\prime}}{p(z|x,\\theta^{\\prime})\\log{p(x, z|\\theta)}} + H(p_{z|x,\\theta^{\\prime}})\\}\n\\end{align*}\n$$\n\n위 식에서 우리는 $\\argmax_{\\theta}{\\mathcal{F}(p_{z|x, \\theta^{(t)}}, \\theta)}$를 구하기 위한 과정에서 $H(p_{z|x,\\theta^{\\prime}})$는 필요없다는 것을 알 수 있다.\n\n$$\n\\begin{align*}\n\\mathcal{Q}(\\theta; \\theta^{\\prime}) &= \\mathcal{F}(p_{z|x, \\theta^{(t)}}, \\theta) - H(p_{z|x,\\theta^{\\prime}}) \\\\\n&= \\sum_{x\\in D}\\{\\int_{z|x, \\theta^{\\prime}}{p(z|x,\\theta^{\\prime})\\log{p(x, z|\\theta)}}\\} \\\\\n&= \\sum_{x\\in D}\\{ E_{z|x, \\theta^{\\prime}}[\\log{p(x, z|\\theta)}] \\}\n\\end{align*}\n$$\n\n그 결과 우리는 다음과 같은 결론을 내릴 수 있다.\n\n$$\n\\begin{align*}\n\\theta^{(t+1)} &= \\argmax_{\\theta} \\mathcal{Q}(\\theta; \\theta^{(t)}) \\\\\n&= \\argmax_{\\theta} \\sum_{x\\in D}\\{ E_{z|x, \\theta^{(t)}}[\\log{p(x, z|\\theta)}] \\}\n\\end{align*}\n$$\n\n따라서, 우리는 이를 효과적으로 구하기 위해서 EM Algorithm을 다음과 같이 정의하고, 단계에 따라 수행한다.\n\n1. Expectation Step  \n   앞에서 제시한 $\\mathcal{Q}(\\theta; \\theta^{(t)})$의 식을 구하는 단계이다. 즉, 변수를 $\\theta$ 외에는 모두 없애는 단계이다. Expectation 단계라고 부르는 이유는 $\\mathcal{Q}(\\theta; \\theta^{(t)})$가 $\\sum_{x\\in D}\\{ E_{z|x, \\theta^{\\prime}}[\\log{p(x, z|\\theta)}] \\}$와 같이 Expectation의 합의 형태로 표현되기 때문이다.  \n   이를 좀 더 쉽게 표현하자면 다음과 같이 말할 수도 있다. 이전 parameter $\\theta^{(t)}$가 주어졌을 때, 각 데이터에 대한 latent variable $z$의 확률을 구하는 것이다. 즉, $p(z|x, \\theta^{(t)})$를 구하는 것이다.\n2. Maximization Step  \n   이제 앞 서 구한 $\\mathcal{Q}(\\theta; \\theta^{(t)})$를 $\\theta$에 대해 최대화하여, $\\theta^{(t+1)}$를 구하는 단계이다.\n\n이것이 EM Algorithm의 본질이다.\n\n그래서 앞 선 Clustering에서 살펴보았던 것처럼 EM Algorithm을 다음과 같이 정의할 수도 있는 것이다.\n\n1. 초기 parameter $\\theta^{(0)}$를 설정한다.  \n2. 이를 기반으로 data가 해당 분포에서 $z$일 확률을 구한다.\n3. 구한 확률을 바탕으로 해당 확률과 data를 잘 표현할 수 있는 새로운 parameter $\\theta^{(t+1)}$를 구한다.\n4. 2, 3번 과정을 parameter가 일정 수준에 수렴할 때까지 반복한다.\n\n## Reference\n\n- Tumbnail : Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n","slug":"ml-em-algorithm","date":"2022-11-24 20:15","title":"[ML] 10. EM Algorithm","category":"AI","tags":["ML","EM-Algorithm","JensensInequality","GibbsInequality"],"desc":"주어지는 data에 항상 feature, label이 정확하게 매칭되지는 않는다. 이럴 경우 우리는 각 data에 대한 label과 주어진 data와 label을 잘 설명할 수 있는 probability distribution을 모두 구해야 한다. 여기서 label과 probability distribution을 동시에 구하기 위해서는 어떻게 해야할지에 대한 방법 중에서 대표적인 EM Algorithm에 대해서 살펴보도록 하겠다.","thumbnailSrc":"https://euidong.github.io/images/ml-thumbnail.jpg"},{"content":"\n## Intro\n\n이전까지의 Posting에서는 Supervised Learning 즉, 이미 Labeling이 완료된 데이터에 의한 Learning을 중점적으로 다루었다. 지금부터는 Unsupervised Learning에 대해서 조금 더 살펴보도록 하겠다. 대표적인 Unsupervised Learning은 Clustering, Feature Selection(or Dimensionality Reduction), Generative Model 등이 존재한다. 이들에 대해서 차근차근 살펴보도록 하고, 해당 Posting에서는 가장 대표적이라고 할 수 있는 Clustering을 먼저 살펴보면서 Unsupervised Learning에 대한 계략적인 이해를 해보도록 하겠다.\n\n## Clustering\n\nClustering은 unlabeled data를 data간 유사성 또는 거리 지표 등을 활용하여 미리 지정한 수 만큼의 partitioning하는 작업을 의미한다. 즉, 우리가 학습을 진행함에 있어 data는 label이 존재하지 않기 때문에 우리는 data간의 관계에서 정보를 추출해서 이를 분류해내는 것이 목표인 것이다.\n\n이를 수행하기 위한 방법은 크게 두 가지로 나눌 수 있다.\n\n1. **Non-Parametric Approach**  \n   이름 그대로 확률적 분포를 가정한 후, Parameter를 찾아가는 방식이 아닌 직관적인 방법(Huristic Approach)을 활용하는 방법이다. 그렇기에 확률적인 해석이 뒷받침되기 보다는 Algorithm을 통해서 이를 설명한다. 대표적인 방법이 K-Means Clustering이다.\n2. **Parametric Approach**  \n   확률적 분포를 가정한 후, Parameter를 찾아가는 방식으로, 대표적인 방법이 Gaussian 분포를 가정하고 찾아나가는 Gaussian Mixture Model(GMM, or MoG, Mixture of Gaussian)이 있다.\n\n따라서, Clustering을 대표하는 K-means Clustering과 GMM을 각 각 살펴보도록 하겠다.\n\n### K-Means Clustering\n\nK-Means Clustering은 K개의 평균값을 통한 Clustering으로 해석하면 의미 파악이 쉽다. 즉, K개의 Partition을 만들기 위해서 K개의 평균값을 찾아 이를 기반으로 더 가까운 평균값에 속하는 Partition에 data를 분배하는 방식이다.\n\n그렇다면, 우리가 구해야할 값은 각 data가 어느 Partition에 속하는지에 대한 정보($\\bold{r}\\leftarrow\\text{one hot vector}$)와 각 Partition의 평균값($\\mu$)이다. 즉, K-means Clustering에서는 기존 data들을 통해서 K개의 평균값(K-means)을 찾아서(**Learning**) 이후에 추가로 들어올 data에 대해서도 똑값은 K-means를 통해서 Partition을 찾을 수 있다(**Inference**).또는 모든 data를 저장해두었다가 K-means를 다시 계산하는 방법도 있다(Online K-means).\n\n그렇다면, $\\boldsymbol{\\mu}(=\\{\\mu_{1}, \\mu_{2}, \\cdots, \\mu_{K}\\})$와 $\\bold{R}$(모든 data의 $\\bold{r}$로 이루어진 Matrix)을 어떻게 구할 수 있을까? 이에 대한 해답은 다음과 같은 Cost Function을 제시하는 것으로 해결할 수 있다.\n\n$$\n\\mathcal{L} = \\min_{\\boldsymbol{\\mu}}\\min_{\\bold{R}} \\sum_{i \\in \\{1,2, \\cdots, N\\}}\\sum_{k \\in \\{1, 2, \\cdots, K\\}}\\bold{R}_{ik}||x_{i} - \\mu_{k}||^{2}\n$$\n\n현재 data의 point로 부터 가장 가까운 평균을 선택하는 경우를 최대화해야 해당 값이 가장 작아질 수 있다는 것을 알 수 있다. <mark>즉, 여기서는 평균과의 거리를 유사성의 지표로 사용한 것이다.</mark> 여기서는 Euclidean distance(L2-norm)를 사용했지만, Manhatan distance(L1-norm)을 활용할 수도 있고 아예 다른 지표를 활용할 수도 있다. 중요한 것은 Cost Function이 아래와 같은 form을 가진다는 것이다.\n\n$$\n\\mathcal{L} = \\min_{\\boldsymbol{\\mu}}\\min_{\\bold{R}} \\sum_{i \\in \\{1,2, \\cdots, N\\}}\\sum_{k \\in \\{1, 2, \\cdots, K\\}}\\bold{R}_{ik}\\times(\\text{Similarity measure})\n$$\n\n그렇다면, 실제로 위에서 제시한 Cost Function을 활용하여 어떻게 $\\boldsymbol{\\mu}$와 $\\bold{R}$을 구할 수 있을까? minimize하고자하는 요소가 두 개이기 때문에 미분을 하기도 다소 난해하다. 따라서, 여기서는 EM Algorithm이라는 방식을 제시한다. 이에 대해서는 다음 Posting에 대해서 자세히 다루겠지만, 간단히 설명하자면 하나의 Variable을 Random하게 지정하고, 다른 Variable의 최적값을 구한 후 이를 다시 대입하고 반대 Variable을 최적값으로 구하기를 반복하면서 더 이상 Variable이 유의미하게 변경되지 않을 때까지 반복해서 구한 값이 최적값과 근사한다는 점을 활용한 Algorithm이다. 지금은 다소 엉뚱할 수 있지만, 지금은 해당 방법을 사용하도록 하겠다. 증명이 궁금하다면, 해당 Posting([🔗 [ML] 10. EM Algorithm](/posts/ml-em-algorithm))을 참고하자.\n\n따라서, 우리가 수행할 과정은 다음과 같다.\n\n1. $\\boldsymbol{\\mu}$를 랜덤하게 초기화한다.\n2. Assignment step: $\\boldsymbol{\\mu}$가 주어졌을 때, $\\bold{R}$을 구한다.  \n   $$\n   R_{ik} = \\begin{cases}\n    1 & \\text{if}\\quad k = \\argmin_{k}||x_{i} - \\mu_{k}||^{2} \\\\\n    0 & \\text{otherwise}\n   \\end{cases}\n   $$\n3. Update step: $\\bold{R}$이 주어졌을 때, $\\boldsymbol{\\mu}$를 구한다.  \n   우리가 분류한 $R$을 활용하여 각 k에 속하는 data의 평균을 통해서 $\\boldsymbol{\\mu}$를 구한다.\n   $$\n   \\mu_{k} = \\frac{\\sum_{i=1}^{N}R_{ik}x_{i}}{\\sum_{i=1}^{N}R_{ik}}\n   $$\n4. 특정값으로 $\\boldsymbol{\\mu}$가 수렴할 때까지 2번, 3번 과정을 반복한다.\n\n아래는 이 과정을 그림을 통해서 표현한 것이다.\n\n![ml-clustering-1](/images/ml-clustering-1.jpg)\n\nK-means 방식은 위와 같은 Iteration 절차를 많이 수행하지 않아도 몇번의 수행만으로 수렴한다는 것을 관측할 수 있다. 또한, Assignment 시에는 $O(KND)$의 시간이 소모되고, Update 시에는 $O(N)$ 만큼의 시간이 소모되기 때문에 무겁지 않고, 굉장히 간단하다는 장점을 갖고 있다. 하지만, 이 방법은 Global Optimal을 찾을 것이라는 확신을 줄 수 없다. 그렇기에 초기값을 어떻게 잡느냐에 따라서 결과가 크게 변할 수도 있다. 뿐만 아니라, outlier data에 대해서도 굉장히 민감하게 반응한다는 단점이 있다. 예를 들어, 아래 사진에서 왼쪽보다 오른쪽이 더 성공적인 Clustering이라고 말할 수 있을 것이다.\n\n![ml-clustering-2](/images/ml-clustering-2.jpg)\n\n이를 해결하기 위한 방법으로 다음과 같은 방법들이 제시되었다.\n\n1. **K-means++**: 초기값을 잘 설정하기 위한 방법으로, 초기값을 잘 설정하면 수렴하는 속도가 빨라지고, Global Optimal에 수렴할 가능성이 높아진다.\n2. **K-mendoids**: K-means에서는 중심점을 data의 평균으로 설정했지만, K-mendoids에서는 중심점을 data의 중간값으로 설정한다. 이렇게 하면 outlier에 민감하지 않게 된다.\n\n> <mark>**Soft K-means**</mark>\n\n마지막으로 K-means Clustering에서 확률적인 접근을 시도한 방법 또한 소개하겠다. 앞 서 본 (Hard)K-means에서는 $\\bold{R}_{ik}$를 0 또는 1로 보았다. 하지만, 이를 확률적으로 표현하는 것에 대해서 생각해 볼 수 있다. 즉, 다음과 같이 soft-max function을 활용한다면 표현이 가능할 것이다.\n\n$$\n\\bold{R}_{ik} = \\frac{\\exp(-\\beta||x_{i}-\\mu_{k}||^{2})}{\\sum_{l \\in {1, 2, \\cdots, K}} \\exp(-\\beta||x_{i}-\\mu_{l}||^{2})}\n$$\n\n이렇게 확률적으로 표현하게 되면, 우리는 추가적인 정보를 활용할 수 있다. 대표적으로 특정 Cluster로 해당 확률이 편향되어 있을 수록 더 좋은 분류일 것이라는 사전 지식(Prior)을 활용할 수 있다. 따라서, 우리는 다음과 같이 Cost Function을 변경할 수 있다.\n\n$$\n\\mathcal{L} = \\min_{\\boldsymbol{\\mu}}\\min_{\\bold{R}} \\sum_{i \\in \\{1,2, \\cdots, N\\}}\\sum_{k \\in \\{1, 2, \\cdots, K\\}}\\bold{R}_{ik}||x_{i} - \\mu_{k}||^{2} - \\frac{1}{\\beta}\\sum_{i \\in \\{1,2, \\cdots, N\\}}\\sum_{k \\in \\{1, 2, \\cdots, K\\}}\\bold{R}_{ik}\\log\\bold{R}_{ik}\n$$\n\n뒷 부분에 새로 추가된 $-\\frac{1}{\\beta}\\sum_{i \\in \\{1,2, \\cdots, N\\}}\\sum_{k \\in \\{1, 2, \\cdots, K\\}}\\bold{R}_{ik}\\log\\bold{R}_{ik}$는 $R_{ik}$가 확률이 되었기 때문에 사실상 Entropy를 의미한다. Entropy는 균형잡힌 분포일 수록 커지고, skew된 경우에는 작아지기 때문에 적절한 지표라고 할 수 있다. $\\beta$는 이러한 prior를 얼마나 사용할지에 대한 hyperparameter이다. $\\beta$가 클 수록 사실상 Hard K-means와 동일한 결과를 얻게 되고, $\\beta$가 작을 수록 Entropy를 더 중요시하는 결과를 얻게 된다.\n\n### Gaussian Mixture Model\n\nGaussian Mixture Model, 일명 GMM은 Finite Mixture Model의 일종이다. Finite Mixture Model은 우리가 추정하고자 하는 확률 분포가 다양한 확률 분포 몇 개의 조합으로 이루어진 분포라고 가정하고, 해당 확률 분포의 Parameter를 학습(Learning) 단계에서 찾아내고, 이를 이용해서 새로운 data에 대해서 추정(Inference)하는 방식이다.\n\n$$\np(x) = \\sum_{k \\in \\{1, 2, \\cdots, K\\}}p(x, z=k) = \\sum_{k \\in \\{1, 2, \\cdots, K\\}}p(x|z=k)p(z=k) = \\sum_{k \\in \\{1, 2, \\cdots, K\\}}p_{k}(x)p(z=k)\n$$\n\n여기서 $z$는 관측할 수 없는 latent(hidden) variable로 data가 몇 번째 확률 분포에 속할 것인지를 의미한다. 따라서, $p(z=k)$ k번째 분포에 속할 확률이라고 볼 수 있다. 대게 이것이 어느정도로 확률 분포를 섞는지를 의미하기 때문에 mixing parameter라고도 부른다.\n\n이에 따라 GMM은 각 $p_{k}(x)$가 Gaussian Distribution이라고 가정하는 Finite Mixture Model인 것이다.\n\n![ml-gmm-graphical-form](/images/ml-gmm-graphical-form.jpg)\n\n그렇다면, 우리는 다음과 같이 Graphical Model 형태로 Finite Mixture Model을 생성할 수 있다. 여기서 $\\pi,\\, \\mu,\\, \\Sigma$는 Parameter를 의미한다.\n\n- $\\pi_{k} = p(z = k)$\n- $\\mu_{k} = E[x|z=k]$ 즉, Gaussian의 기댓값을 의미한다.\n- $\\Sigma_{k} = Cov[x|z=k]$ 즉, Gaussian의 분산을 의미한다.\n\n이를 통해서 우리는 위에서 제시한 확률을 다음과 같이 재정의할 수 있다. (Joint Probability를 Bayesian Network로 푼 식이다. 모르겠다면, [🔗 [ML] 8. Graphical Model](/posts/ml-graphical-model#Graphical-Model)에서 Bayesian Network를 다시 살펴보고 오자.)\n\n$$\n\\begin{align*}\np(x) &= \\sum_{k \\in \\{1, 2, \\cdots, K\\}}p(x, z=k) \\\\\n&= \\sum_{k \\in \\{1, 2, \\cdots, K\\}}p(z=k| \\pi_{k})p(x|z=k, \\mu_{k}, \\Sigma_{k}) \\\\\n&= \\sum_{k \\in \\{1, 2, \\cdots, K\\}}\\pi_{k}\\mathcal{N}(x|\\mu_{k}, \\Sigma_{k})\n\\end{align*}\n$$\n\n여기서 우리가 실제로 추측(Inference)을 할 때에는 $p(z|x)$가 필요하다. 이는 우리가 posterior를 활용해서 구할 수 있다.\n\n$$\n\\begin{align*}\n\\hat{k} &=\\argmax_{k}p(z=k|x) \\\\\n&= \\argmax_{k}\\frac{p(x|z=k)p(z=k)}{p(x)} \\\\\n&= \\argmax_{k}p(x|z=k)p(z=k)\\\\\n&= \\argmax_{k}\\pi_{k}\\mathcal{N}(x|\\mu_{k}, \\Sigma_{k})\n\\end{align*}\n$$\n\n학습(Learning)을 할 때에는 결국 $\\pi,\\, \\mu,\\, \\Sigma$ 이 세 개의 parameter 값을 찾는 것이 중요하다. 이것은 우리가 Parametric Estimation에서 줄기차게 했던 MLE를 이용하면 된다. 이를 위한 Likelihood는 다음과 같다.\n\n$$\n\\begin{align*}\n\\mathcal{L}(\\pi,\\, \\mu,\\, \\Sigma) &= \\log{p(\\mathcal{D} | \\pi,\\, \\mu,\\, \\Sigma)} \\\\\n&= \\log{\\prod_{i=1}^{N}{p(x_{i} | \\pi,\\, \\mu,\\, \\Sigma)}} \\\\\n&= \\sum_{i=1}^{N}{\\log{p(x_{i}| \\pi,\\, \\mu,\\, \\Sigma)}} \\\\\n&= \\sum_{i=1}^{N}{\\log{\\sum_{k=1}^{K}{\\pi_{k}\\mathcal{N}(x_{i}|\\mu_{k}, \\Sigma_{k})}}}\n\\end{align*}\n$$\n\n하지만, 이것을 단순한 Optimization Technique으로는 풀 수 없다. 왜냐하면, 단순한 미분으로 각 parameter를 구할 수 없기 때문이다. 따라서, EM Algorithm을 이용해서 풀어야 한다. (이것은 [🔗 [ML] 10. EM Algorithm](/posts/ml-em-algorithm)에서 다룬다.)\n\n따라서, 아래 그림과 같이 임의의 $\\pi,\\, \\mu,\\, \\Sigma$를 가정한 상태에서 data에 알맞는 최적의 Cluster set을 구하고, data에 cluster가 label된 상태에서 최적의 $\\pi,\\, \\mu,\\, \\Sigma$를 구하는 과정을 반복하는 것이다.\n\n![ml-gmm-1](/images/ml-gmm-1.jpg)\n\n그렇다면, 이를 실제로 어떻게 하는지를 알아보도록 하겠다. 하지만, 그냥 모든 Gaussian 형태를 위한 방법을 사용하면 다소 식이 복잡해지기 때문에 isotropic Gaussian(모든 방향에서 분산이 동일한 Gaussian)을 가정으로 하겠다.\n\n또한, 다음과 같은 요소를 추가로 정의하자.\n\n1. $z_{i} \\in \\{1, 2, \\cdots, K\\}$ : $i$번째 data가 속하는 cluster의 index  \n   $z_{ik} = \\begin{cases} 1 & \\text{if } z_{i} = k \\\\ 0 & \\text{otherwise} \\end{cases}$\n2. $\\theta_{k} = (\\pi_{k},\\, \\mu_{k},\\, \\Sigma_{k})$ : $k$번째 cluster를 위한 parameter의 집합  \n   $\\theta = (\\pi,\\, \\mu,\\, \\Sigma)$ : parameter의 집합  \n\n앞 서 말한 바와 같이 이제 우리는 $\\theta$를 구하는 과정에서 $z_{i}$에 해당하는 정보도 알고 있다. 따라서, Likelihood 식도 변형되어야 한다.\n\n$$\n\\begin{align*}\n\\mathcal{L}(\\theta) &= \\log{p(\\mathcal{D} | \\theta)} \\\\\n&\\geq \\log{p(X, Z | \\theta)} \\\\\n&= \\sum_{i=1}^{N}{\\log{p(x_{i}, z_{i}| \\theta)}} \\\\\n&= \\sum_{i=1}^{N}{\\log{p(z_{i} | \\theta) \\times p(x_{i}| z_{i}, \\theta)}} \\\\\n&= \\sum_{i=1}^{N}{\\log{(\\prod_{k=1}^{K}{\\pi_{k}^{z_{ik}}} \\times \\prod_{k=1}^{K}{\\mathcal{N}(x_{i}|\\mu_{k}, \\Sigma I)^{z_{ik}}})}} \\\\\n&= \\sum_{i=1}^{N}{\\sum_{k=1}^{K}\\log{({\\pi_{k}}{\\mathcal{N}(x_{i}|\\mu_{k}, \\Sigma I)})^{z_{ik}}}} \\\\\n&= \\sum_{i=1}^{N}{\\sum_{k=1}^{K}z_{ik}\\log{({\\pi_{k}}{\\mathcal{N}(x_{i}|\\mu_{k}, \\Sigma I)})}} \\\\\n\\end{align*}\n$$\n\n이에 따라서 우리는 EM Algorithm의 $\\mathcal{Q}$를 다음과 같이 구할 수 있다.\n\n$$\n\\begin{align*}\n\\mathcal{Q}(\\theta; \\theta^{\\prime}) &= \\sum_{i=1}^{N}E_{z_{i}|x_{i}, \\theta^{\\prime}}[\\log p(x_{i}, z_{i} | \\theta)] \\\\\n&= \\sum_{i=1}^{N}E_{z_{i}|x_{i}, \\theta^{\\prime}}[\\sum_{k=1}^{K}z_{ik}\\log{({\\pi_{k}}{\\mathcal{N}(x_{i}|\\mu_{k}, \\Sigma I)})}] (\\because \\text{위의 식에서 3번째 줄을 참고})\\\\\n&= \\sum_{i=1}^{N}\\sum_{k=1}^{K}E_{z_{i}|x_{i}, \\theta^{\\prime}}[z_{ik}\\log{({\\pi_{k}}{\\mathcal{N}(x_{i}|\\mu_{k}, \\Sigma I)})}] \\\\\n&= \\sum_{i=1}^{N}\\sum_{k=1}^{K}E_{z_{i}|x_{i}, \\theta^{\\prime}}[z_{ik}\\log{({\\pi_{k}}{\\mathcal{N}(x_{i}|\\mu_{k}, \\Sigma I)})}] \\\\\n&= \\sum_{i=1}^{N}\\sum_{k=1}^{K}E_{z_{i}|x_{i}, \\theta^{\\prime}}[z_{ik}]\\log{({\\pi_{k}}{\\mathcal{N}(x_{i}|\\mu_{k}, \\Sigma I)})} \\\\\n\\end{align*}\n$$\n\n따라서, 우리는 각 step을 다음과 같이 정의할 수 있다.\n\n- **E-step**  \n  $\\mathcal{Q}$에서 parameter($\\pi,\\, \\mu,\\, \\Sigma$)를 제외하고, 아직 미지수로 남아있는 값은 $E_{z_{i}|x_{i}, \\theta^{\\prime}}[z_{ik}]$이다. 즉, 이 값만 구하면 $\\mathcal{Q}$를 구했다고 할 수 있다.  \n  $$\n  \\begin{align*}\n  E_{z_{i}|x_{i}, \\theta^{\\prime}}[z_{ik}] &= \\sum_{k=1}^{K}{z_{ik}p(z_{i} = k | x_{i}, \\theta^{\\prime})} \\\\\n  &= p(z_{i} = k^{*} | x_{i}, \\theta^{\\prime}) = r_{ik^{*}}\n  \\end{align*}\n  $$  \n  결국 우리가 해당 단계에서 구할 것은 관측 가능한 data와 이전 parameter가 주어졌을 때, 속하게 되는 cluster에서의 확률을 구하는 것이다. 이것을 모든 data에 대해서 구하면, $\\mathcal{Q}$에서 parameter를 제외한 모든 부분을 구할 수 있다. 따라서, 식을 좀 더 정리하면 다음과 같은 결론을 얻을 수 있다.\n  $$\n  \\begin{align*}\n  E_{z_{i}|x_{i}, \\theta^{\\prime}}[z_{ik}] = r_{ik^{*}} &= \\frac{p(x_{i}, z_{i}=k^{*} | \\theta^{\\prime})}{p(x_{i}|\\theta^{\\prime})} \\\\\n  &= \\frac{\\pi_{k^{*}}^{\\prime}{\\mathcal{N}(x_{i}|\\mu_{k^{*}}^{\\prime}, \\Sigma_{k^{*}}^{\\prime} I)}}{\\sum_{l=1}^{K}{\\pi_{l}{\\mathcal{N}(x_{i}|z_{i} = l, \\mu_{l}, \\Sigma_{l} I)}}}\n  \\end{align*}\n  $$  \n  \n- **M-step**  \n  결론적으로 우리는 다음과 같은 $\\mathcal{Q}$와 constraint를 얻었다.  \n  $$\n  \\begin{align*}\n  \\text{maximize}&\\quad \\mathcal{Q}(\\theta; \\theta^{\\prime}) = \\sum_{i=1}^{N}\\sum_{k=1}^{K}r_{ik}\\log{({\\pi_{k}}{\\mathcal{N}(x_{i}|\\mu_{k}, \\Sigma I)})} \\\\\n  \\text{subject to}&\\quad \\sum_{k=1}^{K}{\\pi_{k}} = 1\n  \\end{align*}\n  $$  \n  이제 우리는 이를 Optimization 방식을 활용하여 풀기만 하면 끝이다. ([🔗 참고(Base Knowledge)](/posts/ml-base-knowledge))  \n  $$\n  \\begin{align*}\n  \\mu_{k} &= \\frac{\\sum_{i=1}^{N}{r_{ik}x_{i}}}{\\sum_{i=1}^{N}{r_{ik}}} \\\\\n  \\Sigma_{k} &= \\frac{\\sum_{i=1}^{N}{r_{ik}||x_{i} - \\mu_{k}||^{2}}}{\\sum_{i=1}^{N}{r_{ik}}} \\\\\n  \\pi_{k} &= \\frac{1}{N}\\sum_{i=1}^{N}{r_{ik}}\n  \\end{align*}\n  $$\n\n---\n\n마지막으로 짚고 넘어갈 것은, 바로 K-means Clustering은 사실 GMM의 하나의 special case라는 것이다. 만약, 우리가 $\\pi_{k},\\, \\Sigma_{k}$를 모두 같은 값으로 설정하면, $\\pi_{k} = \\frac{1}{K}$이고 $\\Sigma_{k} = \\Sigma$가 된다고 하자. 이때 EM algorithm을 살펴보면 다음과 같다.\n\n- **E-step**  \n  $$\n  r_{ik} = \\begin{cases} 1 & k = \\argmax_{l\\in \\{1, 2, \\cdots, K\\}} p(x_{i}|z_{i} = l, \\mu_{l}, \\Sigma) \\\\ 0 & \\text{otherwise} \\end{cases}\n  $$  \n  이는 사실상 K-means Clustering에서 중심과의 거리를 통해서 구했던 것과 매우 유사한 식이다.\n- **M-step**  \n  $$\n  \\begin{align*}\n  \\mu_{k} &= \\frac{\\sum_{i=1}^{N}{r_{ik}x_{i}}}{\\sum_{i=1}^{N}{r_{ik}}} \\\\\n  \\pi_{k} &= \\frac{1}{N}\\sum_{i=1}^{N}{r_{ik}}\n  \\end{align*}\n  $$  \n  $\\pi_{k}$가 추가되기는 했지만, $\\mu_{k}$를 구하는 식은 완전 동일하다.\n\n## Reference\n\n- Tumbnail : Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n","slug":"ml-clustering","date":"2022-11-23 09:19","title":"[ML] 9. Clustering","category":"AI","tags":["ML","UnsupervisedLearning","Clustering","K-means","GMM"],"desc":"이전까지의 Posting에서는 Supervised Learning 즉, 이미 Labeling이 완료된 데이터에 의한 Learning을 중점적으로 다루었다. 지금부터는 Unsupervised Learning에 대해서 조금 더 살펴보도록 하겠다. 대표적인 Unsupervised Learning은 Clustering, Feature Selection(or Dimensionality Reduction), Generative Model 등이 존재한다. 이들에 대해서 차근차근 살펴보도록 하고, 해당 Posting에서는 가장 대표적이라고 할 수 있는 Clustering을 먼저 살펴보면서 Unsupervised Learning에 대한 계략적인 이해를 해보도록 하겠다.","thumbnailSrc":"https://euidong.github.io/images/ml-thumbnail.jpg"},{"content":"\n## Intro\n\nMachine Learning은 주어진 data를 가장 잘 설명할 수 있는 pattern(Model)을 찾는 것이 목표라고 하였다. 그렇다면, \"data가 가지는 여러가지 정보(feature)들 중에서 어떤 feature를 중점적으로 보고 이용할 수 있을까?\" 그리고, \"만약 여러 feature들이 서로 연관이 있다면 이를 연산의 최적화를 위해 이용할 수 있지 않을까?\" 라는 접근이 가능하다. 여기서 Graphical Model은 이러한 관계를 시각적으로 표현할 수 있으며, 이를 통해서 연산 최적화에 대한 insight를 얻을 수 있다.\n\n## Relation\n\n각 feature들 즉, Random Variable들 간의 관계는 크게 세 가지 종류가 있다.\n\n1. **Correlation(상관관계)**  \n   쉽게 생각하면 두 Random Variable이 있을 때, 서로가 값 추정에 영향을 준다는 것이다. 즉, 특정 Random Variable의 값이 관측되었을 때, Random Variable이 가지는 값의 범위가 제한되고, 확률이 변화한다.  \n   즉, $X$와$Y$가 서로 Correlation이 존재한다면, $P(X) \\neq P(X|Y)$  \n   그렇기에 두 Random Variable이 서로 독립(independence)이라면, Correlation이 존재하지 않는 것이다.  \n2. **Causality(인과관계)**  \n   쉽게 Correlation과 헷갈릴 수 있지만, Causality는 원인과 결과가 나타나는 관계를 의미한다. 쉬운 예시로 X라는 사건과 Y라는 사건이 빈번하게 같이 발생한다고, 쉽게 X라는 사건이 Y의 원인이라고 말할 수는 없는 것과 같은 원리이다. 또한, 중요한 특징 중에 하나는 방향이 분명하다는 것이다. 원인과 결과는 대게 분리되기 때문에 원인이 되는 사건과 결과가 되는 사건이 분명이 구분된다. 결론적으로, Causality를 가지는 두 사건은 서로 Correlation이 있는 것은 자명하지만, Correlation이 존재한다고 Causality를 단정할 수 있는 것은 아니다. 즉, Correlation이 Causality를 포함하는 개념이다. 그렇기에 서로 독립이라면, Causality도 존재하지 않는 것이다.\n3. **Independence(독립)**  \n   위에 제시된 두 가지는 dependence 관계를 나타낸다. 이는 두 Random Variable의 값이 서로의 값에 영향을 전혀 주지 않음을 의미한다.  \n   즉, $X$와 $Y$가 서로 독립하다면, $P(X) = P(X|Y), P(Y) = P(Y|X)$이다.  \n   (결과적으로 Independence가 아니라면 최소한의 Correlation이 존재한다.)\n\n이러한 관계를 어떻게 활용할 수 있을지를 고민해보자. 우리가 집중적으로 살펴볼 것은 **Independence**이다. 만약, 우리가 구하고자 하는 결과값($Y$)가 존재할 때, 특정 feature($X_{1}$)가 서로 독립한다고 하자. $P(Y|X_{1})=P(Y)$에 의해서 $X_{1}$는 전혀 쓸모가 없는 정보임을 알 수가 있다. 이렇게 명확한 independence를 안다면 해당 feature를 Learning 및 Estimation에서 제거하는 것은 쉬울 것이다. 하지만, 우리는 이러한 관계를 명확하게 밝히기 어려울 때가 많다. 그렇다면 결국 우리가 Machine Learning을 통해서 구하고자 하는 식인 아래 식을 어떻게 하면 좀 더 최적화할 수 있을까?\n\n$$\nP(Y|X_{1}, X_{2}, \\cdots, X_{N}) = \\frac{P(Y, X_{1}, X_{2}, \\cdots, X_{N})}{P(X_{1}, X_{2}, \\cdots, X_{N})}\n$$\n\n여기서의 핵심은 바로 **Joint Probability**에 있다. 우리는 결국 좋든 싫든 **Joint Probability**를 구해야 한다.\n\n$$\n\\begin{align*}\nP(X_{1}, X_{2}, \\cdots, X_{N}) &= P(X_{1} | X_{2}, X_{3}, \\cdots, X_{N}) \\times P(X_{2}, X_{3}, \\cdots, X_{N})\\\\\n&= P(X_{1} | X_{2}, X_{3}, \\cdots, X_{N}) \\times P(X_{2} |, X_{3}, X_{4}, \\cdots, X_{N}) \\times P(X_{3}, X_{4}, \\cdots, X_{N}) \\\\\n&= \\prod_{i=1}^{N} P(X_{i} | X_{i+1}, X_{i+2}, \\cdots, X_{N})\n\\end{align*}\n$$\n\n위에 제시한 **Probability Chain Rule**에 의해서 우리는 Joint Probability는 각각의 Random Variable 의 Conditional Probability라고 할 수 있다. 그렇다면, 우리는 Random Variable이 N개 있고, 각 Random Variable의 dimension이 L이라고 할 때, 다음과 같아짐을 알 수 있다.\n\n$$\nL^{N} \\times L^{N-1} \\times \\cdots \\times L^{1} = O(L^{N})\n$$\n\n이러한 연산을 어떻게 하면 좀 더 최적화할 수 있을까? Hint는 Conditional Probability 각 각의 변수의 양을 줄이는 것이다. 우리가 어떤 관계가 있을 때, 이 Random Variable의 갯수를 줄일 수 있을까? 바로 변수 간 Conditional Independence가 이에 대한 해답을 제시한다.\n\n### Conditional Independence\n\nConditional Independence는 Conditional Probability처럼 특정 정보(다른 Random Variable의 값)가 주어졌을 때, 두 Random Variable이 서로 독립이라는 것이다.\n\n쉽게 예를 들어 설명한다면, \"과음\"과 \"빨간 얼굴\" 사이의 관계라고 할 수 있다. 일반적으로 우리는 \"빨간 얼굴\"인 사람이 \"과음\"을 했을 것이라고 판단할 것이다. 즉, \"빨간 얼굴\"과 \"과음\" 사이에는 관계가 존재한다(dependency). 하지만, \"혈중 알코올 농도\"라는 정보가 주어진다면 어떨까? \"혈중 알코올 농도\"가 주어진다면, 사실 \"빨간 얼굴\"은 더 이상 \"과음\" 여부를 판단하는 기준에 영향을 1도 주지 않을 것이다. 이때에는 \"과음\"과 \"빨간 얼굴\"은 independence하다. 우리는 이런 경우를 다음과 같이 표현할 수 있다.\n\n$$\n\\text{과음} \\not\\!\\perp\\!\\!\\!\\perp \\text{빨간 얼굴}\n$$\n$$\n\\text{과음} \\perp\\!\\!\\!\\!\\perp \\text{빨간 얼굴} |\\ \\text{혈중 알코올 농도}\n$$\n\n즉, 확률에 적용하면 다음과 같다.\n\n$$\nP(\\text{과음} | \\text{빨간 얼굴, 혈중 알코올 농도}) = P(\\text{과음} | \\text{혈중 알코올 농도})\n$$\n\n여기서 우리가 하고 싶었던 것이 나왔다. 바로 \"빨간 얼굴\"이라는 Random Variable이 없어졌다. 즉, \"과음\"과 \"빨간 얼굴\" 사이의 관계 같은 것을 찾을 수 있다면, 우리는 계산 과정을 단순화할 수 있다.\n\n즉, 이것이 우리가 **Graph**를 통해서 찾고자 하는 것이다.\n\n## Graphical Model\n\n**Graphical Model**은 **Graph**를 이용해서 Random Variable들의 관계를 표현하고, 이를 통해서 **Joint Probability**를 계산하는 방법이다. **Graph**를 그리는 방법은 기본적으로 Random Variable 하나 하나가 Graph의 Node가 되고, 각 Node간의 관계가 Edge가 된다. 그런데, 이 관계가 Correlation이냐, Causality냐에 따라서 두 가지 종류로 나뉘게 된다. <mark>**Correlation**은 일반적으로 관계의 방향이 없기에 **Undirected Graph**</mark>로 표현하고, <mark>**Causality**는 관계의 방향이 있기에 **Directed Graph**</mark>로 표현한다. 이는 아래에서 더 자세히 다루도록 하겠다.\n\n### Markov Random Field(Undirected Graphical Model, Correlation)\n\n**Markov Random Field**(MRF)라고 불리며, **Correlation**를 표현한 Graph이다. 각 Node는 Random Variable을 의미하며, Edge는 Correlation를 의미한다. 즉, 두 Node가 Edge로 연결되어 있다면, 두 Random Variable은 Independence하지 않다는 것이다.\n\n![ml-undirected-graph-1](/images/ml-undirected-graph-1.jpg)\n\n여기서 중요한 것은 Random Variable을 대표하는 Node와 Correlation을 대표하는 Edge이기 때문에, Graph $G=(V, E)$에서 Random Variable의 집합 $X = \\{X_{1}, X_{2}, \\cdots, X_{|V|}\\}$이고, $\\{1,2, \\cdots, |V|\\}$가 주어질 때 반드시 아래에 제시된 **Markov Property들**을 만족해야 한다.\n\n1. <mark>**Pairwise Markov Property**</mark>  \n   인접하지 않은 Node 두 개는 다른 모든 Node가 주어질 때 conditionally independent하다.  \n   (아래에서 \\는 포함하지 않는다는 의미이다.)\n   $$\n   X_{i} \\perp\\!\\!\\!\\!\\perp X_{j} | X_{S\\backslash\\{i, j\\}}\n   $$\n2. <mark>**Local Markov Property**</mark>  \n   한 Node에 인접한 모든 Node(Neighbors)가 주어질 때, 해당 Node는 다른 모든 Node와 conditionally independent하다.  \n   (아래에서 $\\mathcal{N}_{i}$는 Node i와 인접한 모든 Node를 의미한다.)\n   $$\n   X_{i} \\perp\\!\\!\\!\\!\\perp X_{S\\backslash \\mathcal{N}_{i}} | X_{\\mathcal{N}_{i}}\n   $$\n3. <mark>**Global Markov Property**</mark>  \n   만약, Node들의 Subset으로 이루어진 $A, B$가 특정 subset $C$가 주어질 때, 서로 conditionally independent하다면, $A, B$에 속하는 어떤 subset이라도 서로 independent하다.  \n   (subset간의 conditionally independent를 확인하기 위해서는 특정 Subset들간에 이어지는 모든 경로를 차단할 수 있는 subset이 있는지를 확인한다.)  \n   $$\n   \\begin{align*}\n   X_{A} &\\perp\\!\\!\\!\\!\\perp X_{B} | X_{C} \\\\\n   X_{\\text{subset of }A} &\\perp\\!\\!\\!\\!\\perp X_{\\text{subset of }B} | X_{C} \\\\\n   \\end{align*}\n   $$  \n   ![ml-global-markov-property](/images/ml-global-markov-property.jpg)\n\n따라서, 우리는 이전 그림에서 Conditional Independence를 활용할 수 있다. $X_{1}, X_{4}$의 경우 다른 모든 Random Variable과 correlation이 존재하지만, $X_{2}, X_{3}$의 경우 $X_{1}, X_{4}$만 알면 된다. 즉, $X_{2} \\perp\\!\\!\\!\\!\\perp X_{3} | X_{1}, X_{4}$이다. 따라서, 우리는 이 관계를 확률 식에서 녹여낼 수 있다.\n\n$$\n\\begin{align*}\nP(X_{1}, X_{2}, X_{3}, X_{4}) &= P(X_{2}|X_{1},\\cancel{X_{3}},X_{4})P(X_{1}, X_{3}, X_{4}) (\\because X_{2} \\perp\\!\\!\\!\\!\\perp X_{3} | X_{1}, X_{4}) \\\\\n&= P(X_{2}|X_{1},X_{4})P(X_{1}, X_{3}, X_{4})\n\\end{align*}\n$$\n\n또한, 우리는 Graph를 통해서 Joint Probability를 다음과 같이 정의할 수 있다.\n\n$$\nP(\\cap_{i=1}^{N}X_{i}) = \\frac{1}{Z} \\prod_{C \\in \\mathcal{C}} \\psi_{C}(\\cap_{X_{j}\\in C}X_{j})\n$$\n\n식이 다소 난해하다. 하나 하나 해석을 해보도록 하자. 먼저, $P(\\cap_{i=1}^{N}X_{i})$이다. 이는 Joint Probability를 표현하는 방법 중의 하나로 단순히 이를 정리하면, $P(\\cap_{i=1}^{N}X_{i})=P(X_{1} \\cap X_{2} \\cap \\cdots \\cap X_{N})=P(X_{1}, X_{2}, \\cdots, X_{N})$이다. 다음은 $C$와 $\\mathcal{C}$이다. 둘 다 아마 집합일 것이라는 것은 $\\in$ 기호 덕분에 알 수 있을 것이다. 그렇다면, 어떤 데이터를 담고 있는 집합일까? 이는 Random Variable들로 이루어진 부분 집합이다. 이를 <mark>**Clique($C$)**</mark>라고 한다. Clique는 Graph에서 Node들의 부분 집합으로, Graph에서 **Fully Connected Node**의 집합을 의미한다. 이것이 가지는 의미는 사실상 하나의 Node로 합칠 수 있다는 것이다.(이를 Graph 상에서의 인수분해(**factorization**)라고도 한다.) Clique에 속하는 Node끼리는 서로 완벽하게 연결되어 있기 때문에 이 중에 하나의 Node라도 다른 Node와 연결을 가진다면, 이에 속하는 모든 Node가 이 관계로 연결된다는 것이다. 추가적으로 Clique들 중에서 다른 Clique에 속하지 않는 Clique들을 <mark>**Maximal Clique($\\mathcal{C}$)**</mark>라고 한다. 아래 그림에서는 Maximal Clique를 빨간색으로 표기한 것이다.\n\n![ml-max-clique](/images/ml-max-clique.jpg)\n\n마지막으로 $\\psi$이다. 이는 <mark>**Clique Potential Function**</mark>로, 각 Clique의 Node(Random Variable)를 parameter로 사용하는 함수로 확률과 비슷한 성질을 가지지만 확률처럼 합이 1이 아닐 수도 있고, 값 자체가 음수일 수도 있다. 즉, 이를 구할 때에는 각 Random Variable의 경우의 수와 해당 경우의 상대적 확률로 이루어진 table을 작성하고, 이를 표현할 수 있는 함수를 찾아낸 것이 $\\psi$이다. 대게의 경우 $\\psi$는 해당 Parameter로 이루어진 Condition Probability 또는 Joint Probability가 되는 경우가 많다. 하지만, 그렇지 않은 경우에도 $\\psi$로 표현이 가능하다.(이에 대한 엄밀한 증명은 여기서 다루지 않을 뿐만 아니라 중요하지 않다.) 여기서 <mark>$Z$</mark>의 의미를 마지막으로 짚어보자면, 단순한 normalization이다. $\\psi$가 운좋게도 Joint Probability, Conditional Probability로 쉽게 구해진다면 $Z=1$이다. 하지만, 그렇지 않을 경우에는 이들의 합이 1이 아니기 때문에 Normalization이 필요한 것이다.\n\n$$\n\\begin{align*}\nZ &= \\sum_{X_{1}}\\sum_{X_{2}} \\cdots \\sum_{X_{N}}{\\prod_{C \\in \\mathcal{C}} \\psi_{C}(\\cap_{X_{j}\\in C}X_{j})} \\\\\n&= \\sum_{X_{1}, X_{2}, \\cdots, X_{N}}{\\prod_{C \\in \\mathcal{C}} \\psi_{C}(\\cap_{X_{j}\\in C}X_{j})}\n\\end{align*}\n$$\n\n결론적으로 의미를 따지자면, 위에서 구한 **Maximal Clique**에 특정 함수를 취한 $\\psi$가 인수분해(**factorization**)에서 하나의 인자(**factor**)가 되는 것이다. 따라서, 이를 **factor function**이라고도 부른다.\n\n자, 마지막으로 우리가 4개의 Random Variable 4개($A, B, C, D$)가 있을 때, Graph로 그릴 수 있는 형태를 네 개 정도 가정하여 예시들을 살펴볼 것이다.\n\n![ml-undirected-graph-2](/images/ml-undirected-graph-2.jpg)\n\n1. $A, B, C, D$가 선형으로 이루어진다.  \n   여기서는 **Maximal Clique**가 3개이다($\\{\\{A, B\\}, \\{ B, C\\}, \\{ C, D\\}\\}$). 따라서, 이를 통해서 Joint Probability를 추정하면 다음과 같다.  \n   $$\n   P(A, B, C, D) = \\frac{1}{Z} \\times \\psi_{1}(A, B) \\times \\psi_{2}(B, C) \\times \\psi_{3}(C, D)\n   $$  \n   여기서 직접적으로 한 번 $P(A, B, C, D)$를 추정해보자.  \n   $$\n   \\begin{align*}\n   P(A, B, C, D) &= P(A| B, C, D) \\times P(B | C, D) \\times P(C, D) \\\\\n   &= P(A|B) \\times P(B|C) \\times P(C, D)\n   \\end{align*}\n   $$  \n   즉, 이렇게 일렬로 된 Graph에서는 마지막 $\\psi$를 제외하고는 모두 Conditional Probability이고, 마지막 $\\psi$는 Joint Probability이다. 그리고, $Z$는 1이라는 것을 알 수 있다.\n2. $A, B, C, D$가 모두 완벽하게 연결되어 있다.  \n   이 경우에는  **Maximal Clique**가 1개이다($\\{\\{A, B, C, D\\}\\}$). 따라서, Joint Probability를 다음과 같이 추정할 수 있다.  \n   $$\n   P(A, B, C, D) = \\frac{1}{Z} \\times \\psi(A, B, C, D)\n   $$  \n   결론적으로 Clique가 하나기 때문에 줄일 수 있는 변수가 없다. 즉, $\\psi$가 Joint Probability이고, $Z$는 1이다.\n3. **Maximal Clique**가 2개이다($\\{\\{A, B, D\\}\\, \\{A, C, D\\}\\}$). 따라서, 다음과 같이 정리된다.  \n   $$\n   \\begin{align*}\n   P(A, B, C, D) &= P(B|A, C, D) \\times P(A, C, D) \\\\\n   &= P(B|A,D) \\times P(A, C, D) \\\\\n   &= \\frac{1}{Z} \\times \\psi_{1}(A, B, D) \\times \\psi_{2}(A, C, D) \\\\\n   \\end{align*}\n   $$\n4. **Maximal Clique**가 4개이다($\\{\\{A, B\\}, \\{ A, C\\}, \\{ B, D\\}, \\{ C, D\\}\\ \\}$).  \n   $$\n   \\begin{align*}\n   P(A, B, C, D) &= P(A|B, C, D) \\times P(B|C, D) \\times P(C, D) \\\\\n   &= P(A|B, C) \\times P(B|D) \\times P(C, D) \\\\\n   &= \\frac{P(A, B, C)}{P(B, C)} \\times P(B|D) \\times P(C, D) \\\\\n   &= \\frac{P(B, C| A)}{P(A)P(B, C)} \\times P(B|D) \\times P(C, D) \\\\\n   &= \\frac{P(B|A)P(C|A)}{P(A)P(B, C)} \\times P(B|D) \\times P(C, D) \\\\\n   &= \\frac{1}{P(B,C)} \\times P(A, B) \\times P(C|A) \\times P(B|D) \\times P(C, D) \\\\\n   &\\neq \\frac{1}{Z} \\times \\psi_{1}(A, B) \\times \\psi_{2}(A, C) \\times \\psi_{3}(B, D) \\times \\psi_{4}(C, D) \\\\\n   \\end{align*}\n   $$  \n   이것이 바로 $\\psi$를 확률 함수라고 부르지 않는 이유이다.  \n   우리가 $\\psi$를 확률 함수 형태로 표현하기 위해서는 **Chordal graph**(4개 이상의 Node로 이루어진 Cycle에서는 중간에 반드시 Cycle을 이루는 Edge가 아닌 Edge가 존재하는 Graph) 형태를 가져야 한다는 것이다. $\\psi$가 확률 함수로 표현되지 않는다고 우리가 하고자 하는 일에 영향을 주지는 않으니 그런가보다 하고 넘어가도 무방하다.\n\n여기서 우리는 **factorization**이라는 개념을 익혔고, 이것이 가능하기 위해서는 Chordal graph가 주어진 상황에서 Markov Property를 만족해야 함을 확인했다. 그리고, 우리는 이러한 **factorization** 형태를 좀 더 명확하게 나타내기 위해서 다음과 같은 형태로 표현하고, 이를 <mark>**factor graph**</mark>라고 정의한다. 따라서, 각 **factor**(인수)는 **Maximal Clique** 단위로 생성된다.\n\n![ml-factor-graph-1](/images/ml-factor-graph-1.jpg)\n\n### Bayesian Network(Directed Graphical Model, Causality)\n\n**Bayesian Network**라고 불리며, **Causality**를 표현한 Graph이다. 각 Node는 Random Variable을 의미하며, Edge는 Causality(원인($C$) -> 결과($R$))를 의미한다. 그렇기에 굉장히 명확하게 표현이 될 수 있다. 왜냐하면, $P(R, C) = P(C|R)P(R)$임을 명백하게 드러낸다. 그렇기에 우리는 해당 Graph가 주어지는 순간 Joint Probability를 다음과 같이 유추할 수 있는 것이다.\n\n![ml-bayesian-network](/images/ml-bayesian-network.jpg)\n\n즉, 이것을 식으로 나타내면 다음과 같다.\n\n$$\nP(\\cap_{i=1}^{N}X_{i}) = \\prod_{i \\in \\{1, 2, \\cdots, N\\}} P(X_{i}| \\cap_{j \\in \\text{Parents}(X_{i})} X_{j})\n$$\n\n이러한 점 때문에 Bayesian Network에서는 Cycle이 존재할 수 없다. 왜냐하면, Cycle이 존재한다는 것은 각 Random Varaible이 서로 원인과 결과가 되는 것이 때문에 사실상 하나의 사건이라는 의미를 내포하는 것이다. 그렇기에 이는 사실상 존재할 수 없다.\n\n여기서도 마찬가지로 Conditional Independence를 찾을 수 있다. 뿐만 아니라 Marginal Independence에 대한 힌트도 얻을 수 있다. 이때 우리는 <mark>**D-Seperation**</mark>이라는 방법을 활용한다. 이를 위해서는 자신과 주변 2개의 Node가 이룰 수 있는 관계 3가지를 정의해야 한다.\n\n![ml-bayesian-network-2](/images/ml-bayesian-network-2.jpg)\n\n1. **head-to-tail**  \n   이 경우에는 $X \\rightarrow Y \\rightarrow Z$의 관계를 의미한다. 따라서, $X$와 $Z$는 $Y$가 주어질 때, 서로 Independent하다.  \n   $$\n   \\begin{align*}\n   P(X, Z | Y) &= \\frac{P(X,Y,Z)}{P(Y)}\\\\\n   &= \\frac{P(X)P(Y|X)P(Z|Y)}{P(Y)}\\\\\n   &= \\frac{P(X, Y)}{P(Y)} \\times P(Z|Y) \\\\\n   &= P(X | Y)P(Z | Y)\n   \\end{align*}\n   $$\n2. **tail-to-tail**  \n   이 경우에는 $X \\leftarrow Y \\rightarrow Z$의 관계를 의미한다. 따라서, $X$와 $Z$는 $Y$가 주어질 때, 서로 Independent하다.  \n   $$\n   \\begin{align*}\n   P(X, Z | Y) &= \\frac{P(X, Y, Z)}{P(Y)} \\\\\n   &= \\frac{P(X|Y)P(Y)P(Z|Y)}{P(Y)} \\\\\n   &= P(X | Y)P(Z | Y)\n   \\end{align*}\n   $$\n3. **head-to-head**  \n   이 경우에는 $X \\rightarrow Y \\leftarrow Z$의 관계를 의미한다. 따라서, $X$와 $Z$는 서로 Independent하다.  \n   즉, Conditional Independence가 아니라 Marginal Independence이다.  \n   $$\n   \\begin{align*}\n   P(X, Z) &= \\sum_{Y} P(X, Y, Z) \\\\\n   &= \\sum_{Y} P(X)P(Y|X,Z)P(Z) \\\\\n   &= P(X)P(Z)\\sum_{Y} P(Y|X,Z) \\\\\n   &= P(X)P(Z)\n   \\end{align*}\n   $$\n\n이 관계에서 중요한 것은 $X,Z$간 edge가 존재해서는 안된다는 점이다. 위의 관계를 활용하면, 인접한 관계에서의 Conditional Independence는 판별이 가능하다.하지만, <mark>**D-Seperation**</mark>을 통해서 이를 더 넓은 범위로 확장할 수 있다. 세 Node의 집합 $A, B, C$가 주어질 때, $A \\perp\\!\\!\\!\\!\\perp B | C$이기 위해서는 다음 조건을 만족해야 한다.\n\n1. A에서 B로 가는 경로가 하나 이상 존재한다.(여기서 경로는 방향을 신경쓰지 않고 연결 여부에 따라 결정한다.)\n2. 모든 경로에 대해서, C에 속하는 Node가 적어도 하나 head-to-tail 또는 tail-to-tail 관계를 중계할 수 있어야 한다.\n3. 모든 경로에 대해서, C에 속하는 Node는 head-to-head 관계를 중계하면 안되며, head-to-head 관계를 중계하는 Node의 자손이여도 안된다.\n\n즉, $A, B, C$가 이러한 조건을 모두 만족할 때, 우리는 $C$가 $A, B$를 Block했다고 하며, $A \\perp\\!\\!\\!\\!\\perp B | C$이다.\n\n예를 들어 아래와 같은 두 경우를 예를 들어볼 수 있다.\n\n![ml-d-seperation](/images/ml-d-seperation.jpg)\n\n왼쪽의 경우 C의 parent가 A에서 B로 가는 경로에서 head-to-head를 중계하고 있다. 따라서, A와 B는 Conditionally Independence를 만족하지 않는다. 반면, 오른쪽의 경우 C가 A에서 B로 가는 경로에서 head-to-tail 관계를 중계하고 있으므로, A와 B는 Conditionally Independence를 만족한다. 여기서 재밌는 점은 A와 B는 두 경우 모두 Marginal Independence를 만족한다는 점이다. 왜냐하면, A에서 B로 가는 경로가 순방향만으로는 이루어지지 않기 때문이다.\n\n마지막으로, Bayesian Network도 **factorization**이 가능하다 A, B의 **Causality**가 $P(A|B)P(B)$를 의미한다는 점을 활용해서 우리는 다음과 같은 형태로 정의하는 것이 가능하다.\n즉, 초기 시작 점은 자신만을 가지는 factor를 가지고, head-to-head 관계는 하나로 통일하며, 나머지 관계(head-to-head, 등)는 별도로 factor를 분리한다. 즉, 다음과 같은 형태를 가진다.\n\n![ml-factor-graph-2](/images/ml-factor-graph-2.jpg)\n\n```plaintext\n 🤔 Markov Blankets\n\n Markov Blanket은 특정 Node에 대한 정보(관계)가 있는 모든 Node를 의미한다. \n 즉, 특정 Random Variable의 확률이 궁금하다면, 이 Markov Blanket만 가지면 된다. \n 그 중에서도 가장 작은 크기로 모든 필요한 정보를 담은 subset을 Markov Boundary라고 한다. \n Markov Boundary는 Markov Random Field에서는 Neighbor이고,\n Bayesian Network에서는 Parent, Child, Co-Parent이다.\n```\n\n![ml-markov-boundary](/images/ml-markov-boundary.jpg)\n\n### Factor Graph\n\n앞 서 본 두 가지 Graph 표현 방법은 각 각 장단점을 가지고 있다.\n\n1. Markov Random Field는 Joint Probability를 Potential이라는 임의의 변수를 통해서 추정하는 것이 가능하다. 따라서, 명확성이 떨이지지만, Conditional Independence를 파악하는 것은 더 분명하고 쉽다.\n2. Bayesian Network는 Joint Probability를 명확하게 판별할 수 있다. 하지만, Conditional Independence를 판별하는 것이 더 어렵고 복잡하다.\n\n이러한 장단점을 모두 살릴 수 있는 방법으로 제시된 것이 Factor Graph이다. 위에서 각 각 Factor Graph를 표현하는 방법에 대해서는 제시하였으므로 여기서는 다루지 않는다. Factor Graph는 근본적으로 Graph의 요소들을 인수분해(Factorization)하여 인수(Factor)로 분리해낸 것이다. 그렇기에 더 명확한 구분이 가능하다. 각 Node는 Factor와 기존 Node에 해당하는 값이 두 개 다 존재하고, Factor는 꽉 찬 네모, 기존 Node(Variable)는 비어있는 동그라미로 표현하는 것이 일반적이다.\n\n그리고, 여기서는 Joint Probability를 다음과 같이 정의한다.\n\nVariable Node는 $\\{X_{1},X_{2}, \\cdots, X_{N}\\}$이고, Factor Node가 $\\{f_{1},f_{2}, \\cdots, f_{M}\\}$일 때, $f_{j}$와 이웃한 Variable Node의 집합을 $\\mathcal{N}_{j}$라고 하자.\n\n$$\nP(X_{1}, X_{2}, \\cdots, X_{N}) = \\prod_{j=1}^{M}{f_{j}(\\cap_{X \\in \\mathcal{N}_{j}} X)}\n$$\n\n이렇게 표현하는 것은 확실히 Markov Random Field에서는 명확하다. 하지만, Bayesian Network에서는 표현할 수 있는 정보를 어느정도 잃었다고 볼 수도 있다. 어차피 Conditional Probability인데, 다르게 표현한 것이기 때문이다. 하지만, 이를 이용하게 되면 기존에 문제였던 Conditional Independence를 쉽게 파악할 수 있다. 왜냐하면 Factor Graph에서는 Conditional Independence를 확인하기 위해서 해당 집합으로 이어지는 모든 경로에서 중간에 하나라도 Variable Node가 껴있는지만 확인해도 충분하다.\n\n![ml-factor-graph-3](/images/ml-factor-graph-3.jpg)\n\n따라서, 앞으로의 과정에서는 Factor Graph를 Main으로 하여 설명을 진행하도록 하겠다.\n\n## Message Passing\n\n우리는 앞의 Graph 표현을 통해서 Feature를 Factor로 압축하는 과정을 익혔다. 이 역시 엄청난 계산 효율을 가져온다. 하지만, 이를 더 효과적으로 활용할 수 있는 방법이 있다. 그것은 Message Passing 방법이다. 우선 우리가 해결하고자하는 문제를 정의해보자. 우리는 Joint Probability($P(X_{1}, X_{2}, \\cdots, X_{N})$)가 주어졌을 때, 다음 값을 구하고 싶을 수 있다.\n\n1. <mark>**Marginalization**</mark>  \n   Marginal Probability는 Joint Probability에서 구하고자 하는 Random Variable을 제외한 모든 경우의 수를 더한 것이다.\n   $$\n   \\begin{align*}\n   P(X_{i}) &= \\sum_{X_{j}}P(X_{i}, X_{j}) \\\\\n   &= \\sum_{X_{j}, X_{k}}P(X_{i}, X_{j}, X_{k}) \\\\\n   &= \\cdots \\\\\n   &= \\sum_{X_{-i}}P(X_{1}, X_{2}, \\cdots, X_{N})\n   \\end{align*}\n   $$  \n   즉, 이를 일반적인 방법으로 풀고자하면 Random Variable($X_{i}$)이 각 각 $\\mathbb{R}^{L}$로 정의된다고 할 때, $L^{N-1}$번의 합연산이 필요하다.\n2. <mark>**Maximization**</mark>  \n   Joint Probability의 최댓값을 갖게 하는 경우의 수($\\hat{X}$)를 구하고자 한다면 다음을 구해야 한다.  \n   $$\n   \\hat{X} = \\argmax_{X_{1}, X_{2}, \\cdots, X_{N}} P(X_{1}, X_{2}, \\cdots, X_{N})\n   $$  \n   이 또한 무식하게 풀고자하면, $L^{N-1}$번의 max 연산이 필요하다.\n\n그렇다면, 이를 한 번 가장 간단한 형태인 일자형 Factor Graph로 표현해보자.\n\n![ml-bp-1](/images/ml-bp-1.jpg)\n\n여기서 $P(X_{2})$를 알고 싶다고 해보자. 그 경우 다음과 같이 식이 정리되는 것을 볼 수 있다.\n\n$$\n\\begin{align*}\nP(X_{2}) &= \\sum_{X_{1}}P(X_{1},X_{2}) \\\\\n&= \\sum_{X_{1}, X_{3}, X_{4}, X_{5}}P(X_{1}, X_{2}, X_{3}, X_{4}, X_{5}) \\\\\n&= \\sum_{X_{1}}\\sum_{X_{3}}\\sum_{X_{4}}\\sum_{X_{5}}P(X_{1}, X_{2}, X_{3}, X_{4}, X_{5}) \\\\\n&= \\sum_{X_{1}}\\sum_{X_{3}}\\sum_{X_{4}}\\sum_{X_{5}}f_{a}(X_{1}, X_{2})f_{b}(X_{2}, X_{3})f_{c}(X_{3}, X_{4})f_{d}(X_{4}, X_{5}) \\\\\n&= (\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))(\\sum_{X_{3}}\\sum_{X_{4}}\\sum_{X_{5}}f_{b}(X_{2}, X_{3})f_{c}(X_{3}, X_{4})f_{d}(X_{4}, X_{5})) \\\\\n&= (\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))(\\sum_{X_{3}}\\sum_{X_{4}}f_{b}(X_{2}, X_{3})f_{c}(X_{3}, X_{4})\\sum_{X_{5}}f_{d}(X_{4}, X_{5})) \\\\\n&= (\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))(\\sum_{X_{3}}f_{b}(X_{2}, X_{3})\\sum_{X_{4}}f_{c}(X_{3}, X_{4})\\sum_{X_{5}}f_{d}(X_{4}, X_{5}))\n\\end{align*}\n$$\n\n이것이 의미하는 바는 무엇일까? 이는 단순하게 순서를 바꾸어 재조합하는 것만으로 Computing을 줄일 수 있음을 보여줬다. 먼저, 앞의 $\\sum$연산만 단독으로 할 때, $L$번의 연산이 필요하고, 뒤에 연속해서 나오는 3번의 $\\sum$을 구하기 위해서는 결국 $L^{3}$의 연산이 필요하다. 즉, $L + L^{3}$의 합연산으로 marginalization 결과를 구할 수 있다는 것이다. 그렇기에 더 효율적인 연산이 가능한 것이다. 이는 특히 Graph의 중앙에 있는 값을 구할 때 더 도드라지게 나타난다. 전체 marginalization 결과를 나타내면 다음과 같다.\n\n$$\n\\begin{align*}\nP(X_{1}) &= \\sum_{X_{2}}f_{a}(X_{1}, X_{2})\\sum_{X_{3}}f_{b}(X_{2}, X_{3})\\sum_{X_{4}}f_{c}(X_{3}, X_{4})\\sum_{X_{5}}f_{d}(X_{4}, X_{5}) \\rightarrow L^{4} \\\\\nP(X_{2}) &= (\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))(\\sum_{X_{3}}f_{b}(X_{2}, X_{3})\\sum_{X_{4}}f_{c}(X_{3}, X_{4})\\sum_{X_{5}}f_{d}(X_{4}, X_{5})) \\rightarrow L^{3} + L \\\\\nP(X_{3}) &= (\\sum_{X_{2}}f_{b}(X_{2}, X_{3})\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))(\\sum_{X_{4}}f_{c}(X_{3}, X_{4})\\sum_{X_{5}}f_{d}(X_{4}, X_{5})) \\rightarrow 2L^{2} \\\\\nP(X_{4}) &= (\\sum_{X_{3}}f_{c}(X_{3}, X_{4})\\sum_{X_{2}}f_{b}(X_{2}, X_{3})\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))(\\sum_{X_{5}}f_{d}(X_{4}, X_{5})) \\rightarrow L^{3} + L \\\\\nP(X_{5}) &= \\sum_{X_{4}}f_{d}(X_{4}, X_{5})\\sum_{X_{3}}f_{c}(X_{3}, X_{4})\\sum_{X_{2}}f_{b}(X_{2}, X_{3})\\sum_{X_{1}}f_{a}(X_{1}, X_{2}) \\rightarrow L^{4}\n\\end{align*}\n$$\n\n이것이 끝이 아니다. 우리는 중복된 연산을 별도로 저장해두어서 더 빠른 연산을 수행하는 것도 가능하다. 예를 들어 다음과 같은 과정이라고 할 수 있다.\n\n$$\n\\begin{align*}\nP(X_{2}) &= \\underbrace{(\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))}_{\\red{\\mu_{a\\rightarrow2}(X_{2})}}(\\sum_{X_{3}}f_{b}(X_{2}, X_{3})\\sum_{X_{4}}f_{c}(X_{3}, X_{4})\\sum_{X_{5}}f_{d}(X_{4}, X_{5})) \\\\\nP(X_{3}) &= \\underbrace{(\\sum_{X_{2}}f_{b}(X_{2}, X_{3})\\red{\\mu_{a\\rightarrow2}(X_{2})})}_{\\red{\\mu_{b\\rightarrow3}(X_{3})}}(\\sum_{X_{4}}f_{c}(X_{3}, X_{4})\\sum_{X_{5}}f_{d}(X_{4}, X_{5})) \\\\\nP(X_{4}) &= \\underbrace{(\\sum_{X_{3}}f_{c}(X_{3}, X_{4})\\red{\\mu_{b\\rightarrow3}(X_{3})})}_{\\red{\\mu_{c\\rightarrow4}(X_{4})}}(\\sum_{X_{5}}f_{d}(X_{4}, X_{5})) \\\\\nP(X_{5}) &= \\underbrace{\\sum_{X_{4}}f_{d}(X_{4}, X_{5})\\red{\\mu_{c\\rightarrow4}(X_{4})}}_{\\red{\\mu_{d\\rightarrow5}(X_{5})}}\n\\end{align*}\n$$\n\n![ml-bp-2](/images/ml-bp-2.jpg)\n\n즉, 이전 Marginalization에서 계산했던 $\\mu_{\\text{factor}\\rightarrow\\text{variable}}(X_{\\text{variable}})$를 저장해서, 다음 Marginalization 연산 시에 사용할 수 있기 때문에 전체 Marginalization을 구하는데에도 더 빠른 연산이 가능하다. 이 방식은 역으로 진행하는 것도 가능한데 다음과 같다.\n\n$$\n\\begin{align*}\nP(X_{4}) &= (\\sum_{X_{3}}f_{c}(X_{3}, X_{4})\\sum_{X_{2}}f_{b}(X_{2}, X_{3})\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))\\underbrace{(\\sum_{X_{5}}f_{d}(X_{4}, X_{5}))}_{\\blue{\\mu_{d\\rightarrow4}(X_{4})}} \\\\\nP(X_{3}) &= (\\sum_{X_{2}}f_{b}(X_{2}, X_{3})\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))\\underbrace{(\\sum_{X_{4}}f_{c}(X_{3}, X_{4})\\blue{\\mu_{d\\rightarrow4}(X_{4})})}_{\\blue{\\mu_{c\\rightarrow3}(X_{3})}} \\\\\nP(X_{2}) &= (\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))\\underbrace{(\\sum_{X_{3}}f_{b}(X_{2}, X_{3})\\blue{\\mu_{c\\rightarrow3}(X_{3})})}_{\\blue{\\mu_{b\\rightarrow2}(X_{2})}} \\\\\nP(X_{1}) &= \\underbrace{\\sum_{X_{2}}f_{a}(X_{1}, X_{2})\\blue{\\mu_{b\\rightarrow2}(X_{2})}}_{\\blue{\\mu_{a\\rightarrow1}(X_{1})}}\n\\end{align*}\n$$\n\n![ml-bp-3](/images/ml-bp-3.jpg)\n\n이를 합쳐서 표현하면 다음과 같은 형태를 가지는 것을 알 수 있다.\n\n$$\n\\begin{align*}\nP(X_{1}) &= \\blue{\\mu_{a\\rightarrow1}(X_{1})} &= \\red{\\mu^{-}(X_{1})}\\blue{\\mu^{+}(X_{1})} \\\\\nP(X_{2}) &= \\red{\\mu_{a\\rightarrow2}(X_{2})}\\blue{\\mu_{b\\rightarrow2}(X_{2})}&= \\red{\\mu^{-}(X_{2})}\\blue{\\mu^{+}(X_{2})} \\\\\nP(X_{3}) &= \\red{\\mu_{b\\rightarrow3}(X_{3})}\\blue{\\mu_{c\\rightarrow3}(X_{3})}&= \\red{\\mu^{-}(X_{3})}\\blue{\\mu^{+}(X_{3})} \\\\\nP(X_{4}) &= \\red{\\mu_{c\\rightarrow4}(X_{4})}\\blue{\\mu_{d\\rightarrow4}(X_{4})}&= \\red{\\mu^{-}(X_{4})}\\blue{\\mu^{+}(X_{4})} \\\\\nP(X_{5}) &= \\red{\\mu_{d\\rightarrow5}(X_{5})}&= \\red{\\mu^{-}(X_{5})}\\blue{\\mu^{+}(X_{5})} \\\\\n&\\therefore P(X_{i}) = \\red{\\mu^{-}(X_{i})}\\blue{\\mu^{+}(X_{i})} \\\\\n\\end{align*}\n$$\n\n![ml-bp-4](/images/ml-bp-4.jpg)\n\n$\\mu^{+}$와 $\\mu^{-}$의 방향이 헷갈릴 수 있는데, 이는 자신($X_{i}$)을 기준으로 큰 쪽에서 왔는지 작은 쪽에서 왔는지를 표시한다고 생각하면 쉽다. 따라서, $\\mu$는 다음과 같이 정의되어질 수 있다.\n\n$$\n\\begin{align*}\n\\mu^{-}(X_{1}) &= 1,\\, \\mu^{+}(X_{N}) = 1 \\text{이고,}\\\\\n\\mu^{-}(X_{i}) &= \\sum_{X_{i-1}}f_{i}(i-1, i)\\mu^{-}(X_{i-1}) \\\\\n\\mu^{+}(X_{i}) &= \\sum_{X_{i+1}}f_{i}(i, i+1)\\mu^{+}(X_{i+1}) \\\\\n\\end{align*}\n$$\n\n여기서 $\\mu$가 바로 <mark>**Message**</mark>를 의미한다. 즉, 우리가 마치 운동장에서 사람 수를 세기 위해서 앞 사람이 말한 수 + 1을 반복하면서 진행하는 것처럼 Message를 전달하며 전체 확률을 구해나가는 것이다. 이러한 방법을 **Message Passing**이라고 하며, 이 방법을 통해서 우리는 Marginal Probability를 더 효과적으로 구할 수 있다. 왜냐하면, $\\mu^{-}(X_{i})$를 구하기 위한 연산량이 $(i-1) \\times L$이라는 것과, $mu^{+}(X_{i})$를 구하기 위한 연산량이 $(N-i) \\times L$이라는 것을 알고 있다. 따라서, 각 각의 Marginalization을 구하기 위한 연산량이 $L^{N-1}$에서 $(N-1)L$로 줄어들었다.\n\n여기까지 우리는 Line으로 되어있는 가장 간단한 Factor Graph에서의 <mark>**Sum-Product Belief Propagation**</mark>을 알아본 것이다. 이제부터 우리는 더 복잡한 상황에서의 Belief Propagation(BP)을 살펴볼 것이다. Belief Propagation과 Message Passing은 대게 비슷한 의미로 사용되어 진다(일부는 Message Passing 후에 데이터를 가공하는 작업을 분리하고 이를 통합하여 Belief Propagation이라고 하기도 한다.)\n\n### Sum-Product Belief Propagation\n\n합의 곱을 통해서 Marginal Probability를 구하는 방법으로, 앞 서 보았던 Linear Factor Graph 뿐만 아니라 Tree형태의 Factor Graph에서도 사용할 수 있다. 물론 Cycle이 존재하는 Factor Graph가 존재할 수도 있지만, 이 경우에 대해서는 특별한 알고리즘을 별도로 적용하는 것이 일반적이다. 따라서, 여기서는 Tree형태의 Factor Graph에서 일반적으로 적용할 수 있는 방법을 제시한다.\n\n우선 아래 그림을 통해서 대략적인 이해를 해보도록 하자.\n\n![ml-sum-product-bp-1](/images/ml-sum-product-bp-1.jpg)\n\n우리는 위에서 Line Factor Graph에서 어떻게 Marginal Probability를 어떻게 구하는지를 보았다. Tree 구조에서도 동일하게 결국 Marginal Probability를 자신과 이웃한 Factor Node들로 부터 전달된 Message의 곱이라고 할 수 있다. 단지 다른 점은 이웃한 factor가 복수 개라는 것이다.  \n(factor 또는 variable에 해당하는 Node 중에서 index가 i인 Node와 인접한 Node(Node i가 factor라면 variable, variable이라면 factor이다.)들의 index 집합을 $\\mathcal{N}_{i}$ 라고하고, 값은 종류의 Node의 index를 모아둔 집합 I가 있을 때 $X_{I} = \\{X_{i}\\}_{i \\in I}$라고 하자.)\n\n$$\nP(X_{i}) = \\prod_{p \\in \\mathcal{N}_{i}}\\mu_{p \\rightarrow i}(X_{i})\n$$\n\n그렇다면, 여기서 $\\mu_{p \\rightarrow i}(X_{i})$를 각 각 어떻게 구할 수 있을까? 그러기 위해서 빨간색 부분을 자세히 봐보자.\n\n![ml-sum-product-bp-2](/images/ml-sum-product-bp-2.jpg)\n\n여기서도 기존 Linear Factor Graph와 다른 점은 Factor Node역시 여러 개의 Variable Node와 연결된다는 점이다. 이 부분만 떼어서 자세히 보면 다음과 같다.\n\n![ml-sum-product-bp-3](/images/ml-sum-product-bp-3.jpg)\n\n그렇기에 이전 Variable Node로 부터 오는 Message들과 factor 값을 함께 곱하는 과정이 필요하다. 여기서, Varaible Node에서 factor Node로 오는 Message를 $\\nu$라고 정의한다면, 다음과 같이 표현할 수 있다. 여기서 주의할 점은 Factor Node와 이웃한 Variable Node 중에서 Message를 전달할 Variable Node는 연산에서 제외해야 한다는 점이다.\n\n$$\n\\mu_{u \\rightarrow i}(X_{i}) = \\sum_{X_{\\mathcal{N}_{u}\\backslash\\{i\\}}}f_{u}(X_{\\mathcal{N}})\\prod_{j \\in \\mathcal{N}\\backslash\\{i\\}}{\\nu_{j \\rightarrow u}(x_{j})}\n$$\n\n그리고 마지막으로 $\\nu$를 구하는 과정은 다음과 같다.\n\n![ml-sum-product-bp-4](/images/ml-sum-product-bp-4.jpg)\n\n$$\n\\nu_{j \\rightarrow u}(X_{j}) = \\prod_{v \\in \\mathcal{N}_{j}\\backslash\\{u\\}}\\mu_{v \\rightarrow j}(X_{j})\n$$\n\n따라서, Marginal Probability($P(X_{i})$)를 구하고자 할 때 우리는 Leaf Node에서 부터 시작해서 차례차례 값을 구하면서, $\\mu_{\\mathcal{N}_{i} \\rightarrow i}$를 모두 구할 때까지 연산을 수행해야 한다.\n\n```plaintext\n 🤔 Loopy Sum-Product BP\n\n 우리는 Sum-Product BP를 Tree에서만 쓸 수 있다고 제한하였지만, \n 사실 Cycle이 존재하는 Factor Graph에서도 동일한 BP를 사용할 수 있다.\n 하지만, 이 경우에는 비례 관계를 통해서 나타낼 수 밖에 없기 때문에\n 결과값에 대해서 100% 확신할 수는 없다.\n```\n\n### Max Product Belief Propagation\n\nBelief Propagation은 앞 서 살펴보았던 Marginal Probability를 구할 때에도 사용할 수 있지만, Maximization 문제를 풀 때에도 사용할 수 있다. 마찬가지로 가장 간단한 예시인 Linear Factor Graph를 가정해보자.\n\n![ml-bp-1](/images/ml-bp-1.jpg)\n\n$$\nP(X_{1}, X_{2}, X_{3}, X_{4}, X_{5}) = f_{a}(X_{1}, X_{2})f_{b}(X_{2}, X_{3})f_{c}(X_{3}, X_{4})f_{d}(X_{4}, X_{5})\n$$\n\n이 경우에 $P(X_{1}, X_{2}, X_{3}, X_{4}, X_{5})$를 최대로 만드는 $\\hat{x_{1}}, \\hat{x_{2}}, \\hat{x_{3}}, \\hat{x_{4}}, \\hat{x_{5}}$를 찾아보자.  \n\n$$\n\\begin{align*}\n&\\max_{X_{1}, X_{2}, X_{3}, X_{4}, X_{5}} f_{a}(X_{1}, X_{2})f_{b}(X_{2}, X_{3})f_{c}(X_{3}, X_{4})f_{d}(X_{4}, X_{5})\\\\\n&= \\max_{X_{1}}\\{f_{a}(X_{1}, X_{2})\\max_{X_{2}}\\{\\max_{X_{3}}\\{f_{b}(X_{2}, X_{3}) \\max_{X_{4}}\\{f_{c}(X_{3}, X_{4})\\max_{X_{5}}\\{f_{d}(X_{4}, X_{5})\\}\\}\\}\\}\\}\\\\\n&= \\max_{X_{2}}\\{\\max_{X_{1}}\\{f_{a}(X_{1}, X_{2})\\} \\max_{X_{3}}\\{f_{b}(X_{2}, X_{3}) \\max_{X_{4}}\\{f_{c}(X_{3}, X_{4})\\max_{X_{5}}\\{f_{d}(X_{4}, X_{5})\\}\\}\\}\\}\\\\\n&= \\max_{X_{3}}\\{\\max_{X_{2}}\\{f_{b}(X_{2}, X_{3})\\max_{X_{1}}\\{f_{a}(X_{1}, X_{2})\\}\\} \\max_{X_{4}}\\{f_{c}(X_{3}, X_{4})\\max_{X_{5}}\\{f_{d}(X_{4}, X_{5})\\}\\}\\}\\\\\n&= \\max_{X_{4}}\\{\\max_{X_{3}}\\{f_{c}(X_{3}, X_{4})\\max_{X_{2}}\\{f_{b}(X_{2}, X_{3})\\max_{X_{1}}\\{f_{a}(X_{1}, X_{2})\\}\\}\\}\\max_{X_{5}}\\{f_{d}(X_{4}, X_{5})\\}\\}\\\\\n&= \\max_{X_{5}}\\{f_{d}(X_{4}, X_{5})\\max_{X_{4}}\\{\\max_{X_{3}}\\{f_{c}(X_{3}, X_{4})\\max_{X_{2}}\\{f_{b}(X_{2}, X_{3})\\max_{X_{1}}\\{f_{a}(X_{1}, X_{2})\\}\\}\\}\\}\\}\\\\\n\\end{align*}\n$$\n\nMarginalization과 굉장히 유사하다고 하다. 이를 이전에 사용한 Tree 구조에 반영해도 동일하다.\n\n![ml-sum-product-bp-1](/images/ml-sum-product-bp-1.jpg)\n\n단, 여기서 Message와 최종 결과를 다음과 같이 재정의하면 끝난다.\n\n$$\n\\begin{align*}\n\\max P(X_{1}, X_{2}, \\cdots, X_{N}) &= \\max_{X_{i}}\\{\\prod_{p\\in\\mathcal{N}_{i}}\\mu_{p \\rightarrow i}(X_{i})\\} \\\\\n\\mu_{u \\rightarrow i}(X_{i}) &= \\max_{\\mathcal{N}_{u}\\backslash\\{i\\}}\\{f_{u}(\\mathcal{N}_{i})\\prod_{j \\in \\mathcal{N}_{u}\\backslash\\{i\\}}\\nu_{j \\rightarrow u}(X_{j})\\} \\\\\n\\nu_{j \\rightarrow u}(X_{j}) &= \\prod_{v\\in\\mathcal{N}_{j}\\backslash\\{u\\}}\\mu_{v \\rightarrow j}(X_{j})\n\\end{align*}\n$$\n\n추가적으로 Max Sum Belief Propagation을 소개하겠다. 이는 Maximization 문제를 풀 때, $\\log$를 취한 결과도 동일하다는 점을 활용하여 문제를 푸는 것이다. 따라서, 다음과 같이 식이 조금 변화한다. 이 방식을 쓰면, 너무 작은 probability로 인한 문제를 피할 수 있다.\n\n$$\n\\begin{align*}\n\\max \\red{\\log} P(X_{1}, X_{2}, \\cdots, X_{N}) &= \\max_{X_{i}}\\{\\red{\\sum_{p\\in\\mathcal{N}_{i}}}\\mu_{p \\rightarrow i}(X_{i})\\} \\\\\n\\mu_{u \\rightarrow i}(X_{i}) &= \\max_{\\mathcal{N}_{u}\\backslash\\{i\\}}\\{\\red{\\log} f_{u}(\\mathcal{N}_{i}) + \\red{\\sum_{j \\in \\mathcal{N}_{u}\\backslash\\{i\\}}}\\nu_{j \\rightarrow u}(X_{j})\\} \\\\\n\\nu_{j \\rightarrow u}(X_{j}) &= \\red{\\sum_{v\\in\\mathcal{N}_{j}\\backslash\\{u\\}}}\\mu_{v \\rightarrow j}(X_{j})\n\\end{align*}\n$$\n\n## Construction from Data\n\n앞에서는 Graph를 통해서 연산 과정을 Optimization하는 방법을 알아보았다면, 여기서는 실제 관측 data를 이용해서 어떻게 Graph를 구조화할 수 있는지에 대해서 알아볼 것이다. 이를 수행하기 위해 많은 Algorithm이 존재하지만 가장 기본이 될 수 있는 Algorithm인 **Chow-Liu Algorithm**만 살펴보도록 하겠다.\n\n### Chow-Liu Algorithm\n\n제일 먼저 구해야할 것은 **Joint Probability**이다. 이는 Empirical distribution을 이용하여 구할 수 있다. 아래는 feature가 N개인 총 K개의 data가 있을 때, 다음과 같이 **Joint Probability**를 구한 것이다.\n\n$$\np(X_{1}=x_{1}, X_{2}=x_{2}, \\cdots, X_{N}=x_{n}) = \\frac{1}{K} \\sum_{k=1}^{K} \\mathbb{1}[x^{(k)}=(x_{1}, x_{2}, \\cdots, x_{n})]\n$$\n\n위와 같이 **Joint Probability**가 주어졌을 때, **Chow-Liu Algorithm**에서는 **Second Order Conditional Probability**(총 두개의 Random Variable로 구성된 Conditional Probability. 즉, Condtion도 하나이고, 확률을 구하고자 하는 변수도 하나이다.)와 **Marginal Probability**로 Graph를 가정하고 **Bayesian Network**를 구성한다. 이 경우에는 형태가 Tree 형태로 만들어지기 때문에 결론적으로 head-to-head 관계가 만들어지지 않는다.(각 각의 node는 하나의 parent만 갖기 때문이다.)\n\n![ml-chow-liu-1](/images/ml-chow-liu-1.jpg)\n\n따라서, 위와 같은 Graph로 추정했다면, 확률은 다음과 같아진다.\n\n$$\np(x_{1}, x_{2}, \\cdots, x_{n}) = p(x_{6}|x_{5})p(x_{5}|x_{2})p(x_{4}|x_{2})p(x_{3}|x_{2})p(x_{2}|x_{1})p(x_{1})\n$$\n\n여기서 이제 우리는 다음과 같은 문제만 풀면 끝이다. Empirical distribution으로 구한 Joint Probability($p$)와 우리가 추정한 Graph에서의 Joint Probability($p_{\\intercal}$)사이의 차이가 최소가 되도록 하면 된다. 이를 위해서 사용하는 것이 **KL Divergence**이다. 따라서, 우리가 구하고 싶은 **Bayesian Network**는 다음과 같이 구할 수 있다.\n\n$$\n\\argmin_{\\intercal\\text{:tree}} KL(p||p_{\\intercal})) = \\argmin_{\\intercal\\text{:tree}} \\sum_{x^{(k)} \\in \\mathcal{D}}p(x^{(k)})\\log \\frac{p(x^{(k)})}{p_{\\intercal}(x^{(k)})}\n$$\n\n그렇다면, 좀 더 면밀하게 $p_{\\intercal}$을 정의해보자.\n\n$$\n\\begin{align*}\np_{\\intercal}(x_{1}, x_{2}, \\cdots, x_{N}) &= \\prod_{i=1}^{N}p(x_{i}|x_{\\text{parent}(i)})\\, (\\because \\text{Bayesian Network Definition})\\\\\n&= p(x_{root})\\prod_{(i,j) \\in E}p(x_{j}|x_{i})\n\\end{align*}\n$$\n\n여기서 V는 node의 집합을 의미하고, E는 edge를 저장하며 각 tuple(i,j)는 (parent, child)를 의미한다. 그리고, Tree에서는 단 하나의 Node만 Root이고 parent가 없기 때문에 해당 Root만 marginal Probability를 가지는 것을 알 수 있다.\n\n$$\n\\begin{align*}\np_{\\intercal}(x_{1}, x_{2}, \\cdots, x_{N}) &= p(x_{root})\\prod_{(i,j) \\in E}p(x_{j}|x_{i})\\\\\n&= p(x_{root})\\prod_{(i,j) \\in E} \\frac{p(x_{j},x_{i})}{p(x_{i})}\\\\\n&= \\red{p(x_{root})}\\prod_{(i,j) \\in E} \\frac{p(x_{j},x_{i})\\red{p(x_{j})}}{p(x_{i})p(x_{j})}\\\\\n&= \\prod_{i\\in V}p(x_{i}) \\prod_{(i,j) \\in E} \\frac{p(x_{j},x_{i})}{p(x_{i})p(x_{j})}\\\\\n\\end{align*}\n$$\n\n마지막이 좀 애매할 수 있는 tree이기 때문에 가능한 것이다. 특정 node로 가는 path는 단 하나이기 때문에 $j$로 끝나는 edge도 하나일 수 밖에 없다. 따라서, $p(x_{root})\\prod_{(i,j) \\in E} p(x_{j}) = \\prod_{i=V}p(x_{i})$일 수 있는 것이다.\n\n이것이 정의되면, 우리는 이제 최적의 Tree인 $\\intercal_{*}$를 찾을 수 있다.\n\n$$\n\\begin{align*}\n\\intercal_{*} &= \\argmin_{\\intercal\\text{:tree}} KL(p||p_{\\intercal})\\\\\n&= \\argmin_{\\intercal\\text{:tree}} \\sum_{x^{(k)} \\in \\mathcal{D}}p(x^{(k)})\\log \\frac{p(x^{(k)})}{p_{\\intercal}(x^{(k)})}\\\\\n&= \\argmin_{\\intercal\\text{:tree}} \\sum_{x^{(k)} \\in \\mathcal{D}}\\cancel{p(x^{(k)})\\log{p(x^{(k)})}} -p(x^{(k)})\\log{p_{\\intercal}(x^{(k)})}\\\\\n&= \\argmax_{\\intercal\\text{:tree}} \\sum_{x^{(k)} \\in \\mathcal{D}}p(x^{(k)})\\log{p_{\\intercal}(x^{(k)})}\\\\\n&= \\argmax_{\\intercal\\text{:tree}} \\sum_{x^{(k)} \\in \\mathcal{D}}p(x^{(k)})\\log({\\prod_{i\\in V}p(x_{i}^{(k)}) \\prod_{(i,j) \\in E} \\frac{p(x_{j}^{(k)},x_{i}^{(k)})}{p(x_{i}^{(k)})p(x_{j}^{(k)})}})\\\\\n&= \\argmax_{\\intercal\\text{:tree}} \\sum_{x^{(k)} \\in \\mathcal{D}}\\sum_{i\\in V}p(x^{(k)})\\log(p(x_{i}^{(k)})) + \\sum_{x^{(k)} \\in \\mathcal{D}}\\sum_{(i,j) \\in E} p(x^{(k)})\\log({\\frac{p(x_{j}^{(k)},x_{i}^{(k)})}{p(x_{i}^{(k)})p(x_{j}^{(k)})}})\\\\\n&= \\argmax_{\\intercal\\text{:tree}} \\sum_{i\\in V}\\sum_{x^{(k)} \\in \\mathcal{D}}p(x^{(k)})\\log(p(x_{i}^{(k)})) + \\sum_{(i,j) \\in E}\\sum_{x^{(k)}_{i}, x^{(k)}_{j}} p(x^{(k)}_{i}, x^{(k)}_{j})\\log({\\frac{p(x_{j}^{(k)},x_{i}^{(k)})}{p(x_{i}^{(k)})p(x_{j}^{(k)})}})\\, (\\because \\text{marginalization})\\\\\n&= \\argmax_{\\intercal\\text{:tree}} \\cancel{\\sum_{i\\in V}-H(X_{i})} + \\sum_{(i,j) \\in E}I(X_{i}, X_{j})\\, (\\because H(X_{i})\\text{는 constant이다.})\\\\\n&= \\argmax_{\\intercal\\text{:tree}}\\sum_{(i,j) \\in E}I(X_{i}, X_{j})\\\\\n\\end{align*}\n$$\n\n마지막 marginalization은 헷갈린다면, 해당 Posting의 Sum-Product BP 부분을 다시 보고오도록 하자.\n\n자, 이제 우리가 얻은 결론은 다음과 같다. 결국, 최적의 Tree는 $I(X_{i}, X_{j})$가 최대가 되는 Tree이다. I(Mutual Information)이 헷갈린다면, [Information Theory](/posts/ml-base-knowledge#Information-Theory) 정리해놓은 Posting을 다시 보고 오자. 결국, $X_{i}, X_{j}$간의 모든 Mutual Information을 구해서 weighted graph를 구축한다음에 Kruskal Algorithm을 통해서 최적 Tree를 찾으면 되는 것이다.\n\n따라서, 과정은 다음과 같다.\n\n1. 가능한 모든 (i,j) 쌍에 대하여 $I(X_{i}, X_{j})$를 구하여, Weighted Graph를 구성한다.\n2. Kruskal Algorithm을 수행한다.\n   1. weight의 내림차순으로 Edge를 정렬한다.\n   2. 하나씩 Edge를 뽑으면서, Cycle이 생기는지 확인하여 생기면 버리고, Cycle이 생기지 않으면 Tree에 추가한다.(Cycle 여부는 동일한 Node가 두 개 다 존재하는지 확인)\n   3. 모든 Node를 뽑았다면 종료하고, 그렇지 않다면 2번을 반복 시행한다.\n\n이렇게 Graph를 만들게 되면, 우리는 Joint Probability를 이전에 배운 Optimization 방법을 통해서 쉽게 구할 수 있다. 그리고, 이를 Model에 직접 적용할 수 있다. 예를 들면, 우리가 Classification을 수행할 때이다.\n\n$$\n\\argmax_{\\mathcal{l} \\in \\{0,1,2,\\cdots, 9\\}} p_{\\mathcal{l}} \\times p(x^{\\text{new}}|\\mathcal{l}^{\\text{new}}=\\mathcal{l}) \\propto \\argmax_{\\mathcal{l} \\in \\{0,1,2,\\cdots, 9\\}} p_{\\mathcal{l}} \\times p_{\\intercal}(x^{\\text{new}})\n$$\n\n위와 같이 추정하여 계산을 획기적으로 줄일 수 있다.\n\n## Reference\n\n- Tumbnail : Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n- Medium[Chullin], Graphical Model이란 무엇인가요?, <https://medium.com/@chullino/graphical-model%EC%9D%B4%EB%9E%80-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80%EC%9A%94-2d34980e6d1f>\n- Wiki, Markov Random Field, <https://en.wikipedia.org/wiki/Markov_random_field>\n- Adaptive Computation and Machine Learning, Thomas G. Dietterich\n- <https://cedar.buffalo.edu/~srihari/CSE574/Chap8/Ch8-PGM-Inference/Ch8.3.2-FactorGraphs.pdf>\n","slug":"ml-graphical-model","date":"2022-11-14 13:08","title":"[ML] 8. Graphical Model","category":"AI","tags":["ML","GraphicalModel","ConditionalIndependence","MarkovRandomField","BayesianNetwork","FactorGraph","D-Seperation","Factorization","MarkovProperty","MessagePassing","BeliefPropagation","Chow-LiuAlgorithm"],"desc":"Machine Learning은 주어진 data를 가장 잘 설명할 수 있는 pattern(Model)을 찾는 것이 목표라고 하였다. 그렇다면, \"data가 가지는 여러가지 정보(feature)들 중에서 어떤 feature를 중점적으로 보고 이용할 수 있을까?\" 그리고, \"만약 여러 feature들이 서로 연관이 있다면 이를 연산의 최적화를 위해 이용할 수 있지 않을까?\" 라는 접근이 가능하다. 여기서 Graphical Model은 이러한 관계를 시각적으로 표현할 수 있으며, 이를 통해서 연산 최적화에 대한 insight를 얻을 수 있다.","thumbnailSrc":"https://euidong.github.io/images/ml-thumbnail.jpg"},{"content":"\n## Intro\n\n여태까지 ML을 수행할 수 있는 여러 가지 방법론을 살펴보았다. 그렇다면, 어떤 Model을 선택하고, 학습과 추정을 해야할지 결정해야 한다. 따라서, 여기서는 어떤 것이 좋은 Model이고, 각 Model 간에 어떻게 비교를 수행할 것인지 그리고 더 나아가 Model을 혼합하는 방법에 대해서 알아볼 것이다.\n\n## What is Good Model?\n\n우리가 사람 image를 입력받아서 긴 머리를 가진 사람인지 여부를 판단하는 classifier를 만든다고 하자. 이때 어떤 Model이 좋은 Model이 될 수 있을까?\n\n가장 쉽게 생각할 수 있는 Model은 Fully Connected Neural Network(FCNN)를 구성하는 것이다. 이를 위해서 Image의 각 pixel을 일렬로 줄 세워 입력할 수 밖에 없다. 하지만, 이는 pixel들 간의 인접 관계를 사용할 수 없게 한다는 단점 때문에 높은 성능을 내기가 어려웠다. 따라서, 이를 극복하기 위헤서 제시된 방법이 Convolutional Neural Network(CNN)를 사용하는 것이다. 이는 FCNN을 적용하기 이전에 Image에 Filter를 적용하여 특정 구간을 대표하는 값을 뽑아내서 더 효율적인 학습을 하는 것을 목표로 한다.(물론 더 자세히 다루면 Pooling Layer 등 더 자세한 설명이 필요하지만, 여기서는 자세히 다루지 않는다. 해당 글을 참고하도록 하자. [🔗 CNN(Convolutional Neural Networks) 쉽게 이해하기](https://halfundecided.medium.com/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-cnn-convolutional-neural-networks-%EC%89%BD%EA%B2%8C-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-836869f88375))\n\n우리의 뇌에서도 Image를 인식하고 처리하기 위해서, color와 motion 그리고 윤곽 등을 따로 따로 처리한다고 한다. 즉, CNN은 이러한 Domain Knowledge를 활용한 훌륭한 예시 중 하나라고 할 수 있다. 즉, 여기서 말하고자 하는 바는 결국 모든 환경에서 최고의 성능을 보여줄 수 있는 Model은 없다는 것이며, Good Model은 우리가 하고자 하는 일에 따라서 Domain Knowledge를 충실하게 활용하여 최고의 성능을 낼 수 있는 Model이라고 할 수 있다.\n\n```plaintext\n 🤔 Data Augmentation\n \n Domain Knowledge를 활용하여 Model의 성능을 높일 수 있는 방법은 \n 단순히 Model 자체를 바꾸는 것 뿐만 아니라 Domain Knowledge를 바탕으로 \n Data를 추가적으로 더 만들어내는 방법이 있다. 이러한 방법을 \n Data Augmentation이라고 한다.\n\n Image data 같은 경우에는 원본 Image를 약간 회전시키거나 확대하거나 \n Noise를 주는 등의 작업을 하여 전체 데이터의 크기를 늘릴 수 있다.\n\nText 같은 경우에는 동의어를 활용하여 문장 데이터의 크기를 효과적으로\n늘리는 것도 가능하다.\n```\n\n![ml-data-augmentation](/images/ml-data-augmentation.png)\n\n## Comparison between Models\n\n여기서 만약 우리가 얻을 수 있는 Model의 종류가 다양하다면 이들을 어떻게 비교하여 하나의 Model을 선택할 수 있을까? 이 역시 중요한 문제이다.\n\n사실 우리가 학습했던 data를 그대로 평가할 때 사용하는 것은 굉장히 불공평하다고 할 수 있다. 우리가 만들고자 하는 Model은 일반적으로 어느 상황에 두어도 그리고 안본 data일지라도 올바르게 분류하기를 원한다. 즉, 우리의 Model이 **Generalization**을 수행할 수 있기를 바란다.\n\n이러한 Model의 **Generalization** 성능을 측정하기 위해서 자주 사용되는 것이 Dataset을 Train과 Test set으로 나누는 것이다. 하지만, 이것도 부족할 때가 있다. 특정 Model이 특정 Train set에서만 성능이 높을 수도 있기 때문이다. 따라서, 우리는 **Cross Validation**이라는 방식을 도입한다. 이는 우리가 가진 dataset을 골고루 test와 train set으로 활용하는 방법이다. 즉, 여러 번의 training을 수행하며, test를 수행하기를 반복하는 것이다. 그리고, 이를 평균을 내서 전체적인 Model 성능을 평가하는 방법이다.\n\n![ml-k-fold-cross-validation](/images/ml-k-fold-cross-validation.png)\n\n위와 같이 공평하게 k개로 나누는 방식을 k fold cross validation이라고 하며, 해당 예시는 $k=4$인 경우이다. 즉, 위와 같이 Validation을 하기 위해서는 Model의 수가 $N$개라고 할 때, 총 $N \\times k$번의 Training과 Evaluation이 필요하다.\n\n하지만, 여기서 또 간과한 사실은 hyperparameter가 각 model마다 큰 영향을 미친다는 사실이다. 즉, Hyper Parameter를 정하는 과정 역시 필요한데, 이는 각 각의 Model 내부에서 어떤 Hyper Parameter를 사용할지에 대한 합의가 필요한 것이다. 이를 확인하기 위해서 어쩔 수 없이 우리는 Training과 Evaluation을 수행해야 하며, 이를 위한 data를 별도로 분리해야 한다. 따라서, 우리가 가지는 dataset을 다음과 같이 세개로 나누어야 한다는 것이다.\n\n![ml-dataset](/images/ml-dataset.png)\n\n여기서 더 정당하게 하고 싶다면, 아래와 같은 과정을 반복해야 한다.\n\n![ml-nested-cross-validation](/images/ml-nested-cross-validation.png)\n\n하지만, 이는 굉장히 비용이 커질 수 있다. validation set을 고를 때, $k^{\\prime}$개가 필요하다고 한다면, 우리는 $N \\times k^{\\prime} \\times k$번의 Training과 Evaluation이 필요한 것이다. 굉장히 비용이 커지기 때문에 대게 validation set까지 cross validation하는 nested cross validation은 상황에 따라 사용되기도 하고, 사용되지 않기도 한다.\n\n## Combining Simple Models\n\n좋은 Model을 만들 수 있는 방법 중에서 가장 쉽게 생각할 수 있는 것 중에 하나가 여러 개의 Model을 활용하는 방법이다. 쉽게 집단 지성을 활용한다고 볼 수 있다. 이러한 방식을 **Ensemble**(앙상블)이라고 부르고, 이를 활용할 수 있는 방법은 여러 가지가 있다.\n\n1. 서로 다른 여러 개의 Model, 또는 Hyperparameter만을 변경하거나 또는 feature를 다르게 변형하여 Model을 여러 개 생성하고 평균 또는 최댓값을 취하는 방법 (**Voting**)\n2. 여러 개의 Model을 혼합하지만, 각 단계에 따라서 Model을 선택하는 방법 (**Stacking**)\n3. dataset을 여러 번 sampling하여 각 각의 Model을 만들고, 각 Model의 결과를 평균 또는 최댓값을 취하는 방법 (**Bagging**, **Pasting**)\n4. 이전과는 달리 앞 서 진행한 Model의 결과를 반영하여 다음 Model에 적용하기를 반복하며, 여러 Model을 제작하고 취합하는 방법 (**Boosting**)\n\n크게는 이렇게 3가지로 나눌 수 있다. 여기서 각각을 자세히 다루지는 않고, **Boosting** 방식 중에서도 많이 사용되는 방법 중에 하나인 **AdaBoost**에 대해서 좀 더 자세히 다뤄보도록 하겠다.\n\n### AdaBoost\n\nAdaptive Boosting의 약자인 AdaBoost는 이름에서 볼 수 있듯이 반복적인 작업을 통해서 최종 Model의 성능을 높이는 것을 목표로 한다. 우선 Boosting 방법 자체가 동시에 Model을 학습시키는 것이 아니고, 순차적으로 학습시키면서 성능을 높이는 방법이다. 그렇다면, 우리가 이전 Model들의 학습 과정에서 다음 Model에게 넘겨줄 수 있는 특별한 정보는 무엇일까? 이는 바로 자신들이 잘못 분류한 데이터에 대한 정보이다. 자신들이 잘못 분류한 data들에게 더 높은 가중치를 부여하도록 하여 다음 Model에서는 이를 중심적으로 분류할 수 있도록 하는 방식으로 최종 Model의 성능을 높여보자는 것이 Idea이다.\n\n그렇다면, 이것이 어떻게 가능할까? 매우 간단한 이진 분류기를 기반으로 이를 설명하도록 하겠다. 우리가 만약 특정 임계값($\\theta_{t}$)보다 작으면 -1, 그렇지 않으면 1이라고 분류하는 아주 간단한 분류기(weak classifier, decision stump)를 가지고 있다고 하자.\n\n$$\nf_{t}(x) = \\begin{cases} -1 & \\text{if } x < \\theta_{t} \\\\ 1 & \\text{otherwise} \\end{cases}\n$$\n\n이제 우리는 이 간단한 분류기 T개를 합쳐서 복잡한 분류 문제를 해결할 분류기를 제작할 것이다. 이 때, 각 분류기는 다음과 같은 가중치($\\alpha_{t}$)를 가지게 된다.\n\n$$\n\\begin{align*}\n\\text{output} = \\text{sign}(F_{T}(x)) \\\\\nF_{T}(x) = \\sum_{t=1}^{T} \\alpha_{t} f_{t}(x)\n\\end{align*}\n$$\n\n그렇다면, 우리는 위 식에서 어떻게 하면, 현명하게 $\\theta_{t}, \\alpha_{t}$를 결정할 수 있을까? 이에 대한 해답으로 **AdaBoost**는 이전 $F_{t-1}$에 의해 발생한 **error**에 집중한다.\n\n우선 $F_{t}$의 Error($E(F_{t})$)를 아래와 같다고 하자.\n\n$$\nE(F_{t}) = \\sum_{i=1}^{N} \\exp(-y^{(i)}F_{t}(x^{(i)}))\n$$\n\n즉, 예측이 맞다면 error는 $1 \\over e$, 틀리다면 $e$만큼 error가 증가한다.  \n여기서 우리는 현재 학습할 Model 이전까지의 Model의 하나의 데이터에 대한 Error를 $\\gamma_{t}^{(i)}$라고 정의해보자.\n\n$$\n\\gamma_{t}^{(i)} = \\exp(-y^{(i)}F_{t-1}(x^{(i)})),\\quad \\gamma_{1}^{(i)} = 1\n$$\n\n다시 한 번 $\\gamma_{t}^{(i)}$의 의미를 정의하면, 간단하게 이전까지의 Model의 합으로 만든 Model이 잘 분류했다면, $e$ 그렇지 않다면, $1 \\over e$가 된다.\n\n그렇다면, 계속해서 Error 식을 정리해보자.\n\n$$\n\\begin{align*}\nE(F_{t}) &= \\sum_{i=1}^{N}\\{\\exp(-y^{(i)}F_{t-1}(x^{(i)})) \\times \\exp(-y^{(i)}\\alpha_{t}f_{t}(x^{(i)}))\\} \\\\\n&= \\sum_{i=1}^{N} \\gamma_{t}^{(i)} \\exp(-y^{(i)}\\alpha_{t}f_{t}(x^{(i)})) \\\\\n&= \\sum_{i:y^{(i)}=f_{t}(x^{(i)})}\\gamma_{t}^{(i)}\\exp(-\\alpha_{t}) + \\sum_{i:y^{(i)}\\neq f_{t}(x^{(i)})}\\gamma_{t}^{(i)}\\exp(\\alpha_{t}) \\\\\n&= \\sum_{i=1}^{N}\\gamma_{t}^{(i)}\\exp(-\\alpha_{t}) + \\sum_{i:y^{(i)}\\neq f_{t}(x^{(i)})}\\gamma_{t}^{(i)}(\\exp(\\alpha_{t})-\\exp(-\\alpha_{t})) \\\\\n&= \\exp(-\\alpha_{t})\\sum_{i=1}^{N}\\gamma_{t}^{(i)} + (\\exp(\\alpha_{t})-\\exp(-\\alpha_{t}))\\sum_{i:y^{(i)}\\neq f_{t}(x^{(i)})}\\gamma_{t}^{(i)}\n\\end{align*}\n$$\n\n여기서 Error를 가장 작게 할 수 있는 $\\theta_{t}, \\alpha_{t}$를 찾기 위한 방법은 각 각 다음과 같다.\n\n1. 식에서 $\\theta_{t}$가 바꿀 수 있는 것은 $f_{t}$밖에 없다. 즉 $\\sum_{i:y^{(i)}\\neq f_{t}(x^{(i)})}\\gamma_{t}^{(i)}$를 조정하는 것이다.  \n   즉, $\\gamma_{t}^{(i)}$는 이전 분류기($F_{t-1}$)가 잘 분류했다면 $e$, 그렇지 않다면 $1 \\over e$가 되는데, 이들의 합이 최소가 되도록 하는 임계값 $\\theta_{t}$를 찾는 것이다.  \n   즉, 기존 분류기가 잘못 분류한 data에 대해서 더 중점적으로 분류할 수 있도록 가중치를 부여하여 다시 분류한다는 것이다.\n2. Error를 $\\alpha_{t}$에 대한 미분을 하여, 0이 되도록 하는 $\\alpha_{t}$를 찾으면 된다. 이 과정은 다음과 같다.\n\n$$\n\\alpha_{t} = \\frac{1}{2}\\ln\\frac{1-\\varepsilon_{t}}{\\varepsilon_{t}},\\quad \\varepsilon_{t} = \\frac{\\sum_{i:y^{(i)}\\neq f_{t}(x^{(i)})}\\gamma_{t}^{(i)}}{\\sum_{i}^{N}\\gamma_{t}^{(i)}}\n$$\n\n여기서 $\\varepsilon_{t}$를 자세히 보면, 분모는 decision stump의 최대 Error이고 분자는 현재 decision stump의 Error를 의미한다. 이것이 직접적으로 $\\alpha_{t}$에 영향을 미치는 것이다.\n\n따라서 이르 조금 더 정리하자면 다음과 같다.\n\n1. $\\varepsilon_{t} \\gt \\frac{1}{2} \\rArr \\alpha_{t} \\lt 0$  \n   $\\varepsilon_{t} \\gt \\frac{1}{2}$라는 것은 사실 $f_{t}$의 성능이 선택지 두 개지 하나를 Random하게 고르는 경우의 확률 $\\frac{1}{2}$보다 못하다는 것이다. 이 경우에 $\\alpha_{t}$를 음수로 설정하여 적용하는 것이 반대로 확률을 적용하는 것이고, 이것이 전체 성능을 높일 수 있기에 타당하다.\n2. $\\varepsilon_{t} = \\frac{1}{2} \\rArr \\alpha_{t} = 0$  \n   만약, 성능이 딱 $\\frac{1}{2}$라면, 더 이상 개선의 여지가 없어진다. 즉, $\\alpha_{t}$를 0으로 설정하여 적용하게 되면, $F_{t}=F_{t-1}$이 된다. 즉, 더 이상의 Model 중첩은 무의미하다는 것을 의미하므로 해당 단계에 도달하면 학습을 중단한다.\n3. $0 \\lt \\varepsilon_{t} \\lt \\frac{1}{2} \\rArr \\alpha_{t} \\gt 0$  \n   일반적인 경우로, 새롭게 만든 분류기가 기존 분류기($F_{t-1}$)를 보완할 만큼 잘 예측을 하고 있기에 $\\alpha_{t}$를 양수로 설정하여 적용한다.\n4. $\\varepsilon_{t} \\rarr 0 \\rArr \\alpha \\rarr \\infin$  \n   $\\varepsilon_{t}$가 0에 가까워지면, 즉, $f_{t}$가 모든 data를 정확하게 분류한다면, 사실상 기존 분류기들은 더 이상 의미가 없다. 하나의 $decision stump$로 완벽하게 분류되는 문제였기 때문이다. 즉, $F_{t} = f_{t}$가 된다.\n\n### Decision Tree\n\n앞 선 **AdaBoost**에서는 Decision Stump를 다루었지만, 더 다양한 분류기를 이용해서 Decision Tree를 구성하는 것도 가능하다. 실제 Stacking 또는 Bagging 등의 작업을 할 때에는 단순한 Decision Stump의 합 같은 형태가 아니라 Tree형태로 구성되는 경우가 많다(Decision을 할 때마다 가지치기를 하며 나뉘는 형태). 그리고 실제로도 이 형태가 인간의 사고 과정도 매우 유사하다. 따라서, 대게의 경우 성능도 좋은 뿐만 아니라 직관적이기 때문에 이러한 방식을 사용해서 여러 Model을 혼합하는 경우도 있다. 이 안에서 Decision을 수행할 때 복잡한 Deep Learning을 수행할 수도 있고, 단순하게 Decision Stump를 사용할 수도 있는 것이다.\n\n![ml-decision-tree](/images/ml-decision-tree.png)\n\n그렇다면, 이러한 Decision Tree를 어떻게 학습하는 게 좋을지를 조금만 살펴보도록 하겠다. 가정을 하나 해보자. 우리가 분류하고자 하는 Category가 10개이고, feature가 100개이다. 이때, 어떤 Feature를 이용한 어떤 Model을 사용한 것을 우선으로 적용해야할까? 이것이 사실 가장 중요한 문제이다. 이를 해결하기 위해서 여러 알고리즘(ID3, CART, 등)이 제시되었다. 하지만, 결국 핵심은 각 각의 단계에서 데이터를 가장 적절하게 나누는 것이 중요한 것이다. 따라서, Model(f)에 대해서 <mark>**얻을 수 있는 정보의 양**(**IG**, Information Gain)</mark>이 많을 수록 좋은 Model이라고 칭하는 것이다. 이를 식으로 표현하면 다음과 같다.\n\n$$\nIG(\\mathcal{D}, f) = I(\\mathcal{D}) - \\sum_{j=1}^{J} \\frac{D_{j}}{D}I(\\mathcal{D}_{j})\n$$\n\n여기서, 또 그렇다면, I는 무엇인지 궁금할 수 있다. 이는 Impurity(정보의 혼탁도)를 의미하며, 이를 표현하는 지표는 아래와 같은 것들이 있다.\n\n1. Gini Impurity\n2. Entropy\n3. Classification Error\n\n위 중에서 우리가 [🔗 ML Base Knowledge(Information Theory)](/posts/ml-base-knowledge#Information-Theory)에서 다루었던 **Entropy**에 기반한 방법이 가장 즐겨서 사용되어진다.\n\n즉, Entropy에 기반한 설명을 하자면, 우리는 IG(정보 획득량)를 최대화하기 위한 선택을 하게 되면, 해당 결정의 Child들은 적은 Entropy를 가지게 되고 이 과정을 반복해 나가면서 최적화를 수행하는 것이다.\n\n즉, Decision Tree를 생성할 때에는 여러 가지 feature와 Model을 적용하며 각 Model이 가지는 IG를 기반으로 하여 Tree의 Root에서부터 Model을 선택하며 내려오는 것이다.\n\n## Cutting down a Compex Model\n\n또한, 좋은 Model을 만들기 위해서 아이러니하게도 일부 정보를 삭제하는 것이 도움이 될 때가 있다. 대게 Deep Learning 환경에서 많이 발생하는 경우인데, **over fitting**으로 인한 문제를 해결하기 위해서 일부 edge를 제거하는 **dropout**을 수행한다. 이러한 방법은 **over fitting**을 방지할 뿐만 아니라 학습의 속도 역시 개선할 수 있기 때문에 자주 사용되어진다. 실제로 model의 성능이 증가할 수 있는지에 대해 다룬 논문이 별도로 있으니 참고할 수 있다면 해보도록 하자. 만약 시간이 된다면 이에 대해서도 다룰 수 있도록 하겠다.\n\n- Frankle, Jonathan, and Michael Carbin. \"The lottery ticket hypothesis: Finding sparse, trainable neural networks.\" ICRL 2019\n\n## Reference\n\n- Tumbnail : Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n- [🔗 CNN(Convolutional Neural Networks) 쉽게 이해하기](https://halfundecided.medium.com/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-cnn-convolutional-neural-networks-%EC%89%BD%EA%B2%8C-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-836869f88375)\n","slug":"ml-model-selection","date":"2022-11-08 16:07","title":"[ML] 7. Model Selection","category":"AI","tags":["ML","ModelSelection","CrossValidation","Boosting","AdaBoost","DecisionTree","NetworkPruning"],"desc":"여태까지 ML을 수행할 수 있는 여러 가지 방법론을 살펴보았다. 그렇다면, 어떤 Model을 선택하고, 학습과 추정을 해야할지 결정해야 한다. 따라서, 여기서는 어떤 것이 좋은 Model이고, 각 Model 간에 어떻게 비교를 수행할 것인지 그리고 더 나아가 Model을 혼합하는 방법에 대해서 알아볼 것이다.","thumbnailSrc":"https://euidong.github.io/images/ml-thumbnail.jpg"}],"categorizedPosts":{"Algorithm":[{"content":"\n## Intro\n\nBinary Search는 가장 기본적이면서도 효과적인 탐색 방법이다. 이는 굉장히 많은 알고리즘의 기본 알고리즘으로 많이 사용된다. 따라서, Binary Search를 제대로 사용할 줄 알아야 한다. 또한, 뒤에 부분에서는 이를 이용해서 중복수를 찾아내는 연산을 어떻게 Binary Search를 통해서 할 수 있는지를 알아볼 것이다.\n\n## Binary Search\n\nBinary Search를 하기 위해서는 먼저 list를 정렬해야 한다. 그렇게 하게 되면, 특정 수를 찾기 위해서 최대 list 전체를 탐색하는 것에서 리스트의 크기를 log 취한 만큼 만 연산해도 충분하다.\n\n일반적인 예시가 Up&Down 게임이다. 이는 특정 범위 안의 숫자를 맞히고자 할 때 기회를 여러 번주고, 시도할 때마다 시도한 값과 목표 값을 비교하여 목표값이 더 크면 Up, 더 작으면 Down을 알려주는 게임이다. 우리가 값을 맞추고자할 때마다 해당 값에 대한 힌트가 주어지게 되는데, 만약 우리가 매번 수의 중앙 값을 말한다면, 얻을 수 있는 정보의 질이 굉장히 높아진다. 물론 범위가 100이고 맞추고자 하는 값이 100일 때, 99라고 말하고 Up을 듣는다면 최상의 정보를 얻게 되는 것이지만, 만약 Down이라면, 받을 수 있는 정보의 질이 굉장히 떨어진다. 왜냐하면 내가 해당 수를 외침으로써 다음 시도에서 제외할 수 있는 수는 2개 밖에 없기 때문이다.\n\n결국 우리는 특정 수를 맞추지 못했을 경우, 고급 정보를 얻어 다음 도전을 할 수도 있고, 안좋은 정보를 얻어 다음 도전에 도움이 덜 될 수도 있다. 즉, 우리가 맞추어야 할 수가 하나라면, 위와 같은 요행에 기대어 도전하는 것도 나쁘지 않은 선택이라고 할 수 있다. 예를들어, 2의 배수 순으로 조회하는 것이다.\n\n하지만, 우리가 해당 게임을 여러 번 진행할 것이고, 범위가 넓어질 경우 질이 안좋은 정보를 얻었을 경우의 Risk가 너무 클 수 있다. 따라서, 우리는 어떤 숫자가 들어오더라도 **확정적으로 연산 횟수를 줄이기를 기대할 것**이다. 그 방법이 항상 범위의 중앙값을 선택하는 것이다. 그렇다면, 어떤 수가 목표이더라도 우리는 선택지를 매번 반으로 나눌 수 있다. 결론상 중앙값 선택을 k 번했을 때, 사실상 $2^{n-1} + 2^{n-2} + ... + 2^{n-k}$ = $2^{n}(1-{1\\over{2^k}})$ = $\\text{전체} \\times (1 - {1 \\over {2^k}})$개를 조회한 것과 같은 효과를 보는 것이다. 이 효과를 본 결과 우리가 K번 시도 후에 정답일 가능성이 있는 수를 나열해보라고 한다면, 해당 수는 $\\lfloor{\\text{전체} \\over {2^k}}\\rfloor$ 개만 남아있게 된다. 결과적으로 우리는 $\\lfloor{\\text{전체} \\over {2^k}}\\rfloor = 0$이 되는 k번만 수행하면, 어떤 수가 들어오더라도 목표값을 확정적으로 구할 수 있다.\n\n이진 탐색을 하기 위해서는 **결국 중앙값을 빠르게 찾는 것이 중요하다.** 따라서, 정렬이 중요한 것이다. 정렬을 하게 되면, 중앙값을 단순히 전체 크기의 반에 위치한 값으로 찾을 수 있기 때문에 이 연산이 매우 간단해진다.\n\n이를 구현하면 다음과 같다.\n\n```python\ndef binary_search(arr, target):\n  start = 0\n  end = len(arr)\n  # end는 이미 봤거나 배열범위의 밖이다.\n  while end > start:\n    mid = (start + end) // 2\n    if arr[mid] > target:\n      end = mid\n    elif arr[mid] < target:\n      start = mid + 1\n    else:\n      return mid\n  return len(arr)\n\nA = [1,2,3,4,5,6,7,8]\nB = [1,3,5,7,10,15,50]\nC = [1,3,-7,-4,-1,-5]\n\nbinary_search(A, 3) # 2 \nbinary_search(B, 5) # 2\nbinary_search(B, 14) # 못찾아서, 배열의 크기(7)을 return\nbinary_search(C, 3) # 못찾고, 배열의 크기(6)를 return\nbinary_search(sorted(C), 3) # 5\n```\n\n다른 언어에서는 -1을 return하는 경우도 있지만, python에서는 -1을 index로 찾을려고 해도 compile 오류가 안나기 때문에 배열의 크기를 return하여 compile 에러를 만드는게 낫다.\n\n## Lower Bound / Upper Bound\n\n이분탐색의 응용으로 나오는 것이 하한선(Lower Bound)과 상한선(Upper Bound)이다. Lower Bound는 특정 수 이상의 값이 처음 나오는 index를 의미하고, Upper Bound는 특정 수를 초과하는 값이 처음 나오는 index를 의미한다.\n\n이들을 찾는 과정이 이분 탐색과 매우 유사하다.\n\n```python\ndef lower_bound(arr, target):\n  start = 0\n  end = len(arr)\n  while end > start:\n    mid = (start+end) // 2\n    if arr[mid] < target:\n      start = mid + 1\n    else:\n      end = mid\n  return end\n\ndef upper_bound(arr, target):\n  start = 0\n  end = len(arr)\n  while end > start:\n    mid = (start + end) // 2\n    if arr[mid] <= target:\n      start = mid + 1\n    else:\n      end = mid\n  return end\n```\n\n## 중복수의 갯수\n\n우리가 중복수를 셀 때 어떻게 해야할까?\n\n1. 앞에서 부터 찾아나간다. $O(N)$\n2. 특정 수를 찾고, 좌우 값을 찾는다. $O(N)$\n3. 해당 수 이상이 처음 나오는 위치를 찾고, 해당 수를 초과한 값이 처음 나오는 위치를 찾는다. $(O(\\log{N}))$\n\n극단적인 예시로 0이 연속으로 1조개 이상 있는 list에서 0의 중복 횟수를 셀려면 100억번의 연산이 필요하다. 하지만, 3번 방법을 사용하면, $2^{40} \\ge \\text{1조}$이므로 총 80회 정도의 연산으로 성공적인 연산이 가능하다.\n\n하지만, 유의할 것은 lower_bound가 해당 값을 실제로 찾았는가이다. 따라서, lower_bound를 통해서 얻은 index가 실제로 해당 목표값이 맞는지를 반드시 확인하자.\n(왜냐하면, return값이 0인 경우, 찾았을 수도 있고, 못찾았을 수도 있다.)\n\n```python\ndef get_dup_cnt(arr, target):\n  lb = lower_bound(arr, target)\n  if lb < len(arr) and arr[lb] == target:\n    return lb - upper_bound(arr, target)\n  return 0\n```\n","slug":"binary-search","date":"2022-05-02 15:34","title":"Binary Search","category":"Algorithm","tags":["Binary Search","Upper Bound","Lower Bound","중복 수의 갯수"],"desc":"Binary Search는 가장 기본적이면서도 효과적인 탐색 방법이다. 이는 굉장히 많은 알고리즘의 기본 알고리즘으로 많이 사용된다. 따라서, Binary Search를 제대로 사용할 줄 알아야 한다. 또한, 뒤에 부분에서는 이를 이용해서 중복수를 찾아내는 연산을 어떻게 Binary Search를 통해서 할 수 있는지를 알아볼 것이다.","thumbnailSrc":"https://euidong.github.io/images/algorithm.png"},{"content":"\n## Intro\n\n우리가 알고리즘을 생각할 때, 가장 먼저 떠올릴 수 있는 방법 중에 하나입니다. 가장 기본적인 알고리즘이기 때문에, 굳이 설명을 하지 않아도 자연스럽게 채득하는 경우가 대부분이지만, 사고의 틀을 정하여 더 빠르게 답을 찾을 수 있습니다.\n\nBrute Force를 직접적으로 번역하면, 이는 \"무차별  대입\"정도로 생각할 수 있습니다. 이는 여러 가지의 경우의 수에서 최적의 답이 한 개 이상 존재할 때, 모든 경우의 수를 하나하나 대입해보면서, 정답이 맞는지를 확인하는 방식입니다. 즉, 가능한 모든 경우를 만들고, 그 후에 이것이 정답인지를 계속해서 확인하는 과정이 알고리즘의 핵심입니다.\n\n가장 흔한 예시가 해커들이 특정 유저의 password를 알아내기 위해서 모든 경우의 수를 대입하여 확인하는 것이 있습니다.\n\n## 해결 방법\n\n이 알고리즘의 구현 순서는 다음과 같습니다.\n\n1. 모든 경우의 수를 헤아린다.\n2. 하나의 경우의 수를 갖고 하는 연산의 횟수를 헤아린다.\n3. 해당 알고리즘이 시간 내에 작동할 수 있는지 확인한다.  \n    대게, 1초동안 할 수 있는 연산은 대략 1억회라고 가정하면 쉽습니다.\n4. 알고리즘을 직접 구현한다.\n\n## 대표 예시\n\n모든 경우의 수를 확인하는 문제가 굉장히 많기 때문에, 순열/조합/부분집합 문제가 굉장히 많습니다. 고등학교 시절 C, P로 경우의 수를 푸는 문제를 굉장히 많이 풀었다면, 아마 쉽게 할 수 있을 것입니다.\n\n일단 순열 조합을 가장 효율적으로 구현하는 방법에 대해서, 일단 정리를 해보겠습니다.\n\n### 1\\. 순열(Permutation)\n\n```python\ndef permutation_helper(k, arr=[], prev=[]):\n    if len(prev) == k:\n        return [prev]\n    ss = []\n    for idx in range(len(arr)):\n        ss += permutation_helper(k, arr[:idx] + arr[idx+1:], prev + [arr[idx]])\n    return ss\n\n\ndef permutation(n, k):\n    arr = [i for i in range(1, n+1)]\n    return permutation_helper(k, arr, [])\n    \nprint(permutation(5, 2))\nprint(permutation_helper(2, [1,2,3,4,5], []))\n```\n\n### 2\\. 조합(Combination)\n\n```python\ndef combination_helper(k, arr=[], prev=[]):\n    if len(prev) == k:\n        return [prev]\n    ss = []\n    for idx in range(len(arr)):\n        ss += combination_helper(k, arr[idx+1:], prev + [arr[idx]])\n    return ss\n\n\ndef combination(n, k):\n    arr = [i for i in range(1, n+1)]\n    return combination_helper(k, arr, [])\n\nprint(combination(5, 2))\nprint(combination_helper(2, [1,2,3,4,5], []))\n```\n\n### 3\\. 부분집합(Subset)\n\n```python\ndef subset_helper(k, arr=[], prev=[]):\n    if len(prev) == k:\n        return []\n    ss = []\n    for idx in range(len(arr)):\n        ss.append(prev + [arr[idx]])\n        ss += subset_helper(k, arr[idx+1:], prev + [arr[idx]])\n    return ss\n\n\ndef subset(n, k):\n    arr = [i for i in range(1, n+1)]\n    return subset_helper(k, arr, [])\n\nprint(subset(5, 2))\nprint(subset_helper(2, [1,2,3,4,5], []))\n```\n","slug":"brute-force","date":"2022-04-14 13:51","title":"Brute Force","category":"Algorithm","tags":["BruteForce","순열","조합","부분 집합"],"desc":"우리가 알고리즘을 생각할 때, 가장 먼저 떠올릴 수 있는 방법 중에 하나입니다. 가장 기본적인 알고리즘이기 때문에, 굳이 설명을 하지 않아도 자연스럽게 채득하는 경우가 대부분이지만, 사고의 틀을 정하여 더 빠르게 답을 찾을 수 있습니다.Brute Force를 직접적으로 번역하면, 이는 \"무차별  대입\"정도로 생각할 수 있습니다. 이는 여러 가지의 경우의 수에서 최적의 답이 한 개 이상 존재할 때, 모든 경우의 수를 하나하나 대입해보면서, 정답이 맞는지를 확인하는 방식입니다. 즉, 가능한 모든 경우를 만들고, 그 후에 이것이 정답인지를 계속해서 확인하는 과정이 알고리즘의 핵심입니다.가장 흔한 예시가 해커들이 특정 유저의 password를 알아내기 위해서 모든 경우의 수를 대입하여 확인하는 것이 있습니다.","thumbnailSrc":"https://euidong.github.io/images/algorithm.png"},{"content":"\n## Intro\n\nGraph의 탐색에서 가장 기본이 되는 방법입니다. 한 점에서 연결된 다른 점으로 이동을 하면서, 모든 연결된 점을 순화하는 것을 목표로 가진다고 가정해봅시다. 이때, 정점을 고르는 방식에 따라서, DFS, BFS로 나눕니다. DFS에서는 자신과 연결된 정점 중에서 하나를 선택하고 이동한 뒤에 해당 점에서 다시 연결된 지점을 찾아서 이동합니다. 즉, 바로 지금 뽑은 점에 인접해있는 지점이 이전에 인접해있던 지점보다 가중치가 높다는 것입니다. 이를 모두 진행하고도 답을 찾을 수 없다면, 이제 이전 시점으로 돌아와서 다시 작업을 재개하는 방식입니다.\n\n## DFS(Depth First Search)\n\n이를 구현하기 위해서는 `Stack`이 가장 중요합니다. 이전의 연결되었던 점보다 현재 연결된 점이 더 중요하기 때문에, 현재가 우선순위가 높지만, 후에 이를 다시 찾아와야 하기 때문에, 이를 저장하기 위한 자료구조가 필요한데 이것이 `Stack`이 되는 것입니다.\n\n따라서, 이를 직접 구현해보면 다음과 같습니다.\n\n```python\nadj = [\n  [2,3],\n  [3],\n  [0,3],\n  [0,1,2]\n]\n\nvisited = [False] * 4\nstack = [(0, visited)]\nwhile len(stack) > 0:\n  cur, visited = stack.pop(-1)\n  visited[cur] = True\n  for next in adj[cur]:\n    if visited[next] === False:\n      stack.append((next, visited))\n```\n\n또는, Recursive Call(함수의 재귀 호출)을 통해서 구현할 수 있습니다. 재귀 호출을 통한 구현이 더 일반적이며, 이해하기 쉬운 구조이기 때문에 많이 사용됩니다. 왜냐하면, 함수는 기본적으로 `stack` 형식으로 호출한 함수들을 쌓아두기 때문에, 더 원활한 구현이 가능합니다.\n\n```python\nadj = [\n  [2,3],\n  [3],\n  [0,3],\n  [0,1,2]\n]\n\ndef dfs(cur, visited):\n  visited[cur] = True\n  for next in adj[cur]:\n    if visited[next] === False:\n      dfs(next, visited)\n\ndfs(0, [-1] * 4)\n```\n\n추가적으로 만약 순회해야 하는 그래프가 확실하게 모두 연결된 그래프가 아니라면(중간에 간선이 끊겨 연결이 되지 않는 정점이 존재하는 경우), 우리는 모든 정점에서 `dfs`를 수행하도록 설정을 해주어야 합니다. 그래야만 전체 점을 순환할 수 있습니다.\n\n```python\nadj = [\n  [2,3],\n  [3],\n  [0,3],\n  [0,1,2]\n\n]\n\ndef dfs(cur):\n  visited[cur] = True\n  for next in adj[cur]:\n    if visited[next] === False:\n      dfs(next)\n\ndef dfsAll():\n  visited = [False] * len(adj)\n  for v in range(len(adj)):\n    if not visited[v]:\n      dfs(v)\n  \n```\n\n### 시간복잡도\n\n일반적으로 모든 노드를 순환하는 것이 목표라면,\n\n- 인접 리스트 : $O(|V| + |E|)$\n- 인접 행렬 : $O(V^2)$\n\n### Example\n\n> **연결된 부분집합 갯수**\n\ndisjoint set을 통해서 구현할 수 있는 문제이지만, DFS를 통해서 쉽게 구현할 수 있습니다. 바로, 앞 서 보았던 `dfsAll`에서 `dfs`의 호출 횟수를 counting하면 값을 구할 수 있습니다.\n\n```python\n# adj = [[...], [...], ...]\n# visited = [False, False, ..]\n\ndef dfs(cur):\n  visited[cur] = True\n  for next in adj[cur]:\n    if not visited[next]:\n      dfs(next)\n\ndef dfsAll():\n  visited = [False] * len(adj)\n  cnt = 0\n  for v in range(len(adj)):\n    if not visited[v]:\n      cnt += 1\n      dfs(v)\n  return cnt\n```\n\n---\n\n> **위상정렬**\n\n위상 정렬이란 directed edge(유향 간선)로 이루어진 그래프를 규칙을 깨지 않으면서 정렬하는 방식입니다. 간선이 없는 경우에는 순서가 상관없지만, 간선이 있는 경우에는 순위가 있는 형태입니다. (우선순위 : 출발점 < 도착점)\n언뜻 보기에는 어려워 보이지만, DFS를 통해서 쉽게 해결할 수 있습니다. DFS를 실행하면서 끝에 지점에서 부터 배열에 저장하고 이를 역순으로 정렬하면 위상정렬이 되는 것을 볼 수 있습니다.\n\n```python\n# adj = [[...], [...], ...]\n# visited = [False, False, ..]\n\norder = []\n\ndef dfs(cur):\n  visited[cur] = True\n  for next in adj[cur]:\n    if not visited[next]:\n      dfs(next)\n  order.append(cur)\n\ndef dfsAll():\n  visited = [False] * len(adj)\n  order = []\n  for v in range(len(adj)):\n    if not visited[v]:\n      dfs(v)\n\nprint(order[::-1])\n```\n\n> **오일러 서킷(한 붓 그리기)**\n\n시작 점과 끝 점이 동일할 때, 모든 경로를 지나는 길찾기입니다.\n이를 해결할 때에는 우선 다음 조건을 먼저 확인해야 합니다.\n\n- 두 개 이상의 Component로 분리된 경우 만들 수 없습니다.\n- 어느 한 점이라도 차수가 홀수이면, 만들 수 없습니다.\n\n해결책은 간단합니다. 반복적으로 Circuit(순환)을 찾아서, 최종 구조로 완성하면 됩니다.\n\n다음이 기본적인 프로세스입니다.\n\n1. 먼저 자신으로 시작해서 자신으로 돌아오는 순환을 먼저 찾는다.\n2. 위의 과정을 진행하고도, 아직 지나지 않은 간선을 포함한 정점이 있다면, 이를 시작점으로 하여 다시 순환을 찾을 수 있다. 이러한 정점이 없을 때까지 이를 반복해서 시행한다.\n3. 이를 최초의 순환에 붙여나가면서, 최종으로 오일러 서킷을 완성한다.\n\n1번과 2번 과정에서 만약, 순환을 찾을 수 없다면 오일러 서킷이 불가능하다는 결론을 내리고 process를 종료합니다.\n\n```python\n# adj = [[...],[...],...] (인접행렬) - 동일 간선이 여러 개 있을 수도 있음\ndef eulerCircuit(cur, circuit):\n  for next in range(len(adj)):\n    if adj[cur][next] > 0:\n      adj[cur][next] -= 1\n      adj[next][cur] -= 1\n      eulerCircuit(next, circuit)\n  circuit.push_back(cur)   \n```\n\n**만약,** 시작점과 끝점이 다른 EulerTrail일 경우에는 임의로 시작점과 끝점을 잇고, Euler Circuit을 찾은 뒤에 삭제하면 됩니다.\n","slug":"dfs1","date":"2022-02-03 09:00","title":"DFS(1)-기본","category":"Algorithm","tags":["DFS","Graph","Tree"],"desc":"Graph의 탐색에서 가장 기본이 되는 방법입니다. 한 점에서 연결된 다른 점으로 이동을 하면서, 모든 연결된 점을 순화하는 것을 목표로 가진다고 가정해봅시다. 이때, 정점을 고르는 방식에 따라서, DFS, BFS로 나눕니다. DFS에서는 자신과 연결된 정점 중에서 하나를 선택하고 이동한 뒤에 해당 점에서 다시 연결된 지점을 찾아서 이동합니다. 즉, 바로 지금 뽑은 점에 인접해있는 지점이 이전에 인접해있던 지점보다 가중치가 높다는 것입니다. 이를 모두 진행하고도 답을 찾을 수 없다면, 이제 이전 시점으로 돌아와서 다시 작업을 재개하는 방식입니다.","thumbnailSrc":"https://euidong.github.io/images/algorithm.png"},{"content":"\n## Intro\n\n이전에는 DFS의 기본이 되는 요소에 대해서 알아보았지만, 이제는 좀 더 심화적인 부분을 배워보고자 한다.\nDFS가 그래프를 순회하면서 만드는 DFS Spanning Tree에 대한 내용이다.\n\n## DFS Spanning Tree\n\n우리는 총 4가지로 간선을 분류할 수 있습니다.\n\n1. **Tree Edge(트리 간선)**- DFS Spanning Tree에 포함된 간선\n2. **Forward Edge(순방향 간선)** - 해당 간선이 가르키는 정점이 DFS Spanning Tree에서 자신의 descendant(후손)에 속하는 경우\n3. **Backward Edge(역방향 간선)** - 해당 간선이 가르키는 정점이 DFS Spanning Tree에서 자신의 ancestor(조상)에 속하는 경우\n4. **Cross Edge(교차 간선)** - 해당 간선이 가르키는 정점이 후손도 조상도 아닌 sibiling(형제 또는 그들의 자손)에 속하는 경우\n\n![dfs-spanning-tree](/images/dfs-spanning-tree.png)\n\n이를 구현하기 위해서는 총 두 개의 추가적인 자료구조가 필요하다.\n\n1. order[1...N] = 해당 노드의 발견 순서\n2. finished[1...N] = 모든 간선의 사용 여부\n\n```python\nadj = [\n  [1,3],\n  [2],\n  [1],\n  [1,2]\n]\nN = len(adj)\n\norder = [-1] * N\nfinished = [False] * N\ncnt = [0]\ndef dfs(curr):\n  order[curr] = cnt[0]\n  cnt[0] += 1\n  for next in adj[curr]:\n    prefix = curr + \"에서 \" + next + \"까지는\"\n    # 아직 방문하지 않았다면, 트리 간선이다.\n    if order[next] == -1:\n      print(prefix + \"트리 간선이다.\")\n      dfs(next)\n    # 만약 다음 정점의 order가 더 낮다면, 순방향 간선이다.\n    elif order[next] > order[curr]:\n      print(prefix + \"순방향 간선이다.\")\n    # 만약, 다음 정점이 아직 거쳐야 하는 정점이 있다면, 역방향 간선이다.\n    elif not finished[next]:\n      print(prefix + \"역방향 간선이다.\")\n    # 그 외에는 교차 간선이다.\n    else:\n      print(prefix + \"교차 간선이다.\")\n  finished[curr] = True\n\ndef dfsAll():\n  for i in N:\n    if order[i] == -1:\n      dfs(i)\n```\n\n위와 같이 구현하게 되면, 적절하게 간선을 구분할 수 있다. 위에는 방향이 존재하는 그래프였지만, 만약 방향이 존재하지 않는 무향 그래프라면 위의 과정을 좀 더 단순화할 수 있다.\n먼저 간선은 다음과 같이 줄어든다.\n\n1. **트리 간선** = DFS Spanning Tree에 포함된 간선\n2. **중첩 간선** = DFS Spanning Tree에 포함되지 않은 간선\n\n다음과 같이 총 2개로 줄어드는 것을 볼 수 있다. 교차 간선과 역방향 간선은 기본적으로 이후에 방문하는 정점에서 이미 방문한 정점으로 이동하는 것인데 이런 일은 무향 그래프에서는 발생하지 않기 때문에 존재할 수 없다.\n그러면, 구현은 다음과 같이 진행됩니다.\n\n```python\nadj = [\n  [1,2,3],\n  [0,2,3],\n  [0,1,3],\n  [0,1,2]\n]\nN = len(adj)\n\norder = [-1] * N\n# finish는 필요하지 않다.\ncnt = [0]\ndef dfs(curr):\n  order[curr] = cnt[0]\n  cnt[0] += 1\n  for next in adj[curr]:\n    prefix = curr + \"에서 \" + next + \"까지는\"\n    # 아직 방문하지 않았다면, 트리 간선이다.\n    if order[next] == -1:\n      print(prefix + \"트리 간선이다.\")\n      dfs(next)\n    # 만약 다음 정점의 order가 더 낮다면, 중첩 간선이다.\n    # 여기서 유의해야 할 점은 바로 중첩 간선은 두 번 호출된다는 점이다.\n    # 중첩 간선이기 때문에 서로 한 번씩 호출히기 때문이다.\n    # 이를 구분하기 위해서 order를 사용할 수 있다.\n    elif order[next] < order[curr]:\n      print(prefix + \"order가 높은 곳에서 낮은 곳으로 가는 중첩 간선이다.\")\n    else:\n      print(prefix + \"order가 낮은 곳에서 높은 곳으로 가는 중첩 간선이다.\")\n\ndef dfsAll():\n  for i in N:\n    if order[i] == -1:\n      dfs(i)\n```\n\n여기서 각 간선의 특징을 이해하면, 다른 문제를 풀기 쉽다.\n\n1. 역방향 또는 중첩 간선의 갯수 = circle의 갯수\n    - 여기서 주의할 점은 바로 무향 그래프에서는 바로 직전의 방문한 정점으로 돌아가는 정점은 매번 존재하기 때문에 이는 제외해야 한다는 것을 주의하자.\n2. 무향 그래프에서 특정 정점에서 시작되는 Spanning Tree가 중첩 간선이 없다는 것은, 해당 정점을 기준으로 연결된 정점들은 실제 그래프에서도 트리 형태로 존재한다는 점(절단점)이다.\n3. 방향 그래프에서 역방향 간선과 교차 간선이 없다면, 똑같은 의미를 가진다.\n\n## 문제 풀이\n\nDFS 문제에서는 대게 다음과 같은 자료 구조가 많이 사용한다.\n\n- visited : 방문 여부에 대한 checklist로, graph의 정점의 크기 만큼 존재한다. 초기 값은 False로 초기화한다.\n- order : 방문 순서에 대한 checklist로, graph의 정점의 크기 만큼 존재한다. 초기 값은 -1로 초기화하고, 방문 시마다 올려 주기 위해서, global variable로 cnt를 추가적으로 설정해주기도 한다.(그렇지 않으면, dfs parameter로 전달해주어야 한다.) 또한, 이를 통해서, visited 판단이 가능하기 때문에, 이를 사용할 시에는 visited의 사용을 하지 않아도 된다.\n- finished : 방향 그래프에서 해당 정점에 대한 탐색이 종료되었는지를 확인하기 위해서 사용되는 자료구조이며 graph의 정점의 크기 만큼 존재한다. 초기 값은 False로 초기화하고, dfs의 모든 정점을 방문하는 것이 끝난 경우에 이를 True로 세팅하자.\n- parent : 이는 대게 DFS를 재구조화할 때, 이 역시 graph의 정점의 크기 만큼 존재한다. 대게 경로를 다시 그려야 하는 경우에 많이 사용한다. 만약 visited도 같이 표현하고 싶으면, -2로 초기화하는 것이 좋다. 하지만, visited를 따로 사용할 것이라면, -1로 초기화해도 된다. 왜냐하면, parent -1은 dfs spanning tree의 root라는 의미를 가지는 값으로 쓰는 경우가 대부분이기 때문이다.\n\n### Circle 찾기\n\n위에서 나온 대로 Circle을 찾아나가면 됩니다.\n\n> 백준 16929\n\n<https://www.acmicpc.net/problem/16929>\n\n가장 기본적인 문제로 대놓고, Circle을 찾으라고 합니다. 유의할 점은 직전에 그쳐간 지점으로 돌아가는 것은 막아야 한다. 따라서, prev 값을 들고 가는 것을 추천한다.\n\n> 백준 12946\n\n<https://www.acmicpc.net/problem/12946>\n\n응용 문제입니다. 처음에는 circle 찾기라는 것을 이해하기 어렵다. 하지만, 최대 색은 3이고, circle을 이루는 원소가 홀수인지 짝수인지를 찾는 문제로 받아들이면, 굉장히 쉽게 풀 수 있다.\n\n> 백준 16947\n\n<https://www.acmicpc.net/problem/16947>\n\n가장 많이 응용되어지는 응용 예시입니다. DFS + BFS 기술을 사용해야 한다. 먼저, DFS를 통해서 Circle에 속하는 원소를 찾아내고, 해당 Circle에 속하는 원소들을 queue에 넣은 후에 거기서부터 bfs로 방문하지 않은 점을 찾아나가면 된다.\n","slug":"dfs2","date":"2022-04-23 10:30","title":"DFS(2)-DFS Spanning Tree","category":"Algorithm","tags":["DFS","Graph","Tree","Cycle 찾기"],"desc":"이전에는 DFS의 기본이 되는 요소에 대해서 알아보았지만, 이제는 좀 더 심화적인 부분을 배워보고자 한다.DFS가 그래프를 순회하면서 만드는 DFS Spanning Tree에 대한 내용이다.","thumbnailSrc":"https://euidong.github.io/images/algorithm.png"},{"content":"\n## Intro\n\nDynamic Programming은 기본적으로 이전에 계산했던 데이터를 여러 번 사용할 때 적은 시간 비용으로 문제를 해결할 수 있는 알고리즘입니다. 이를 정의하기 위해서 Overlapping Subproblem, Optimal Structural 라는 단어를 주로 사용하며 이에 대해 살펴보겠습니다.\n\n## 정의\n\n우리말로 동적 계획법이라고 번역되어지는 말입니다. 우선 명칭에 대해서 좀 어색할 수 있다. 이는 해당 어원이 오래되었기 때문입니다. 당시에 programming이란 문제 풀이를 위한 planning(계획) 정도로 생각했습니다. 따라서, **Dynamic Programming이 의미하는 바는 다단계 처리에 대한 최적화된 계획법 정도로 해석**할 수 있습니다.\n\nDynamic Programming을 사용하기 위해서는 해당 문제가 다음과 같은 조건을 만족할 때입니다.\n\n1. **Optimal Substructure**\n2. **Overlapping Subproblem**\n\n**Optimal Substructure**란 문제의 최적해가 이것의 하위 문제(subproblem)의 최적해에 의해서 정의되어질 수 있어야 한다는 것입니다. 쉽게 말해서 수열의 경우 점화식을 작성할 수 있어야 한다는 의미입니다. 가장 일반적인 예시가 fibonacci 수열을 예로 들 수 있습니다.\n\n$$ fibo(n) = fibo(n-1) + fibo(n-2) $$\n\n**Overlapping Subproblem**이란 문제의 하위 문제(subproblem)들이 중첩해서 사용되는 경우를 말합니다. 위의 fibonacci 수열만 보아도 fibo(100)은 fibo(101), fibo(102)를 계산하기 위해서 쓰이기 때문에 중복이 발생하며, 더 나아가 fibo(101), fibo(102)를 사용하는 경우에는 fibo(100)을 다시 계산해야 합니다. 이것은 굉장한 비용을 초례합니다.\n\n이러한 문제들에 대한 해결책으로써 Dynamic Programming에서는 점화식을 이용해서 문제를 해결하지만, 이때, 한 번 계산한 값을 두 번 계산하지 않도록 하는 것입니다. **이를 가능하게 하는 것이 Memoization(함수의 실행 결과를 저장)입니다.** 즉, 이전에 호출한 함수의 결과값을 별도의 저장 공간(array, list, map, file 등)에 저장해두는 것입니다. 이를 통해서 우리는 problem의 subproblem이 이미 계산된 적이 있다면, 하위 문제를 다시 풀 필요없이 바로 solution(점화식)을 계산할 수 있는 것입니다. 이를 통해서, **계산 시간을 획기적으로 줄일 수 있습니다. 하지만, 추가적인 memory를 사용한다는 점을 반드시 기억해야 합니다.**\n\n여기서 계속해서 반복 및 교체되어 사용되는 단어가 점화식, solution, optimal substructure, function, 함수입니다. 이는 모두 같은 뜻을 가지는데, 여기서도 특히 함수는 **referential transparency**를 보장하는 함수만을 지칭합니다. 수학에서는 아주 당연한 얘기이지만, input값이 동일할 때 항상 같은 output을 내놓아야 한다는 것입니다. programming에서의 함수는 대게 side effect가 존재할 수 있고, 외부 변수를 사용하기도 하므로, 같은 input이라도 상황(context)에 따라 다른 output이 발생할 수도 있는데 이러한 것이 해당 함수에서는 발생해서는 안된다는 것입니다.\n\n---\n\n## 구현\n\n기본적으로 Dynamic Programming을 적용하기 위해서는 반드시 위에서 언급한 두 조건을 만족하는지를 확인해야 합니다. 따라서, 먼저 점화식을 찾아내고, 이것이 반복 사용되는지를 반드시 확인한 후에 적용하는 것이 기본입니다.\n\nDynamic Programming의 기본적인 구현 방식은 두 가지가 존재합니다. 둘 다 장단점이 있기 때문에 이것에 유의하여 사용해야 합니다.\n\n따라서, 아래에서는 가장 기본적인 예시로 combination을 구하는 방식을 두 가지 방식으로 구현하겠습니다. 일단 Combination은 다음과 같은 점화식을 만족합니다.\n\n$$ {{}_{n}C_{k}} = {{}_{n-1}C_{k-1}} + {{}_{n-1}C_{k}}$$\n\n따라서, 이를 Dynamic Programming을 통해서 구현할 수 있습니다.\n\n### 1\\. Top Down(=Recursive)\n\n 먼저 input으로 들어올 데이터의 크기를 고려하여, cache list의 크기를 지정합니다. 그 후에 점화식을 함수 내에서 나타내고, 해당 함수값을 return해주면 됩니다. 이때 중요한 것이 이미 함수값을 계산한 적이 있는지를 확인하고 있다면, 바로 return해버리는 점입니다.\n\n```python\nsize = 100\n# 1차원 배열\ncache = [-1] * size\n\n# 2차원 배열\ncache = [[-1 for _ in range(size)] for _ in range(size)]\n\n# 기저값 세팅\ncache[0][0] = 1\ncache[1][0] = 1\ncache[1][1] = 1\n\n# 함수 지정\ndef recursive_call(a, b):\n    # 이미 저장된 값이 있는 경우 return\n    if cache[a][b] != -1:\n        return cache[a][b]\n    # 없다면, 연산 및 저장 후 return\n    cache[a][b] = cache[a-1][b-1] + cache[a-1][b]\n    return cache[a][b]\n    \nprint(recursive_call(10, 2))\n```\n\n해당 방식의 가장 큰 장점은 이해하기 쉽다는 것입니다. 점화식이 분명하게 들어나며, 값을 찾아가는 과정을 상상하는 것이 쉽습니다. 또한, 모든 경우의 수를 탐색하지 않을 수 있다는 점이 있습니다. 왜냐하면, 연관된 데이터만 찾기 때문에 관련 없는 데이터는 찾지 않을 수도 있습니다. **하지만,** recursive call인 만큼 함수 호출의 최대 횟수가 정해져있어, 모든 경우에 올바른 답을 찾지는 못합니다. 이를 해결하기 위해서 끊어서 실행 시켜두는 방법도 있습니다. 예를들어 200을 구하는 문제면, 50, 100, 150을 미리 호출해둡니다. 하지만, 이 또한, 매번 적용할 수 있는 방법은 아니기에 대다수의 경우에는 Bottom Up으로 구현하는 것을 추천합니다.\n\n### 2\\. Bottom Up(with Loop)\n\n위와 똑같은 원리를 이용해서 구현한 Combination입니다. for문을 이용해서 처음부터 끝까지 구하면서 올라가는 방식입니다. 이렇게 하게 되면, 빈틈없이 아래부터 계산하는지를 체크하면서 구현해야합니다. 중간에 빈값이 발생하는 경우가 없도록 하는 것이 중요합니다.\n\n```python\nsize = 100\n# 1차원 배열\ncache = [-1] * size\n\n# 2차원 배열\ncache = [[-1 for _ in range(size)] for _ in range(size)]\n\n# 기저값 세팅\ncache[0][0] = 1\ncache[1][0] = 1\ncache[1][1] = 1\n\n# 함수 지정\nfor i in range(2, size):\n for j in range(0, i+1):\n     cache[i][j] = cache[i-1][j-1] + cache[i-1][j]\n    \nprint(cache[10][2])\n```\n\n---\n\n## 문제 풀이\n\n모든 Dynamic Programming 문제를 풀기 위해서 거쳐야 하는 단계는 총 3단계입니다.\n\n1. **문제를** **정의**한다.\n2. **점화식**을 찾는다.\n3. **시간 복잡도**를 만족하는지 확인한다.\n4. **공간 복잡도**를 만족하는지 확인한다.\n\n문제를 정의하고, 점화식을 찾을 때에 나타나는 대략 4가지 유형을 나누어 보았습니다. 제가 만든 분류기준이니 공식적이지는 않습니다.\n\n### 1. 자신의 Subproblem으로만 표현되는 유형\n\n**A = operate(sub A, sub A)와** 같은 형태로 나타나는 경우를 말한다. 이 경우에는 문제의 재정의가 필요없이 바로 점화식을 작성하면 됩니다. 이런 유형의 문제가 위에서 살펴보았던 combination, fibonacci가 대표적입니다. 가장 기본적인 예시를 풀어봅시다.\n\n> **백준 11726**  \n\n\\*문제를 읽고 오시기 바랍니다.\n\n[11726번: 2×n 타일링](https://www.acmicpc.net/problem/11726)\n\n먼저 이 문제는 2xN 평면에 타일을 채울 수 있는 경우의 수를 찾는 것이 목표입니다.\n\n따라서, $cache[n] = \\text{2xN을 채울 수 있는 경우의 수}$라고 정의하겠습니다.\n\n또한, 규칙을 찾아보면 해당 값은 다음과 같은 pattern을 가진다는 것을 알 수 있습니다.\n\n![tile_2_1](/images/tile_2_1.jpeg)\n\nf(n)의 처음 시작을 세로 block으로 시작하면, 다음 block들의 경우의 수는 모두 이전에 구한 경우의 수와 같고, 처음 block을 가로 block으로 설정하면, 위에 block을 놓으면 아래도 가로로 놓는 것이 강제됩니다. 따라서, 가로로 위 아래를 두는 수 밖에 없고, 이렇게 두면 이전전에 두었던 것과 동일한 형태로 놓는 경우의 수만큼의 경우를 갖게 됩니다. 따라서, 결론상 현재의 block의 경우의 수는 이렇게 두 개의 경우의 수의 합으로 정의할 수 있는 것입니다.\n\n> 관련 유형 : 1463, 11727, 11052, 16194, 15988, 1699, 2193\n\n#### 2\\. 문제의 재정의가 필요한 유형\n\n**A = operate(B), A' = operate(sub B, sub B)와** 같은 형태로 나타나는 경우를 말한다. 이와 같은 유형은 기존에 제시된 문제에 특정 조건을 추가하여, 최종값을 구한 후에 이를 이용해서 답을 구하는 방식입니다. 이 경우에는 문제를 다시 정의해야 하기 때문에 다소 어려울 수 있습니다. 쉬운 예제부터 풀어보겠습니다.\n\n> **백준 1912**\n\n[1912번: 연속합](https://www.acmicpc.net/problem/1912)\n\n이 문제는 점화식으로 나타기가 어렵습니다. 따라서, 약간 문제를 바꾸어서 나타내야 합니다. 수열을 A라 하고, 수열의 i번째 원소를 A[i]라고 할 때, A[i]를 마지막 연속 합의 값으로 했을 때, 최댓값을 S[i]라고 합시다. 이 경우에 이전의 연속합이 음수인 경우는 오히려 값이 낮아지기 때문에 이때는 A[i]를 반환하고, 그렇지 않은 경우에는 S[i-1]에 A[i]를 더해서 연속합을 구하면 됩니다. 따라서 다음과 같은 형태가 됩니다.\n\n$$\n\\begin{align}\n  S[i] &= S[i-1] + A[i] (\\text{if } S[i-1] > 0) \\\\\n  &= A[i]\n\\end{align}\n$$\n\n와 같은 형태로 나타낼 수 있습니다. 이를 이용해서, S 중에서 가장 큰 값을 찾으면, 그것이 답이 됩니다. 여기서 S가 cache와 같은 역할입니다.\n\n> 관련 유형 : 11053, 2225\n\n#### 3\\. Problem의 Subproblem과 다른 Subproblem이 연계되는 유형\n\n**A= operate(sub A, sub B), B = operate(sub A, sub B)와** 같은 형태로 나타나는 경우를 말합니다. 이와 같은 유형은 두 개 이상의 subproblem이 서로 연계되기 때문에 이들을 동시에 연산하면서, 진행해야 합니다. 일반적으로는 이중 배열을 이용해서 수행하는 것이 일반적입니다. 이런 내용들을 대게 문제에서 제약사항이 있는 문제에 많이 사용됩니다. 예제를 보면 쉽게 이해가 됩니다.\n\n> **백준 2133**\n\n [2133번: 타일 채우기](https://www.acmicpc.net/problem/2133)\n\n앞 서 풀었던 2xn 타일 문제와 똑같지만, 3xn으로 바뀌었을 뿐이다. 이번에도, 앞에서 부터 한 번씩 경우의 수를 따져보는 것이 중요하다. 먼저 세로를 넣은 경우에는 아래에 가로가 하나 강제되는 것을 볼 수 있다. 그리고, 가로로 넣은 경우에는 세로로 세우거나 가로로 세우는 것을 볼 수 있다. 따라서, 3가지의 경우의 수로 볼 수 있다. 하지만, 우리가 구하고자 하는 모양과는 다른 모양의 조각이 남는 것을 볼 수 있다. 따라서, 우리가 구하고자 하는 것(3xn을 채우는 경우의 수)을 cache[n][0]이라 하고, 그를 위해 부가적으로 해결해야 하는 문제(밑변이 n이고, 윗변은 n-1, 좌는 2, 우는 3인 도형을 채우는 경우의 수)를 cache[n][1]이라고 하자.\n\n그렇게 하면 아래와 같은 점화식을 얻을 수 있다.\n\n![tile_3_1](/images/tile_3_1.jpeg)\n\n하지만, 다른 부가적인 문제에 대한 점화식을 세우지 못했기 때문에, 이에 대한 점화식도 찾아주어야 한다. 왼쪽에 세로를 채우게 되는 경우와 가로를 바로 채우는 경우가 있을 것이다. 해당하는 경우는 각 각 다음과 같이 묘사되고, 점화식도 동일하게 얻을 수 있다.\n\n![tile_3_2](/images/tile_3_2.jpeg)\n\n이제 이를 반복해서 풀어나가면 쉽게 답을 구할 수 있다.\n\n이런 식으로 하나의 subproblem을 풀기 위해서 연계되는 subproblem이 생기는 유형도 존재한다.\n\n> 관련 유형 : 11054, 13398, 1309, 2156, 1149\n\n#### 4\\. 동적계획법을 통해서 얻은 결과값을 추적하는 유형\n\n해당 유형은 상당히 간단하게도 parent라는 별도의 list를 만들어서 구현할 수 있다. 즉, cache의 값을 갱신해줄 때 영향을 준 subproblem의 index를 저장해두는 것이다. 이를 통해서 해당 값이 어디서부터 유래되었는지를 후에 추적하는 것이 가능하다.\n\n> **백준 14002**\n\n [14002번: 가장 긴 증가하는 부분 수열 4\n\n수열 A가 주어졌을 때, 가장 긴 증가하는 부분 수열을 구하는 프로그램을 작성하시오. 예를 들어, 수열 A = {10, 20, 10, 30, 20, 50} 인 경우에 가장 긴 증가하는 부분 수열은 A = {10, 20, 10, 30, 20, 50} 이\n\nwww.acmicpc.net](<https://www.acmicpc.net/problem/14002>)\n\n유형 2와 동일한 풀이로 풀 수 있는 문제이다. 만약, cache값을 수정하는 연산이 발생하면, parent를 변경하면 된다.\n\n---\n\n위에 언급한 모든 풀이는 해당 Github에 존재합니다.\n\n[GitHub - euidong/BOJ: 백준 알고리즘 문제 풀이](https://github.com/euidong/BOJ)\n","slug":"dynamic-programming","date":"2022-04-14 13:51","title":"Dynamic Programming","category":"Algorithm","tags":["Dynamic Programming","BOJ2133","BOJ11726","BOJ14002","BOJ1912","Memoization","Optimal Structural","Overlapping Subproblem","Referential Transparency"],"desc":"Dynamic Programming은 기본적으로 이전에 계산했던 데이터를 여러 번 사용할 때 적은 시간 비용으로 문제를 해결할 수 있는 알고리즘입니다. 이를 정의하기 위해서 Overlapping Subproblem, Optimal Structural 라는 단어를 주로 사용하며 이에 대해 살펴보겠습니다.","thumbnailSrc":"https://euidong.github.io/images/algorithm.png"},{"content":"\n## Intro\n\nGraph란 여러 개의 Vertex(정점)와 그를 잇는 Edge(간선)로 이루어진 형태의 자료 구조를 의미한다.\n\n## 핵심 종류\n\n- 무향 그래프: 방향이 없이 선으로 이어진 그래프\n- 방향 그래프: 방향을 가진 그래프로 한 정점에서 다른 정점으로 가는 방향을 명시한 그래프\n- 가중치 그래프: 각 간선이 가중치를 가지는 형태를 그래프\n- 이분 그래프: 정점을 두 개의 그룹으로 나누었을 때, 각 그룹은 서로 연결되지 않은 점들로만 이루어지는 그래프\n- **방향 비순환 그래프(Directed Acyclic Graph(DAG))**: 어느 정점에서 시작해도 cycle(순환)이 존재하지 않는 형태의 그래프. 이 그래프 형태에 tree(트리)도 해당되며, 이것이 특별한 이유는 선형으로 정렬하는 것이 가능하기 때문이다. ([DFS_위상정렬 참고](/post/DFS))\n\n## Dense vs Sparse\n\n그래프 관련 문제를 해결할 때, 반드시 고려해야 할 점은 해당 그래프가 Dense(밀도가 높은, edge가 많은)한 경우와 Sparse(희귀한, edge가 적은)한 경우를 모두 고려해주어야 한다. 이에 따라서, 시간복잡도가 굉장히 천차만별하게 나타나기 때문이다.\n\n## 표현 방법\n\n> **1. adjacent list(인접 리스트)**\n\n각 정점마다 해당 정점에서 나가는 간선의 목록을 저장해서 그래프를 표현하는 법  \n\n```python\nimport sys\n# N = 정점의 수, M = 간선의 수\nN, M = [int(i) for i in sys.stdin.readline().split()]\nadj = [[] for _ in range(N)]\nfor _ in range(M):\n  a, b = [int(i) for i in sys.stdin.readline().split()]\n  adj[a].append(b)\n  # 무향 그래프에서는 다음과 같이 반대 방향도 추가해주어야 한다.\n  adj[b].append(a)\n```\n\n> **2. adjacent matrix(인접 행렬)**\n\n인접 리스트 방식의 단점은 특정 두 정점이 연결 되었는지를 알기 위해서는 해당 정점과 연결된 모든 정점을 확인해야 한다. 인접 행렬에서는 이를 해결할 수 있다. 연결 여부를 직접 2차원 $V \\times V$ 행렬로 나타내기 때문에 이를 바로 index 조회로 알 수 있다. **하지만,** 메모리를 더 잡아 먹을 수도 있고, 단순히 연결된 정점만 조회하는 연산일 경우에는 오히려 모든 정점을 조회해야 하기 때문에 비용이 증가할 수 있다. (Sparse한 graph일 수록 비용 증가가 크다.)  \n\n```python\nimport sys\n# N = 정점의 수, M = 간선의 수\nN, M = [int(i) for i in sys.stdin.readline().split()]\nadj = [[0 for _ in range(N)] for _ in range(N)]\nfor _ in range(M):\n  a, b = [int(i) for i in sys.stdin.readline().split()]\n  adj[a][b] += 1\n  # 무향 그래프에서는 다음과 같이 반대 방향도 추가해주어야 한다.\n  adj[b][a] += 1 \n```\n","slug":"graph","date":"2022-04-20 12:00","title":"Graph","category":"Algorithm","tags":["자료구조","Graph"],"desc":"Graph란 여러 개의 Vertex(정점)와 그를 잇는 Edge(간선)로 이루어진 형태의 자료 구조를 의미한다.","thumbnailSrc":"https://euidong.github.io/images/algorithm.png"},{"content":"\n## Intro\n\nlist를 갖고 놀 수 있는 능력은 python으로 알고리즘을 풀기 위해서 굉장히 중요한 기술이다.\n여기서는 기본적인 방법에서부터 어떻게 배열을 제대로 갖고 놀 수 있는지를 알아볼 것이다. 여기서는 Python을 활용하지만, 알고리즘 풀이를 목표로 하기 때문에 numpy를 활용하지 않는 방법을 소개합니다. 물론 numpy를 이용하면, 훨씬 쉽게 구현할 수 있습니다.\n\n## 선언\n\npython에서는 list를 통해서 데이터를 모읍니다. 또한, list라는 type 자체가 예약어이기 때문에 아래부터는 arr를 통해서 `list`를 표현합니다.\n\n```python\n# 비어 있는 1차원 배열\narr = []\n\n# 꽉 찬 1차원 배열\nN = 100\narr = [0] * N\n\narr = [0 for _ in range(N)]\n\n# 비어 있는 2차원 배열\narr = [[]]\n\n# 꽉 찬 2차원 배열\nN = 100\nM = 100\n\narr = [[0 for _ in range(M)] for _ in range(N)]\n```\n\n여기서 유의해야할 점은 2차원 배열에서 꽉 찬 배열을 만들기 위해서 반드시 for 문을 통해서 생성해야 한다는 것이다. 1차원 배열을 생성할 때 사용했던 곱하기 연산을 통한 배열의 요소 복사는 불가능하다. (ex, `[[0] * M] * N`, `[[0] * M for _ in range(N)]`) 왜냐하면, **reference로** 복제되기 때문이다.\n\n## 순환\n\npython의 가장 기본적인 순환 방법은 `for element in arr` 구문을 이용하는 것이다. 이를 기본적으로 사용하면서, 사용하기에 유용한 순환 방법은 다음과 같은 것들이 있다.\n\n```python\n# (1)\nfor element in arr:\n  print(element)\n\nfor idx in range(len(arr)):\n  print(arr[idx])\n\n# (2)\nwhile len(arr) > 0:\n  element = arr.pop(0)\n  print(element)\n\n# (3)\nlist(map(lambda x: x**2, arr))\n\nfrom functools import reduce\nreduce(lambda acc, cur: acc + cur, arr, 0)\n\nlist(filter(lambda x: x == 1, arr))\n\n# (4)\narr = []\n\ndef call(idx):\n  if len(arr) <= idx:\n    print(arr[idx])\n    return\n  call(idx+1)\n  print(arr[idx])\n```\n\n1. 가장 기본적인 순환 방식이다. 일반적으로 foreach라고 부른다.\n  이 방식은 대게의 경우 효율적이다. 하지만, 사용에 유의해야할 때가 있다. 바로, 내부 element의 추가,삭제가 발생하는 경우이다. 따라서, 반드시 내부에서는 순환 중인 배열에 대한 추가 및 삭제 연산을 수행하지 않도록 하자.\n2. 대게, queue를 순환하는 경우에 많이 사용되게 되는 형태이다.\n  이 경우는 추가, 삭제가 발생할 때에도 안정적으로 동작하도록 할 수 있다.\n3. 이는 위에서 보았던 foreach 형태에서 내부 변수의 변경을 강제로 막을 수 있는 방식이다.\n  이런 식으로 구현하는 것도 에러를 줄이는데에 좋다. 주의해야할 것은 기존 arr와 새로 생기는 arr의 크기가 동일하기 때문에 이에 유의해야 한다.\n  reduce는 반드시 import가 필요하기 때문에 번거롭지만, 배열의 크기를 바꿀 수도 있고, 누적을 수행하는 경우 유용하다.\n  filter를 통해서, 특정 데이터를 filtering 할 때 사용할 수 있다.\n4. 재귀함수의 특징인 call stack을 활용해서 순환하는 방식이다. 이런 식으로 그래프를 순환한다면, 그것이 DFS이다.\n\n## 자르기\n\npython의 장점 중 하나가 자르기(slicing)가 매우 쉽다는 것이다.\n배열 내부에 `:`을 통해서 시작점(start index), 끝점(end index), 그리고 순서(order)를 명시하는 방식으로 배열을 쉽게 변환하는 방법을 제공한다.\n또한, 이 방식을 사용해도, 기존의 list는 변형되지 않고, 잘라진 list를 반환한다는 것을 기억하자.\n\n### 1차원 자르기\n\n```python\narr = [1,2,3,4,5]\n\narr[1:3:1] # [2,3]\narr[1:3] # [2,3] <-- 생략 시 순서는 기본적으로 1\n\narr[1:5] # [2,3,4,5]\narr[1:] # [2,3,4,5] <-- 생략 시 끝점은 기본적으로 가장 끝점\n\narr[0:] # [1,2,3,4,5]\narr[:] # [1,2,3,4,5] <-- 생략 시 시작점은 기본적은 가장 첫점\n```\n\n### 2차원 자르기\n\n2차원 배열을 자르는 것은 numpy를 사용하지 않는다면, 어쩔 수 없이 for문을 작성해서 잘라주어야 한다.\n\n```python\narr = [\n  [1,2,3,4],\n  [5,6,7,8],\n  [9,10,11,12],\n  [13,14,15,16]\n]\n\n# arr의 a[0~2][0~2]를 가져오고 싶다고 하자.\nsliced_arr = [line[:2] for line in arr[:2]]\n```\n\n물론 `arr[:2][:2]` 이런식으로 쓰고 싶겠지만, 이를 수행하면, arr을 [:2] slicing한 결과물 `[[1, 2, 3, 4], [5, 6, 7, 8]]`을 다시 slicing하여 동일하게 `[[1, 2, 3, 4], [5, 6, 7, 8]]`가 나오게 된다. 따라서, 위와 같이 for문을 이용하는 형식으로 바꿔주는 것이 일반적이다.\n\n## 복제\n\n기본적으로 복제는 두 가지 종류가 존재한다. 하나는 대상 자체를 모두 복사하는 것이고, 하나는 사실상 해당 배열에 또 다른 이름을 붙여주는 것이다.\n기본적으로 우리가 다음과 같이 하면 변수가 복제되기 때문에 배열도 똑같이 복사될 것이라고 생각하지만 실상은 그렇지 않다.\n\n```python\n# (1)\na = 3\nb = a\n\n# (2)\narr = [1,2,3,4,5]\ncopy = arr\n```\n\n일반 변수에 `=` 연산을 사용한다면, 값을 복사하여 target에게 대입해주는 것이 맞다. 하지만, 배열에서는 변수가 가르키는 것은 배열이 존재하는 주소를 가르킨다. 즉, `arr`이라는 구역에 변수가 있는 것이 아니라 변수가 있는 주소를 가지고 있는 것이다. 따라서, 우리가 `=` 을 통해서 `copy`에게 대입해주면, `copy`는 단지 `arr`과 똑같은 주소지를 가르키고 있는 것일 뿐이다. 물론 이렇게 되어도 크게 문제가 되지 않는 경우가 있다. `copy`와 `arr` 모두 절대 변경되지 않을 것이라는 확신하거나 해당 행위 자체를 의도한 경우이다. 하지만, 대게의 경우에는 원본이 회손되기를 원하지 않기 때문에 우리는 별개의 list를 생성하는 방법을 알고 있어야 한다. python에서는 이를 위해 slicing을 이용하는 것이 일반적이다.\n\n```python\n# 1차원 배열\narr = [1,2,3,4,5]\ncopy = arr[:] \n\n# 2차원 배열\narr = [\n  [1,2,3,4],\n  [5,6,7,8],\n  [9,10,11,12],\n  [13,14,15,16]\n]\ncopy = [line[:] for line in arr]\n```\n\n2차원을 복사할 때에도 `arr[:]`을 쓰고 싶겠지만, 이렇게 하게 되면, 내부에 있는 배열은 모두 주소를 복사하는 것이기 때문에 똑같은 별명을 붙여주는 것과 똑같이 동작한다.\n\n## modulo\n\nlist에서는 modulo 연산이 중요하다. 애초에 배열의 index가 0에서 시작하는데, 이것은 modulo 공간에서의 가장 큰 특징이기도 하다. 만약, 우리가 특정 배열을 반복해서 시계방향, 반시계방향 처럼 순환할 일이 생긴다면, modulo 연산을 반드시 기억해야 한다.\n\n```python\narr = [1,2,3,4,5]\nidx = 0\nwhile True:\n  print(arr[(idx) % len(arr)])\n  idx+=1\n```\n\n## 반전\n\n이전에 보았던 slicing의 응용을 통해서 쉽게 반전이 가능하다.\n\n```python\n# 1차원 배열\narr = [1,2,3,4,5]\nreversed_arr = arr[::-1]\n\n# 2차원 배열\narr = [\n  [1,2,3,4],\n  [5,6,7,8],\n  [9,10,11,12],\n  [13,14,15,16]\n]\n\n# 좌우 반전\nreversed_arr = [line[::-1] for line in arr]\n# 상하 반전\nreversed_arr = [line[:] for line in arr[::-1]]\n```\n\n## 회전\n\n회전은 2차원 배열에서만 의미있으므로, 해당 연산만 다룹니다.\n회전은 총 두 가지 종류가 있을 수 있다.\n> **1. 시계 또는 반시계 방향으로 1칸 이동하는 연산**\n\n```python\narr = [\n  [1,2,3,4], \n  [5,6,7,8], \n  [9,10,11,12], \n  [13,14,15,16],\n  [17,18,19,20],\n  [21,22,23,24]\n]\nN = len(arr)\nM = len(arr[0])\n\n# 시계 방향\n# 시계 방향 이동 시의 이동 정도\ndy = [0, 1, 0, -1]\ndx = [1, 0, -1, 0]\n\nrotated_arr = [[-1 for _ in range(M)] for _ in range(N)]\nfor i in range(min([N, M]) // 2):\n  cursor = (i, i+1)\n  prev = (i, i)\n  rotated_arr[i][i] = arr[i+1][i]\n  d = 0\n  while True:\n    y = cursor[0] + dy[d]\n    x = cursor[1] + dx[d]\n    if -1 + i < y < N - i and -1 + i < x < M - i:\n      rotated_arr[cursor[0]][cursor[1]] = arr[prev[0]][prev[1]]\n      prev = (cursor[0], cursor[1])\n      cursor = (y, x)\n    else:\n      d += 1\n      if d == 4:\n        break\n\n# 반시계 방향\n# 반시계 방향 이동 시의 이동 정도\ndy = [1, 0, -1, 0]\ndx = [1, 0, 0, -1]\n\nrotated_arr = [[-1 for _ in range(M)] for _ in range(N)]\nfor i in range(min([N, M]) // 2):\n  cursor = (i+1, i)\n  prev = (i, i)\n  rotated_arr[i][i] = arr[i][i+1]\n  d = 0\n  while True:\n    y = cursor[0] + dy[d]\n    x = cursor[1] + dx[d]\n    if -1 + i < y < N - i and -1 + i < x < M - i:\n      rotated_arr[cursor[0]][cursor[1]] = arr[prev[0]][prev[1]]\n      prev = (cursor[0], cursor[1])\n      cursor = (y, x)\n    else:\n      d += 1\n      if d == 4:\n        break\n```\n\n예제 - [백준 16926](https://www.acmicpc.net/problem/16926)\n\n>**2. $90^{\\circ}$, $180^{\\circ}$, $270^{\\circ}$ 회전 연산**\n\n해당 연산의 keypoint는 연산이 점화식 형태로 표현된다는 점이다. (A=After, B=Before, size=(NxM))\n\n- $90^{\\circ}$ : `A[i][j] = B[j][N-1-i]`\n- $270^{\\circ}$ : `A[i][j] = B[M-1-j][i]`\n- $180^{\\circ}$ : `A[i][j] = B[N-1-i][M-1-j]`\n\n```python\narr = [\n  [1,2,3,4], \n  [5,6,7,8], \n  [9,10,11,12], \n  [13,14,15,16],\n  [17,18,19,20],\n  [21,22,23,24]\n]\nN = len(arr)\nM = len(arr[0])\n\n# 90도\nrotated_arr = [[-1 for _ in range(N)] for _ in range(M)]\nfor i in range(M):\n  for j in range(N):\n    rotated_arr[i][j] = arr[N-1-j][i]\n\n# 270도\nrotated_arr = [[-1 for _ in range(N)] for _ in range(M)]\nfor i in range(M):\n  for j in range(N):\n    rotated_arr[i][j] = arr[j][M-1-i]\n\n# 180도\nrotated_arr = [[-1 for _ in range(M)] for _ in range(N)]\nfor i in range(N):\n  for j in range(M):\n    rotated_arr[i][j] = arr[N-1-i][M-1-j]\n```\n\n예제 - [백준 20327](https://www.acmicpc.net/problem/20327)\n","slug":"list","date":"2022-04-26 21:10","title":"List 갖고 놀기","category":"Algorithm","tags":["List","Python","순환","복사","자르기","반전","회전"],"desc":"list를 갖고 놀 수 있는 능력은 python으로 알고리즘을 풀기 위해서 굉장히 중요한 기술이다.여기서는 기본적인 방법에서부터 어떻게 배열을 제대로 갖고 놀 수 있는지를 알아볼 것이다. 여기서는 Python을 활용하지만, 알고리즘 풀이를 목표로 하기 때문에 numpy를 활용하지 않는 방법을 소개합니다. 물론 numpy를 이용하면, 훨씬 쉽게 구현할 수 있습니다.","thumbnailSrc":"https://euidong.github.io/images/algorithm.png"},{"content":"\n## Intro\n\n우리가 자료를 저장하기 위해서는 여러가지 방법이 필요하다. 그 중에서도 연관성을 가지는 데이터를 정리하는 경우에는 선형적인 list만으로는 너무나 부족할 수도 있다. 하지만, Graph를 이용하기에도 데이터의 양이 방대해지고, 규칙이 없기 때문에 원하는 데이터를 찾는 연산에서 많은 시간을 소모하게 된다.\n\n따라서, 보다 규칙적인 형태를 가지면서, 각 지점간의 관계를 가지고, 더 안정적인 구조를 찾기 위해서 고안된 것이 트리이다.\n\n## Tree\n\n트리(tree)란 그래프의 일종으로, 하나의 정점(root) 자체를 의미하거나 또 다른 독립된 (sub)트리를 directed edge(방향 간선)를 이용해서 연결한 자료구조를 말한다.\n\n![Tree's Recursive form](/images/tree1.jpeg)\n\n언뜻 보기에 굉장히 추상적인 표현일 수 있지만, 위와 같은 **재귀적 정의**를 기억하는 것도 많은 도움이 된다.\n\n이를 좀 더 쉽게 설명하자면, 기본적으로 트리는 방향을 가진 간선으로 이루어진 그래프에서 다음과 같은 요소를 가지고 있을 경우를 트리라고 말한다.\n\n1. 루트(root)라는 다른 정점을 가진다.\n2. 루트를 제외한 모든 정점은 해당 정점으로 가는 간선(edge)이 단 하나이다.\n3. 그렇기에 루트에서 모든 정점으로 연결되는 간선들의 경우의 수도 단 하나이다.\n\n![Tree's Normal form](/images/tree2.jpeg)\n\n이를 이해했다면, 앞 서 살펴보았던 재귀적 정의도 이해가 되었는지 다시 한 번 확인하고 가자.\n\n**위와 같이 트리에서 루트에 연결된 서브 트리는 마치 하나의 독립적인 바구니라고 볼 수도 있다.** 트리에서는 연결된 subtree가 서로 독립적이기 때문에, 독립적인 바구니에 담는 규칙을 마음대로 정하여 독립적인 특징이 있는 데이터를 **분류**하기에 적절한 구조를 가지고 있다.\n\n## 용어\n\n- 깊이(depth) : 트리의 최대 높이를 의미한다. 대게 루트의 높이를 0으로 보기 때문에 노드가 2개라면, 깊이가 1인 걸로 본다. 하지만, 이는 구현자의 마음에 따라 다르게 구현할 수 있다.\n- 부모(parent) : 특정 정점을 기준으로 자신을 가르키는 간선을 가진 정점을 말한다. 즉, 트리의 구조에서 상위에 있는 노드라고 할 수 있다.\n- 자식(child) : 특정 정점을 기준으로 자신에서 출발하는 간선에 연결된 정점을 말한다. 즉, 트리의 구조에서 하위에 있는 노드라고 할 수 있다.\n- 조상(ancestor) : 특정 정점을 기준으로 자신으로 오는 경로가 존재하는 정점을 말한다. 즉, 트리의 구조에서 부모에서 부터 루트까지에 경로의 모든 노드가 이에 포함된다.\n- 루트(root) : 부모가 없는 최상단의 정점을 의미한다.\n- 리프(leaf) : 자식이 없는 최하단의 정점들을 의미한다.\n- 서브트리(subtree) : 트리의 각 정점은 해당 정점을 루트로 하는 트리라고 볼 수 있다. 이러한 본래 트리에 존재하는 내부 트리를 서브트리라고 한다.\n\n## Binary Tree\n  \n모든 정점의 자식의 크기가 2 이하로 정해진 트리를 이진 트리(Binary Tree)라고 한다.\n\n- Skewed Binary Tree  \n  이진 트리에서 같은 depth에 있는 정점이 단 하나 밖에 없는 경우를 말한다. 마치 Linked List와 같은 형태이다. 이는 트리의 목적 중 하나인 분류라는 기능을 적절히 수행하지 못하는 형태이기 때문에 대게 좋지 않은 형태로 본다.\n\n![skewed tree](/images/skewed-tree.png)\n\n- Balanced Binary Tree  \n  균형 잡힌 이진 트리로 좌우의 depth가 최대 1까지만 차이가 나는 경우를 의미한다.\n\n![balanced tree](/images/balanced-tree.png)\n\n- Full Binary Tree  \n  정점이 가질 수 있는 자식의 수가 0 아니면 2로 제한되는 형태의 이진 트리를 의미한다. 그렇기에 기본적으로 균형 잡힌 형태의 트리가 생길 수 밖에 없다.\n\n![full tree](/images/full-tree.png)\n\n- Complete Binary Tree  \n  균형잡힌 트리이면서 정점이 반드시 왼쪽부터 채워지는 트리를 말한다. 해당 트리의 가장 큰 특징은 이를 Array로 표현하기에 최적화되어있다는 점이다. 이는 후에 있을 **구현법** 파트에서 더 자세히 알아본다. 따라서, Complete Tree를 기억하고 가자.\n\n![complete tree](/images/complete-tree.png)\n\n- Perfect Binary Tree  \n  Complete Tree와 가장 혼돈되는 개념이다. 이는 모든 이진 트리가 빈틈없이 꽉 채워진 경우를 말한다. 즉, leaf 노드의 자식의 갯수가 모두 0일 때이다.\n\n![perfect tree](/images/perfect-tree.png)\n\n## 속성\n\n해당 속성은 정의에 의해서 파생되는 내용이다. 직접 상상해서 왜 안되는지를 생각해보자.\n\n- 루트에 연결된 subtree 간에는 간선이 존재하지 않는다.\n- Cycle이 존재하지 않기 때문에, Graph의 종류 중 하나인 DAG에 속한다.\n- 정점과 정점 사이의 경로가 있다면, 해당 경로는 유일한 경로이다.\n- 형제 노드로 이동할 수 있는 방법은 존재하지 않는다.\n\n## 구현법\n\n트리는 표현하기 위해서 대표적으로 두 가지를 사용한다. 리스트를 이용한 구현 방법과 구조체(or Class)를 이용한 구현이다.\n\n### 1. 구조체\n\n일반적으로 가장 널리 사용하는 방법이다. 먼저 Tree라는 구조체(or Class)를 정의한다.\n\n```python\nclass Tree:\n  def __init__(self, value, subtrees):\n    self.root = value\n    self.subtrees = subtrees\n    # 필요에 따라서, 부모의 정보가 필요한 경우에는 parent를 저장할 수도 있다.\n```\n\n이진 트리에 경우에는 단 두 개의 subtree로 정해져있기 때문에 아래와 같은 형태를 빈번히 사용한다.\n\n```python\nclass Tree:\n  def __init__(self, value, left, right):\n    self.root = value\n    self.left = left\n    self.right = right\n```\n\n이를 통해서 각 Tree type의 변수는 모두 루트 값과 subtree들을 포함하게 된다.\n\n### 2. 리스트\n\n트리의 각 정점의 유일한 특징을 이용하여 표현한다. depth와 왼쪽에서부터 몇 번째 인지를 나타내는 index를 같이 사용하면, 정점의 위치를 특정하여 표현할 수 있다.\n따라서, 다음과 같은 식으로 Tree의 정점을 표현하는 것이다.\n\n만약, 이진 트리와 같은 경우에는 아래와 같은 식으로 해당 노드가 어느 곳에 존재하는지를 찾을 수 있다.\n\n1. $\\text{tree}[2^{i} + j] = $ depth가 i이고, 왼쪽에서 j만큼 떨어진 정점이 지닌 값\n2. $\\text{tree}[i]$의 자식은 $\\text{tree}[i \\times 2]$ 또는 $\\text{tree}[i \\times 2 + 1]$이다.\n\n![tree-to-list](/images/tree-to-list.jpeg)\n\n이때 반드시 주의할 점은 시작 점은 0이 아니라 1이 되도록 해야한다는 점입니다.\n\n이는 트리의 노드의 수가 제한되어 있는 경우에만 사용할 수 있으며, 효율적으로 사용하기 위해서는 최대한 Complete Tree형태를 갖추어야 한다. 왜냐하면, 왼쪽에서부터 데이터를 채우기 때문에 Complete Tree 형태의 구조여야지만 최대 효율을 낼 수 있는 것이다.\n\n## Binary Search Tree\n\n검색 트리(Search Tree)란 트리를 이용해서 검색을 쉽게하기 위해서 **일정한 규칙**에 따라서 데이터를 저장한다. 이 방식은 해당 자료를 조회하는 과정이 굉장히 단순화 될 수 있다는 장점을 가진다. 그 중에서도 Binary Search Tree는 일정한 규칙을 `데이터의 삽입 시에 현재 위치에 정점보다 데이터가 크다면 오른쪽, 작다면 왼쪽에 배치시킨다.`로 정의한 경우를 말한다. 이렇게 데이터를 저장하게 되면, 마치 이진 검색을 통해서 데이터를 찾는 것과 같은 효과를 가질 수 있다. 왜냐하면, 후에 내가 데이터를 찾을 때 현재 위치의 값을 확인하고 해당 값보다 찾고자 하는 값이 크다면 반드시 오른쪽에 있을 것이라는 확신을 가질 수 있기 때문이다. 이를 통해서, 검색 범위를 줄일 수 있기 때문에 우리가 마치 이진 검색을 하는 것처럼 데이터의 범위를 한정할 수 있다. 이게 앞에서 설명했던 트리가 가지는 분류의 기능이다. 기존의 리스트에서는 정렬을 통해서 index 번호가 순서라는 정보를 담고 있었다면, Binary Search Tree에서는 좌우 subtree가 대소 비교라는 정보를 갖고 있는 것이다.\n\n하지만, 위에서 살펴보았다시피 유의할 점은 데이터가 좌우로 골고루 퍼져 있어야 한다는 점이다. 만약, 데이터가 좌축에만 쏠려있다면(skewed), 결국에는 분류로 얻는 이득이 없어진다. 따라서, 검색 시에는 시간 복잡도가 $O(N~\\log{N})$ 이다.\n\n### Skew 해결책\n\n여기서는 Skew에 대한 자세한 해결책을 제시하지 않는다. 아래 키워드를 제시하였으니 이를 검색하여 찾아보길 권장한다. (후에 정리할 시간이 있다면, 정리하겠다.)\n\n- 각 정점에 우선순위를 랜덤 값으로 지정하고, 각 subtree의 root는 해당 subtree에서의 랜덤 값의 총합을 우선순위로 가지게 하여 특정 트리가 데이터의 순서에 의해서 skew되는 현상을 막기 우히나 방법이 있다.(Treap)\n- Tree의 Skew가 발생할 시에 rotation이라는 방법을 통해서 Skew를 해결 시키는 방법도 있다. (AVL Tree)\n- 빨강과 검정이라는 이진 정보를 추가 활용하여 해결하는 방법도 있다. (Red Black Tree)\n\n## Advanced Topic\n\n아래 설명된 Tree에 대한 정보는 앞으로 차근차근 포스팅할 계획이다.\n\n- DFS Tree\n- Segment Tree\n- Fenwick Tree\n- Heap\n","slug":"tree","date":"2022-04-30 17:58","title":"Tree","category":"Algorithm","tags":["자료구조","Graph"],"desc":"우리가 자료를 저장하기 위해서는 여러가지 방법이 필요하다. 그 중에서도 연관성을 가지는 데이터를 정리하는 경우에는 선형적인 list만으로는 너무나 부족할 수도 있다. 하지만, Graph를 이용하기에도 데이터의 양이 방대해지고, 규칙이 없기 때문에 원하는 데이터를 찾는 연산에서 많은 시간을 소모하게 된다.따라서, 보다 규칙적인 형태를 가지면서, 각 지점간의 관계를 가지고, 더 안정적인 구조를 찾기 위해서 고안된 것이 트리이다.","thumbnailSrc":"https://euidong.github.io/images/algorithm.png"},{"content":"\n## Intro\n\n해당 Posting에서는 Modulo연산의 정의와 특징을 이해하고, 이를 이용한 알고리즘을 소개합니다.\n\n사칙연산과 같은 연산자입니다. 하지만, modulo 연산은 기존 사칙연산과는 다른 다양한 특징을 가지기 때문에, 이를 정리하고 이해하는 것은 중요합니다.\n\n## Modulo 연산\n\n우선 modulo 연산이란 무엇인지부터 알아야 합니다.\n\n$$a = bq + r$$\n\n$$r = a \\mod b = a \\mod q$$\n\nex.\n\n1. $100 \\mod 3 = 1$\n2. $12 \\mod 32 = 12$\n3. $123 \\mod 11 = 2$\n4. $1 \\mod 1 = 0$\n\n로 정의할 수 있습니다.\n\n쉽게 말해서, a와 b에 대해서, 나눗셈한 나머지를 반환하는 연산자입니다.\n\n이는 여러 programming language에서는 % 표기로 나타내는 경우가 많습니다. 따라서, 아래에서 부터는 %로 표기합니다.\n\n이 연산자는 기타 여러 알고리즘에서 유용하게 사용되기 때문에 특징을 알아두는 것이 좋습니다.\n\n## 특징\n\n1. 연산 결과는 0보다 크거나 같고 연산을 수행하는 값($b$)보다는 작습니다.\n2. 만약, modulo 연산을 했을 때, 결과가 같다면, 두 정수는 **합동**이라고 합니다. 이에 따라, 합동인 정수는 무한히 많습니다.\n\n## 연산 특징\n\n1. **덧셈의 항등원(0)이 존재합니다.**  \n    $(A + 0) \\% C = A \\% C$\n2. **덧셈의 역원(-A = C-A)이 존재합니다.**  \n    $-A \\% C = (C - A) \\% C$  \n    ex) $-105 \\% 100 = -5 \\% 100 = 95$\n3. $(A+B) \\% C = \\{(A\\%C) + (B\\%C)\\} \\% C$  \n    ex) $54 \\% 17 = \\{(29\\%17) + (25\\%17)\\} \\% 17 = (12+8) \\%17 = 3 $\n4. $(A-B) \\% C = \\{(A\\%C) - (B\\%C)\\} \\% C$  \n    ex) $54 \\% 17 = \\{(70\\%17) - (16\\%17)\\} \\% 17 = (2-16) \\%17 = -14 \\% 17 = 3 $  \n5. $(A \\times B) \\% C = \\{(A\\%C) \\times (B\\%C)\\} \\% C$  \n    ex) $960 \\% 17 = \\{(20\\%17) \\times (18\\%17)\\} \\% 17 = (3 \\times 1) \\%17 = 3 $\n6. **정수 k, p에 대하여, p가 k의 약수라면,**  \n    $A^k \\% C = (A^{k \\over p}\\%C)^p \\% C$  \n    ex) $2^{10}(=1024) \\% 29 = (2^5(=32) \\% 29)^2 \\%29 = 3^2 \\% 29 = 9$\n7. **곱셈의 항등원(1)이 존재합니다. ($ C \\ge 2$)**  \n    $A \\times 1 \\% C = A \\% C$\n8. **곱셈의 역원(A^{-1})가 존재합니다.**  \n    $A \\times A^{-1} \\% C = 1 $  \n    하지만, 이를 구하는 것은 직접 해보는 수밖에 없습니다.\n9. **곱셈의 역원을 통해서 나눗셈을 정의할 수 있습니다.**  \n    $ ({B \\over{A}} ) \\% C = B \\times A^{-1} \\% C$\n\n위와 같은 특징들 때문에, 수의 범위를 제한하는 문제를 푼다고할 때, 굉장히 유용하게 이를 이용할 수 있습니다. 왜냐하면, modulo 합동끼리는 사칙연산의 여러 특징들을 모두 사용할 수 있기 때문입니다.\n\n교환 법칙, 결합법칙, 역원, 항등원이 모두 존재합니다.\n\n또한, 만약, **나누는 수가 만약 소수라면**, 나눗셈을 더 쉽게 정의할 수 있습니다.\n\n바로 **Fermat's little theorem**(페르마의 소정리)를 활용하는 것입니다.\n\n이에 따르면, $A^{n-1} \\% C = 1$이라는 것입니다.\n\n이를 통해서, 우리는 아래를 증명할 수 있으며,\n\n$$ A \\times A^{-1} \\% C = 1  % C $$\n\n$$ A \\times A^{-1} \\% C = A^{n-1} \\% C $$\n\n$$ A^{-1} \\% C = A^{n-2} \\% C $$\n\n결론상 다음과 같이 나눗셈을 변형할 수 있습니다.\n\n$$ {A\\over B} \\% C = A\\times B^{n-2} \\% C$$\n\n## 유클리드 호제법\n\n최대공약수(GCD), 최소공배수(LCM)를 구하는 문제에서 가장 단골로 사용되는 알고리즘입니다.\n\n해당 알고리즘의 동작순서는 다음과 같습니다.\n\n1. 큰 수(p)로 작은 수(q)를 modulo 연산하여, 결과값(r)을 얻습니다.\n2. r이 0이라면, q는 최대공약수입니다.\n3. 그렇지 않다면, q와 r을 갖고, 1로 돌아가서 다시 시행합니다.\n\n이 결과를 통해서, 최대공약수(GCD)를 구할 수 있고, 모두가 알다시피, 최소공배수는 ${p \\times q}\\over {gcd}$이므로, 쉽게 유도가 가능합니다.\n","slug":"modulo","date":"2022-04-01 09:00","title":"modulo","category":"Algorithm","tags":["Modulo","나머지"],"desc":"해당 Posting에서는 Modulo연산의 정의와 특징을 이해하고, 이를 이용한 알고리즘을 소개합니다.사칙연산과 같은 연산자입니다. 하지만, modulo 연산은 기존 사칙연산과는 다른 다양한 특징을 가지기 때문에, 이를 정리하고 이해하는 것은 중요합니다.","thumbnailSrc":"https://euidong.github.io/images/algorithm.png"},{"content":"\n## Intro\n\n**구간 누적합**을 구하는 경우가 많이 발생한다. 하지만, 이를 저장하기 위해서 너무 많은 공간을 쓸 수는 없다. 예를 들어서 크기가 10,000인 집합에서 누적합으로 만들 수 있는 특정 수의 경우의 수를 구하고자 한다고 가정하자.\n\n이 경우에 우리는 모든 누적합을 저장하기에는 공간이 너무 크다는 것을 알 수 있고, 이를 그렇다고 Brute Force하게 수행하기에도 시간이 충분하지 않을 수도 있다.\n\n따라서, 우리는 효율적으로 누적합 정보를 저장할 수 있는 자료구조를 만들었다.\n그것이 `Segment Tree`와 `Fenwick Tree`이다. 이들을 하나씩 살펴보도록 하자.\n\n## Segment Tree\n\n이전에 tree posting에서 Tree를 표현하는 방법으로 List를 소개하였다. 여기서도 그 방식을 이용해야 하니 잘 알지 못하겠다면, 한 번 보고 오도록 하자. 👉 [posting](/posts/tree)\n\n우선 Segment Tree는 누적합을 표현하기 위한 이진 트리 형태의 자료구조이다. 이전에 트리는 데이터를 분류하기 위해 자주 사용한다고 하였는데, 이곳에서도 동일하다.\n\n이는 트리의 leaf node가 원래 누적합을 배우고자 하는 리스트의 원소가 된다. 그리고 그 부모는 해당 원소들의 합으로 표현된다. 이렇게 하여 root는 전체 리스트의 총합이 되는 형태로 구현하는 것이다.\n\n이러한 자료 구조를 가지게 되면 우리는 두 가지의 장점을 가질 수 있다.\n\n1. 특정 구간에서의 누적합을 굉장히 빠르게 구할 수 있다. ($\\log{N}$)\n2. 업데이트 시에도 깨지지 않고, 이를 빠르게 적용할 수 있다. ($\\log{N}$)\n\n### 누적합 구하기 in segment\n\n우선 해당 트리가 이미 만들어졌다는 가정하에서 어떻게 $\\log{N}$ 만에 **누적합을 찾을 수 있는지**를 확인해보자.\n\n이는 1번째 index b에서부터 6번째 index g까지의 합을 구하는 연산이다.\n\n![segment tree find](/images/segment-tree-find.jpeg)\n\n위에서 부터 탐색을 하기 위해서 다음과 같은 동작을 수행한다.\n\n1. 내가 조회하고자 하는 범위가 해당 지점이 표현하는 범위의 밖이라면, 해당 지점은 의미없으므로, 탐색을 중지한다.\n2. 조회 범위가 해당 지점을 완전 포함한다면, 해당값을 반환한다. (가장 큰 범위를 포함하는 지점에서부터 탐색하기 때문에 조회 범위에 엉뚱한 것이 섞이지 않는다.)\n3. 만약, 그렇지 않다면 해당 지점에 포함된 영역을 더 추출해야 하기 때문에 하위 지점으로 이동한다.\n\n노드 방문 횟수가 대략 $\\log{N}$ 까지 감소하는 것을 볼 수 있다.\n\n### 누적합 갱신 in segment\n\n이제 실제로 **update를** 수행해보자.\n\n5번째 index f에 1을 더하는 연산을 수행하는 그림이다.\n\n![segment tree update](/images/segment-tree-update.jpeg)\n\n위에서 부터 변동사항을 적용하기 위해서 다음과 같은 동작을 수행한다.\n\n1. 내가 추가하고자 하는 위치가 해당 지점이 표현하는 범위의 밖이라면, 해당 지점은 의미없으므로, 탐색을 중지한다.\n2. 추가하고자 하는 값을 해당 지점에 추가한다.\n3. 해당 지점이 leaf 인지 확인하고, 맞다면 종료한다.\n4. 그렇지 않다면, 하위 지점을 더 탐색한다.\n\n### 구현 in segment\n\n업데이트 시에도 복잡한 연산이 없이 바로 내려가면서, 덧셈이 필요한 구역에 더해주는 것으로 쉽게 구현이 가능하다.\n\n```python\nS = [1,2,3,4,5,6,7]\n# tree의 크기는 원래 원래의 배열의 크기보다 큰 2의 제곱수 * 2 - 1이다.\n# 하지만, 이를 더 쉽게 만드는 방법은 간단하게 곱하기 4하는 것이다.\ntree = [0] * (len(S) * 4)\n\n# 트리를 구성하는 함수이다.\n# 루트에서부터 호출하지만, 결과는 밑에서 부터 구하면서 올라온다.\ndef make_seg(start=0, end=len(S) - 1, cursor=1):\n  if start == end:\n    tree[cursor] = S[start]\n    return tree[cursor]\n  mid = (start + end) // 2\n  tree[cursor] = make_seg(start, mid, 2 * cursor) + \\\n                  make_seg(mid + 1, end, 2 * cursor + 1)\n  return tree[cursor]\n\n# 위에서 보았던 누적합을 조회하는 연산이다.\ndef find(left, right, cursor=1, start=0, end=len(S)-1):\n  if left > end or right < start:\n    return 0\n  if left >= start and right <= end:\n    return tree[cursor]\n  mid = (start + end) // 2\n  return find(left, right, cursor * 2, start, mid) \\\n    + find(left, right, cursor * 2 + 1, mid + 1, end)\n\n# 위에서 보았던 누적합을 업데이트 하는 연산이다.\ndef update(idx, diff, cursor=1, start=0, end=len(S) - 1):\n  if idx > end or idx < start:\n    return\n  tree[cursor] += diff\n  if start == end:\n    return\n  mid = (start + end) // 2\n  update(idx, diff, start, mid)\n  update(idx, diff, mid + 1, end)\n\nmake_seg() \nprint(find(1, 6)) # 28\nupdate(3, 5)\nprint(find(1, 6)) # 33\n```\n\n## Fenwick Tree\n\nsegment tree와 동일하게 fenwick tree도 list를 통해서 tree를 표현한다.\n또한, segment tree에서는 기존 배열의 시작점을 어디로 하던 상관없었지만, 구현 상의 편의를 위해서 기존 배열을 왼쪽에서 한 칸 밀어주는 것을 추천한다.\n\n기본적으로 Fenwick Tree는 이진수의 특징을 활용한 연산을 통해서 합을 빠르게 찾을 수 있다. 먼저 Fenwick tree는 다음과 같은 형태로 구조화된다.\n\n![fenwick-tree](/images/fenwick-tree.jpeg)\n\n즉, 해당 수의 약수 중 가장 큰 2의 제곱 수만큼 자신을 포함한 하위 수의 누적합을 포함하는 방식이다. 따라서, 홀수의 경우는 자신만을 누적합으로 가지는 것을 볼 수 있다.\n이렇게 구조화된 데이터는 LSB(Least Significant Bit, 이진수에서 가장 오른쪽에 있는 bit를 의미한다.)라는 특징을 이용해서 누적합과 해당 원소를 포함한 대상들을 찾기에 유용하다.\n\n### 누적합 구하기 in Fenwick\n\n우선 Fenwick Tree는 구간합을 반드시 맨 처음부터 특정 위치까지 구하는 연산만 수행가능하다. 따라서 구간이 처음부터가 아니라면, Fenwick Tree의 조회 연산을 두 번 수행하여 두 값을 빼서 구한다.\n\n> 예시\n\n1. h라는 값을 조회하는 경우  \n  $$\n  \\begin{align}\n      &= origin[8] \\notag \\\\\n      &= sum(8) - sum(7) \\notag \\\\\n      &= fenwick[8] - (fenwick[4 to 7]) \\notag\n  \\end{align}\n  $$\n2. e + f + g의 구간합이 필요한 경우  \n  $$\n  \\begin{align}\n      &= origin[5to7] \\notag \\\\\n      &= sum(7) - sum(4) \\notag \\\\\n      &= (fenwick[4 to 7]) - fenwick[4] \\notag\n  \\end{align}\n  $$\n\n여기서 `sum`을 구현하기 위해서 parameter로 들어온 값의 LSB에서 부터 1을 삭제하면서 진행하면 된다.\n즉, 7이 들어왔다면, 이는 이진수로 $111_{(2)}$이고, 오른쪽에서부터 1을 발견할 때마다 해당 값을 누적합에 축적하고, 삭제하면 된다.\n\n1. 누적합 acc를 0으로 초기화한다.\n2. $111_{(2)}$는 LSB가 1이다. 따라서, 누적합에 fenwick[$111_{(2)} = 7$]를 더한다.\n3. $111_{(2)}$에서 마지막 1을 지운다. (결과값은 $110_{(2)}$)\n4. $110_{(2)}$는 LSB의 다음이 1이다. 따라서, 누적합에 fenwick[$110_{(2)} = 6$]를 더한다.\n5. $110_{(2)}$에서 마지막 1을 지운다. (결과값은 $100_{(2)}$)\n6. $100_{(2)}$는 LSB의 다다음이 1이다. 따라서, 누적합에 fenwick[$100_{(2)} = 6$]를 더한다.\n7. $100_{(2)}$에서 마지막 1을 지운다. (결과값은 $000_{(2)}$)\n8. 결과값이 0이므로 탐색을 종료한다.\n\n![fenwick-tree-add](/images/fenwick-sum.jpeg)\n\n### 누적합 갱신 in fenwick\n\n특정 값에 누적합을 갱신하는 것 역시 간단하게 구현이 가능하다. LSB에서 가장 가까운 1에 1을 더해주는 연산을 더해가면서 업데이트를 수행해주면 된다.\n\n1. $11_{(2)}$는 LSB가 1이다. 따라서, fenwick[$11_{(2)} = 3$]에 값을 더한다.\n2. $11_{(2)}$에서 가장 오른쪽의 1을 더한다. (결과값은 $100_{(2)}$)\n3. $100_{(2)}$는 LSB의 다디음이 1이다. 따라서, fenwick[$100_{(2)} = 4$]에 값을 더한다.\n4. $100_{(2)}$에서 마지막 1을 더한다. (결과값은 $1000_{(2)}$)\n5. $1000_{(2)}$는 LSB의 다다다음이 1이다. 따라서, 누적합에 fenwick[$1000_{(2)} = 8$]에 값을 더한다.\n6. 더이상 더하는 것은 범위 밖이므로 종료한다.\n\n![fenwick-tree-update](/images/fenwick-update.jpeg)\n\n### 구현 in fenwick\n\n```python\norigin = [None, 1,2,3,4,5,6,7,8,9]\nfenwick = [0] * len(origin)\n\ndef update(idx, val):\n  while idx < len(fenwick):\n    fenwick[idx] += val\n    idx += (idx & -idx)\n\ndef sum(idx):\n  acc = 0\n  while idx > 0:\n    acc += fenwick[idx]\n    idx -= (idx & -idx)\n  return acc\n\ndef make_fen(origin):\n  for idx in range(1, len(origin)):\n    update(idx, origin[idx])\n\nmake_fen(origin)\nprint(sum(7) - sum(4)) # 18\nupdate(5, 5)\nprint(sum(7) - sum(4)) # 23\n```\n\n## Versus\n\n둘 다 구간합을 구하기에 적합한 구조이지만 다음과 같은 차이점을 가지고 있다는 점을 명시하자. 상대적으로 활용성이 높은 Segment Tree를 사용하는 것이 대다수 좋을 수 있지만, Fenwick Tree가 가지는 크기의 장점과 코드의 구현이 쉽다는 점은 굉장한 이점이다.\n\n|                    | Segment Tree                                      | Fenwick Tree                  |\n| :----------------- | :------------------------------------------------ | :---------------------------- |\n| find 시간복잡도    | $O(\\log{N})$                                      | $O(\\log{N})$                  |\n| update 시간복잡도  | $O(\\log{N})$                                      | $O(\\log{N})$                  |\n| 공간복잡도(사이즈) | $2^{k + 1}$($2^{k} \\ge$ len(origin))              | len(origin)                   |\n| 활용성             | 구간 내 합 뿐만 아니라 최대, 최소값으로 응용 가능 | **오직 구간 합에만 사용가능** |\n| 구현 코드 길이     | 상대적으로 김                                     | 상대적으로 짧음               |\n","slug":"accumerated-number","date":"2022-04-30 14:09","title":"누적합","category":"Algorithm","tags":["자료구조","Segment Tree","Fenwick Tree"],"desc":"구간 누적합을 구하는 경우가 많이 발생한다. 하지만, 이를 저장하기 위해서 너무 많은 공간을 쓸 수는 없다. 예를 들어서 크기가 10,000인 집합에서 누적합으로 만들 수 있는 특정 수의 경우의 수를 구하고자 한다고 가정하자.이 경우에 우리는 모든 누적합을 저장하기에는 공간이 너무 크다는 것을 알 수 있고, 이를 그렇다고 Brute Force하게 수행하기에도 시간이 충분하지 않을 수도 있다.따라서, 우리는 효율적으로 누적합 정보를 저장할 수 있는 자료구조를 만들었다.그것이 Segment Tree와 Fenwick Tree이다. 이들을 하나씩 살펴보도록 하자.","thumbnailSrc":"https://euidong.github.io/images/algorithm.png"},{"content":"\n## Intro\n\n소수찾기는 굉장히 많은 프로그래밍 책에서 for문 입문 시에 사용하는 예제로 많이 사용된다.\n여기서는 소수를 찾기 위한 알고리즘으로 에라토스테네스의 체를 제시한다.\n\n---\n\n만약 이를 사용하지 않고, 소수를 찾기 위해서는 다음과 같은 식으로 작성하는 것이 일반적이다.\n\n```python\nprimes = [2]\n\nmax_num = 100_000\nfor num in range(3, max_num+1):\n  is_prime = True\n  max_prime = inr(num ** 0.5)\n  for prime in primes:\n    if num % prime == 0:\n      is_prime = False\n      break\n    if prime > max_prime:\n      break\n  if is_prime:\n    primes.append(num)\n```\n\n이는 아래의 수부터 소수를 찾으면서 진행하고, 소수가 있다면 다음에 수를 찾을 때, 이를 이용해서 소수 여부를 확인하는 방식이다.\n(여기서 sqrt를 이용한 이유는 소수가 아니라면 약수는 두 수의 곱으로 나타낼 수 있어야 하므로, 제곱수까지만 확인해도 충분하다.)\n하지만, 이 방식은 소수를 매 반복문마다 반복해서 사용하는 것을 볼 수 있다. 따라서, 이러한 불필요한 동작을 최소화하기 위해서 범위가 정해져 있는 소수를 찾을 경우에는 에라토스테네서의 체를 이용할 수 있다.\n\n에라토스테네스의 체는 배열의 index를 수의 값으로 하고, value를 소수 여부로 나타내는 비트마스크 형태이다. (*비트 마스크 : 0과 1로 이루어진 체로, index를 통해서 무언가를 검색할 때, O(1)로 연산할 수 있는 자료구조)\n\n여기서, 소수를 찾을 때마다 이를 약수로 갖는 모든 수들을 소수가 아니라고 마킹하여 쉽게 O($N^{1\\over{2}}$)만에 해당 범위안의 모든 소수를 판별할 수 있는 알고리즘이다.\n\n```python\nN = 100_000\nis_primes = [True] * (N+1)\n\nfor num in range(2, int(N ** 0.5) +1):\n    if not is_primes[num]:\n        continue\n    for j in range(2 * num, N+1, num):\n        is_primes[j] = False\n\nprimes = [i for i in range(2, n) if is_primes[i] == True]\n```\n","slug":"find-prime","date":"2022-05-01 14:23","title":"소수찾기","category":"Algorithm","tags":["소수찾기","에라토스테네스의 체"],"desc":"소수찾기는 굉장히 많은 프로그래밍 책에서 for문 입문 시에 사용하는 예제로 많이 사용된다.여기서는 소수를 찾기 위한 알고리즘으로 에라토스테네스의 체를 제시한다.","thumbnailSrc":"https://euidong.github.io/images/algorithm.png"}],"Computer Architecture":[{"content":"\n## Intro\n\n해당 내용은 컴퓨터 구조를 더 잘 이해하기 위해서 논리회로의 내용을 축약하여 정리한 포스팅이다.\n\n컴퓨터 회로에서는 모든 연산이 이진수로 이루어진다. 그 이유는 높은 전압이 흐를 때를 1, 그렇지 않을 때를 0으로 정의를 하여 이를 통해서 값을 구분하기 때문이며, 이것이 우리가 이진수 체계에서 컴퓨터 연산을 표현하는 이유이다.\n\n만약, 이를 삼진수 이상으로 표현할 수 있다면, 더 획기전 연산이 가능하겠지만, 비용적인 측면과 물리적인 측면에서 아직은 한계가 있다. (양자 컴퓨터 역시 이와 유사한 원리이다.)\n\n해당 분야에서는 0->1로 바뀌는 것을 active(활성화)시켰다고 한다.\n또한, 0인 상태를 deasserted signal, 1인 상태를 asserted signal이라고 한다.\n\n---\n\n### Truth Table(진리표)\n\n이진수로 표현되는 값의 input과 이를 통한 output을 나타내기 위해서 우리는 진리표를 활요한다. 여기서는 A,B가 input, C가 output이 된다. C는 A와 B를 OR 연산한 결과이다.\n\n| A    | B    | C    |\n| :--- | :--- | :--- |\n| 0    | 0    | 0    |\n| 0    | 1    | 1    |\n| 1    | 0    | 1    |\n| 1    | 1    | 1    |\n\n---\n\n### Gate\n\n그림은 위에서 부터 AND, OR, NOR, NAND, 그리고 input을 뒤집는 inversion Gate를 나타낸 것이다.\n\n![AND Gate](/images/and.png)\n\n![OR Gate](/images/or.png)\n\n![NOR Gate](/images/nor.png)\n\n![NAND Gate](/images/nand.png)\n\n![Inversion Gate](/images/inversion.png)\n\n각 Gate는 다음과 같은 연산을 출력한다.\n\n**1. AND**\n   2 inputs / 1 output\n   | A    | B    | C    |\n   | :--- | :--- | :--- |\n   | 0    | 0    | 0    |\n   | 0    | 1    | 0    |\n   | 1    | 0    | 0    |\n   | 1    | 1    | 1    |\n\n$0 \\cdot0 = 0 \\\\\n0 \\cdot1 = 0 \\\\\n1 \\cdot0 = 0 \\\\\n1 \\cdot1 = 1$\n\n**2. OR**\n   2 inputs / 1 output\n   | A    | B    | C    |\n   | :--- | :--- | :--- |\n   | 0    | 0    | 0    |\n   | 0    | 1    | 1    |\n   | 1    | 0    | 1    |\n   | 1    | 1    | 1    |\n\n$0 + 0 = 0 \\\\\n0 + 1 = 1 \\\\\n1 + 0 = 1 \\\\\n1 + 1 = 1$\n\n**3. NOR**\n   2 inputs / 1 output\n   | A    | B    | C    |\n   | :--- | :--- | :--- |\n   | 0    | 0    | 1    |\n   | 0    | 1    | 0    |\n   | 1    | 0    | 0    |\n   | 1    | 1    | 0    |\n\n$\\overline{(0 + 0)} = 1 \\\\\n\\overline{(0 + 1)} = 0 \\\\\n\\overline{(1 + 0)} = 0 \\\\\n\\overline{(1 + 1)} = 0$\n\n**4. NAND**\n   2 inputs / 1 output\n   | A    | B    | C    |\n   | :--- | :--- | :--- |\n   | 0    | 0    | 1    |\n   | 0    | 1    | 1    |\n   | 1    | 0    | 1    |\n   | 1    | 1    | 0    |\n\n$\\overline{(0 \\cdot0)} = 1 \\\\\n\\overline{(0 \\cdot1)} = 1 \\\\\n\\overline{(1 \\cdot0)} = 1 \\\\\n\\overline{(1 \\cdot1)} = 0$\n\n**5. Inversion(=NOT)**\n   1 inputs / 1 output\n   | A    | C    |\n   | :--- | :--- |\n   | 0    | 1    |\n   | 1    | 0    |\n\n$\\overline{1} = 0 \\\\\n\\overline{0} = 1$\n\n여기서 하나 특별한 개념이 나온다. 바로 Functional Complete이다. 특정 Gate만 가지고, 위에서 제시된 모든 연산을 표현할 수 있으면, 이를 Functional Complete라고 한다. 여기서 우리는 가장 보편적으로 생각할 수 있는 {AND, OR, NOT}는 모두 표현할 수 있다는 것을 알 수 있다. 그런데, 여기서 {NAND} 하나만 가지고 이를 표현할 수 있는데, 아래가 이에 대한 예시이다.\n\n![NAND complete](/images/complete-1.png)\n\n그리고, {NOR}만 가지고도 똑같이 표현가능하다.\n\n![NOR complete](/images/complete-2.png)\n\n동일한 값을 NAND, NOR하면 역수가 나온다는 특징과 [드 모르간의 법칙](https://ko.wikipedia.org/wiki/%EB%93%9C_%EB%AA%A8%EB%A5%B4%EA%B0%84%EC%9D%98_%EB%B2%95%EC%B9%99)에 의해서 이것이 정의된다고 할 수 있다.\n\n---\n\n### Decoder\n\nn bit로 표현할 수 있는 $2^{n}$개의 값을 회선을 통해서 표현하기 위해서 $2^{n}$개의 회선 중에서 단 하나의 값만 active한다.\n\n| input1 | input2 | input3 |\n| :----: | :----: | :----: |\n|   0    |   0    |   0    |\n|   0    |   0    |   1    |\n|   0    |   1    |   0    |\n|   0    |   1    |   1    |\n|   1    |   0    |   0    |\n|   1    |   0    |   1    |\n|   1    |   1    |   0    |\n|   1    |   1    |   1    |\n\n| output1 | output2 | output3 | output4 | output5 | output6 | output7 | output8 |\n| :------ | :------ | :------ | :------ | :------ | :------ | :------ | :------ |\n| 1       | 0       | 0       | 0       | 0       | 0       | 0       | 0       |\n| 0       | 1       | 0       | 0       | 0       | 0       | 0       | 0       |\n| 0       | 0       | 1       | 0       | 0       | 0       | 0       | 0       |\n| 0       | 0       | 0       | 1       | 0       | 0       | 0       | 0       |\n| 0       | 0       | 0       | 0       | 1       | 0       | 0       | 0       |\n| 0       | 0       | 0       | 0       | 0       | 1       | 0       | 0       |\n| 0       | 0       | 0       | 0       | 0       | 0       | 1       | 0       |\n| 0       | 0       | 0       | 0       | 0       | 0       | 0       | 1       |\n\n![Decoder](/images/decoder.png)\n\n---\n\n### Multiplexor(=Selector)\n\nControl에 의해서 선택되어진 Input을 Output으로 내보낸다. 이를 위해서 Input 여러 개와 이 중에 무엇을 선택할지를 의미하는 Selector(=Control) Value을 입력한다.\n형태는 input의 갯수만큼의 AND Gate와 Output Gate, 그리고 Decoder로 이루어진다.\n\n1. Decoder를 통해서 Signal Bit를 나눈다.\n2. 각 Input의 크기만큼 Decoder의 각 Input의 크기를 확장하여 AND 연산을 취한다.\n3. 나온 모든 결과를 OR로 연산한다.\n\n| Input1 | Input2 | Signal | Output |\n| :----- | :----- | :----- | :----- |\n| x      | y      | 0      | x      |\n| x      | y      | 1      | y      |\n\n![Mux](/images/mux.png)\n\n---\n\n### Clock\n\nClock이란 고정된 Cycle time을 주기로 하여 발생하는 신호를 의미한다. 여기서 고정된 Cycle Time은 Clock이 높은 시점과 낮은 시점으로 구분할 수 있다. 우리의 모든 연산은 Clock이 감소하거나 증가하는 그 시점에 동작한다. 이를 `Edge Triggered Clocking`이라고 부른다. 따라서, 우리는 정확히 상태값이 변하는 `edge`에서를 active 상태라고 부르는데 이를 오르는 `edge`로 할지 내려가는 `edge`로 할지는 설계자의 몫이다.\n\n하나의 Clock이 의미하는 것은 특정 상태에서 연산이 이루어져서 다음 단계로 넘어간다는 의미이다. 따라서, Clock Period가 짧을 수록, 다음 상태로 빠르게 넘어갈 수 있다. 하지만, 이를 무한정으로 올리는 것은 불가능하며, 열이 너무 증가하여 회로 전체에 악영향을 줄 수도 있다.\n\n![clock](/images/clock-1.png)\n\n![clock](/images/clock-2.png)\n\n---\n\n### Latches\n\n걸쇠를 의미하며, 값을 저장해놓는다는 의미를 가진다. 이를 이용해서 Memory와 같은 저장장치를 만들 때 사용한다. 두 가지 형태가 존재하니 하나씩 알아보자. (물론 자세히 알면 좋겠지만 필자는 이정도 개념이 있다는 정도로만 기억한다.)\n\n> **S-R Latch(Set Reset Latch)**\n\nS와 R이 모두 0이면 값이 변하지 않고, Cross되는 위치에 데이터가 저장되게 된다.\nR(Reset)만 1로 하면, 데이터 값이 0으로 초기화된다.\nS(Set)만 1로 하면, 데이터 값이 1로 세팅된다.\nR과 S를 모두 1로 하면 해당 값은 저장이라는 의미를 갖지 못한다.\n\n| S    | R    | Q    |\n| :--- | :--- | :--- |\n| 0    | 0    | keep |\n| 0    | 1    | 0    |\n| 1    | 0    | 1    |\n| 1    | 1    | x    |\n\n![sr-latch](/images/sr-latch.png)\n\n> **D Latch**\n\nClock단위로 데이터를 저장하기 위해서 이와 같은 장치를 이용한다. 하지만, 이는 Clock이 asserted된 상태(1)인 상태에 언제든지 변환된다는 특징을 갖고 있다. Output은 저장되어있는 값과 등일하다.\n\n![d-latch](/images/d-latch.png)\n\n---\n\n## Flip-Flop\n\nClock단위로 데이터를 저장하기 위해서 이와 같은 장치를 이용한다. 하지만, 이는 Clock이 변화하는 edge에서만 상태가 변한다는 특징을 갖고 있다. Output은 저장되어있는 값과 동일하다. 아래는 대표적인 D Flip-Flop이다.\n\n![flip-flop](/images/flip-flop.png)\n\n---\n\n실제로는 Latch보다 Flip Flop을 이용하는 것이 일반적인데, 왜 그렇게 하는 것일까? 이는 우리가 입력을 받을 때, 이를 처리하기 위한 최소하의 시간이 필요하기 때문이다.\n\n이 최소한의 시간은 다음과 같이 정의된다.\n\n$t_\\text{prop} + t_\\text{combinational} + t_\\text{setup} + t_\\text{skew}$\n\n1. $t_\\text{prop}$  : flip-flop 내에서 신호가 처리되는데 까지 걸리는 시간을 의미한다.\n2. $t_\\text{combinational}$ : 실제 연산이 수행되는 부분이다.\n3. $t_\\text{setup}$  : 전기적 신호가 바로 low에서 high로 이동하는 것이 아니기 때문에 이를 setup하는데 걸리는 시간을 의미한다.\n4. $t_\\text{skew}$ : 공정과정에서 완벽하게 만들더라도 각 소자마다 어느정도 차이가 발생하게 되는데 이를 의미한다.\n\n이처럼 이 시간동안 우리는 다른 처리를 수행할 수 없다. 따라서, 이것을 처리하는 동안의 시간을 확보하기 위해서 우리는 Edge에서만 수행하는 방식을 사용하고 있다. 또한, Clock Cycle Time 또한 이보다는 크게 setting하는 것이 일반적이다.\n","slug":"digital-logic-circuit","date":"2022-04-27 23:28","title":"0. 논리회로 요약","category":"Computer Architecture","tags":["논리회로"],"desc":"해당 내용은 컴퓨터 구조를 더 잘 이해하기 위해서 논리회로의 내용을 축약하여 정리한 포스팅이다.컴퓨터 회로에서는 모든 연산이 이진수로 이루어진다. 그 이유는 높은 전압이 흐를 때를 1, 그렇지 않을 때를 0으로 정의를 하여 이를 통해서 값을 구분하기 때문이며, 이것이 우리가 이진수 체계에서 컴퓨터 연산을 표현하는 이유이다.만약, 이를 삼진수 이상으로 표현할 수 있다면, 더 획기전 연산이 가능하겠지만, 비용적인 측면과 물리적인 측면에서 아직은 한계가 있다. (양자 컴퓨터 역시 이와 유사한 원리이다.)해당 분야에서는 0-1로 바뀌는 것을 active(활성화)시켰다고 한다.또한, 0인 상태를 deasserted signal, 1인 상태를 asserted signal이라고 한다.","thumbnailSrc":"https://euidong.github.io/images/default.jpg"},{"content":"\n## Intro\n\nComputer Organization and Design이라는 책을 정리하고 되돌아볼 것이다. 여기서는 가장 기본이 되는 Idea들을 정리할 것이다.\n\n## 1\\. 8 Greate Ideas\n\n컴퓨터 구조를 설계하는 과정에서 중요하게 여겨지는 8가지 핵심 아이디어들이다. 뿐만 아니라 이는 전체적인 컴퓨터 과학에서 중요하다고 볼 수 있는 아이디어들이다. 따라서, 앞으로의 Posting에서 Why라는 의문이 든다면, 아래 8가지 이유 중의 하나로 설명할 수 있다.\n\n1. **Moore's Law**  \n    18 ~ 24 개월마다 컴퓨터 성능의 지대한 영향을 미치는 IC 칩의 성능이 2배씩 성장한다는 Moore의 주장에서 유래하였다. 즉, **컴퓨터의 성능은 지수적으로 빠르게 성장을 하고 있음을 의미한다.** 이로 인해 구조를 설계하는 과정에서도 현재의 IC 칩의 성능에 맞추는 것이 아닌 이보다 더 큰 성능을 타겟으로 설정을 한다.\n2. **Abstraction**  \n    우리 말로 추상화라고 표현하며, 복잡한 하위 내용을 모두 기술하지 않고, 간단하게 표현하여 이를 쉽게 사용할 수 있도록 하는 방식이다. 이를 통해서, **설계 과정에서의 복잡도를 줄일 수 있다.**\n3. **Common Case Fast**  \n    **드물게 일어나는 case보다는 일반적인 case를 빠르게 만듬으로써 성능을 향상시킬 수 있다.** 드물게 일어나는 case는 매우 복잡하고, 해결하기도 난해할 수 있다. 하지만, 대게의 경우 일반적인 case는 간단하다. 이를 최적화하는 것이 전체적인 시스템 성능 향상에 큰 도움이 되는 것은 당연하며 해결도 매우 쉽다.\n4. **Performance via Parallelism**  \n    성능 향상을 위한 방법은 크게 두 가지이다. 하나는 하나의 장치의 성능을 올리는 것이고 또 하나가 바로 **하나의 작업을 여러 명이 동시에 수행하는 방식이다.**\n5. **Performance via Pipelining**  \n    성능 향상을 위한 병렬처리 방식 중에서 가장 유명한 방식이 pipelining이다. 쉽게 생각하면, 분업이라고 할 수 있다. **여러 명이서 하나의 목적을 위해 일을 할 때, 효율적으로 작업하기 위해서 업무를 분담하여 동시에 작업**하는 방식이다.\n6. **Performance via Prediction**  \n    우리는 무슨 작업을 할 때, 아직 결정되지 않은 사항 때문에 기다리는 경우가 있는데, 이것이 어떻게 될지를 **예측하여 기다리지 않고, 미리 진행하자**는 발상에서 나온 것이다. 만약, 이 예측의 적중률이 높다면, 성능 향상에 굉장한 도움을 줄 수 있다.\n7. **Hierarchy of Memories**  \n    컴퓨터의 사용자가 원하는 메모리는 빠르고, 크고, 싸야 한다. 하지만, 빠르기 위해서는 비싸야하고, 크기 위해서도 비싸야 한다. 그래서 생각해낸 방법이 계층화이다. **빠르고, 작은 memory를 위로 쌓고, 느리고, 큰 memory를 아래로 쌓음으로써 비용을 절감**하자는 것이다.\n8. **Dependability via Redundancy**  \n    컴퓨터는 빠르기만 해서 되는 것은 아니다. **신뢰**할 수 있는 시스템을 구축해야 한다. 실패하지 않는 시스템을 구축하는 것은 매우 힘든 일이기 때문에, 우리는 **여분 장치**를 두어 이를 통해서 실패 시에 이를 떠맡을 수 있도록 하는 설계를 해야 한다.\n\n## 2\\. Below Your Program\n\nprogram 밑에는 무엇이 있는가?\n\n우리의 program은 모두 application software이고, 이는 hardware 바로 위에 존재하는 것이 아닌 system software위에서 동작하게 된다.\n\n![kernel](/images/kernel.png)\n\n**System Software**는 Hardware를 직접적으로 제어하거나 computer가 작동하기 위해 필수적이며 기본적인 softwre를 말한다. 그 중에서 가장 대표적인 것이 OS이고 **OS**는 사실상 우리가 보는 Software와 Hardware 간의 interface역할을 한다. 예를 들어, memory 관리, process 관리 등(이는 OS 에서 자세히 배웁시다.)을 수행한다. 반면, **Application** **Software**는 직접적으로 hardware를 관리하거나 필수적인 요소는 아니지만 computer를 통해서 가치있는 작업을 수행하도록 한다. 대표적인 예시가 웹브라우저, word, game 등이 여기에 포함된다.\n\n  그렇다면, 우리가 만든 코드(Application Software)가 어떻게 실행되어질 수 있을까? 이 또한, System Software인 compiler, assembler, linker, loader의 도움을 통해서 실행되어진다. **compiler**는 우리가 고 수준의 언어(C++, Java, 등)로 만든 software code를 Assembly 언어로 변경한다. 그러면, 이를 **Assembler**가 0과 1로 이루어진 기계어로 번역해준다. 해당 작업이 끝나면, **Linker**가 나타나 여러 개로 나뉘어져있던 이 파일과 기존 라이브러리를 하나의 파일로 묶어주는 역할을 한다. 이 작업을 마치고 만들어진 최종 파일을 실행하고자할 때, **Loader**는 이를 memory에 올리는 역할을 한다. 이렇게 실행된 program은 여기서 그치지 않고, memory의 아예 다른 영역에 위치하는 library도 불러와서 사용하는 것이 가능하다. 이것을 **Dynamic Linked Library**(DLL)라고 한다.\n\n![run-process](/images/run-process.png)\n\n이렇게 하나의 코드를 작성하면, 실제로 실행되기까지 여러 작업들을 거쳐야만 한다. 그럼에도 assembly 언어나 기계어를 사용하여 코딩을 하지 않는 이유는 아래 세 가지 이유가 주요하다.\n\n1. 사람이 이해하기 쉽다.\n2. 생산성을 높일 수 있다.\n3. Compiler와 assembly를 통해서 어디서든 돌아가는 프로그램을 제작할 수 있다.\n\n## 3\\. Under the Covers\n\n우리의 컴퓨터는 어떻게 이루어지는가를 크고 얇게 한 번 알아볼 것이다.\n\n- **Input Device** : 우리의 입력을 받는 부분이다. 마우스, 키보드, 터치스크린 등이 있다.\n- **Output Device** : 우리가 출력을 받는 부분이다. 모니터, 프린터 등이 있다.\n- **IC(Integrated Circuits, Chip)** : 집적 회로로 번역되어지며, 통상 우리가 chip이라고 부르는 녀석들이다. 이들은 적게는 수십개 많게는 억 단위 이상에 이르는 양의 transister를 가지고 있고, 이를 통해서 데이터를 저장하거나 처리하는 역할을 할 수 있다. 즉, IC를 통해서 CPU, Memory를 만들 수 있다.\n  - trasistor: 쉽게 말해서 전기를 통해서 on/off를 수행할 수 있는 switch라고 볼 수 있다. 이를 통해서, 데이터를 연산하거나 저장하는 것이 가능하다.\n- **CPU (Central Processor Unit, Processor, MicroProcessor)** : 중앙 처리 장치라는 의미로, 각종 연산과 I/O Device 처리 등의 중심 역학을 수행한다. CPU는 크게 두 개의 요소로 이루어진다.\n  - DataPath : 수학적인 연산을 수행한다.\n  - Control : program의 instruction이 무엇을 요구하는지를 입출력 장치, memory 또는 datapath에 전달합니다.\n- **Memory(RAM(Random Access Memory), main memory, primary memory)** : 실행되고 있는 프로그램이 위치하는 곳이다. 실행되는 프로그램에 대한 정보와 같은 내용을 포함한다고 할 수 있다. 이는 DRAM으로 이루어진다. 또한, Random Access Memory라고 불리는 이유는 어느 위치에 데이터를 저장하고 있어도 해당 데이터를 찾는데 걸리는 시간이 동일하기 때문이다.\n  - DRAM(Dynamic Random Access Memory) : IC chip을 통해서 만들어진다. 여기서 Random Access란 접근할 때, 앞에서부터 차례로 접근하는 것이 아닌 한 번에 바로 짚을 수 있음을 의미한다.\n- **Cache Memory** : 대게 Cache라고도 부르며, Processor 내부에 존재하는 memory라고 볼 수 있다. 즉, 실제 Memory의 buffer 기능을 한다. 여기서는 SRAM을 사용한다.\n\n- SRAM(Static Random Aceess Memory) : DRAM보다는 빠르지만, 집적도가 낮고 더 비싸기 때문에 많이 사용할 수는 없는 chip이다. 하지만, 성능 향상을 위해서 processor 바로 앞에 buffer로써 사용한다.\n- buffer : 자료구조의 queue를 이용한 것으로, 처리를 요청한 대상과 처리를 수행하는 대상 사이에서 데이터를 잠깐 보관하기 위한 장소로 사용된다.\n\n- **Secondary Memory** : main memory는 휘발성이라는 특징을 갖고 있기 때문에 시스템이 종료되어 전기가 더 이상 공급되지 않으면, 모든 데이터는 날라간다. 이를 막기 위해서 그리고 부족한 main memory의 저장공간을 보조하기 위해서 보조 기억 장치를 사용한다. 이것에 사용되는 것은 크게 두 가지 이다.\n  - magnatic disk : 자기 disk를 이용해서 정보를 저장하는 방식이다. 전기가 공급되지 않음에도 정보를 저장하고 있을 수 있다.\n  - flash memory : 반도체를 이용하여 데이터를 저장하며, DRAM보다는 느리지만, 더 싸고 휘발성이 없다.\n- **Instruction Set Architecture(ISA, architecture)** : 0과 1로 이루어진 기계어가 들어왔을 때, 이것이 무슨 의미인지를 나타내는 instruction \bSet에 따라 CPU가 알맞은 연산을 수행하는 architecture이다.\n  - Instruction \bSet : hardware에게 동작을 요청하는 하나의 명령어를 Instruction이라고 한다. 이들이 무슨 역할을 하는지를 정리해놓은 것이 Instruction Set이다. 이를 통해서, Operating System은 hardware에 접근하여 특정 동작을 수행시킬 수 있다.\n  - ABI(Application Binary Interface) : application 단에 programmer가 hardware 작업 등을 수행하기 위하여 호출할 수 있다. 이를 통해서, binary한 동작도 application programmer가 조작할 수 있다. 일반적인 API와 역할이 동일하지만, programming language가 아닌 machine language를 사용하여 구현되기 때문에 hardware 접근 등에 제한이 없다.\n\n## 4\\. Performance\n\n우리가 Computer의 성능을 측정하는 것은 중요하다. 왜냐하면, 이를 지표로 계속해서 computer의 성능을 향상시켜야 하기 때문이다.\n\n그래서 우리는 다음과 같이 표현하는 것이 일반적이다.\n\n$$\\text{Excution Time} = \\text{Clock Cycle Time} \\times {\\text{Number of Instruction}} \\times {CPI}$$\n\n즉, **총 실행 시간**(Execution Time)은 **한 번 Clock이 회전하는데 걸리는 시간**(Clock Cycle Time)에 해당 **program의 instruction 수**(Number of Instruction) 그리고 **하나의 instruction을 처리하는데 걸리는 clock cycle의 횟수**(CPI)라고 볼 수 있다.\n\n즉, 우리가 특정 프로그램을 빠르게 돌리고 싶다면, 다음과 같은 식으로 생각할 수 있다.\n\n1. 한 번 회전하는데 걸리는 시간을 줄이기 위해 클락 frequency를 높인다. **하지만, 회전열로 인해 현재는 frequency를 올리는 것은 포기하고 있다.**\n2. 프로그램을 잘 짜거나 Compiler를 더욱 더 최적화하여 instruction의 수를 줄인다.\n3. 하드웨어를 잘 설계해서 명령 하나를 처리하는데 걸리는 시간(CPI)을 줄인다.\n4. 동시에 여러 CPU를 실행시켜서, 실행을 하는 unit 자체를 더 만드는 방법도 있다.\n\n따라서, 앞으로 우리가 Performance를 올리기 위해서, Compiler를 어떻게 최적화할지를 개략적으로 배우며, 하드웨어를 어떻게 잘 설계할지를 자세히 알아볼 것이다. 또한, Parallelism을 통해서 작업을 더 빠르게 수행하는 방법 또한 다룰 것이다.\n\n---\n\n## \\+ Amdahl's Law\n\n작업의 성능을 개선시켰을 때 이전과 비교하여 얼마나 효율이 증가했는지를 보여주는 지표이다.\n\n$$1\\over{(1-P) + {P\\over{S}}}$$\n\n여기서 개선된 작업이 전체에서 차지하는 비율을 P라고 하고, 해당 작업의 향상된 작업 효율을 S라고 한다.\n\n만약, 전체에 10%를 차지하는 작업을 2배 빠르게 진행한다면,\n\n$${1\\over{(1-0.1) + {0.1\\over{2}}}} = {1\\over{0.95}} \\approx 1.05$$\n\n따라서, 단기간의 성능향상을 하고 싶다면, 비율이 큰 작업의 성능향상을 꾀하는 것이 좋다는 것을 알 수 있다.\n\n## Reference\n\n- David A. Patterson, John L. Hennessy, Computer Organization and Design\n","slug":"architecture-base","date":"2022-04-12 09:00","title":"1. Base","category":"Computer Architecture","tags":["Computer Organization And Design","ISA"],"desc":"Computer Organization and Design이라는 책을 정리하고 되돌아볼 것이다. 여기서는 가장 기본이 되는 Idea들을 정리할 것이다.","thumbnailSrc":"https://euidong.github.io/images/default.jpg"},{"content":"\n## Intro\n\n컴퓨터가 알아들을 수 있는 명령을 우리는 Instruction이라고 한다. 그렇다면, 이들을 모아놓은 단어장(Vocabulary)는 **Instruction set**이 되는 것이다. 이런 의미에서 현대의 computer는 이를 기반으로 동작하도록 설계되었기 때문에, 이를 **Instruction set architecture**라고 부른다. 해당 책에서는 MIPS를 기준으로 하기 때문에 똑같이 MIPS를 기준으로 설명합니다. 이는 다른 processor들과 매우 유사하니 이를 배우면 쉽게 다른 것도 이해할 수 있을 것이다.\n\n그렇다면, Instruction이란 무엇일까? 이는 기계어(0과 1로 이루어진 이진수 체계)의 형태로 표현된다. 따라서, 이를 Assembly Instruction이라고도 한다. 이는 hardware에게 특정 동작을 수행하도록 하는 명령어라고 할 수 있다. 그렇기에 우리가 실행하거나 작성하는 모든 program들은 사실 Instruction들의 집합이라고 볼 수 있다. 실제로 Computer에서 Program이 동작할 때, 이는 Computer는 memory에 program의 내용과 program에서 사용할 data들을 위한 공간을 배정해준다. 그런 후에 실제로 실행될 때에는 program의 Instruction을 차례차례 읽어가면서 실행하는 것이다.\n\n## Assembly Instruction의 구성요소\n\n기본적으로 MIPS는 32bit(=4Bytes) 시스템을 사용한다. 따라서, 하나의 Instruction은 4 Bytes로 표현된다. 이를 하나의 가장 단위라고 여겨서 word라고도 부른다. 따라서, 64bit(=8Bytes) CPU에서는 1 word가 8 Bytes가 될 수도 있다. 결국 모든 Instruction이 0과 1로 이루어진다. 하지만, 이는 너무 읽기 어렵기 때문에 우선 Assembly(기계어보다는 사람의 언어에 가깝지만 아주 원초적인 형태의 언어) Instruction을 알아볼 것이다. 이를 기계어로 바꾸는 것은 해당 포스팅의 밑에서 다룬다.\n\n### 1\\. Operand\n\n연산을 위해서 필요한 것은 연산자와 피연산자이다. 보통의 programming 언어에서는 이를 변수라고 한다.\n\nMIPS에서는 총 두 가지의 변수 type이 존재한다.\n\n1. **Constant**  \n    하나의 상수로써 동작하는 변수이다. 주어진 범위 내에서 자유롭게 상수로 사용가능하다.\n2. **Register No**  \n    하드웨어 상의 register들과 programming에서의 변수와 차이점이 있다면, 바로 갯수의 제한이 있다는 것이다. 보통은 갯수를 32개로 제한한다. 그렇게 하는 것이 효율적이라고 찾아냈다고 한다. 더 많이 써도 Clock Cycle이 더 소모될 뿐이고, 적다면 표현력이 부족해지 수도 있다. 또한, 하나의 register의 크기 또한 우리는 대게 32bit(1 word)로 제한한다. 이를 표현할 때에는 보통 \\$ 표시를 활용하고, register는 특정 목적을 위해서 지정되어 있다. (밑에 표를 참고)  \n    Instruction에서는 Register를 가르키기 위해서 5bit를 사용한다. $2^5$이면 모든 Register를 구분할 수 있기 때문이다.\n3. **Memory Address**  \n    해당 공간에는 기본적으로 register에 담기진 못한 모든 정보가 저장된다. 왜냐하면, register 가 하나의 변수를 표현할 수 있는데 만약, 변수가 32개를 넘어간다면, 이를 처리하는 것이 매우 버거워진다. 따라서, 이를 임시로 저장해두어야 한다. 따라서, 이를 memory에 잠깐 저장하는데 이를 **spilling register**라고 부른다.  \n    좀 더 복잡한 데이터 구조를 가지는 경우에도 이를 모두 register에 담는 것은 불가능하다. 따라서, 우리는 Memory라는 것을 활용한다. Memory는 8bit 단위로 한 칸으로 나누어 4개의 칸을 합친 것을 하나의 단위로 봅니다. (왜냐하면 이것이 4x8bit = 32bit = 1word가 되기 때문이다.) 따라서, 우리가 특정 값에 접근할 때에는 4의 배수로 접근하는 것이 올바른 접근이다. 또한, 하나의 데이터가 4개의 칸으로 쪼개지기 때문에 저장 방법에 차이가 있을 수 있다. 어떤 사람들은 앞 자리부터 차곡차곡 넣을 수도 있지만, 누구는 역순으로도 넣을 수 있기 때문에 이를 유의해야 한다. MIPS에서는 앞에서붙터 차곡차곡 넣는 Big Endian 방식을 사용한다. (즉, 4개 중 가장 낮은 주소값에 높은 값을 의미하는 값(MSB)이 쓰인다.)  \n    하나의 Memory address를 가르키기 위해서는 32bit가 필요하다. 이렇게 하여 $2^{32}$ = 4GB 이하까지의 Memory는 가르킬 수 있는 것이다. Instruction 자체가 32bit인데, 이를 Instruction에 바로 넣을 수는 없기 때문에 특정 Memory address를 가르키기 위해서 별도의 register에 해당 Memory의 address를 저장해두고 해당 지점부터 offset을 constant로 전달하는 식으로 표기한다.(여기서 4의 배수로 memory가 표현되므로, 2bit를 뺀다고 해도 30bit로 여전히 많다.)\n\n다음은 MIPS의 Register와 Memory를 나타낸 것이다.\n\n![registers](/images/registers.png)\n\n상식적으로 알아두고 갈 부분은 reigster는 직접적으로 연산이 이루어지는 곳이기 때문에, register에 접근하는 비용이 memory에 접근하는 부분보다 확연하게 비용이 싸다.(시간이 짧게 걸린다.) 따라서, 이를 효율적으로 다루어주는 것이 효율 향상에 도움이 된다.\n\n#### 2\\. Operation\n\n모든 computer는 기본적인 연산을 수행할 수 있어야 한다. MIPS에서는 다음과 같은 표기법을 사용한다.\n\n```plaintext\n1. <명령어(operation)> <연산자(operand) 1> <연산자(operand) 2> <연산자(operand) 3>\n\n2. <명령어(operation)> <연산자(operand) 1> <연산자(operand) 2>\n\n3. <명령어(operation)> <연산자(operand)>\n```\n\n마치 우리가 영어를 처음 배울 때, 1형식, 2형식 배우는 형태랑 유사하다. 그리고 여기서는 모든 문장이 명령형으로 구성된다는 점을 유의하자. 이에 따라서, 다음 MIPS의 피연산자(operand)와 주요 Operation을 살펴보자.\n\n> **Add / Substract**\n\n`add [연산자1] [연산자2] [연산자3]`\n\n모든 연산의 기본으로 위의 형태 중에서 첫번째에 해당한다. 이를 수학 기호로 나타내면 다음과 같다.\n\n`[연산자1] = [연산자2] + [연산자3]`\n\nSubstraction 연산도 이와 동일하게 동작한다.\n\n> **Load / Save**\n\n우리가 Register에 특정 데이터를 저장하기를 원한다면, $zero register 에 저장하기를 원하는 값 또는 register를 add해서 해당 register에 저장하면 된다.\n\n`add [저장을 원하는 register No] [$zero] [1234]`\n\n하지만, Memory에 데이터를 저장하기 위해서는 별도의 명령어가 필요하다. 그것이 save 명령어 입니다. 앞 서 말한 것과 같이 memory address를 직접적으로 Instruction에 표현할 수는 없기 때문에 특정 register에 주소값을 저장하고, 해당 주소를 base로 해서 offset을 더해서 주소를 찾는 형태로 수행한다.\n\n`sw [불러올 register No] [Memory의 Base Address를 가진 register No] offset`\n\n이와 반대로 Memory에서 데이터를 register로 불러올 때에도 별도의 명령어가 필요하다.\n\n`lw [불러올 register No] [Memory의 Base Address를 가진 register No] offset`\n\n> **Jump**\n\nInstruction 역시 Memory에 상주하고 있는데, 만약 필요에 따라 이전 Instruction으로 돌아가거나 Instruction을 뛰어넘어야 한다면, 그때 사용할 수 있는 Instruction이다.\n\n`j [이동할 instruction offset]`\n\n> **Branch**\n\nBranch(분기)는 특정 조건의 부합 여부를 확인하고, Jump를 수행하는 Instruction이다. 이를 위한 operator가 beq, bne가 있다.\n\n`beq [비교할 register1] [비교할 register2] [이동할 instruction offset]`\n\nregister1과 2가 서로 동일하다면, 해당 instruction offset으로 이동하라는 의미이다. bne는 반대로 두 register가 다를 때에 이동할 수 있다.\n\n> **기타 주요 명령어**\n\n![instruction](/images/instruction.png)\n\n\\* PC : Program Counter의 줄임말로 현재 실행하고 있는 Program에서 어느 위치의 Instruction을 실행시키고 있는지를 나타낸다. 이를 이용해서 CPU는 다음 Instruction을 불러온다.\n\n\\* offset : offset은 대게 instruction 단위로 나타내기 때문에 1 offset은 4Bytes를 의미한다. 따라서, offset을 실제 주소에 더할 때에는 곱하기 4(실제로는 shift left 2)를 해야한다. 이로 인해서, 현재 Instruction의 다음 Instruction의 주소를 PC+4 라고 한다.\n\n---\n\n## Instruction를 이용한 Programming 언어 기본 요소 구현\n\n### 1\\. 조건문 (if / else)\n\n```pseudo\nif (i == j) \n f = g + h;\nelse\n f = g - h;\n```\n\n다음과 같은 c의 조건문 코드를 아래와 같은 Instruction들로 변환이 가능하다.\n\n```pseudo\nbne $s3, $s4, Else # go to Else if i != j\nadd $s0, $s1, $s2 # f = g + h (skipped if i != j)\nj Exit # go to Exit\n\nElse: \nsub $s0, $s1, $s2 # f = g - h (skipped if i = j)\n\nExit:\n```\n\n여기서 Else는 임의의 offset을 나타낸다. 따라서, \"Else:\"라고 표시된 부분에 해당하는 offset이라고 생각하면 된다.\n\nSwitch/Case 문 같은 경우는 if/else로 변환해서 나타내기도 하고, 아니면 Switching 위치를 적어놓은 Table을 만들어서 해당 위치로 바로 이동하는 식으로 구현하기도 한다.\n\n### 2\\. 반복문 (while)\n\n```pseudo\nwhile(save[i] == k)\n i += 1;\n```\n\n다음과 같은 c의 반복문을 아래와 같은 Instruction들로 변환이 가능하다.\n\n```pseudo\n# $t1 : save[i] address pointer\n# $t0 : save[i] value\n# $s3 : i\n# $s6 : save의 base address (save[0] address pointer)\n# $s5 : k\n\n# sll shift left \"<<\" 를 의미합니다. \n# 즉, 아래에서는 두 번하므로, *2^2를 의미합니다.\nLoop: \nsll $t1, $s3, 2 # temp reg $t1 = i * 4\nadd $t1, $t1, $s6 # $t1 = address of save[i]\nlw $t0, 0($t1) # temp reg $t0 = save[i]\nbne $t0, $s5, Exit # go to Exit if save[i] != k\naddi $s3, $s3, 1 # i = i + 1\nj Loop # go to Loop\n\nExit:\n```\n\n### 3\\. 함수 (function)\n\nprocedure는 대게 function(함수)이라고도 불린다. 함수를 우리는 하나의 예시를 통해서 설명할 수 있다.\n\nprocedure를 비밀 작전을 맡고 떠난 spy라고 하자. 작전은 자원을 습득하여, 특정 작업을 수행하고, 흔적을 감춘 뒤에, 바람직한 결과를 들고 돌아오는 것을 의미한다. 즉, spy는 작업을 마치고, 원하는 결과를 갖고 왔지만, 해당 결과 외에는 아무것도 바뀌지 않기를 기대한다. (누군가한테 의심받지 않아야하기 때문에)\n\n이러한 과정이 똑같이 함수의 호출마다 발생한다. 아래는 이를 다소 축약한 형태입니다.\n\n1. parameter를 procedure가 접근할 수 있는 곳에 위치시킵니다.\n2. control을 procedure(callee)로 옮깁니다.\n3. procedure는 해당하는 자원(parameter)을 습득합니다.\n4. 목표한 바를 수행합니다.\n5. 결과값을 자신을 호출한 program(caller)이 접근할 수 있는 곳에 위치시킵니다.\n6. control을 호출한 곳(caller)으로 넘깁니다.\n\n\\* 여기서 control이 이동했다는 것은 \bPC값이 PC+4가 아닌 함수의 주소로 이동했다는 것을 의미합니다.\n\n이를 구현하기 위해서 우리는 다음과 같은 별도의 register를 사용합니다.\n\n```pseudo\n$a0 - $a3 : 4 argument(=parameter) registers.\n$v0 - $v1 : 2 return value registers.\n$ra : 1 return address register. 원래 위치를 기억하기 위한 register.\n```\n\n\\$a와 \\$v는 사실 함수 사용에서 필수적이기 때문에 쉽게 받아들일 수 있지만, \\$ra가 의아할 수 있을 것이다. 이는 procedure를 호출했던 시점으로 다시 돌아오기 위해서 호출한 시점의 주소(실제로는 호출한 시점에서 다음 Instruction의 주소)를 저장하고 있는 것이다. 이러한 과정 즉, \\$ra에 저장과 jump를 동시에 해주는 것이 jal instruction이다. 이는 바로 다음 instruction을 가르키도록 하여 PC+4로 저장하고, 특정 지점으로 이동한다. 그리고 돌아올 때에는 jr instruction을 이용해서 \\$ra로 돌아올 수 있다.\n\n만약, 더 많은 변수를 return value, argument로 쓰고 싶다면 우리는 이를 memory로 옮기는 과정을 수행해야 한다. 이때, computer 에서는 stack이라는 구조를 사용한다. (실제로 구현하는 것은 아니고, 마치 stack 처럼 사용하기에 이렇게 부른다.) Stack pointer라는 register(\\$sp)를 이용하여 현재 사용하고자 하는 data가 stack의 어디를 가르키고 있는지를 저장한다.\n\n> **실제 예제**\n\n```c\nint leaf_example (int g, int h, int i, int j) {\n int f;\n \n f = (g + h) - (i + j);\n return f;\n}\n```\n\n```c\nleaf_example:\naddi $sp, $sp, –12 # adjust stack to make room for 3 items\nsw $t1, 8($sp) # save register $t1 for use afterwards\nsw $t0, 4($sp) # save register $t0 for use afterwards\nsw $s0, 0($sp) # save register $s0 for use afterwards\n\nadd $t0,$a0,$a1 # register $t0 contains g + h\nadd $t1,$a2,$a3 # register $t1 contains i + j\nsub $s0,$t0,$t1 # f = $t0 – $t1, which is (g + h)–(i + j)\n\nadd $v0,$s0,$zero # returns f ($v0 = $s0 + 0)\n\nlw $s0, 0($sp)  # restore register $s0 for caller\nlw $t0, 4($sp)  # restore register $t0 for caller\nlw $t1, 8($sp)  # restore register $t1 for caller\naddi $sp,$sp,12 # adjust stack to delete 3 items\n\njr $ra # jump back to calling routine\n```\n\n해당 방식을 통해서, 만약 우리가 argument를 각 argument register 채워주고, \"jal leaf\\_example\"를 수행하게 되면, 해당 함수를 실행하는 것과 같은 동작을 하게 되는 것이다.\n\n하지만, 더 고민해야 하는 경우가 있다. 바로 함수 안에서 또 함수를 호출하는 경우이다.\n\n> **Nested Function call(Function 내부에서 Function의 호출)**\n\nprocedure가 또 procedure를 호출하는 경우에는 어떻게 해야할까? 이 때에는 간단한게 stack의 retuern address를 저장해놓고, \\$ra를 덮어씌우는 식으로 작동한다. 아래는 recursive call을 수행한 경우를 담은 내용이다.\n\n```c\nint fact (int n) {\n if (n < 1) \n  return 1;\n else\n  return n * fact(n-1); \n}\n```\n\n```pseudo\nfact:\naddi  $sp, $sp, –8    # adjust stack for 2 items\nsw    $ra, 4($sp)     # save the return address\nsw    $a0, 0($sp)     # save the argument n\n# slti 는 $a0의 값이 상수보다 작다면, 0 크다면 1이 저장됩니다.\nslti  $t0, $a0, 1     # test for n < 1\nbeq   $t0, $zero, L1  # if n >= 1, go to L1\n\naddi  $sp, $sp, 8     # pop 2 items off stack\n\naddi  $v0, $zero, 1   # return 1\njr    $ra             # return to caller\n\nL1: addi $a0,$a0,–1   # n >= 1: argument gets (n – 1)\njal fact              # call fact with (n –1)\n\nlw $a0, 0($sp)        # return from jal: restore argument n \nlw $ra, 4($sp)        # restore the return address\naddi $sp, $sp, 8      # adjust stack pointer to pop 2 items\n\nmul $v0,$a0,$v0       # return n * fact (n – 1)\njr   $ra              # return to the caller\n```\n\n이제 끝일 거 같지만, 마지막으로 생각해야 할 게 있다. 바로 내부에서 또 local variable을 선언한 경우이다. 이 경우에도 memory에 공간에 저장해야 하는데 이때에도 stack pointer를 이동 시켜서 구현하는 것은 후에 동작에 혼란을 야기할 수 있다. 따라서, frame pointer라는 것을 추가로 할당하였다. 이는 함수의 진입 시점에 stack pointer의 초기 위치를 가르킨다. 따라서, 쉽게 후에 돌아올 지점을 알 수 있기에 stack pointer를 더 유동적으로 움직일 수 있다.\n\n---\n\n## 여러 변수 형태 표현법\n\n### Signed Numbers\n\n일반적으로 unsigned number라고 하면, 0과 양수를 포함하는 범위이다. 하지만, signed number는 음수까지 포함한다. 그렇다면, 컴퓨터에서는 음수를 어떻게 표현할 수 있을까?\n\n사람의 머리로 가장 쉽게 생각할 수 있는 방법은 부호를 나타내기 위한 별도의 표시 bit를 하나 넣어주면 될 거 같다는 생각을 할 것이다. 이것이 정확하다. 바로 오른쪽 끝에 있는 bit가 1이면 음수 0이면 양수로 보는 방식이다. 1이 맨 앞에 올 때는 0이 원래 1의 역할을 대신한다. 그리고 0이 앞에 올 때는 원래 계산하던대로 수행하면 된다. 그러면 놀랍게도 우리가 생각하는 것처럼 덧셈 뺄셈 연산이 동작한다. 그리고 오른쪽 끝에 있는 수를 우리는 MST 라고 하고, 이를 sign bit라고 부른다.\n\n```pseudo\n0000 0000 0000 0000 0000 0000 0000 0000(two) = 0(ten) \n0000 0000 0000 0000 0000 0000 0000 0001(two) = 1(ten)\n0000 0000 0000 0000 0000 0000 0000 0010(two) = 2(ten)\n...\n0111 1111 1111 1111 1111 1111 1111 1101(two) = 2,147,483,645(ten)\n0111 1111 1111 1111 1111 1111 1111 1110(two) = 2,147,483,646(ten)\n0111 1111 1111 1111 1111 1111 1111 1111(two) = 2,147,483,647(ten)\n1000 0000 0000 0000 0000 0000 0000 0000(two) = –2,147,483,648(ten)\n1000 0000 0000 0000 0000 0000 0000 0001(two) = –2,147,483,647(ten)\n1000 0000 0000 0000 0000 0000 0000 0010(two) = –2,147,483,646(ten)\n...\n1111 1111 1111 1111 1111 1111 1111 1101(two) = –3(ten)\n1111 1111 1111 1111 1111 1111 1111 1110(two) = –2(ten)\n1111 1111 1111 1111 1111 1111 1111 1111(two) = –1(ten) \n```\n\n> **Proof**\n\n```pseudo\n# 덧셈\n  1111 1111 1111 1110 (-2)\n+                   1 (+1)\n----------------------\n  1111 1111 1111 1111 (-1)\n\n\n                   11  (+3)\n+ 1111 1111 1111 1000  (-8)\n----------------------\n  1111 1111 1111 1011  (-5)\n\n\n# 뺄셈 1\n  1111 1111 1111 1110 (-2)\n-                   1 (+1)\n----------------------\n  1111 1111 1111 1101 (-3)\n\n\n# 뺄셈 2\n                   11  (+3)\n- 1111 1111 1111 1000  (-8)\n----------------------\n                   11  (+3)\n+ 0000 0000 0000 1000  (+8)\n----------------------\n  0000 0000 0000 1011  (+11)\n```\n\n연산을 하다보면, 당연히 너무 큰 양수를 더하게 되면 overflow가 발생할 수 있는데 이 경우 운영체제마다 compiler마다 처리 방식이 상이하다. C에서는 overflow가 되면 그대로 값을 내놓기 때문에, 대게 굉장히 큰 음수가 나오게 된다.\n\n### Character\n\ncomputer에서 수가 아닌 값을 어떻게 표현할 수 있는가는 ASCII code 표가 답해줄 수 있을 것이다. 하나의 문자를 우리는 character라고 부르고, ASCII code 표와 같은 방식을 통해서 수를 글자로 변환하여 표현한다. 또한, 하나의 문자가 아닌 단어, 문장에 이르게 되면 이를 우리는 string이라고 하며, 이는 이 데이터의 길이를 표기하기 위해서 다음 3가지 중 하나를 선택하게 된다.\n\n1. string의 가장 앞에 길이를 나타내는 값을 넣어준다.\n2. string을 구조체로 만들어서 길이를 나타내는 값을 따로 넣는다.\n3. string의 가장 끝 문자를 구분자로 채워서 구분할 수 있도록 한다. ⇒ C에서는 \\\\0 을 사용하여 구분한다.\n\n---\n\n## Representing Instruction with Machine Language\n\n위에 나온 MIPS Assembly code를 이제 MIPS의 기계어로 변환하는 과정을 수행할 것이다.\n\n다시 한 번 설명하자면, 우리의 program들은 사실상 instruction의 집합이라고 볼 수 있다. 또한, 현대의 컴퓨터는 이러한 instruction들을 memory에 마치 데이터처럼 쌓아서 실행시킨다. 그래서 우리는 이러한 프로그램 실행 방식을 **stored program** 이라고 부른다. 우리는 위에서 memory에 데이터를 저장하기 위해서 하나의 word 즉 32bit를 사용했다. 따라서, 우리의 instruction도 하나의 word 단위로 표현한다.\n\n아래 그림은 32bit의 각 각 부분이 무엇을 의미하는지를 표현한 것이다. 위의 연산을 표시하기 위해서 다음과 같이 word를 구분한다. 이때 주의할 점은 큰 값을 처리할 때에는 I-Type을 사용하기 때문에 형태가 기본형인 R-Type과는 다소 다른 것을 볼 수 있다.\n\n> **R-Type**\n\n![r-type](/images/r-type.png)\n\n- op : opcode라고 불리며, instruction의 동작이 무엇인지를 정의한다. (ex. add, jump, ...)\n- rs : first source register\n- rt : second source register\n- rd : destination register. 연산의 결과값이 저장되는 위치를 의미한다.\n- shamt : shift amount라는 의미로 shift 연산을 사용할 때 이용된다.\n- funct : op field에서 구체적인 동작을 정의할 때 사용한다.\n\n> **I-Type**\n\n![i-type](/images/i-type.png)\n\n- op : opcode라고 불리며, instruction의 동작이 무엇인지를 정의한다. (ex. addi, jump, ...)\n- rs : first source register\n- rt : second source register\n- constraint or address : 긴 값이 필요한 연산에서는 다음과 같은 형태로 표현한다.\n\n## Addressing\n\nMIPS는 여러가지 instruction을 가지고 있기 때문에, 주소를 targeting하는 방식도 여러가지이다. 또한, 따른 instruction set architecture에서도 다양한 방법을 통해서 memory의 주소를 가르킨다.\n\n1. Immediate addressing : 상수를 통해 직접 address를 지정하는 방식이다.\n2. Register addressing : register로 address를 지정하는 방식이다.\n3. Base addressing : 상수에 특정 register값을 더해서 구하는 방식이다.(MIPS → Load Word, Save Word)\n4. PC-relative addressing : PC 값에 상수 값을 더해서 구하는 방식이다. (MIPS → Branch)\n5. Psedodirect addressing : PC의 맨앞 내자리를 가져와서 쓰는 방식이다. (MIPS → Jump)\n\n## Reference\n\n- David A. Patterson, John L. Hennessy, Computer Organization and Design\n","slug":"architecture-instruction","date":"2022-04-14 09:00","title":"2. Instruction","category":"Computer Architecture","tags":["Computer Organization And Design","Instruction","ISA"],"desc":"컴퓨터가 알아들을 수 있는 명령을 우리는 Instruction이라고 한다. 그렇다면, 이들을 모아놓은 단어장(Vocabulary)는 Instruction set이 되는 것이다. 이런 의미에서 현대의 computer는 이를 기반으로 동작하도록 설계되었기 때문에, 이를 Instruction set architecture라고 부른다. 해당 책에서는 MIPS를 기준으로 하기 때문에 똑같이 MIPS를 기준으로 설명합니다. 이는 다른 processor들과 매우 유사하니 이를 배우면 쉽게 다른 것도 이해할 수 있을 것이다.그렇다면, Instruction이란 무엇일까? 이는 기계어(0과 1로 이루어진 이진수 체계)의 형태로 표현된다. 따라서, 이를 Assembly Instruction이라고도 한다. 이는 hardware에게 특정 동작을 수행하도록 하는 명령어라고 할 수 있다. 그렇기에 우리가 실행하거나 작성하는 모든 program들은 사실 Instruction들의 집합이라고 볼 수 있다. 실제로 Computer에서 Program이 동작할 때, 이는 Computer는 memory에 program의 내용과 program에서 사용할 data들을 위한 공간을 배정해준다. 그런 후에 실제로 실행될 때에는 program의 Instruction을 차례차례 읽어가면서 실행하는 것이다.","thumbnailSrc":"https://euidong.github.io/images/default.jpg"},{"content":"\n## Intro\n\n컴퓨터 구조에서 기본이 되는 **사칙연산**과 **소수**의 표현방식(**Floating Point**)을 다룬다.\n\n## Overflow\n\n시작하기에 앞서서 Overflow라는 개념을 알고가야한다. Overflow란 특정 변수의 표현범위를 벗어나는 경우에 발생하게 되는 에러 상황을 의미한다. 일반적인 사람의 생각에는 수의 범위가 있는 것은 이상할 수 있지만, 컴퓨터에서는 이것이 매우 당연하다. 무한대를 표현하는 것은 사실상 컴퓨터로는 불가능하다. 대신 매우 큰 수를 통해서 표현하는 것이 컴퓨터에게는 일반적이다. 예를 들어 우리가 빈번하게 사용하는 integer 변수 type은 그 값의 범위가 정해져있다. 이는 대게 하나의 변수를 표현하기 위해서 4bytes를 사용하는데 이는 32bits이기 때문에, 최대 $2^{32}$까지가 표현의 범위가 되는 것이다. 여기에 음수를 표현하게 되는 경우에는 범위가 $-2^{31}$ ~ $2^{31}$로 제한된다. 따라서, 이렇게 범위를 벗어나는 경우에 대해서는 programming language 마다 처리가 달라지지만, 대게 에러를 발생시키는 것이 일반적이다. (python에서는 알아서 범위를 추가한다.)\n\n## 덧셈 / 뺄셈\n\n덧셈은 각 자릿수의 합과 이전 자릿수에서 올림된 수(Carry)의 합이라고 다시 해석할 수 있다.\n이진수에서는 결국 올림된 수와 두 수가 만들어 낼 수 있는 경우의 수는 00 ~ 11이다.\n\n| A    | B    | Carry | Result |\n| :--- | :--- | :---- | :----- |\n| 0    | 0    | 0     | 00     |\n| 0    | 0    | 1     | 01     |\n| 0    | 1    | 0     | 01     |\n| 0    | 1    | 1     | 10     |\n| 1    | 0    | 0     | 01     |\n| 1    | 0    | 1     | 10     |\n| 1    | 1    | 0     | 10     |\n| 1    | 1    | 1     | 11     |\n\n이를 수행하기 위해서 우리는 XOR 2개와 AND 2개 그리고 OR 1개로 만들 수 있다.(C'와 S가 결과값이다.)\n\n| A    | B    | Carry(C) | A XOR B(D) | A AND B(E) | C AND D(F) | E OR F(C') | C XOR D(S) |\n| :--- | :--- | :------- | :--------- | :--------- | :--------- | :--------- | :--------- |\n| 0    | 0    | 0        | 0          | 0          | 0          | 0          | 0          |\n| 0    | 0    | 1        | 0          | 0          | 0          | 0          | 1          |\n| 0    | 1    | 0        | 1          | 0          | 0          | 0          | 1          |\n| 0    | 1    | 1        | 1          | 0          | 1          | 1          | 0          |\n| 1    | 0    | 0        | 1          | 0          | 0          | 0          | 1          |\n| 1    | 0    | 1        | 1          | 0          | 1          | 1          | 0          |\n| 1    | 1    | 0        | 0          | 1          | 0          | 1          | 0          |\n| 1    | 1    | 1        | 0          | 1          | 0          | 1          | 1          |\n\n![fullAdder](https://upload.wikimedia.org/wikipedia/commons/5/57/Fulladder.gif)\n\n### 음수\n\n음수는 기본적으로 2의 보수라는 방식을 활용한다. 만약 특정 수를 음수로 변환하고 싶다면 전체 수를 반전 시킨 후 `+1`을 수행하는 방식이다. 이를 통해서, 우리는 쉽게 음수를 생성할 수 있다. 그리고 놀랍게도 특정 수를 음수로 변환하고 덧셈을 하게 되면, 이것이 바로 뺄셈이 된다.\n\n## 곱셈\n\n먼저 이진수의 곱셈은 아래와 같이 십진수에서의 곱셈 연산과 방법은 같다.\n\n곱해지는 수(multiplicand), 곱하는 수(multipler), 곱해진 결과(product)이다.\n\n![곱셈 예제](/images/multiplication.png)\n\n하지만, 여기서 하나의 특징을 발견할 수 있다. 각 자릿수의 결과값은 곱하는 수에 의해서 결정된다는 점이다. 곱하는 수가 1이면, 곱해지는 수의 해당 자릿수가 결과값이 되고, 0이면 무조건 0이라는 결과가 나온다는 것을 알 수 있다. 따라서, 다음과 같은 알고리즘에 따라서 연산이 수행된다는 것을 알 수 있다.\n\n![곱셈 알고리즘](/images/multiplication-flow.png)\n\n만약, 음수의 곱셈의 경우에는 간단하게 해당 값을 양수로 변환하고, 연산을 수행한 뒤에 다시 음수로 변환하는 방식을 수행한다.\n\n## 나눗셈\n\n나눗셈은 역시 동일하다.\n\n나누어지는 수(Dividend), 나누는 수(Divisor), 몫(Quotient), 나머지(Remainder) 이다.\n\n![나눗셈 예제](/images/division.png)\n\n이때는 역으로 나누는 수를 오른쪽으로 32번 shift하여 매우 큰 수로 만들고, 나머지를 나누어지는 수로 초기화하여 차근차근 빼보면서 양수이면 빼고, 음수이면 되돌리기를 반복하면서 몫과 나머지를 계산할 수 있다.\n\n![나눗셈 알고리즘](/images/division-flow.png)\n\n## 실수 연산\n\n위에서는 여태까지 정수의 연산을 다루었지만, 소수점을 포함하는 실수 연산을 수행할 때에는 달라지는 사항이 꽤나있다.\n\n먼저, 실수를 표기하기 위한 방법을 먼저 보자.\n\n$$31231.4_{(10)} = 3.12314_{(10)} \\times 10^{4_{(10)}}$$\n\n$$100101.1_{(2)}= 1.001011_{(2)} \\times 2^{101_{(2)}} $$\n\n이를 일반적으로 normalization이라고 하며, 이진수 체계에서는 다음과 같은 형태를 갖게 된다.\n\n$$\\text{1.xxxxx} \\times 2^{yyyyy}$$\n\n따라서, 대게 실수를 표현할 때에는 x부분(fraction)과 y부분(exponent) 그리고 부호를 표현(sign)하는 부분으로 나누어서 저장한다. 이 또한, 4byte를 통해서 표현할 경우에는 x부분에 8bits, y부분에 23bits 그리고 부호에 1bit를 할당한다.\n\n따라서, 일반적으로 표현하면 다음과 같이 쓰는 것이 일반적인 실수의 표현이다.\n\n$$(-1)^s \\times(1+\\text{Fraction})\\times2^{(\\text{Exponent})}$$\n\n단, 모두 0이면 0으로 친다. floating point 연산은 후에 더 시간이 있으면 자세히 다루겠다.\n\n## Reference\n\n- David A. Patterson, John L. Hennessy, Computer Organization and Design\n- Full Adder 이미지는 WIKIPEDIA full adder의 발췌이다. (<https://upload.wikimedia.org/wikipedia/commons/5/57/Fulladder.gif>)\n","slug":"architecture-arithmetic","date":"2022-04-27 20:50","title":"3. Arithmetic","category":"Computer Architecture","tags":["Computer Organization And Design","Arithmetic"],"desc":"컴퓨터 구조에서 기본이 되는 사칙연산과 소수의 표현방식(Floating Point)을 다룬다.","thumbnailSrc":"https://euidong.github.io/images/default.jpg"},{"content":"\n해당 내용은 이전에 다루었던, [논리회로 리뷰 내용](/posts/digital-logic-circuit)을 보고 보는 것을 추천합니다.\n\n## Intro\n\n우리의 컴퓨터 시스템은 결국 Finite State Machine(유한상태장치)라고 할 수 있다. 즉, 순서에 따라 유한한 상태에서 다음 상태로 넘어가면서, Output을 계속해서 내보내는 장치라는 것이다. 이때 하나의 작업은 하나의 Clock 단위로 수행되며, 연속적은 작업 처리를 통해서 컴퓨터는 사용자가 요구한 명령을 수행하게 된다.\n\n## Processor\n\nprocessor와 program의 성능을 측정하기 위해서 우리는 다음과 같은 식을 활용하였다.\n\n$$\\text{instruction count} \\times \\text{Clock Cycle Time} \\times \\text{Clock Cycles per Instruction}$$\n\n[2. post](/posts/architecture-instruction)에서는 Instruction Count를 관리하고, 어떻게 계산되는지를 보았다면, **해당 포스팅에서는 Clock Cycle Time과 Clock Cycle per Instruction이 어떻게 구성되는지를 알아보며, 이들을 어떻게 줄일 수 있는지를 알아볼 것이다.**\n\n이를 위해서 우리는\n\n1. MIPS CPU의 가장 기본적인 구현\n2. pipeline된 MIPS\n3. Instruction 단계에서의 병렬화\n\n를 살펴볼 것이다.\n\n```plaintext\n 🤔 주의\n\n 해당 단계에서는 다음과 같은 사항은 배제한다.\n 1. multiply, shift, divide 연산\n 2. floating point 연산\n\n 결론적으로, 앞으로 구현할 MIPS에서는 다음과 같은 연산을 할 수 있다.\n 1. Memory에 접근하는 Load Word, Store Word\n 2. 기본 연산자 ADD, SUB, AND, OR, 등\n 3. Branch 구문 (BEQ, JUMP)\n```\n\n## 1. 기본적인 MIPS 구현(Single Cycle CPU)\n\n기본적인 processor에서 program이 동작은 다음과 같다.\n\n1. PC(Program Counter)를 Memory에 보내서 code를 포함한 부분을 특정하여 Instruction을 불러온다.(Instruction Fetch)\n2. 하나 또는 두 개의 register를 읽어서 Instruction을 수행한다.\n\n따라서, 이를 수행할 수 있는 논리 구조를 간략히 그려보면, 다음과 같은 형태를 가지게 됩니다.\n\n![Basic MIPS](/images/basic-mips.png)\n\n먼저, PC값의 형성 부분부터 보면 기본적으로 PC는 현재값에 4를 더하는 연산이기 때문에 상단에서 더한 값이 바로 다음 Clock에 적용된다고 할 수 있다. 그런데, 만약 Jump나 Branch 연산이 들어온다면, 해당 PC값에 특정값을 더한 결과로 이동하게 될 수 도 있다.\n\n그리고, 나머지 부분은 PC를 통해서 첫번째 박스에서 Instruction을 골라내고, Instruction의 특정 부분에서 OP와 register 등에 대한 정보를 토대로 Register와 상수 등을 이용하여 ALU 장치에서 OP 정보에 따라 연산을 수행한 뒤에 결과값을 특정 Register에 돌려주거나 Memory에 저장하도록 한다.\n\n물론 위에서는 **mux**(Multiplexor)에서 사용하는 데이터에 대한 내용은 빠져있지만, 아래 그림을 보면 더 정확하게 이해할 수 있을 것이다. 여러가지 경우의 수 중 상황의 따라서 output이 다른 경우에 mux를 사용하게 되는데, 여기서는 Instruction의 특정부분을 통해서 Control bits를 얻어내고, mux를 설치하여 적절하게 행동하도록 제어하고 있다.\n\n대표적인 예시로 아까 PC값을 선택하는 부분이 보다 명확하게 표시되는 것을 볼 수 있다. 현재 계산된 PC+4를 사용할 것인지 아니면, Branch 명령어에서 계산된 값을 사용할 것인지를 Control bit가 결정하는 것을 볼 수 있다.\n\n![Basic MIPS 2](/images/basic-mips2.png)\n\n이제부터는 각 단계별로 뜯어서 살펴본다.\n\n### 1) IF 단계 - Instruction Fetch\n\n해당 단계에서는 PC에 저장된 값에 따라서, Memory에서 Instruction을 추출하면서 PC에 4가 더해지는 것을 볼 수 있다. 그리고, Instruction의 특정 부분과 연산이 수행되는 것을 볼 수 있는데 이는 Branch 구문에 의한 이동을 위해서 주소를 저장해놓는 것이다.\n\n그리고, 이를 mux와 signal bit를 통해서, 최종적으로 다음 Program의 line을 가르킬 수 있다.\n\n![MIPS IF](/images/mips-if.png)\n\n### 2) ID 단계 - Instruction Decode and Register File Read\n\n해당 단계에서는 크게 두가지의 일을 한다.\n\n첫 번째는, Instruction에 포함된 정보를 기반으로 하여 Register를 선택하고, 해당 Register에 해당하는 정보를 내보내는 것이며,\n\n![MIPS ID](/images/mips-id1.png)\n\n두 번째는, Control bits를 생성하는 역할이다.\n\n![MIPS ID](/images/mips-id2.png)\n\n### 3) EX 단계 - Execution or Address Calculating\n\n다음 단계에서는 `R-Type`, `I-Type`에 따라서 두번째(2nd) Register를 사용할지 아니면, 상수로 받아들일지를 선택해야 한다. 이는 이전 단계(ID)에서 생성했던 Control bit를 mux에 통과시키는 식으로 구현한다.\n\n이후에는 control bit들을 통해서 연산의 종류를 선택한 후에, ALU 내부에서 연산을 수행하여 결과값을 내보낸다.\n\n결과값은 일반적인 결과를 내보내며, 추가적으로 beq 또는 여타 연산의 결과를 쉽게 알리기 위해서 zero라는 output으로 결과값이 0인지를 알려준다. 이는 다른 beq와 같은 연산에서 control bit로 사용한다.\n\n![MIPS EX](/images/mips-ex.png)\n\n### 4) MEM 단계 - Data Memory Access\n\nData Memory에 접근하는 동작으로 만약 Memory에 데이터를 update하는 동작을 한다면, MemWrite가 1로 설정되어있고, 이를 보고 명령어를 처리하게 된다.(read도 동일하게 MemRead를 활용한다.) 물리적으로 CPU와 떨어져있는 장비이기 때문에 접근하는데 많은 시간이 소요된다. 따라서, MIPS의 Instruction 실행의 모든 단계들 중에서 가장 오랜 시간이 필요한 연산이라고 할 수 있다.\n\n![MIPS MEM](/images/mips-mem.png)\n\n### 5) WB 단계 - Write Back\n\n실제로 Register의 값을 update해주는 부분으로 register의 update는 Data Memory에서 값을 불러오거나 연산 결과를 받을 때 사용하기 때문에 둘 중에 어떤 경우인지를 확인하여 데이터를 update한다.\n\n![MIPS WB](/images/mips-wb.png)\n\n위와 같이 하나의 Instruction을 수행하기 위한 일련의 작업이 한 Clock을 단위로 실행되는 경우를 Single Cycle CPU라고 한다.\n\n### 2. Pipelining\n\n가장 기본적인 구조를 살펴보았으니 위의 형태를 최적화하기 위한 가장 효과적이였고, 모든 CPU에서 사용되고 있는 설계 방법을 설명할 것이다. 위의 과정을 보고 있으면 우리는 비효율을 하나 발견하게 된다. **바로 특정 단계가 실행 중인 동안에 해당 단계에 포함되지 않은 장비들은 놀려지고 있다는 점이다.** 즉, 위에서 processor의 성능을 측정하는 지표인 Clock Cycle Time이 증가한다. 따라서, 모든 장비를 계속해서 실행시키기 위해서, 한 단계가 한 Clock이 되도록 하는 방법이 고안되었다.(Multi Cycle CPU)\n\n하나의 예를 살펴보자.\n\n세차장에 갔다고 하자. 우리는 당연히 일열로 서서 자신의 차례가 되기를 기다린다. 하나의 장비가 세차에 들어가기 전에 사람에 의해서 먼저 비누거품을 내는 단계가 있다면, 우리는 당연히 줄을 서있는 동안 세차장 아르바이트생이 비누칠을 해주기를 기다릴 것이다. 하지만, 해당 세차장에서는 만약 기다리는 동안 해주는 것이 아니라 세차 기계가 이전 차량에 대한 작업을 마치고 안정적으로 작업이 끝난 후에 비누칠을 해준다고 하자. 이것은 굉장한 짜증을 유발하는 요소가 될 것이다.\n\n따라서, Single Cycle CPU를 사용하는 것은 하드웨어 장비를 최적화하지 못한 사례라고 할 수 있다.\n\n위와 같이 단게를 나누어 여러 Cycle에 나누어 하나의 명령어를 처리하게 되면, 우리는 다음과 같은 효과를 얻게 된다.\n\n1. Clock Cycle Time이 줄어든다.\n2. 하나의 CPU가 동시에 여러 개의 명령어를 실행하게 할 수도 있다.(**Instruction Overlapping**)\n\n![Pipeline Example](/images/pipeline-example.png)\n\n이렇게 Instruction을 동시에(병렬적으로) 실행할 수 있다면, 1개의 Cycle 동안 Hardware 장치의 잉여 시간을 최소화할 수 있다.\n\n하지만, tradeoff 역시 존재한다.\n\n1. 각 단계의 연산이 끝난 후에 해당 값을 보관할 추가적인 하드웨어 장비(register)가 필요하다.\n2. Clock이 올라가고, 떨어지는 동안의 미세한 시간의 추가로 시간 비용이 증가한다.\n3. Clock Cycle Time은 반드시 하나의 상수로 정해져야 하기 때문에 가장 실행 시간이 긴 단계에 의존하게 된다. 즉, 실행시간이 더 짧은 단계라고 할지라도 다른 긴 단계가 있다면 기다려야 한다.\n4. 2와 3번을 이유로 결론상 하나의 Instruction을 수행하는데 걸리는 시간은 증가할 수 밖에 없다.\n   그렇기에 결론상 단계를 생각없이 무조건 잘게 자른다고 좋은 것이 아니다. 바로 균등하게 많이 나눌 수 있는 만큼 나누는 것이 좋은 것이다.\n5. Instruction을 동시에 실행하는 것으로 인한 문제가 발생할 수 있다(Hazard). 이는 바로 다음 부분에서 다룬다.\n\n### Hazard\n\nHarzard는 아래와 같이 총 3가지의 종류가 있다.\n\n> **1. Structural Hazard**\n\nHardware가 구조적으로 동시에 특정 Instruction 조합을 처리하지 못할 경우를 의미한다. 즉, 서로 다른 pipeline stage에서 동일한 resource(Hardware)에 접근하고자 할 때 발생할 수 있다. 만약 Instruction Memory와 Data Memory의 분리가 되어 있지 않은 경우에는 이러한 문제가 IF, MEM 단계에서 발생할 수도 있지만, MIPS에서는 발생하지 않는다.\n\n> **2. Data Hazard**\n\n바로 Instruction이 서로 연관(의존)되어있을 때의 문제이다.\n\n다음과 같은 상황을 가정해보자. 우리가 memory에서 데이터를 불러와서 3을 더하는 연산을 한다고 하자. 그렇다면 명령어는 다음과 같다.\n\n```assembly\nlw $v 0\naddi $v 3\n```\n\n이를 실행하면 불행하게도 load가 채 끝나기도 전에 채워지지 않은 \\$v에 3이 더해지는 것을 알 수 있다.\n\n이를 해결하기 위해서 3가지의 선택지가 있다.\n\n1. 의존성이 있는 명령어가 실행 중인 경우 끝날 때까지 대기 (**Stall**)\n   가장 간단한 방법이지만, pipelining을 통한 성능 향상을 감소시킬 수 있다.\n2. Compiler 단에서 의존이 발생하는 Instruction 사이에 순서가 상관없는 Instruction을 끼워넣어서 resource가 낭비되지 않으면서 hazard가 발생하지 않도록 한다. (**Reordering**)\n   Hazard를 해결하는 좋은 방법이지만, 항상 이것이 가능할 수는 없다.\n3. 추가적인 Hardware를 사용하여 결과값을 필요로 하는 resource에게는 단계를 생략하고 넘긴다. (**Forwarding**, **Bypassing**)\n   현재까지는 가장 괜찮다고 받아들여지는 방법이다. 예를 들어서, EX 단계에서 ALU 연산이 끝나자마자 Write Back을 자체적으로 수행해주면 총 3번의 stall을 1번으로 줄일 수 있다.\n\n> **3. Control Hazard**\n\nBranch Hazard라고도 불리며, 이전 Instruction의 결과에 따라서 실행시킬 Instruction이 변화할 때, 어느 Instruction을 실행시킬지 알 수 없기 때문에 발생하는 Hazard이다. (JUMP, BEQ)\n\n이 경우에도 총 3가지의 선택지를 가진다.\n\n1. 성공적으로 분기문이 실행될 때까지 대기한다.(**Stall**)\n2. 어느 곳으로 Branch가 될지를 예상하여, 미리 시행해둔다. (**Branch Prediction**)\n   Resource를 최적화한다. 별도의 hardware를 설치하여 미리 JUMP 및 Branch address를 계산해 놓는다(**Hardware Optimization**)는 가정이 필요하다. 또한, 예측이 얼마나 적중하는가 역시 굉장히 중요한 요소로 작용한다.\n   대게 이러한 예측은 두 가지의 종류가 있다.\n   1. 정적 예측\n      쉽게 생각할 수 있는 것은 반드시 실패한다고 생각하거나 성공한다고 생각해서 진행하는 방식이다. 좀 더 복잡한 방식은 loop문에 의한 branch인 경우 branch가 수행될 확률이 높다는 것을 기반으로 하여 성공 가능성이 크다고 예측할 수 있다.\n   2. 동적 예측\n      이전 예측들을 기반으로 하여 현재 예측을 수행하는 방식이다. 이를 사용하면, 여러 번 반복되는 행위에 대한 예측율이 상당히 높아진다. 대게, 우리가 하는 분기문이 loop 등에 의한 경우가 많으므로 좋다고 할 수 있다. 또한, 최근에는 machine learning을 활용하여 예측을 수행하는 방식 또한 나오고 있다.\n3. Branch 여부에 상관없는 요청을 Control Hazard에 의해서 발생하는 구간에 넣는다. (**Delayed Decision**)\n\n## Parallelism via Instruction\n\nPipelining을 통해서, Instruction을 동시에 여러 개 실행시킬 수 있는 환경이 구축되었다. 그 와중에 resourece 자체를 하나 이상 두어서 Instruction을 동시에 수행할 수 있도록 하는 방식이 고안되었는데, 이를 Multiple Issue processor라고 한다.\n\n이를 대표하는 방식은 크게 두가지로 나눌 수 있다.\n\n### 1. Static Multiple Issue\n\n이는 compiler가 program을 기계어로 번역하는 과정에서 이루어지며, 대표적으로 다음과 같은 것들이 있다.\n\n1. VLIW(Very Long Instruction Word)\n   의존성이 없는 여러 Instruction을 하나의 Instruction으로 뭉쳐서 실행시키는 방법이다. 이를 통해서 중첩되는 OPCODE 및 기타 처리 등을 최소화할 수 있다. Processor가 해당 기능을 지원하는 경우에만 사용가능하다.\n2. Loop Unrolling\n   loop를 풀어서 여러 개의 Instruction으로 만들어서 branch로 인한 비용을 줄일 수 있다.\n\n### 2. Dynamic Multiple Issue\n\nprocessor에서 직접 Instruction이 실행되는 동안 이루어진다. 이는 여러 개의 pipeline을 CPU에 두어 이를 SuperScalar 방식이라고도 한다. 이를 효율적으로 수행하기 위해서는 앞 서 보았던 Compiler 단에서의 조율도 필요하며, 실행 중에 Instruction을 어떻게 나눌 것인가에 대한 Dynamic Scheduling 역시 매우 중요하다. 대표적인 예시가 OoO(Out of Order) Execution을 이용하는 것이다. Instruction의 Fetch를 순서대로가 아닌 의존성에 알맞게 실행되도록 조절하는 방식이다.\n\n## Reference\n\n- David A. Patterson, John L. Hennessy, Computer Organization and Design\n","slug":"architecture-processor","date":"2022-04-28 19:25","title":"4. Processing","category":"Computer Architecture","tags":["Computer Organization And Design","Processing","MIPS Implementation","Pipeline","Branch Prediction","SuperScalar"],"desc":"우리의 컴퓨터 시스템은 결국 Finite State Machine(유한상태장치)라고 할 수 있다. 즉, 순서에 따라 유한한 상태에서 다음 상태로 넘어가면서, Output을 계속해서 내보내는 장치라는 것이다. 이때 하나의 작업은 하나의 Clock 단위로 수행되며, 연속적은 작업 처리를 통해서 컴퓨터는 사용자가 요구한 명령을 수행하게 된다.","thumbnailSrc":"https://euidong.github.io/images/default.jpg"},{"content":"\n## Intro\n\n컴퓨터를 사용할 때, 우리는 기본적으로 Memory가 무한한 크기를 가지고 있기를 바란다. 하지만, 이를 실제로 구현하는 것은 비용적으로도, 기술적으로도 불가능하다. 따라서, 이를 마치 존재하는 것처럼 느끼도록 하는 Virtual Memory라는 기술을 사용한다.\n\n## Locality\n\nVirtual Memory를 위한 핵심은 `Locality`를 활용하는 것이다. 동작에는 인과가 존재하고, 그렇기에 직전에 자신이 했던 행동 그리고 근처의 대상들이 했던 행동이 지금의 자신이 할 행동에 영향을 주는 것은 어찌보면 당연한 사실이다. 이러한 특징이 `Locality`이다. 이를 이용해서 우리는 Memory를 마치 무한인 것처럼 느낄 수 있게 할 수 있다.\n\n1. **Temporal Locality**\n   하나의 Instruction 또는 data가 사용되었다면, 해당 내용은 곧 다시 사용될 확률이 매우 높다.(반복문일 경우에는 극명하게 드러날 것이다.)\n2. **Spatial Locality**\n   하나의 Instruction 또는 data가 사용되었다면, 후에 이 근처에 있는 내용을 사용할 확률이 매우 높다. (일반적으로 연속적으로 동작하는 경우가 많기 때문에 근처의 명령어들을 같이 가져올 수 있다면, 가져오는 것은 합리적이다.)\n\n이를 활용하기 위해서, 우리는 **Memory Hierarcy**라는 방법을 사용한다. 즉, 메모리를 계층화하는 것이다. 모든 장치를 빠르고, 크고, 싸게 만들 수 있으면 좋겠지만, 실제로는 불가능하기에 빠르고, 작은 장치를 processor에 가까이에 두고, 그 보다는 덜 빠르고, 큰 장치를 좀 더 거리를 두고 위치시키는 방식이다. 이렇게 하면 이용자에게 싸면서, 빠른 시스템을 제공할 수 있다.\n\n이를 위해서, 우리는 더 멀리 있는 Memory에서 정보를 복사해서 더 상위의 Memory에 붙여넣기하는 것이다. 계층 구조이기 때문에 한 번에 수행되는 것이 아니라 여러 단계가 있다면, 차근차근 순서에 맞춰서 수행된다. 즉, 단계를 skip하여 이동하는 것은 불가능하다.\n\n만약, 상위 Memory 장치에서 원하는 정보(Block, Line)를 찾았다면 이를 `hit`라고 하고, 찾지 못했다면 이를 `miss`라고 한다. 또한, `hit time`은 상위 Memory가 해당 Block에 접근하는데 걸리는 시간을 의미한다. 반대로 `miss penalty`는 상위 Memory로 해당 Block을 위치시키는 시간과 Block을 processor에 전달하는 시간까지를 포함한다.\n\n---\n\n시작하기에 앞 서, 컴퓨터 공학을 공부하는 누구나 겪는 현상이라고 생각하는데 바로 Memory 파트는 언어가 매우 자기 멋대로 나오는 경향이 있다. 즉, 깔끔한 정리가 되지는 않았다. Memory가 어떨 때는 Main Memory를 의미하다가 전체 모든 저장 장치를 의미하기도 한다. 따라서, 이 아래부터는 다음과 같이 엄격하게 분리하여 설명한다.\n\n1. Memory : 모든 저장 장치들을 의미한다. 즉, cache, secondary storage, main memory 등을 모두 포함한 개념이다.\n2. Cache : Processor에 붙어서 바로 동작하는 Memory 장치\n3. Main Memory : 우리가 주로 RAM이라고 부르는 장치\n4. Secondary Storage : 주로 HDD, SSD로 이루어지는 보조 기억 장치\n\n## Memory Components\n\n시작하기에 앞서 실제로 메모리를 이루는 구성요소들을 먼저 살펴보고 간다.\n\n1. **DRAM**(**Dynamic Random Access Memory**)\n   Main Memory에 주로 사용되는 장치로 SRAM보다는 느리지만, 확실히 많은 데이터를 저장할 수 있다. 하나의 bit를 저장하기 위해서 1개의 transistor를 사용하는데, 이 transistor에서 전력이 새어 나가기 때문에 정보를 잃는 것을 막기 위해서 주기적으로 refresh를 해주어야 한다.\n   Random Access라는 의미는 순차적으로 앞에서부터 탐색하는 방식이 아니고, 찾고자하는 데이터를 바로 찾을 수 있다는 의미이다. 따라서, 앞에서부터 찾는 방식보다 더 빠를 수 밖에 없다.\n   휘발성 저장 장치이기 때문에 전력이 공급되지 않으면 정보를 모두 잃는다.\n2. **SRAM**(**Static Random Access Memory**)\n   Cache에 주로 사용되는 장치로 매우 빠른 연산이 가능하지만, 크기를 크게 만들기 위해서는 비용이 너무 비싸진다는 단점이 있다. 하나의 bit를 처리하기 위해서 6개의 transistor를 사용한다. 이 덕분에 전력을 다시 공급해주는 refresh 과정이 필요없다.\n   과거에는 processor 밖에서 chip 형태로 존재하였지만, 점점 회로가 집적이 되며, processor에 통합되었다.\n   휘발성 저장 장치이기 때문에 전력이 공급되지 않으면 정보를 모두 잃는다.\n3. **Flash Memory**\n   Electrically Erasable Programmable Read-Only Memory(EEPROM)의 한 종류이다. 다른 장치들과는 달리 write가 flash memory를 닳게 만들 수 있다. 따라서, 대부분의 flash memory는 한 bit를 쓰기가 집중되는 현상을 막기 위해서, 이를 분산시키는 방식을 사용한다. (wear leveling, 쓰기 횟수에 제한이 존재한다.) 이는 대게 모바일 장치들의 저장 장치로 많이 사용되며, PC에서 사용하는 SSD와 매우 유사하다.\n4. **Magnetic Disk**\n   일명 자기 테이프 방식으로, 다른 장치들과는 다르게 자기력을 이용하여 정보를 저장하는 방식이다. 실제로 물리적으로 존재하는 Disk로 하여 Hard Disk라고도 부른다.이를 읽고 쓰기 위해서는 arm(팔)이라는 개체가 disk의 정보가 스여진 위치로 이동해야 읽을 수 있다. 따라서, 이것이 물리적으로 움직이는 시간이 소요되기 때문에 여타 Random Access 장비보다 느릴 수 밖에 없다. 하지만, 이를 통해서 저장할 수 있는 정보의 양은 매우 많다.\n\n## Cache\n\nMain Memory와 Processor 사이에서 memory hierarchy를 수행하는 장치라고 한다. 하지만, 현대에는 이러한 구조에 영감을 받아서 cache를 여러 곳에서 사용하기 때문에, 많은 분야에서 이를 **locality의 장점을 활용하기 위한 일종의 저장소**라는 의미로 많이 사용한다.\n\n### Cache의 역할\n\nCache가 수행하는 역할은 저장 장치이기 때문에 읽기와 쓰기가 가능해야 한다.\n\n> **Read**\n\n읽기를 수행하기 위해서 Cache에서는 다음과 같은 동작을 수행할 수 있어야 한다.\n\n1. **Main Memory의 데이터를 일부 저장할 수 있어야 한다.**\n   Cache는 Main Memory보다 크기가 작기 때문에 Main Memory의 모든 데이터를 저장하지 못한다. 따라서, 일부분을 저장하는데 이를 저장할 때, 기존의 Main Memory에서의 데이터의 address를 cache의 크기만큼 나누어 cache의 범위에 들어오도록 하는 것이 Directed Mapping이다. 따라서, 다음과 같은 식이 성립한다.(여기서의 Block이란 한 번에 cache로 가져올 데이터의 단위를 의미한다.)\n   $\\text{Cache에서 Block의 주소} =$ $\\text{(Main Memory에서 Block의 주소)} \\%$ $\\text{(Cache의 용량)}$\n2. **특정 word가 cache에 존재하는지 확인할 수 있어야 한다.**\n   이를 위해서 우리는 tag를 이용한다. cache 공간으로 address가 변환되어서 생략된 address를 포함하고 있다. 즉, cache의 index로 쓰이지 않은 Main Memory Address의 상위값을 가지고 있다. 쉽게 생각해서 위에서 만들어진 Cache의 Block 주소가 나머지라면, tag는 몫이라고 볼 수 있다. 따라서, tag는 담기는 데이터에 따라서, 계속해서 변하여 저장되는 값이다.\n3. **해당 데이터가 타당한지 확인할 수 있어야 한다.**\n   만약, system을 막 booting시켰다면, cache에는 모두 이상한 값이 들어갈 것이다. 따라서, 잘못된 값을 참조할 수도 있다. 따라서, 우리는 **valid bit**(1 bit)를 이용하여, 해당 값이 적절하게 할당한 값인지를 표기한다.\n4. **덮어 씌우기가 가능해야 한다.**\n   이 경우는 간단히 덮어 씌어버린다. 이는 앞 서 설명한 **temporal locality**와 일맥상통한다. 최근에 쓴 데이터가 다시 호출할 확률이 높기 때문이다.\n\n> **Example**\n\n왼쪽이 Cache고, 오른쪽이 Main Memory이다.\n\n1. 초기 상태  \n  ![directed-mapping-1](/images/directed-mapping-1.png)\n2. 001011 요청  \n  ![directed-mapping-2](/images/directed-mapping-2.png)\n3. 001011 재요청  \n  ![directed-mapping-3](/images/directed-mapping-3.png)\n4. 110011 요청  \n  ![directed-mapping-4](/images/directed-mapping-4.png)\n\nBlock 단위를 4Bytes로 했다면, 하나의 word 단위가 Block의 단위가 될 것이다. 그렇지 않고 더 큰 단위로 Block을 저장할 수도 있다. 일반적으로는 이 Block의 단위를 늘리면 miss rate를 낮출 수 있다. 근처의 데이터를 한 번에 여러 개 가지므로, **spatial locality**를 활용할 수 있다. 하지만, 과도하게 늘리게 되면, 오히려 이로 인해서 index가 표현할 수 있는 범위가 점점 작아진다. (한 마디로 cache의 전체 크기(용량)은 고정이기 때문에, 가로를 의미하는 block의 사이즈가 늘어나면, 세로를 의미하는 index의 범위가 줄어들 수 밖에 없다.) 이로 인해서 block size를 너무 크게 늘리게 되어도, miss rate는 증가하게 된다. 뿐만 아니라 miss penalty도 크게 증가한다. 해당 데이터를 cache에 끌어오는 동안의 시간이 증가할 것이기 때문이다. 따라서, 적당한 크기의 block 사이즈를 지정해야 한다.\n\n마지막으로, Cache를 읽기를 요청하였지만 해당 정보가 없는 경우 이를 `Miss`라고 하는데, `Miss`가 발생하면 이 데이터를 Main Memory에서 불러오기 위해서 어쩔 수 없이 우리는 stall을 수행해야 한다. 이러한 `Miss`는 굉장한 비용을 발생시키기 때문에 대게 세가지 방식에 의해서 이를 해결한다.\n\n1. Multiprocess or Multithread 환경에서는 다른 process를 해당 stall 동안 실행시켜서 이를 해결한다.\n2. OoO(Out of Order) Execution을 지원하는 장비에서는 이를 통해서 stall을 방지한다.\n3. Software를 개발할 당시에 해당 사항을 인지하고 최적화를 수행하는 것이다. cache의 hit 정도를 아래 그림에서 오른쪽과 같이 설정하게 되면, 결론적으로 hit 확률이 급격하게 증가하는 것을 알 수 있다. 이런식으로 Cache 크기에 유의하여 소프트웨어를 해당 장치에 최적화하는 방식도 존재한다.\n\n![software-optimize](/images/software-optimize.png)\n\n> **Write**\n\n데이터를 Main Memory로 write하는 상황을 생각해보자. cache에서 작업을 진행하여 해당 위치에만 데이터를 최신화하게 되면, 필연적으로 cache와 Main Memory 사이에서 불일치가 발생할 수 밖에 없다. 따라서, 이를 해결하기 위한 방법이 세 가지가 있다.\n\n1. **Write Through**\n   가장 간단한 방법으로, write가 발생하면, 모든 저장 장치의 일관성을 유지하기 위해 모두 update 해주는 것이다. 그러나, 이 write의 비용이 엄청나게 크다는 것을 알기 때문에 이를 최대한 적게 하는 것이 사실상 performance 향상에 핵심이라고 생각하면, 이는 실제로 사용하기에는 무리가 있다.\n2. **Write Buffer**\n   Main Memory에 쓰이기를 기다리는 buffer를 만들어 놓고, 해당 장치에서 write를 일임하여 놓는 방식이다. 이를 이용하게 되면, Write의 완료를 cache에서 더 이상 기달릴 필요가 없다. 하지만, Write 명령어를 processor가 처라하는 속도가 buffer가 Main Memory에 쓰는 속도보다 훨씬 빠르기 때문에 당연하게 buffer가 꽉찰 수 있다. 그렇게 되면, 반드시 공간이 날 때까지 stall을 해야만 한다.\n3. **Write Back**\n   이 방식은 일관성을 포기하는 방식이다. 즉, 데이터를 가지고 있다가 실제로 이 값이 다른 값으로 변경될 때, cache의 특정 index에 있는 값이 다른 tag의 값으로 변경될 때에만 데이터를 쓰는 방식이다. 또는 강제적으로 하위 memory로의 저장을 요구할 경우에만 쓰도록 한다. 이를 이용하면, 성능은 확연히 올라가지만, 불일치성으로 인해 발생하는 문제를 해결하기 위해서 더 복잡한 요구사항이 발생한다. (일단 cache의 table에 각 row에 해당 값이 하위 Memory에서 copy된 이후로 변경되었는지를 표시하는 dirty bit가 필요하며, multi processor 환경에서는 더 큰 문제를 야기한다.)\n\n### 더 나은 Cache 저장법\n\n`Directed Mapping`을 통해서 Cache에 데이터를 저장하게 되면, 특정 Block이 위치할 수 있는 장소가 고정되어 버린다. 만약, index가 겹치는 값이 동시에 여러 번 사용된다면, miss rate가 크게 증가할 수 밖에 없다. 여기서, cache의 위치를 고정하지 않고, 자유롭게 하여 이러한 문제는 크게 줄일려고 하는 방법이 있다.\n\ntag에 모든 address 값을 저장하고, index를 address의 값으로 전혀 사용하지 않는 방식이 있다. 이것을 `full-associative cache`라고 한다. 이 경우에는 해당하는 index 범위에서 tag가 존재하는지를 확인하기 위해서 추가적인 연산이 필요하지만, hardware 장치를 추가적으로 배치하여 이를 동시에 실행시켜 성능을 향상시키는 방식을 택한다. 이 방식은 결론적으로 많은 hardware 장비를 추가적으로 요구하기 때문에 매우 비싸진다. 따라서, 적당한 합의점을 찾는 것이 `set-associative cache`이다. 이는 index 값을 일부만 이용하는 방식이라고 할 수 있다. 즉, 3bits를 index로 사용하는 cache에서 상위 n개의 bit만 실제로 사용하여 표현하는 것이다. 동일한 index를 가진 block은 $2^{전체 bit 수 - n}$ 존재하게 된다. 여기서, 이제부터 tag를 통해서 사용해서 검색을 수행하는 것이다. 따라서, 만약 n이 전체 bit 수와 같아 진다면, 이것이 `full-associative cache`가 되는 것이고, n = 0이라면, 일반적인 `Directed Mapping`이 되는 것이다.\n\n![set-associative](/images/set-associative.png)\n\n그렇다면, 이렇게 여러 개의 index가 data를 담을 수 있는 그릇이 될 때, 어느 위치에 값을 덮어 씌우는 것이 현명할 것인가는 **temporal locality**에 따라서 우리는 가장 쓰인지 오래된 index에 값을 덮어씌운다. 이것이 LRU(Least Recently Used) 방식이다. 이를 구현하기 위해서는 cache에 추가적인 reference bit라는 것을 위치시킨다.\n\n### MultiLevel Cache\n\n이제 cache를 여러 개 층(multilevel cache)을 이루어 사용한다고 해보자. process에 가까운 쪽을 primary cache라고 하고, 그 다음을 secondary cache라고 하자. 만약, primary cache에서 miss가 발생했을 대, secondary cache에 있으면, miss penalty를 줄일 수 있을 것이다. 하지만, secondary cache도 miss가 나면, miss penalty자체가 증가한다. 왜냐하면, secondary 로 불러오고, 다시 primary로 옮겨야 하기 때문이다. 그렇기에 무조건 cache를 많이 둔다고 좋은 것은 아니다. 적절한 cahce를 설정하는 것이 중요하고, 대게 이는 3개 정도로 한다.\n\n그리고 직관적으로 각 cache를 보면, primary cache는 hit time을 줄이는 것이 목표이고, secondary cache는 miss rate를 줄여야 한다. 그래서, primary cache에서는 block size를 줄이고, associative의 크기를 줄이지만, secondary cache에서는 block size를 키울 뿐만 아니라 associative의 크기 역시 키우는 것이 일반적이다.\n\n## Virtual Memory\n\nMain Memory를 안정적으로 관리하기 위해서, Virtual Memory라는 개념을 도입한다. 이는 실제로 존재하는 Main Memory와 Secondary Storage의 주소(**Physical Address**)를 가상의 주소(**Virtual Address**)로 바꾸고, 필요에 따라 이를 번역하여 사용함으로써, 하나의 process가 마치 Main Memory 하나를 장악하고 있는 거 같은 느낌을 느끼도록 할 수 있다. 왜냐하면, 당장에 쓰지 않는 process의 data는 Secondary Storage로 빼놓고, Virtual Address로 번역 시에는 해당 위치를 가르키도록 하면 된다. 그러면, 마치 각 process는 Main Memory 이상의 data를 갖고 있는 것 같다고 느낄 수 있다. 이러한 Virtual Memory를 이용하면 다음과 같은 작업을 쉽게할 수 있다.\n\n1. **동일한 장치에서 program 간의 Memory 영역을 구분할 때**, 일반적으로 Main Memory에 있는 데이터 역시 **locality**에 따라 계속해서 바뀌게 되는데, 특정 process 전체 크기를 실행 중일 동안 계속해서 제공한다면, 유연한 동작이 어렵다. 따라서, Virtual Memory는 이를 더 쉽게 하도록 돕는다.\n2. **동일한 장치 내에서 돌아가는 Virtual Machine간의 Main Memory 영역을 구분할 때**, 각 Virtual Memory는 Physical Memory로 번역되었을 때, 서로 충돌하지 않는 것을 보장하기 때문에 서로 다른 process간에 간섭이 없음을 보장할 수 있다.\n3. **Main Memory 보다 큰 크기의 Program을 돌리고자 할 때**, Main Memory 이상의 process를 돌리기 위해서는 Secondary Storage에 직접적인 접근을 수행해야 하는데, 이를 수행하지 않고, 실제로 현재 사용하지 않는 Memory 공간의 데이터는 Secondary Storage로 옮기고 이를 가르키는 Virtual Address만 바꾸어주면 되기 때문에, 쉽게 Main Memory 보다 큰 크기의 Program을 동작시키는 것도 가능하다.\n\nVirtual Memory 방식은 각 program, Virtual Machine마다 고유한 address space를 가지기 때문에 각자 독립되었다고 볼 수 있다. 그렇기에 각자가 서로의 동작으로 인한 영향을 받지 않는다. 즉, 다른 process에서 사용 중인 Memory에 접근할 수 없을 뿐만 아니라 이들에 의해서 발생하는 Memory의 변화가 자신이 진행 중인 process에 영향을 미치지 않는다. 즉, protection를 제공한다고 할 수 있다.\n\n또한, program을 상호간의 영향이 없는 조각으로 나눈 Overlay 단위로 나누어 초과되는 용량은 Secondary Storage에 상주시키고, 필요에 따라 Main Memory로 올려서 실행시킬 수 있다. 따라서, 용량이 부족한 Main Memory에서도 이보다 큰 크기의 Program을 동작시킬 수 있다.\n\nCache의 방식과 매우 유사하지만, 언어의 기원이 다르기 때문에 여기서는 Block을 **Page**라고 부른다. 그리고, 이 Page의 크기는 Page Offset이라고 표기한다. 따라서, **Virtual Address**는 사실상 두 개의 Part로 나뉘어진다. 첫 번째는 **Virtual Page Number**이고, 하나의 **Page offset**이다. 또한, Miss는 **Page Fault**라는 말로 바뀌어진다. 마지막으로, Virtual Address에 Mapping 되는 Physical Address를 Physical Page Number와 Page offset으로 이루어진다.\n\n위에서 말한 것처럼 Virtual Address를 Physical Address로 바꾸는 과정을 **Address Translation**이라고 한다.\n\n### Page 관리\n\n> **Virtual Page Number를 통해서 실제 Physical Page Number로 변환하기**\n\n기존의 Cache에서도 Miss로 인한 비용도 컸지만, **Page Fault**의 비용은 이보다도 훨씬 크다고 할 수 있다. 이를 막기 위해서, Cache에서는 Full Associative한 구조를 가져갔지만, Main Memory는 Cache보다 훨씬 크기 때문에 이를 위한 추가적인 Hardware를 추가하는 것은 경제적으로 불가능하다고 볼 수 있다. 따라서, Main Memory에 존재하는 Page의 Address를 Mapping하기 위해서 table을 이용한다. 이를 **Page Table**이라고 부른다. 이는 Main Memory에 상중하고 있다. 각 각의 program은 고유의 Page Table을 하나씩 가지게 되며, Page Table 자체의 처음과 끝을 가르키는 register를 가지고 있다(**Page Table Register**). 그리고 Page Table에는 Virtual Page가 지금 어느 Physical Address에 존재하는지에 대한 정보와 이것이 Main Memory에 있는지를 표기하는 Valid Bit가 존재한다. 만약, Valid Bit가 0이라면, 이는 해당 Page가 지금 Main Memory가 아닌 Secondary Storage에 존재한다는 뜻이다.\n\n따라서, Page를 찾는 과정은 다음과 같다.\n\n1. Page Table Register를 기반으로 하여 Main Memory에서 **Page Table을 찾는다**.\n2. Virtual Address의 Virtual Page Number를 이용해서 Page Table에서 Page를 조회한다.\n3. Valid Bit를 확인하여 해당 Page가 현재 Main Memory에 존재하는지 아니면 Secondary Storage에 존재하는지를 확인한다.\n4. 이제 실제 Physical Page Number를 얻어와서, 기존의 Page Offset을 합치면, 이것이 Physical Address가 된다.\n\n```plaintext\n  \n  🤔 Page Table의 크기가 너무 크면 어떻게 될까?\n\n  Page가 너무 많아지면, Page Table의 크기가 너무 커질 수 있다.\n  따라서, 이를 해결하기 위해서 계층 구조를 가지고 정리한다. \n  즉, Page Table의 Table이 생기는 형태라고 보면 되겠다.\n\n```\n\n> **Page Fault**\n\n위에서 말한대로 Page Fault가 발생한다면, 즉 Valid Bit가 0인 경우, 해당 Page를 Secondary Storage에서 찾고, 이를 Main Memory의 어느 위치에 놓을지를 결정해야 한다.\n\n우리가 번역한 Physical Address는 Secondary Storage의 직접적인 주소를 의미하기도 하지만 대게는 이를 이용해서 실제 Secondary Storage의 주소를 찾을 수 있도록 하는 자료구조를 가르키도록 되어있다. 그래서, 우리의 Operating System은 Process가 생성될 때, Process의 모든 Page를 Secondary Storage에 저장할 공간을 생성한다. 이를 `Swap Space`라고 부르며, 해당 Virtual Page가 실제 disk의 어디에 저장될지를 기록한 자료구조이다.\n\n만약, 이제 모든 Main Memory가 Page로 가득 차 있다면, OS는 어떤 Page를 대체할 것인지를 선택한다. 이때는 LRU(Least Recently Used) Algorithm을 사용한다. 지금까지 가장 사용하지 않은 Page를 삭제하는 것이다. 이를 구현할 때는 Reference bit를 설정하고, 주기적으로 0으로 변경하기를 반복하면서, 해당 Page를 사용할 때마다 1로 변경주는 것을 수행하는 것이다. 그리고, Page Fault가 발생할 시에 Reference Bit가 0인 대상이 있다면, 이를 우선으로 제거하는 방식이다.\n\n> **Write**\n\nWrite하는 것은 굉장히 많은 시간을 소요한다. 따라서, Virtual Memory System에서는 이를 최소화하는 것을 목표로 하기 때문에 이전에 소개한 Write Back이 default이다.\n\n> **TLB를 이용한 변환작업 속도 향상**\n\nPage Table이 실제로 Main Memory에 저장되기 때문에 우리는 Page를 조회하기 위해서 결국 무조건 Main Memory에 한 번 접근해야 한다. 이는 많은 시간을 소요하는 동작이기에 이를 최소화할 방법이 필요했다. 또한, Temporarl / Spatial Locality에 따라 사용한 Page는 다시 사용할 확룰이 많다. 따라서, 대게의 processor에서는 이를 위한 특별한 cache를 추가로 가지고 있다. 이것이 TLB(Translate Lookaside Buffer)이다. (아마 Translation cache라고 부르는 것이 더 자연스럽긴 할 것이다.) 따라서, TLB는 Virtual Page Number와 Dirty Bit, 그리고 Reference Bit를 가진다. TLB를 설계할 때에는 fully associative하게 만드는 것이 기본이다. 왜냐하면, TLB 자체가 매우 작고, hit rate가 성능에 큰 영향을 미치기 때문이다. 이렇게 구축하는 것이 성능에 큰 도움이 된다. 또한, replacing을 할 때에도 LRU를 구현할 수도 있지만 대게 이를 구현하기가 너무 경제적으로 어렵기 때문에, 대부분의 system은 랜덤하게 고르는 것을 선택한다고 한다.\n\n따라서, Page를 얻는 과정은 다음과 같다고 다시 요약할 수 있다.\n\n1. Page Table Register를 기반으로 하여 TLB에서 **Page Table을 찾는다**. 존재하지 않는다면, Main Memory에서 조회해야 한다.(TLB miss)\n2. Virtual Address의 Virtual Page Number를 이용해서 Page Table에서 Page를 조회한다.\n3. Valid Bit를 확인하여 해당 Page가 현재 Main Memory에 존재하는지 아니면 Secondary Storage에 존재하는지를 확인한다.\n4. 이제 실제 Physical Page Number를 얻어와서, 기존의 Page Offset을 합치면, 이것이 Physical Address가 된다.\n5. 이를 통해서, 조회를 수행하는데 만약, Secondary Storage에 있었다면, LRU를 이용해서 Page Swap을 수행하여 Page를 Main Memory로 올린다.\n6. 만약, TLB miss가 발생했었다면, 해당 Page 정보를 업데이트한다.\n\n자주 헷갈릴 수 있는 TLB miss가 Page Fault가 아니라는 것을 꼭 명심하자.\n\n![Virtual Memory](/images/virtual-memory.png)\n\n## Reference\n\n- David A. Patterson, John L. Hennessy, Computer Organization and Design\n","slug":"architecture-memory","date":"2022-04-29 19:25","title":"5. Memory Hierarchy","category":"Computer Architecture","tags":["Computer Organization And Design","Memory","Memory Hierarchy","Cache","Directed Mapping","Virtual Memory","Page"],"desc":"컴퓨터를 사용할 때, 우리는 기본적으로 Memory가 무한한 크기를 가지고 있기를 바란다. 하지만, 이를 실제로 구현하는 것은 비용적으로도, 기술적으로도 불가능하다. 따라서, 이를 마치 존재하는 것처럼 느끼도록 하는 Virtual Memory라는 기술을 사용한다.","thumbnailSrc":"https://euidong.github.io/images/default.jpg"},{"content":"\n## Intro\n\n우리가 원하는 것은 강한 performance를 발휘하면서도, 가용성(availability, 끊김 없이 사용할 수 있는 능력의 정도)가 높은 computer를 만드는 것이다. 이를 위해서, 우리는 단순히 하나의 processor를 정교하게 만들기보다는 동등한 기능을 하는 여러 개의 processor를 연결하여 사용하는 것이 더 효율적이라는 것이라는 것을 알아냈다. (이를 software가 잘 활용할 수만 있다면, 성능이 크게 향상될 것이다.)\n\n- 하나의 장치를 동작시키는 방식보다 적은 에너지로 같은 작업을 수행할 수 있다. (동시에 실행시키기 때문에 더 짧은 시간 사용할 수 있다.)\n- n개의 processor에서 하나가 실패하여도 n-1개는 정상 작동하기 때문에 전체 시스템은 문제 없이 동작한다. (Redundant, 추가자원을 통해서 가용성을 향상시킴)\n\n이에 따라 우리는 multi-processor를 사용한다.\n이는 multi-processor가 어떻게 존재하느냐에 따라서 다음과 같은 형태로 나눈다.\n\n1. **Multicore Microprocessor** : 하나의 IC(집적 회로) 칩에 여러 개의 processor(core)가 존재한다.\n2. **Multiple Processor** : IC칩의 갯수를 늘린다.\n3. **Cluster System** : Machine(Computer) 자체의 갯수를 늘린다.\n\n따라서, 개인 PC에서는 Multiple Multicore Microprocessor를 지원하고, 있는 상황이고, Datacenter와 같은 환경에서는 이러한 Machine들이 여러 개 존재하는 Cluster System이라고 생각하면 되겠다.\n\n또한, 이용하는 방식에 따라 크게 두 가지로 나눌 수 있다.\n\n1. Task Level Parallelism(=Process Level Parallelism) : 동시에 독립된 여러 program을 실행시키는 방식\n2. Parallel Processing Program : 동시에 여러 개의 processor를 이용하여 하나의 program을 실행시키는 방식\n\n## Parallel Processing Program의 구현\n\n하나의 작업을 더 빠르게 처리하기 위하여 multiple processor를 사용하는 software를 작성하는 것은 어렵다. 이는 processor의 수가 늘어날 수록 심해진다. multiprocessor program을 이용할 경우에, 수가 늘어날 수록 우리는 다음과 같은 작업에 대한 부담을 가질 수 밖에 없다.\n\n1. **Scheduling** : process 또는 thread를 scheduling하여 어떤 것을 먼저 실행시킬지에 대한 scheduling 역시 큰 부담이다.\n2. **Partitioning** : Memory의 구간을 각 processor에게 어떻게 나누고 서로 독립되게 존재하기 위한 관리를 수행하는 것 역시 큰 부담이 된다.\n3. **Balancing the Load** : 작업을 각 processor에게 균등히 분배하는 것 역시 어렵다.\n4. **Time to Synchronize** : 여러 개가 동시에 하나의 process를 실행시키면, 읽고 쓰기에서 충돌이 발생하는 것에 의한 문제가 발생하고 이를 해결하기 위해서 시간을 사용할 수 밖에 없다.\n5. **Overhead for Communication** : 각 processor간의 의사소통에 너무 큰 비용이 발생하는 경우 오히려 하나의 processor가 실행시키는 것보다 더 많은 시간을 요구할 수도 있다.\n\n이 모든 것을 software에서 제대로 관리할 수 있을 때, 그제서야 우리는 multi processor 시스템을 제대로 활용할 수 있는 것이다.\n\n우리가 processor의 갯수를 늘림으로써 얻을 수 있는 혜택은 각 processor에 전달되는 작업의 수를 균등하게 나누어, 기존에 하나의 processor가 할 수 없던 일을 처리(weak scaling)하거나, 기존의 문제를 더 빠르게 처리(strong scaling)할 수 있다.\n\n## Data Stream, Instruction Stream\n\nprocessor들로 들어오는 data의 양을 의미하는 **Data Stream**과 instruction의 양을 의미하는 **Instruction Stream**에 따라서, 우리는 각 processor들을 다양한 이름으로 부른다.\n\n1. **SISD**(Single Instruction Stream, Single Data Stream) : 대게 single processor일 경우 이와 같은 형태를 채택한다.\n2. **MIMD**(Multiple Instrunction Stream, Multiple Data Stream) : Multiple Processor System에서는 당연히 이와 같은 시스템을 채택한다.\n3. **MISD**(Multiple Instrunction Stream, Single Data Stream) : 잘 사용하지 않는 형태이다. 대게는 Data의 처리가 더 많이 발생하기 때문이다.\n4. **SIMD**(Single Instruction Stream, Multiple Data Stream) : 하나의 Instruction을 이용하여 복합적인 여러 개의 데이터를 한 번에 처리하는 vector 연산 등을 빠르게 처리할 수 있다.\n   1. vector 연산 하나가 for loop 하나를 의미할 수 있다. 이는 processor part의 각 pipeline 단계에서 fetch와 decode에 의한 비용을 크게 감소시킬 수 있다.\n   2. 하나의 vector 연산은 내부에서 각각이 독립적으로 수행되기 때문에, data hazard를 check하는 비용이 발생하지 않는다. 👉 따라서, vector의 각 요소를 모두 검사하는 것이 아닌 vector 외부 간의 data hazard 유무만 확인하면 된다.\n   3. Main Memory에서 데이터를 불러올 경우에도 각 요소를 불러오는 것이 아닌 한 번에 가져올 수 있기 때문에 매우 빠르다.\n   4. Loop를 표현이 vector 연산으로 대체되기 때문에, Loop Branch가 줄어든다.\n\n## Hardware Multithreading\n\nprogrammer의 입장에서 MIMD는 hardware multithreading처럼 동작한다고 생각하게 한다. 이는 processor의 사용성을 최대화하기 위해서, 특정 thread가 stall 되었을 때, 다른 thread를 수행하도록 하는 방식이다. 즉, 하나의 processor에서 여러 개의 thread를 실행시킨다는 것이다. 그러기 위해 사실상 여러 processor가 존재하는 multiprocessor 환경에서 서로간 실행 환경을 서로 공유해야 한다. 이를 실현하려면, 각 thread의 독립된 상태를 복사할 수 있어야 한다. 즉, 각 각의 register file과 PC가 존재해야 한다. 이들 간의 Memory 공유 같은 경우는 이전에 보았던 Virtual Memory 정보를 공유하여 수행하게 된다. 그리고 무엇보다 중요한 것은 이 실행하는 thread를 바꾸는 시간적 비용이 작아야 한다. 이를 위해서, process가 아닌 thread를 바꾸는 것이다. process를 바꾸는 것보다는 비용이 훨씬 적기 때문이다.\n\nthread를 변경 시에 어떤 방법을 택할 것인가 역시 중요한데, 아래와 같은 방법론이 존재한다.\n\n> **1. Fine Grained Multithreading**\n\nthread의 명령어를 round robine 방식을 이용하여 매번 바꾸면서 실행시키는 방식이다. 변경한 thread 역시 stall이 된 thread라면, 건너뛰고 다음 thread를 실행시킨다.\n\n- 장점 : stall 기간이 짧던 길던 이로 인한 손실을 감추고, 그 동안 다른 thread를 실행시킬 수 있다.\n- 단점 : 실행 준비가 된 상태(stall이 아닌 상태)에서도 다음 차례가 올 때까지 반드시 기다려야 하기 때문에 하나의 thread에 대한 처리 속도가 dramatic하게 줄어든다.\n\n> **2. Coarse Grained Multithreading**\n\n하나의 thread에 대한 Instruction만 처리하다가 stall이 발생했을 때에만 thread를 변경하도록 하는 방식이다.\n\n- 장점 : 하나의 thread에 대한 처리 속도의 손실이 적고, switching을 빨리 하는 것에 대한 부담이 적다.\n- 단점 : 하나의 thread에 대한 Instruction만 처리하기 때문에, thread를 변경하는 것에 대한 비용이 크다. (long pipeline setup time) 따라서, 짧은 기간의 stall인 경우에는 해당 stall이 끝나길 기다린다.\n\n> **3. Simultaneous Multithreading(SMT)**\n\nThread Level에서 Parallelism과 Instruction Level에서의 Parallelism을 동시에 수행하는 방식이다. Multiple Instruction 시스템에서는 더 많은 functional unit(register, pc, etc)이 있기 때문에 이를 Multi Threading에서도 적절히 사용할 수 있다는 접근법에서 나왔다. 여기서는 register renaming과 dynamic scheduling을 이용하여 multiple thread에서 여러 개의 Instruction을 빈틈없이 배치할 수 있다. 의존성은 dynamic scheduling이 해결하고, register renaming을 통해 필요에 따라 여분의 register를 불러와서 사용하는 것이 가능해졌다. 이를 통해서 위의 두 방식으로 할 수 없었던, multi processor를 최대한으로 사용하는 효과를 볼 수 있다.\n\n![multi-threading](/images/multi-threading.png)\n\n## GPU(Graphic Processing Unit)\n\ngame 산업 및 그래픽 분야의 큰 성장에 힘업어 graphic 처리에 대한 processor의 성능 향상이 필요했다. 즉, 기존 micro processor와 겉아 다용도로 사용되는 것이 아닌 graphic 연산만을 빠르게 처리할 수 있는 processor를 분리할 필요가 생긴 것이다. 이것만을 위해서 만들어진 것이 GPU이다.\n\nGPU는 앞 서 설명한 Multi Threading 기술을 적극 도입했기 때문에 Memory 접근에 따른 Latency가 성능에 큰 영향을 미치지 않는다. 그런 만큼 반대로 높은 Bandwidth를 가진 저장 장치를 필요로 한다.\n\n후에는 이 장치가 수행하는 vector 연산이 여러 용도로 사용됨에 따라 이를 위한 programming language들도 만들어졌다. 대표적인 것이 NVidia가 C를 통해서 만든 CUDA이다.\n\n## Reference\n\n- David A. Patterson, John L. Hennessy, Computer Organization and Design\n","slug":"architecture-parallel-processors","date":"2022-05-02 20:22","title":"6. Parallel Processors","category":"Computer Architecture","tags":["Computer Organization And Design","Multi Processors","Multi Threading","MTU"],"desc":"우리가 원하는 것은 강한 performance를 발휘하면서도, 가용성(availability, 끊김 없이 사용할 수 있는 능력의 정도)가 높은 computer를 만드는 것이다. 이를 위해서, 우리는 단순히 하나의 processor를 정교하게 만들기보다는 동등한 기능을 하는 여러 개의 processor를 연결하여 사용하는 것이 더 효율적이라는 것이라는 것을 알아냈다. (이를 software가 잘 활용할 수만 있다면, 성능이 크게 향상될 것이다.)- 하나의 장치를 동작시키는 방식보다 적은 에너지로 같은 작업을 수행할 수 있다. (동시에 실행시키기 때문에 더 짧은 시간 사용할 수 있다.)- n개의 processor에서 하나가 실패하여도 n-1개는 정상 작동하기 때문에 전체 시스템은 문제 없이 동작한다. (Redundant, 추가자원을 통해서 가용성을 향상시킴)이에 따라 우리는 multi-processor를 사용한다.이는 multi-processor가 어떻게 존재하느냐에 따라서 다음과 같은 형태로 나눈다.1. Multicore Microprocessor : 하나의 IC(집적 회로) 칩에 여러 개의 processor(core)가 존재한다.2. Multiple Processor : IC칩의 갯수를 늘린다.3. Cluster System : Machine(Computer) 자체의 갯수를 늘린다.따라서, 개인 PC에서는 Multiple Multicore Microprocessor를 지원하고, 있는 상황이고, Datacenter와 같은 환경에서는 이러한 Machine들이 여러 개 존재하는 Cluster System이라고 생각하면 되겠다.또한, 이용하는 방식에 따라 크게 두 가지로 나눌 수 있다.1. Task Level Parallelism(=Process Level Parallelism) : 동시에 독립된 여러 program을 실행시키는 방식2. Parallel Processing Program : 동시에 여러 개의 processor를 이용하여 하나의 program을 실행시키는 방식","thumbnailSrc":"https://euidong.github.io/images/default.jpg"}],"Tech":[{"content":"\n## Intro\n\n문자열 데이터의 전처리 시에 많이 사용되는 기술로 대게 문자열에서 특정 pattern을 추출하거나 검색, 필터링할 때 많이 사용되어진다.\n\n## regex\n\nRegular Expression의 약자로 한국어로 **정규표현식**이라고 부른다. 대게 모든 언어에서 이를 이용할 수 있는 라이브러리를 제공하거나 기본으로 포함하고 있기 때문에 이를 이해하는 것은 문자열을 다루는 능력치를 한 층 더 끌어올려준다.\n\n우선 기본적으로 모든 character를 이용해서 pattern으로 생성할 수 있다. 하지만, 이것만으로는 복잡한 기능을 수행하는데 부족하다. 따라서, 특별한 character를 활용하여 이를 수행할 수 있다.\n\n> **Special Character**  \n\n기본적으로 특수 문자는 regex에서 표현할 때, \\를 이용해서 구분해주어야 한다. 하지만, 이를 사용하지 않고 바로 사용할 경우에는 대게 특별한 의미를 갖는 경우가 많다. 반대로, 일반 문자의 경우에는 \\에 영어 character를 더하는 경우 특별한 의미를 갖는 경우가 있다. 하지만, 핵심적인 기능은 아래 문자들이다.\n\n| Character | Mean | Example. pattern | Example. matched string |\n| :-- | :-- | :-- | :-- |\n| ? | 이전 문자가 있는 경우와 없는 경우를 모두 포함한다. | colou?r | <u>color</u> <u>colour</u> |\n| + | 이전 문자가 하나 이상 있는 경우를 모두 포함한다. | o+h | <u>oh</u> <u>ooh</u> <u>ooooooooh</u> |\n| * | 이전 문자가 0개 이상 존재하는 경우를 모두 포함한다. | oo*h | <u>oh</u> <u>ooh</u> <u>oooooooh</u> |\n| . | 모든 문자라는 의미를 갖는다. | beg.n | <u>begin</u> <u>begun</u> <u>begUn</u> |\n| ^ | 문자열의 시작 부분을 특정 짓는다. | ^a | <u>a</u>aaaa <u>a</u>lto |\n| $ | 문자열의 끝 부분을 특정 짓는다.  | a$ | aaaa<u>a</u> se<u>a</u> |\n| \\| | \\|를 좌우로 있는 두 word를 모두 포함한다. | hello\\|world | <u>hello</u> <u>world</u> <u>hello</u>,<u>world</u> |\n\n> **Square Bracket**\n\n또한, square bracket([])이 가지는 기능이 다양하다. 이 내부에 있는 모든 문자를 하나의 문자로 취급한다는 것이 특징이며, 앞에서 살펴본 \\|의 확장 버전이라고 볼 수 있겠다. 또한, 이 안에서는 일부 특수 기호가 또 다른 의미를 가지게 된다.\n\n| Character | Mean | Example. pattern | Example. matched string |\n| :-- | :-- | :-- | :-- |\n| [] | []내부에 있는 모든 문자를 포함하는 글자가 하나라도 있는지를 확인 | [wW]ood | <u>wood</u> <u>Wood</u> |\n| [a-z] | alphabet의 대소문자와 숫자에만 제한된 기능으로, 그 사이의 모든 문자를 포함한다는 의미를 내포한다. | [a-zA-Z0-9]+ | <u>1234</u> <u>hello</u> <u>Hel10</u> <u>Hell</u>ㅇ <u>Happy</u> |\n| [^] | ^ 이후로 오는 문자를 포함하지 않는지 확인 | ^[^a-z] | <u>A</u> a <u>1</u>234 | \n\n더 많은 기능 예를 들면, Grouping이라는 기능도 존재하지만 위의 내용만 숙지해도 문자열 처리의 기본은 가능하다.\n\n사실 이것만으로는 내용이 부족할 수 있는데 playground 및 regex 용법에 대한 설명이 잘 정리된 사이트를 해당 사이트를 참고하기 바란다. [🔗 Regexr](https://regexr.com/)\n\n## Reference\n- Thumbnail : Photo by [Mingwei Lim](https://unsplash.com/es/@cmzw?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/s/photos/word-pattern?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n- https://regexr.com/","slug":"regex","date":"2022-10-19 21:48","title":"REGEX","category":"Tech","tags":["String","TextProcessing"],"desc":"문자열 데이터의 전처리 시에 많이 사용되는 기술로 대게 문자열에서 특정 pattern을 추출하거나 검색, 필터링할 때 많이 사용되어진다.","thumbnailSrc":"https://euidong.github.io/images/regex-thumbnail.jpg"},{"content":"\n## Intro\n\ndocker에 기본 이념은 하나의 container에는 하나의 process만 두어야 한다는 것이다. 하지만, 이에 대해서 반대를 하고, 하나의 container에 여러 개의 process를 심고 이를 이용하겠다는 생각으로 만들어진 open source이다. 사용 예시는 main process 내부에 cronjob을 끼워넣는 것과 같은 경우가 있을 것이다.\n\n이는 결론적으로 Dockerfile의 확장 버전이라고 볼 수도 있을 거 같다. 좀 더 복잡한 작업을 더 체계적으로 할 수 있는 틀을 제공한다. 아이디어 자체는 참신하나 남발하게 되면, stateless하던 container가 점점 stateful하게 되면서 시스템이 오염될 수도 있음을 유의하자.\n\n아래 내용은 해당 opensource의 README를 직접 번역한 내용이니 의역도 많이 포함된다. 주의해서 읽도록 하자. 또한, 모르는 용어는 아래 Terminology를 확인해보도록 하자.\n\n## Goals\n\n- 이미지 제작자가 쉽게 s6(s6는 process를 감독, 관리, logging, 초기화하는 기능들의 집합)를 활용할 수 있도록 지원\n- 다른 docker image들처럼 동일하게 작동\n\n## Features\n\n- cont-init.d →초기화 작업과 같은 end-user 실행 작업을 허용하는 간단한 초기 작업\n- cont-finish.d → 마무리 작업\n- fix-attrs.d → ownership 권한을 수정\n- s6-overlay는 적당한 PID 1 기능을 제공한다.\n  - container에 걸리는 zombie process를 가지지 않고, 적당한 절차에 따라 제거될 것이다.\n- **여러 개의 process를 하나의 container에서 작동시키는 것이 가능하다.**\n- **\"The Docker Way\"(아래에서 설명)에 따라 작동시키는 것이 가능하다.**\n- 모든 기반 이미지(Ubuntu, CentOS, Fedora, 심지어는 Busybox)를 사용하는 것이 가능하다.\n- 이미지의 layer의 수를 작게 유지하기 위하여 하나의 tar, gz 파일로 배포한다.\n- s6 와 s6-portable-utils 는 손쉽고 작성이 쉬운 유틸리티 전체를 포함한다.\n- 비밀리에 s6-log 를 사용하는 logutil-service는 오래된 로그의 순환을 수행한다.\n- 특정 유저로 전체 process tree를 동작시키기 위하여, Docker의 USER 지침에 대하여 지원한다. 모든 feature에 대하여 지원하는 것은 아니라는 것을 알아두어야 한다. 자세한 사항은 여기서 확인가능하다.([🔗 notes](https://github.com/just-containers/s6-overlay#notes))\n\n## The Docker Way\n\n자주 강조되어지는 Docker의 신념은 \"하나의 container에 하나의 process만 두어야 한다.\"는 것이다. 그러나, S6 overlay 팀은 이에 대하여 동의하지 않는다. 하나의 container에 여러 process를 동작시키는 것에 대한 본질적 문제는 없다. 더 추상적으로 \"하나의 container에 하나의 thing만 두어야 한다.\"는 것이 해당 프로젝트의 목적이다. → 하나의 container는 하나의 것만 수행할 수 있다. 예로써, chatting service 또는 gitlab의 동작을 들 수 있다. 이것들은 여러 개의 process를 포함하지만, 하나의 thing이다. 따라서, 올바르다는 것이다.\n\n이미지 제작자가 process supervisor를 피하는 이유는 하나의 process supervisor가 실패한 서비스를 다시 시작해야 한다고 생각하기 때문입니다. 이로 인해서 결국 Docker container는 절대 죽지 않을 것이다. 이러한 container가 죽지 않는 현상은 docker 생태계를 파괴할 것이다. 대부분의 이미지는 에러가 발생했을 때, 중단을 요청하는 하나의 process를 동작시킨다. 에러에 대해서 종료를 수행함으로써, 시스템 관리자는 실패를 원하는대로 다루는 것을 허락받는다. 만약 이미지를 절대 종료시키지 않는다면, 에러 회복과 실패 알림에 대한 대안책이 필요하다. 즉, container를 실패에도, 종료하지 않는 것은 매우 위험하다.\n\nS6 overlay 팀의 정책은 만약 thing이 실패한다면, 그때 container가 반드시 실패햐야 한다는 것이다. 우리는 어떤 process들을 다시 동작시킬 수 있을지와 어떤 container를 끌어내릴지를 결정한다. 예를 들어, cron 이나 syslog에서 실패가 발생했을 때, container는 부정적 영향 없이 이것을 재시작하는 것이 가능할 것이다. 그러나 만약, ejabberd 가 실패했을 경우에는 container는 종료될 것이고, 이를 통해서 시스템 관리자는 이에 대한 대책을 수행할 수 있을 것이다.\n\n따라서, S6 team에서 생각하는 \"The Docker Way\"란 다음과 같다.\n\n- Container는 반드시 하나의 thing만 수행해야 한다.\n- Container는 thing이 멈춘다면, 반드시 멈춰야 한다.\n\n그리고, 우리의 초기 시스템은 이를 위해서 설계되었다. 이미지는 여전히 다른 Docker 이미지처럼 동작할 것이고, 이미 존재하는 이미지들의 생태계와 함께 어우러질 것이다.\n\n---\n\n## Init stages\n\nS6 overlay init은 container화된 환경에 적당하게 동작하기 위해 적당하게 맞춤화한 프로그램이다. 해당 section에서는 어떻게 stage들이 동작하는지 간단히 설명한다. 만약 더 자세한 사항이 궁금하다면, 다음 article을 읽기를 추천한다. ([How to run s6-svscan as process 1](http://skarnet.org/software/s6/s6-svscan-1.html))\n\n- **stage 1 :** 해당 단계의 목적은 두 번째 단계에 진입하기 위해서 이미지를 준비하는 것이다. 다른 것들 사이에서, 이것은 container 환경변수들을 준비하는 것과 s6 가 효과적으로 시작될 때까지 두 번째 stage의 시작을 막는 것에 대한 책임이 있다.\n- **stage 2 :** end-user가 제공한 대부분의 파일들이 수행되어지는 단계이다.\n  1. /etc/fix-attrs.d를 사용하여, 소유권과 권한을 고정한다.\n  2. /etc/cont-init.d에 기술된 초기화 script를 실행시킨다.\n  3. /etc/services.d에 적힌 user service들을 s6가 supervision을 동작 중인 폴더에 복사하고, signal을 보냄으로써 적절하게 supervising을 시작할 수 있다.\n- **stage 3 :** 해당 단계는 종료 단계이다. 이는 다음과 같은 동작을 수행한다.\n  1. TERM signal을 모든 관리 중인 service에게 전송한다.\n  2. /etc/cont-init.d에 포함된 종료 scripts를 수행한다. 이는 서비스가 여전히 종료되어지는 중에도 종료되어질 수 있다.\n  3. 모든 service가 종료되기를 기다린다.(S6\\_SERVICES\\_GRACETIME milliseconds를 넘지 않는 선에서 - default 3000)\n  4. 모든 process에게 TERM signal을 보낸다.\n  5. S6\\_KILL\\_GRACETIME milliseconds(default 3000)만큼 sleep을 수행한다.\n  6. 모든 process에게 KILL signal을 전송한다.\n\n## Usage\n\n해당 project는 표준 tar, gz으로 배포되어졌다. 이를 사용하기 위해서는 image의 root에 이를 추출하고, ENTRYPOINT에 /init 을 기입해주면 된다. (만약, 기존 ENTRYPOINT가 있다면, 이를 cont-init으로 옮겨주어야 할 것이다. 또는 S6\\_CMD\\_ARG0를 이용하면 된다.)\n\n여기서, 해당 project는 wget 또는 curl을 수행할 때, Docker의 RUN보다 ADD 지시어를 사용할 것을 추천한다. (왜냐하면, 이를 이용하면, Docker가 https URL을 다룰 수 있다.)\n\n여기서부터, 서비스를 작성할 때에는 두 쌍의 선택지를 갖게 된다.\n\n> **1. image의 CMD 를 이용하여 service/program을 실행시킨다.**\n\n```Dockerfile\nFROM busybox\nADD https://github.com/just-containers/s6-overlay/releases/download/v1.21.8.0/s6-overlay-amd64.tar.gz /tmp/\nRUN gunzip -c /tmp/s6-overlay-amd64.tar.gz | tar -xf - -C /\nENTRYPOINT [\"/init\"]\n```\n\n```bash\n# run\ndocker-host $ docker build -t s6demo .\ndocker-host $ docker run -ti s6demo /bin/sh\n[fix-attrs.d] applying owners & permissions fixes...\n[fix-attrs.d] 00-runscripts: applying... \n[fix-attrs.d] 00-runscripts: exited 0.\n[fix-attrs.d] done.\n[cont-init.d] executing container initialization scripts...\n[cont-init.d] done.\n[services.d] starting services\n[services.d] done.\n\n# ps\ndocker-host $ docker ps\nPID   USER     COMMAND\n    1 root     s6-svscan -t0 /var/run/s6/services\n    21 root     foreground  if   /etc/s6/init/init-stage2-redirfd   foreground    if     s6-echo     [fix-attrs.d] applying owners & permissions fixes.\n    22 root     s6-supervise s6-fdholderd\n    23 root     s6-supervise s6-svscan-log\n    24 nobody   s6-log -bp -- t /var/log/s6-uncaught-logs\n    28 root     foreground  s6-setsid  -gq  --  with-contenv  /bin/sh  import -u ? if  s6-echo  --  /bin/sh exited ${?}  foreground  s6-svscanctl  -t\n    73 root     /bin/sh\n    76 root     ps\n\n# exit\n/bin/sh exited 0\ndocker-host $\n```\n\n> **2. s6-overlay를 활용하는 쉬운 방법이라고 할 수 있다.**\n\nDockerfile이 build할 때, 작성하거나 runtime에 command line으로 입력이 가능하다. 이것은 s6 supervisor에 의해서 실행되어질 것이다. 그리고 실패나 종료 시에 해당 container는 종료되어질 것이다. interactive program도 s6 supervisor 하위에서도 동작시킬 수 있다. service script를 작성하여 실행시킨다.\n\n`/etc/services.d/myapp/run`\n\n```shell\n  !/usr/bin/execlineb -P\n  nginx -g \"daemon off;\"\n```\n\n관리되는 서비스를 제작하는 것은 단지 /etc/services.d에 service directory를 만들고, 장기간 존재할 process 실행에 대한 내용을 적은 run 파일을 이 안에 만드는 것보다 더 쉬워질 수 없다. 이거면 다다. 만약 s6 supervision에 대한 더 많은 내용을 알기를 원한다면 다음 문서를 살펴보아라. (\\[servicedir\\](<[http://skarnet.org/software/s6/servicedir.html](http://skarnet.org/software/s6/servicedir.html)\\>))\n\n## 소유권 및 권한 고정\n\n때때로, 진행 전에 소유권과 권한을 고정하는 것이 필요할 때가 있다. 대표적인 예시가 container 내부에 host folder와 mount된 folder가 있을 때이다. overlay는 /etc/fix-attrs.d의 파일을 사용하여 이를 헤쳐나갈 방법을 제공한다.\n\n- Format\n  - path : File 또는 Directory의 경로\n  - recurse : folder가 발견되었다면, 해당 folder 내부의 내용도 포함할지를 결정합니다. (true or false)\n  - account : target의 account이다. account를 찾을 수 없을 경우 default로 예비 uid:gid(user id, group id)를 사용할 수 있다. 예를들어, nobody, 32768:32768 이라고 입력할 경우, nobody account를 첫번째로 사용하기 위한 시도를 하고, 예비로 uid가 32768인 대상을 예비로 찾는다. 예를들어, daemon 의 계정이 UID=2이고, GID=2인 경우 다음과 같은 account 도 사용할 수 있다.\n    - daemon: UID=2 GID=2\n    - daemon,3:4: UID=2 GID=2\n    - 2:2,3:4: UID=2 GID=2\n    - daemon:11111,3:4: UID=2 GID=11111\n    - 11111:daemon,3:4: UID=11111 GID=2\n    - daemon:daemon,3:4: UID=2 GID=2\n    - daemon:unexisting,3:4: UID=2 GID=4\n    - unexisting:daemon,3:4: UID=3 GID=2\n    - 11111:11111,3:4: UID=11111 GID=11111\n  - fmode : target file의 mode → example 0644\n  - dmode : target directory의 mode → example 0755\n- path recurse account fmode dmode\n\n> **Example**\n\n`/etc/fix-attrs.d/01-mysql-data-dir`\n\n```shell\n/var/lib/mysql true mysql 0600 0700\n```\n\n`/etc/fix-attrs.d/02-mysql-log-dirs`\n\n```shell\n/var/log/mysql-error-logs true nobody,32768:32768 0644 2700\n/var/log/mysql-general-logs true nobody,32768:32768 0644 2700\n/var/log/mysql-slow-query-logs true nobody,32768:32768 0644 2700\n```\n\n## 초기화 작업 실행하기\n\n`/etc/fix-attrs.d`에 따라 속성을 고정하는 작업을 수행한 후, `/etc/services.d`에 적힌 user에게 제공되는 서비스를 시작하기 전에, overlay는 /etc/cont-init.d 에서 발견된 모든 script를 실행시킨다.\n\n`/etc/cont-init.d/02-confd-onetime`\n\n```shell\n#!/usr/bin/execlineb -P\n\nwith-contenv\ns6-envuidgid nginx\nmultisubstitute\n{\n  import -u -D0 UID\n  import -u -D0 GID\n  import -u CONFD_PREFIX\n  define CONFD_CHECK_CMD \"/usr/sbin/nginx -t -c {{ .src }}\"\n}\nconfd --onetime --prefix=\"${CONFD_PREFIX}\" --tmpl-uid=\"${UID}\" --tmpl-gid=\"${GID}\" --tmpl-src=\"/etc/nginx/nginx.conf.tmpl\" --tmpl-dest=\"/etc/nginx/nginx.conf\" --tmpl-check-cmd=\"${CONFD_CHECK_CMD}\" etcd\n```\n\n## 부가적인 종료 작업 작성하기\n\n기본적으로, /etc/services.d 에 의해 생성된 서비스는 자동적으로 재시작된다. 만약, 서비스가 container를 down 시켜야한다면, finish script를 통해서 이를 수행할 수 있다.\n\n`/etc/services.d/myapp/finish`\n\n```shell\n#!/usr/bin/execlineb -S0\n\ns6-svscanctl -t /var/run/s6/services\n```\n\n더 발전된 기능을 사용할 수도 있다.\n\n`/etc/services.d/myapp/finish`\n\n```shell\n#!/usr/bin/execlineb -S1\nif { s6-test ${1} -ne 0 }\nif { s6-test ${1} -ne 256 }\n\ns6-svscanctl -t /var/run/s6/services\n```\n\n## Logging\n\nS6 overlay는 즉시 \\[s6-log\\](<[http://skarnet.org/software/s6/s6-log.html](http://skarnet.org/software/s6/s6-log.html)\\>)를 통한 logging mechnism으로 쉽게 logging을 관리하는 방법을 제공한다.\n\n또한, logging을 하나의 바이너리 호출로 만들 수 있도록 logutil-service라는 도움 장치를 제공한다.\n\n이는 다음 순서에 따라 진행된다.\n\n- s6-log가 어떻게 S6\\_LOGGING\\_SCRIPT에 적힌 logging script를 읽을지를 조회합니다.\n- nobody user의 root 권한을 삭제한다.(만약, 존재하지 않는다면, 기본적으로 32768:32768 에게 넘겨집니다.)\n- 모든 환경 변수를 지웁니다.\n- s6-log를 실행함으로써 logging을 시작합니다.\n\n> **주의사항**\n\n- 권한이 자동적으로 삭제된 이후로, s6-setuidgid로 user를 변경할 필요가 없다.\n- 둘 중 하나의 내용을 log folder에서 보장해야 한다.\n  1. 존재한다면, nobody user에 의해 작성이 가능해야 한다.\n  2. 존재하지 않는다면, 상위 폴더가 nobody user에 의해 작성이 가능해야 한다.\n\nlog foder는 cont-init.d script에서 또는 run script 안에서 생성하는 것이 가능하다.\n\n### Example\n\n> **1. cont-inid.d를 활용한 방법**\n\n`/etc/cont-init.d/myapp-logfolder`\n\n```shell\n#!/bin/sh\nmkdir -p /var/log/myapp\nchown nobody:nogroup /var/log/myapp\n```\n\n> **2.  run script를 활용한 방법**\n\n`/etc/services.d/myapp/log/run`\n\n```shell\n#!/bin/sh\n# input stdin을 기반으로 하는 logging\nexec logutil-service /var/log/myapp\n\n#!/bin/sh\n# fifo에 따른 log를 쌓기를 원한다면, 다음과 같이 수행하는 것도 가능하다.\nexec logutil-service -f /var/run/myfifo /var/log/myapp\n```\n\n## 권한 삭제\n\n서비스 실행이 다가오면, 실행 전에 권한을 부여하는 것은 서비스이건 logging 서비스이건 매우 중요한 작업이다. s6는 이미 이러한 작업을 위한 기능을 포함하고 있다.\n\n> **In execline**\n\n```shell\n#!/usr/bin/execlineb -P\ns6-setuidgid daemon\nmyservice\n```\n\n> **In sh**\n\n```shell\n#!/bin/sh\nexec s6-setuidgid daemon myservice\n```\n\n만약 이러한 기능에 대하여 더 알고 싶다면, 다음 문서들을 살펴 보아라. [s6-setuidgid](http://skarnet.org/software/s6/s6-setuidgid.html),  [s6-envuidgid](http://skarnet.org/software/s6/s6-envuidgid.html), [s6-applyuidgid](http://skarnet.org/software/s6/s6-applyuidgid.html)\n\n## Container 환경\n\n만약 container 환경을 제공하기 위해서 직접 만든 script를 원한다면, with-contenv를 통해서 이를 수행하는 것이 가능하다.\n\n> **/etc/cont-init.d/01-contenv-example**\n\n```shell\n#!/usr/bin/with-contenv sh\necho $MYENV\n```\n\n## Read-Only Root 파일 시스템\n\n최근 dokcer의 버전에서 read-only 파일 시스템으로 container를 동작시키는 것을 허용하였다. 2단계 과정에서, overlay는 사용자가 제공하는 cont-init.d 의 권한을 변경하는 부가작업을 수행한다. 만약, root 파일 시스템이 read-only라면, S6\\_READ\\_ONLY\\_ROOT=1 라는 설정을 해주어 stage 2에서 이를 알 수 있도록 해야 한다. 이를 통해서 permission을 변경하기 이전에, /var/run/s6 에 사용자의 파일을 복사하게 된다.\n\n이는 /var 가 수정이 가능한 권한을 갖게된다는 것이고, 이는 tmpfs 라는 파일시스템에 의해서 가능하다.\n\n→ 다음과 같이 사용하면, 수행이 가능하다.\n\n```bash\n$ docker run -e S6_READ_ONLY_ROOT=1 --read-only --tmpfs /var:rw,exec [image name]\n```\n\n> **주의사항**\n\n만약 S6\\_READ\\_ONLY\\_ROOT=1 를 사용할 때, fix-attrs.d, cont-init.d, cont-finish.d, services.d의 symbol link를 유의해야 한다. s6의 제한사항 때문에, 앞 선 디렉토리가 /var/run/s6에 복사되며 symbol link가 실행되어 예기치 않은 중복이 발생한다.\n\n### s6 동작 사용자화\n\ns6의 동작을 이미 정의된 환경 변수를 설정함으로써 실행단계에서 조정하는 것이 가능하다.\n\n- S6\\_KEEP\\_ENV (default = 0): 만약 설정이 되면, 환경과 전체 관리 과정이 바라보는 원본 환경변수는 reset되지 않는다. 이는 with-contenv를 무의미하게 바꿔버린다.\n- S6\\_LOGGING (default = 0):\n  - **0**: 모든 Output이 stdout/stderr로 전달된다.\n  - **1**: 내부의 catch-all logger를 사용하여, 지속적으로 이것에 전송한다. 이는 /var/log/s6-uncaught-logs에 위치한다. 그래도 CMD에서는 stdout/stderr를 통해 전달한다.\n  - **2**: 내부의 catch-all logger를 사용하여, 지속적으로 이것에 전송한다. 이 과정에 CMD도 포함된다. 따라서, stdout/stderr로 쓰여지는 것은 아무것도 없다.\n- S6\\_BEHAVIOUR\\_IF\\_STAGE2\\_FAILS (default = 0):\n  - **0**: script(fix-attrs or cont-init)에서 에러가 발생했더라도 조용하게 지속한다.\n  - **1**: 에러 메세지에 대한 경고를 제공한 후에 지속한다.\n  - **2**: 관리 시스템에 종료 signal을 전송하면서 종료한다.\n- S6\\_KILL\\_FINISH\\_MAXTIME (default = 5000): /etc/cont-finish.d 의 script가 종료 signal을 받을 때까지 가질 수 있는 최대 대기 시간을 의미한다. 각 script가 수행될 때마다 수행된다.\n- S6\\_SERVICES\\_GRACETIME (default = 3000): 얼마나 s6 가 서비스가 TERM signal을 보낼 때까지 기달릴지를 의미합니다.\n- S6\\_KILL\\_GRACETIME (default = 3000): 얼마나 s6 가 zombie를 거두는데 기다릴지를 의미합니다. 시간이 지나면 KILL signal을 전송합니다.\n- S6\\_LOGGING\\_SCRIPT (default = \"n20 s1000000 T\"): 해당 변수는 어떻게 무엇을 logging할지를 결정한다. 기본적으로 ISO8601를 모든 line에 덧붙이고, 1mb에 도달하거나 20개 이상의 파일이 생성되면 rotation을 수행한다.\n- S6\\_CMD\\_ARG0 (default = not set): 해당 환경 변수의 값은 docker에 의해 전달된 CMD 인자에 덧붙여진다. 존재하는 이미지를 s6-overlay로 변경할 때, 이전에 사용했던 ENTRYPOINT의 값을 이곳에 전달함으로써 이를 사용하는 것이 가능하다.\n- S6\\_FIX\\_ATTRS\\_HIDDEN (default = 0): 어떻게 fix-attrs.d script가 파일과 directory를 처리할지를 제어한다.\n  - **0**: 숨겨진 파일과 directory를 제외한다.\n  - **1**: 모든 파일과 directory를 포함한다.\n- S6\\_CMD\\_WAIT\\_FOR\\_SERVICES\\_MAXTIME (default = 5000): CMD 실행을 지속하기 전에 기다리는 최대 시간을 의미한다.\n- S6\\_READ\\_ONLY\\_ROOT (default = 0): read-only 파일 시스템을 사용하는 container 내부에서 동작할 때, 1로 설정하여 초기화 scripts를 권한 설정이전에 /etc에서 /var/run/s6/etc 로 복사하도록 하는 방식이다. 자세한 사항은 다음을 참조([Read-Only Root Filesystem](https://github.com/just-containers/s6-overlay#read-only-root-filesystem))\n- S6\\_SYNC\\_DISKS (default = 0): 1로 설정하여 stage 3에서 container 종료 이전에 file 시스템의 sync를 맞추어야 함을 알린다.\n\n### Terminology\n\n- PID 1 : linux kernel에서 첫번째로 시작되어진 process에게 PID 1이 부여된다. PID 1은 다른 process들과는 달리 다음과 같은 특징일 갖는다.\n  - PID 1 process가 종료된다면, 모든 다른 process는 KILL signal로 종료된다.\n  - 자식 process를 가진 어떤 process라도 무슨 이유에서건 죽는다면, 자식들은 PID 1 process의 자식으로 다시 태어난다.\n- Zombie process : 실행이 종료되었지만, 아직 삭제되지 않은 process를 의미합니다. 이를 실제로 유지하는 것이 일반적인데, 그 이유는 부모 process가 자식 process의 종료 상태를 파악하기 위해서이다. 이러한 데이터는 실행한 명령의 결과에 따라서 분기를 하고 싶을 때, 종료 값은 유용하게 사용된다. 이렇게 zombie 상태로 진입한 process는 부모 process가 종료되거나 wait() 계열의 함수를 이용해서 process가 정리될 대까지 남아있게 된다. 만약, 이러한 zombie process가 다수 남아 있게 된다면 시스템에도 악영향을 미칠 수 있다.\n- process supervisor : 여러 process를 모니터링하고, 제어하는 program을 의미한다.\n- ejabberd : Robust, Scalable and Extensible Realtime PlatformXMPP Server + MQTT Broker + SIP Service\n- symbol link : soft link라고 불리기도 하며, 다른 파일을 가르키는 특별한 파일로 여길 수 있다. target 파일의 데이터를 포함하는 것이 아닌 단순히 파일 시스템의 다른 파일을 가르키고, 이를 통해 실행하는 것이 가능한 방법이다.\n- nobody user: 대다수의 Unix 시스템에서, \"nobody\"는 전통적으로 파일을 가지지 않고, 어느 권한 그룹에도 속하지 않으며, 다른 모든 유저들이 가지는 기능을 제외하면 기능이 없는 유저를 의미한다.\n\n## 출처\n\n- [🔗 just-containers/s6-overlay](https://github.com/just-containers/s6-overlay)\n","slug":"s6-overlay","date":"2021-07-11 12:13","title":"S6 Overlay","category":"Tech","tags":["Docker"],"desc":"docker에 기본 이념은 하나의 container에는 하나의 process만 두어야 한다는 것이다. 하지만, 이에 대해서 반대를 하고, 하나의 container에 여러 개의 process를 심고 이를 이용하겠다는 생각으로 만들어진 open source이다. 사용 예시는 main process 내부에 cronjob을 끼워넣는 것과 같은 경우가 있을 것이다.이는 결론적으로 Dockerfile의 확장 버전이라고 볼 수도 있을 거 같다. 좀 더 복잡한 작업을 더 체계적으로 할 수 있는 틀을 제공한다. 아이디어 자체는 참신하나 남발하게 되면, stateless하던 container가 점점 stateful하게 되면서 시스템이 오염될 수도 있음을 유의하자.아래 내용은 해당 opensource의 README를 직접 번역한 내용이니 의역도 많이 포함된다. 주의해서 읽도록 하자. 또한, 모르는 용어는 아래 Terminology를 확인해보도록 하자.","thumbnailSrc":"https://euidong.github.io/images/docker-picture.jpg"},{"content":"\n## Intro\n\nVirtual Machine과 Container는 현재의 여러 Computing 영역에서 빼놓을 수 없는 내용이 되었다. 그렇기에 이들의 발전 역사를 기반으로 하여 이들을 비교하고 정리해보도록 하겠다.\n\n## History\n\nVirtual Machine과 Container의 차이점을 이해하기 보다는 서사를 이해하는 것이 편할 것이다.\n\n시작은 다음과 같다.\n\n당신은 현재 다양한 service를 운영하고 있다. 그리고, 이를 운영하는 과정에서 가장 큰 문제를 겪게 된다.\n\n여러 service는 매 번 다양한 요구에 의해서 상황이 바뀐다. 어느 날은 주문이 폭주해서 서버를 증설해야하고, 어느 순간에는 유지 비용이 아까워서 서버를 다시 축소시킨다.\n\n또한, Hardware가 성능의 노후와 새로운 기기 및 시스템을 도입하고자 하는 욕구도 따른다.\n\n> **Service 1, Service 3의 비용이 증가하면 Service 3이 영향을 받는다.**\n\n![vm-container-1](/images/vm-container-1.jpeg)\n\n이 과정에서 우리는 결국 하나의 machine에 하나의 service 만을 배포하게 된다. 다른 service가 과부화가 걸려서 다른 service도 같이 에러가 발생한다면, 얼마나 머리가 아프겠는가? 그런데, 여기서 공학자들이 참을 수 없는 일이 발생하는 것이다.\n\n> **\"비효율적\" 자원 사용**\n\n그래서 사람들은 선택에 기로에 빠진다. 머리가 아플정도로 고민해서, 최적의 상황을 만들어서 우리의 server를 예쁘게 만들고, 새로운 service가 나오고 기기가 추가될 때마다 이 고민을 반복하는가 아니면 그냥 하나의 machine에는 하나의 service만 넣는가?\n\n이때, 사람들은 하나의 물리적 기기를 여러 개의 작은 기기로 나누는 것에 눈을 돌리게 된다.\n\n그때, 떠오른 발상이 Virtual Machine이다. 물리적으로 존재하는 Machine을 이용해서 가상의 Machine을 만드는 것이다. 즉, 하나의 Machine이 이제 여러 개의 Virtual Machine이 될 수 있는 것이다.\n\n이 발견을 통해서 사람들은 하나의 server를 여러 개의 virtual Machine으로 나누고 관리하는 것에 익숙해지며, Virtual Machine을 주류로 하는 VMware와 같은 업체가 큰 성장을 이루게 된다.\n\n그러나, 여기서 Virtual Machine의 사용자들은 큰 고민을 갖게 된다. 바로 성능적인 Issue이다.\n\n기존에는 Virtual Machine을 완벽하게 동작하는 OS 위에서 동작하도록 하였다. 하지만, 시간이 갈 수록 이러한 구조는 오히려 큰 비용을 유발했다.\n\n이에 따라서 다양한 가상화 방법들이 연구되게 된다. 그렇게 나온 것이 지금까지는 3가지의 큰 흐름으로 이해할 수 있다.\n\n![vm-container-2](/images/vm-container-2.jpeg)\n\n> **1. Host 기반의 가상화**\n\n우리가 앞서 봤던 사례들과 같이 기존에 Host가 존재하고, 거기에서 Virutalize SW를 이용하여, 가상화된 장치를 만들어서 사용하는 방식이다.\n\n> **2. Hypervisor 기반의 가상화**\n\nHost Machine을 배제하고, Host의 OS를 없애고, Hypervisor를 기반으로 여러 OS를 능동적으로 처리할 수 있는 형태로 구성한 것이다.\n\n- 종류\n  - 전가상화 : 전가상화란 전체 Hardware를 모두 가상화하는 방식으로 Hypervisor가 각 OS로 부터 오는 요청을 모두 사용하는 Hardware에 맞게 번역하는 기능을 수행한다.\n  - 반가상화 : OS에서 자신의 명령어를 표준화된 형태로 전달합니다. 이를 수행하게 되면, Hypervisor에서 수행하는 동작의 비용을 크게 줄일 수 있습니다. 하지만, 이 경우에는 OS 자체를 수정해야 하기 때문에 큰 비용이 발생합니다.\n\n> **3. Container 기반의 가상화**\n\nContainer 는 guest OS를 구현하지 않습니다. 각 Container에서 발생하는 OS 요청을 Host OS를 공유함으로서 수행합니다. 추가적인 기능은 Container 내부로 위임하여 훨씬 더 가볍고 이식성이 좋은 형태의 가상화가 가능합니다.\n\n## Simulator vs Emulator\n\n여러가지 이야기가 simulator와 emulator 사이에서 존재한다. 예를들어, high level로 작성하는 것이 simulator고 low level로 작성하는 것이 emulator라는 이런 말이다. 하지만, 이는 각 경우를 구현하는 과정에서 발생하는 특징이지 정의가 되지는 않는다.\n\nSimulator는 특정 목적에 따라 기능을 수행할 수 있도록 임의로 구현하는 것을 의미한다. 즉, 완벽하게 동일할 필요는 없이 원하는 특징을 뽑아내는 것이 중요한 것이다. 반면에, Emulator는 완전 동일한 기기를 software로 구현하는 것을 말한다. 그 과정에서 Emulator는 Smulator보다 무거워질 수 밖에 없고, 그렇기에 low level language에 손이 가게 되고, 느려지게 된다.\n\n이해가 어렵다면, 오락실 게임을 PC에서 하고, 동물의 숲 닌텐도 게임을 핸드폰으로 하는 불법적인 일도 해본 적이 있을 수 있다. 이는 가상으로 해당 기기를 구현하고, 이를 다른 기기에서 구동하는 것의 예이다.\n\n## Reference\n\n- [🔗 가상화 각 각을 비교](https://tech.cloud.nongshim.co.kr/2018/09/18/%EA%B0%80%EC%83%81%ED%99%94%EC%9D%98-%EC%A2%85%EB%A5%983%EA%B0%80%EC%A7%80/)\n- Thumbnail: Photo by [william william](https://unsplash.com/@william07?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/s/photos/cargo-ship?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n","slug":"vm-container","date":"2021-05-23 14:31","title":"VM & Container","category":"Tech","tags":["VirtualMachine","Container"],"desc":"Virtual Machine과 Container는 현재의 여러 Computing 영역에서 빼놓을 수 없는 내용이 되었다. 그렇기에 이들의 발전 역사를 기반으로 하여 이들을 비교하고 정리해보도록 하겠다.","thumbnailSrc":"https://euidong.github.io/images/cargo-ship.jpg"},{"content":"\n## Intro\n\n**Vagrant**(베이그런트)는 Virtual Machine의 실행환경을 하나의 workflow 내에 구축하고 관리하는 도구이다. 쉬운 workflow 사용법과 자동화에 초점을 맞추어 **Vagrant**는 setup time이 굉장히 짧다. 또한, production과정과의 동등함을 제공하고, 과거의 시스템을 \"나의 machine 내부에서\" 동작시키는 것이 가능하다.\n\n## Why Vagrant?\n\n**Vagrant**는 `configuration`이 쉽고, 동일한 조건으로 재실행을 보장(reproducible)하며, 어느 장비에서든지 동작가능(호환성이 높은, portable)한 작업 환경을 제공한다. 이러한 작업 환경은 산업 표준 기술에 기반하며, 하나의 일관성있는 workflow에 의해서 제어되어 생산성과 유연성을 최대화한다.\n\n이러한 마법같은 일을 성취하기 위해서, **Vagrant**는 `VirtualBox`, `VMware`, `AWS`, 또는 다른 `Virtual Machine` 제공자에 기반 위에서 동작하며, 이들을 활용하여 가상 환경을 구축할 수 있다.\n\n### For Developers\n\n만약 당신이 개발자라면, **Vagrant**는 의존성과 그들의 설정을 격리시킬 수 있다. 이때에 일회용으로 사용하든, 지속적인 환경으로 사용하든 상관없이 그 어떤 tool들(browser, editor, debugger 등)도 빠짐없이 포함시킬 수 있다. 일단 하나의 `Vagrantfile`을 생성하면, 단지 `vagrant up`만 실행시켜주면 모든 것이 설치되고 설정될 것이다. 이는 개발팀의 누구에게든지 공유될 수 있고, 어느 환경(Linux, MAC OS X, Window)에 있든 모든 팀 구성원은 동일한 환경(동일한 의존성, 동일한 설정)에서 code를 실행시킬 수 있다. 이를 통해서 `내 머신에서는 잘 동작하는데...`와 같은 에러를 해결할 수 있다.\n\n### For Operators\n\n만약 당신이 System operation/DevOps engineer라면, **Vagrant**는 개발 또는 테스팅을 위한 infrastructure(기반 환경)을 관리하기 위한 일회용 또는 일관적인 workflow를 제공한다. 이때에는 `sh`, `Chef`, `Puppet` 과 같은 방법을 통해 제어할 수 있으며, 실행 환경은 `VirtualBox`, `VMware`, `AWS` 등 다양한 환경을 활용할 수 있다. 여러 machine을 `ssh`를 통해서 접속하지 않고, **Vagrant**를 통해서 모든 것을 쉽게 제어할 수 있다.\n\n### For Designers\n\n만약 디자이너 직군이라면, **Vagrant**는 자동적으로 web app을 구동시킬 수 있는 모든 환경을 자동적으로 제공할 수 있다. 따라서, design 작업 외에는 더 알아야 할 것이 없다. 일단 개발자가 **Vagrant**를 설정하고 나면, 당신은 이를 다시 실행시키는 방법에 대해서 고민할 필요가 없다. 더 이상 개발자들을 괴롭히지 않고도 당신의 환경을 쉽게 변경할 수 있으며, version control만 쉽게할 수 있다면, 단순히 `vagrant up`으로 쉽게 적용이 가능하다.\n\n## What is Vagrant?\n\n해당 tutorial에서는 **Vagrant**를 통해 너의 첫번째 개발 환경을 생성할 것이다. 이를 통해서, **Vagrant**의 간략한 소개와 사전 준비사항과 가장 기본적이고 중요한 **Vagrant** 활용을 배울 것이다.\n\n해당 tutorial에서는 `VirtualBox`를 활용하여 **Vagrant**환경을 구성해볼 것이다. 왜냐하면 이것이 여러 platform에서 사용되는 무료 software이기 때문이다.\n\n### 사전 준비사항\n\n1. **Vagrant** 설치  \n  [🔗 link](https://www.vagrantup.com/docs/installation)\n2. `VirtualBox` 설치  \n  [🔗 link](https://www.virtualbox.org/wiki/Downloads)\n\n단 두 개의 명령어로 원하는 환경의 VM(Virtual Machine)을 생성할 수 있고, 하나의 명령어로 삭제가 가능하다. 여기서는 Ubuntu 18.04 이미지를 이용할 것이다.\n\n### 실행 테스트\n\n> **1. Vagrant 초기화**\n\n```bash\n$ vagrant init hashicorp/bionic64\nA `Vagrantfile` has been placed in this directory. You are now\nready to `vagrant up` your first virtual environment! Please read\nthe comments in the Vagrantfile as well as documentation on\n`vagrantup.com` for more information on using Vagrant.\n```\n\n이를 통해서, 현재 directory에 `Vagrantfile`을 생성하는 것이 가능하다.\n\n> **2. (Optional) Box 설정**\n\nVirtual Machine을 구성할 때, scratch(밑바탕, 대게 OS만 포함한 상태)에서 시작하는 것은 매우 느리다. 따라서, **Vagrant**에서는 setup time을 최적화하기 위해서, `box`라는 것을 이용한다. 이는 기존의 VM 구성 시에 사용하는 image와 비슷한 의미를 가진다. 따라서, `Vagrantfile`을 생성한 후에 해야할 가장 첫번째로 수행할 것이 해당 `box`를 구체화하고 기술하는 것이다.\n\n`box`는 [Vagarnt Cloud](https://app.vagrantup.com/boxes/search)와 같은 registry에 upload가 가능하다. 또는 local filesystem에서도 참조가 가능하다.\n\n우리가 이전에 했던 것처럼 `vagrant init`을 수행할 때, `box` 명을 써주면, `Vagrantfile`을 만들 때 현재 나의 machine에 해당 `box`가 존재한다면 불러오고, 그렇지 않으면 download한다. 그렇지 않고 download만 하고 싶은 경우에는 다음과 같은 명령어를 수행할 수도 있다.\n\n```bash\n$ vagrant box add hashicorp/bionic64\n==> box: Loading metadata for box 'hashicorp/bionic64'\n...\n```\n\n이를 수행한 후에 `Vagrantfile` 내부에서 VM의 box를 변경할 수 있다.\n\n```Vagrantfile\n# \"2\"는 Vagrant version을 의미\nVagrant.configure(\"2\") do |config|\n  config.vm.box = \"hashicorp/bionic64\"\nend\n```\n\n이렇게 설정하게 되면, 해당 `box`의 latest 버전을 기본으로 사용하게 되는데, 특정 버전을 원한다면 다음과 같이 작성할 수도 있다.\n\n```Vagrantfile\nVagrant.configure(\"2\") do |config|\n  config.vm.box = \"hashicorp/bionic64\"\n  config.vm.box_version = \"1.0.282\"\nend\n```\n\n현재 내 machine에서 `box`를 조회하거나 삭제하기를 원한다면, 다음과 같이 수행할 수 있다.\n\n```bash\n$ vagrant box list\nhashicorp/bionic64 (virtualbox, 1.0.282)\n\n$ vagrant box remove hashicorp/bionic64\nRemoving box 'hashicorp/bionict64' (v1.0.282) with provider 'virtualbox' ...\n```\n\n> **3. VM 실행**\n\n기본적으로 현재 directory에서 `Vagrantfile`을 찾아서 Virtual Environment를 구성한다.\n\n```bash\n$ vagrant up\nBringing machine 'default' up with 'virtualbox' provider...\n...\n```\n\n실행이 완료되면, 다음과 같이 ssh 접근 및 종료가 가능하다.\n\n```bash\n$ vagrant ssh\nWelcome to Ubuntu 18.04.3 LTS (GNU/Linux 4.15.0-58-generic x86_64)\n\nvagrant@vagrant:~$ logout\nConnection to 127.0.0.1 closed.\n```\n\n> **4. VM 삭제**\n\n```bash\n$ vagrant destroy\n    default: Are you sure you want to destroy the 'default' VM? [y/N] y\n==> default: Forcing shutdown of VM...\n==> default: Destroying VM and associated drives...\n```\n\n### 반드시 알아야할 사항\n\n> **1. Synchronize Local and Guest Files**\n\nVM을 이용하여 개발하는 것은 편리하지만, 대부분의 사람들은 ssh를 이용해서 해당 시스템에 접속하여 작성하는 것은 불편하다고 느낄 것이다. 프로젝트가 두 개만 되어도 상당히 귀찮은 작업이다. 따라서, **Vagrant**는 자동으로 VM과 현재 나의 machine(host)의 file을 자동으로 sync한다.(동일한 file이 되도록 한다.) 즉, 내가 host에서 file을 작성함으로써 VM에 이를 적용하는 것도 가능하다는 것이다. 기본적으로 **Vagrant**는 VM에 Vagrantfile을 포함한 project directory를 `/vagrant` directory와 동기화한다.\n\n> **2. VM으로 project 배포**\n\n아주 간단한 예제로 apcache를 이용하여 project 배포를 수행해보자.\n\n먼저, `Vagrantfile`이 존재하는 directory에 `html`이라는 폴더를 만든다.\n\n```bash\n$ mkdir html\n...\n```\n\n아주 기본적인 HTML을 작성하자.(index.html)\n\n```html\n<!DOCTYPE html>\n<html>\n  <body>\n    <h1>Hello, My First Vagrant Deploy!</h1>\n  </body>\n</html>\n```\n\n이제 실제로 apache를 설치하고, 지금 만든 파일을 apache process가 바라보는 folder로 전달해주는 shell script를 작성하자.(`bootstrap.sh`이라는 이름으로 project directory에 작성)\n\n```shell\n#!/usr/bin/env bash\n\napt-get update\napt-get install -y apache2\n\nif ! [ -L /var/www ]; then\n  rm -rf /var/www\n  ln -fs /vagrant /var/www\nfi\n```\n\n이제 이를 **Vagrant**에서 실행 시에 시작하도록 설정만해주면 끝이다.\n\n```Vagrantfile\nVagrant.configure(\"2\") do |config|\n  config.vm.box = \"hashicorp/bionic64\"\n  config.vm.provision :shell, path: \"bootstrap.sh\"\nend\n```\n\n이제 다음을 통해서 실제로 html이 배포되었는지를 확인할 수 있다.\n\n```bash\n$ vagrant up\n\n$ vagrant ssh\n\nvagrant@vagrant:~$ wget -qO- 127.0.0.1\n<!DOCTYPE html>\n<html>\n  <body>\n    <h1>Hello, My First Vagrant Deploy!</h1>\n  </body>\n</html>\n\nvagrant@vagrant:~$ logout\nConnection to 127.0.0.1 closed.\n```\n\n> **3. Port Forwarding**\n\n가장 기본적으로 많이 사용되는 Network 기술로 VM의 port를 host의 port와 mapping하여 host의 port를 통해 VM의 port에 접근할 수 있도록 하는 기술이다.\n\n2번에서 작성했던 `Vagrantfile`을 다음과 같이 변경해주면 된다.\n\n```Vagrantfile\nVagrant.configure(\"2\") do |config|\n  config.vm.box = \"hashicorp/bionic64\"\n  config.vm.provision :shell, path: \"bootstrap.sh\"\n  config.vm.network :forwarded_port, guest: 80, host: 4567\nend\n```\n\n이를 적용하여 **Vagrant**를 재실행하기 위해서는 다음을 실행해주면 된다.\n\n```bash\n$ vagrant reload\n==> default: Attempting graceful shutdown of VM...\n...\n```\n\nbrowser를 통해 확인하면 아래와 같은 결과를 얻을 수 있다.\n\n![vagrant-forwarding-test](/images/vagrant-forwarding-test.png)\n\n> **4. WebApp 공유**\n\n`ngrok`를 이용해서 WebApp을 공유하는 기능을 **Vagrant**가 포함하고 있다. 이를 `vagrant share`라고 부른다. 실행을 원한다면, 기본적으로 `ngrok`을 [🔗 설치](https://ngrok.com/download)한 후에 다음 command들을 실행시키면 webpage를 남들에게 share하는 것이 가능하다.\n\n```bash\n# vagrant share를 수행하기 위한 plug인을 설치한다.\n$ vagrant plugin install vagrant-share\n\n# (MAC OS) development tools가 없다는 에러 발생시 아래 명령어 실행\n# xcode-select --install\n\n$ vagrant share\n...\n==> default: Creating Vagrant Share session...\n==> default: HTTP URL: http://b1fb1f3f.ngrok.io\n...\n```\n\n`ngrok`은 무료로 server domain을 생성하고, web service를 hosting 해주는 tool이다. 사용법도 굉장히 간단해서 알아두면 좋다.\n\n> **5. 여러 Machine 배포**\n\n다음과 같이 `vm.define`을 통해서 여러 개의 machine을 한 번에 정의하는 것도 가능하다. 따라서, **Vagrant**가 VM을 configuration하는 것이 아니라 Virtual Environment를 configuration하는 것이라고 부르는 것이다.\n\n```Vagrantfile\nVagrant.configure(\"2\") do |config|\n  config.vm.provision \"shell\", inline: \"echo A\"\n\n  config.vm.define \"web\" do |web|\n    test.vm.provision :shell, inline: \"echo B\"\n    web.vm.box = \"apache\"\n  end\n\n  config.vm.define \"db\" do |db|\n  config.vm.provision :shell, inline: \"echo C\"\n    db.vm.box = \"mysql\"\n  end\nend\n```\n\n## Reference\n\n- [🔗 Why Vagrant?, Vagrant 공식 사이트](https://www.vagrantup.com/intro)\n- [🔗 Getting Started, Vagrant 공식 사이트](https://learn.hashicorp.com/collections/vagrant/getting-started)\n","slug":"vagrant","date":"2022-06-01 12:39","title":"Vagrant","category":"Tech","tags":["Vagrant","VirtualEnvironment","VirtualBox"],"desc":"Vagrant(베이그런트)는 Virtual Machine의 실행환경을 하나의 workflow 내에 구축하고 관리하는 도구이다. 쉬운 workflow 사용법과 자동화에 초점을 맞추어 Vagrant는 setup time이 굉장히 짧다. 또한, production과정과의 동등함을 제공하고, 과거의 시스템을 \"나의 machine 내부에서\" 동작시키는 것이 가능하다.","thumbnailSrc":"https://euidong.github.io/images/vagrant.png"},{"content":"## Intro\n\nBlockchain을 공부하게 되었는데, 이번 기회에 제대로 하자는 생각에서 Bitcoin 구현을 직접 수행해볼 생각입니다. 학습에 사용한 책은 위에 나와있는 책을 활용하였습니다.\n\n**해당 Posting은 Bitcoin이 무엇이고, 이것으로 무엇을 할 수 있는지에 대해서 설명하지 않고 Bitcoin을 구현하는 기술에 대하여 다룹니다.** 또한, 책의 모든 내용을 충실히 번역하는 것이 아닌 작성자의 생각이 많이 담겨 있으니 유의 바랍니다.\n\n**해당 chapter에서는 데이터의 인증을 어떻게 수행할 것인가에 대한 세부적인 내용을 다루겠습니다.**\n\n> **(+) 들어가기에 앞 서...**\n\nBitcoin에서는 결제가 발생할 때, 이전 거래에서 얻은 Bitcoin을 통해서만 결제가 가능합니다. (거래를 통해 Bitcoin을 받은 적이 없다면, Bitcoin이 없는 것으로 간주합니다.)\n\n또한, 우리는 이 거래 내역을 모두가 볼 수 있도록 공개합니다. 이 상황에서 우리가 특정 거래 내역에서 돈을 받은 사람이 자신이고, 그 거래에서 얻은 Bitcoin을 현재 거래에 사용할 것임을 증명하기 위해서는 어떻게 해야할까요?\n\n---\n\n일반적으로 인증이라는 것은 누군가가 특정 사실을 증명하는 것을 말합니다. 여기서는, 데이터의 작성자가 진짜 작성자가 맞는지를 확인하는 것입니다. 이는 대게 믿을 만한 제3 자에게 맡기거나 직접 눈으로 확인하는 방식이 있습니다. 하지만, 매번 이를 수행하는 것은 어렵기 때문에 우리는 원본 데이터에 서명을 하는 것을 택합니다. 이를 통해서, 자신이 해당 데이터의 작성자임을 분명하게 표시할 수 있습니다. 그런데, 이것을 programming 적으로 구현하는 것은 쉬운 일이 아닙니다.\n\n대게 이를 위해서 우리는 공개키 방식이라는 것을 사용합니다. 공개키 방식이란, 암호화하는 도구와 해독하는 도구가 서로 다른 경우를 말합니다.\n\n즉, 해독하는 도구는 누구나에게나 제공을 하고, 암호화하는 도구는 자신만이 가지고 있도록 하여, 원본 데이터와 원본 데이터를 암호화한 데이터를 같이 보내면, 이를 받은 사용자들이 해독하는 도구를 통해 암호화한 데이터를 복구하고, 원본데이터와 대조해보면, 원본데이터의 작성자가 전송자임을 명확하게 확신할 수 있는 것입니다. 즉, 원본데이터를 암호화한 데이터가 바로 하나의 서명이 되는 것입니다. 왜냐하면, 이를 암호화하는 키는 전송한 사람만 갖고 있기 때문입니다.\n\n**programming적으로 이러한 공개키 방식을 구현하는 것은 one way function (한 방향 함수, 암호화는 쉽지만 inversion이 어려운 함수, 암호화 도구)이면서, trap door(속임수, 해독하는 도구)를 가지는 algorithm을 찾아내는 것입니다.** 즉, key를 갖고 있으면 쉽게 암호를 생성할 수 있지만, key가 없다면, 이를 만드는 것이 사실상 불가능하도록 만드는 것입니다. 여기에서 일반적으로 가장 많이 사용되는 것이 RSA라는 소인수 분해의 난해함을 이용하는 algorithm이 있습니다.\n\n하지만, Bitcoin에서는 서명을 하기 위해서, ECDSA(Elliptic Curve Digital Signature Algorithm)를 사용합니다. 따라서, 여기서는 이 기술에 대해서 자세히 알아볼 것입니다.\n\n일단 이를 이해하기 위해서 이를 이루는 기반 수학적 용어를 먼저 배워야 합니다.\n\n1. 유한 공간 Finite Field\n2. 타원 곡선 Elliptic Curve\n\n따라서, 이에 대한 내용을 이제부터 하나하나씩 살펴보겠습니다.\n\n## 1. 유한 공간 Finite Field\n\n들어가기에 앞 서 두 가지 개념을 정리하고 가야 합니다.\n\n먼저, 소수입니다. **소수**(**Prime Number**)는 1과 자신 이외의 자연수로 나눌 수 없는, 1보다 큰 자연수입니다. 또한, 해당 숫자들은 규칙성을 갖고 있지 않기 때문에, 하나의 소수가 주어진 뒤에 이보다 큰 바로 다음 소수를 찾는 것은 직접 해보지 않으면 알 수 없습니다.\n\n다음은 **modulo(나머지 연산자, %)입니다.** 특정 값을 나누고, 남은 나머지를 반환하는 연산자라고 말할 수 있습니다.\n\n$$10 \\% 3 = 1, 10 \\% 2 = 0$$\n\n해당 연산은 일반적인 대수학의 연산과는 다르게 동작하게 하기 때문에, 이에 대하여, 앞으로 사용할 특징 몇 가지를 정리해보겠습니다.\n\n1. $ a \\% b \\lt b $\n2. $ (a \\times b) \\% c = \\{(a \\% c) \\times (b \\% c)\\} \\% c $\n3. $ a^{b} \\% (b-1) = 1 $\n\n위의 3가지 특징에 대한 자세한 증명은 여기서 다루기보다, 궁금하시다면, 직접 찾아보시길 바랍니다.\n\n이를 통해서 Finite Field에서의 연산을 표현할 수 있으니 이를 기억해둡시다.\n\n**Finite Field**란 특정 소수보다 작은, 0을 포함한 자연수 집합으로, 이루어지고,\n\n$$ F\\_3 = \\{ 0, 1, 2 \\} $$\n\n$$ F\\_{11} = \\{ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 \\} $$\n\n다음 6가지 조건을 만족하는 집합을 의미합니다.\n\n- Additive closed, 덧셈에 대하여 닫혀있다.\n- Multiplicative closed, 곱셈에 대하여 닫혀있다.\n- Additive identity, 덧셈에 대한 항등원($0$) 을 갖는다.\n- Multicative identity, 곱셈에 대한 항등원($1$) 을 갖는다.\n- Additive inverse, 덧셈에 대한 역원($-a$)을 갖는다.\n- Multicative inverse, 곱셈에 대한 역원($a^{-1}$)을 갖는다.\n\n각 조건을 살펴보기에 앞서서 Finite Field를 정의하는 소수보다 큰 값은 해당 소수를 통해서 modulo 연산되어, Finite Field에 속하게 됩니다. (이는 modulo 연산의 첫 번째 특징($a \\% b \\lt b $)을 통해 알 수 있습니다.) 마치 시계와 같이 순환하는 구조를 가진다고 생각할 수 있습니다.\n\n이를 통해서, Finite Field의 첫 번째와 두 번째 조건은 만족한다는 것을 알 수 있습니다. 왜냐하면, 덧셈과 곱셈으로 생성된 결괏값은 반드시 다시 Finite Field에 속하게 되기 때문입니다.\n\n세 번째, 네 번째 조건은 소수는 항상 2보다 크기 때문에, 0과 1을 포함할 수밖에 없음을 알 수 있습니다. 따라서, Finite Field는 덧셈과 곱셈에 대한 항등원을 가진다는 것을 확인할 수 있습니다.\n\n다섯 번째는 다음과 같습니다.\n\n$F\\_{p} = \\{0,1,2,3,..., p - 2, p - 1\\}$이고, $ a \\in F\\_{p} $인 경우\n\n$$ -a = p - a $$\n\n라고 정의할 수 있습니다.\n\n여섯 번째는 다음과 같습니다.\n\n$F\\_{p} = \\{0,1,2,3,..., p - 2, p - 1\\}$ 이고, $ a \\in F\\_{p} $인 경우\n\n$$ a^{-1} = a^{-1} \\times 1 = a^{-1} \\times a^{p-1} $$\n\n$$ a^{-1} = a^{p - 2} $$\n\nmodulo의 세 번째 특징을 활용하여 다음과 같이 정의할 수 있습니다.\n\n이러한 modulo 연산을 활용하는 Finite Field의 특징은 다음과 같습니다.\n\n위에서 보았듯이 덧셈과 곱셈 연산은 역원이 존재하여, 결괏값을 갖고 역으로 원래 값을 찾아내는 것이 가능합니다. 하지만, 이 공간에 역이 없는 연산자를 추가한다면 어떻게 될까요? 이를 기억하고 넘어갑시다.\n\n## 2. 타원 곡선 Elliptic Curve\n\n다음 식을 만족하는 점들이 그리는 곡선을 우리는 타원 곡선이라고 합니다.\n\n$$ y^2 = x^3 + ax + b$$\n\n![elliptic-curve](/images/elliptic-curve.jpeg)\n\n타원 곡선 상에서 우리는 덧셈 연산과 굉장히 유사한 연산을 정의할 수 있습니다. 실제로 동작은 일반적인 수학에서의 덧셈은 아니지만, 덧셈의 특징을 갖기 때문에 $+$ 기호로 표현합니다.\n\n바로, 각 타원 곡선과 3개의 점을 가지는 선을 그었을 때, 항상 다음 식을 만족한다는 것입니다. (R은 타원곡선과 만나는 세 번째 점을 X축 대칭이동한 점을 말합니다.)\n\n$$ P + Q = R $$\n\n![elliptic-curve-addition-1](/images/elliptic-curve-addition-1.jpeg)\n\n$P(x\\_1, x\\_2)$, $Q(x\\_2, y\\_2)$가 타원 곡선 $y^2=x^3 + ax + b$ 위의 점이라고 할 때, $R(x\\_3, y\\_3)$의 좌표는 다음과 같이 표현할 수 있습니다.\n\n- $ s = {dx \\over dy} = { 3x^2 \\over  2y } = { {y\\_2 - y\\_1} \\over  {x\\_2 - x\\_1}} $\n- $ x\\_3 = s^2 - x\\_1 -x\\_2 $\n- $ y\\_3 = s(x\\_1 - x\\_3) - y\\_1 $\n\n이 연산 역시 다음과 같은 조건을 만족시킵니다.\n\n- Identity, 항등원이 존재한다. => $ A + I = A $\n- Invertibility, 역원이 존재한다. => $ A = (a\\_1, a\\_2)이면, -A= (a\\_1, -a\\_2) $\n- Commutativity, 교환 법칙 => $ A + B = B + A $\n- Associativity, 결합 법칙 => $ A + (B + C) = (A + B) + C $\n\n여기서의 역원은 x축 대칭 이동을 통해 얻은 값이라는 것을 확인할 수 있습니다. 또한, 교점이 세 개인 시점에서 직선의 기울기를 무한대로 계속 올리다 보면 결국은 y축에 대칭인 형태로 직선이 만들어지는 것을 볼 수 있습니다. (아래 그림에서 두 번째) 이 경우에 우리는 실제로는 교점이 두 개지만, 무한대 지점에서 교점이 하나 더 있다고 말하고 이를 I(Infinity)라고 정의합니다. 그렇게 되면, 항등원이 바로 I가 되는 것을 확인할 수 있습니다. (두 번째 그림에서 $P + I = P$가 되는 것을 확인할 수 있습니다.) 이를 통해서 두 번째에 존재하는 역원까지도 증명이 가능합니다.($P + (-P) = I$)\n\n![elliptic-curve-addtion-2](/images/elliptic-curve-addition-2.png)\n\n![elliptic-curve-addition-3](/images/elliptic-curve-addition-3.jpeg)\n\n세 번째는 너무나 자명하기 때문에 넘어가고, 네 번째는 아래 그림을 통해서 설명할 수 있습니다.\n\n주황색 : $ (P + Q) + S = R\\_1 + S = T $\n\n초록색 : $ (P + S) + Q = R\\_2 + Q = T $\n\n![elliptic-curve-addition-4](/images/elliptic-curve-addition-4.jpeg)\n\n추가적으로 살펴볼 수 있는 하나의 연산을 하나 더 알아보고 갑시다.\n\n바로 접선에서 연산입니다. 이 경우는 P와 Q가 같다고 여깁니다. 즉, 자기 자신을 두 번 더 하는 것과 같습니다. 따라서, 우리는 이를 $ P + P = R = 2P $라고 표현합니다. 또한, 이를 반복하면서, 결과 값을 도출할 수 있습니다. 따라서, 우리는 다음과 같은 식도 작성이 가능합니다. (이를 우리는 Elliptic Curve에서의 **Scalar Multiplication**이라고 합니다.)\n\n$$ kP = R $$\n\n이를 계산하기 위해서는, 일반적으로 k 번의 Elliptic Curve Addition을 수행하게 됩니다. 하지만, 이를 더 간략화할 수 있는 방법이 있습니다.\n\n$$ R = 63P = (1 + 2 + 4 + 8 + 16 + 32) P = (1 + (1+1) + (2+2) + (4+4) + (8+8) + (16+16)) P $$\n\n즉, 이전 계산의 결과를 현재 계산에 활용하여 계산을 더 빠르게 할 수 있습니다. 위 예시에서는 62(63 - 1) 번의 더하기 연산을 10번으로 줄인 것을 볼 수 있습니다. (물론 이외에도 많은 방식으로 최적화를 할 수 있지만, 이 정도면 대게 충분합니다.)\n\n![elliptic-curve-addition-5](/images/elliptic-curve-addition-5.jpeg)\n\n여기서 주목할 포인트를 하나 짚어보고 가야합니다. 우리가 $R$과, $P$를 알고 있을 때, $k$ 구하는 것이 가능할까요?\n\n이는 쉽지 않은 문제가 됩니다. 왜냐하면, 이러한 scalar multiplcation문제에서는 역원이 존재하지 않기 때문에, k에 값을 1부터 대입해보면서 확인해 볼 수밖에 없습니다.\n\n---\n\n이제 기본이 되는 두 이론을 세팅하였습니다.\n\n일단은 유의해야 할 점은 바로 Finite Field로 Elliptic Curve를 가져오게 되면, 이는 discrete(불연속) 해진다는 점입니다. 또한, Scalar Multiplication에도 변화가 발생합니다. **바로 순환이라는 것이 생긴다는 점입니다.** $nP = R = 0$ 이 되는 $n$값이 존재하게 된다는 것입니다. 또한, 역원이 없는 성질 또한 유지되기 때문에, $kP$를 통해서 생성된 값($R$)과 P를 모두 공개하더라도, $k$가 밝혀질 가능성은 $n$값이 커질수록 불가능에 가깝다는 것입니다.\n\n실제로 Bitcoin에서는 이 N을 매우 크게 설정하였기 때문에 문제가 없다고 할 수 있습니다. 한 번 Bitcoin에서, Finite Field 상의 Elliptic Curve의 모든 변수를 정리해봅시다.\n\n기본적으로, 해당 암호화에 사용되는 모든 값의 단위는 256 bits 즉, 32 bytes를 사용합니다.\n\n1. Elliptic Curve의 형태 : $a=0$, $b=7$을 사용하는 secp256k 1을 사용합니다. 이 형태는 다음과 같습니다. $$y^2 = x^3 + 7$$\n2. Finite Field의 소수 : 위에서 말한 대로 $n$의 값을 크게 하기 위해서 finite field 자체의 크기도 매우 커져야 하기 때문에, $p$ 역시 매우 큽니다. $$p = 2^{256} - 2^{32} - 977 $$\n3. Scalar Multiplication에 사용되는 Elliptic Curve 위의 한 점($G$) : 이 또한 매우 크기 때문에 각 좌표별로 따로 적겠습니다. $G\\_x = $ 0x79be667ef9dcbbac55a06295ce870b07029bfcdb2dce28d959f2815b16f81798  \n    $G\\_y = $ 0x483ada7726a3c4655da4fbfc0e1108a8fd17b448a68554199c47d08ffb10d4b8\n4. Scalar Mutiplication에 의해서 만들어지는 $k$의 범위 ($n$) : 위에서도 보았겠지만, 0x는 16진수를 의미합니다.  \n    $n = $ 0xfffffffffffffffffffffffffffffffebaaedce6af48a03bbfd25e8cd0364141  \n\n위의 데이터를 보다시피 매우 큰 범위의 값을 사용하는 것을 알 수 있습니다.\n\n여기서 한 번 우리가 암호화 키와 해독 키(공개키)를 각 각 만들어보도록 하겠습니다.\n\n먼저, 암호화 키($e$)를 만드는 것은 매우 쉽습니다.\n\n바로 $n$보다 작은 임의의 수를 고르면 됩니다.\n\n그리고, 이를 이용해서, 우리는 바로 해독 키인 공개키를($P$) 만들 수 있습니다.\n\n$$ P = eG $$\n\n이렇게 하면 끝입니다. 우리는 $e$를 모르기 때문에, $P$와 $G$가 모두가 아는 값이라고 할지라도 $e$를 알아낼 수 없습니다.\n\n그렇기에 우리는 안심하고, P를 공개할 수 있는 것입니다.\n\n이제 우리는 이것을 이용해서 한 번 서명을 통한 인증을 수행해보도록 하겠습니다.\n\n먼저, 우리가 보내고자 하는 데이터를 $m$이라고 하겠습니다. 하지만, 이를 바로 사용하는 것은 쉽지 않습니다. 왜냐하면, 보내고자 하는 데이터의 크기가 32 bytes를 항상 만족하지 않기 때문입니다. 그렇다면, 이를 32 bytes로 변환해줄 방법이 필요할 것입니다. 그래서, 우리는 hashing을 수행합니다. 또한, 원본데이터 자체를 알아볼 수 없게 바꿔버리는 역할도 해서 암호화의 역할도 할 수 있습니다. 이를 통해서 만들어진 데이터를 우리는 $z$라고 하겠습니다.\n\n이제 여기서, 우리는 비밀키가 아닌 또 하나의 값을 하나 생성해야 합니다. 바로 $k$입니다. 이는 비밀키와 마찬가지로 $n$보다 작은 32bytes로 지정해야 합니다.\n\n$$ kG = R $$\n\n을 전송자 측에서 계산을 하고, $R$의 $x$ 좌표를 $r$이라고 정의하면 거의 모든 설정은 끝났다고 할 수 있습니다.\n\n이제 진짜로 서명을 시작할 수 있습니다.\n\n바로 $ uG + vP = kP = R $라고 할 때,\n\n$$ u + ve = k $$\n\n$$ u = z / s $$\n\n$$ v = r / s $$\n\n가 되도록 하는 것입니다.\n\n이렇게 되면, $u$라는 값은 $z$를 가지므로, 원본 데이터를 포함한다고 할 수 있습니다. 또한, $v$는 $r$을 포함하기 때문에 결과 값 자체를 포함하고 있다고 볼 수 있습니다.\n\n이는 해당 방정식을 풀어서 보면, $$ s = ( z + re ) / k $$라는 것을 알 수 있습니다. 여기서 $e$와 $k$라는 감춰져야만 하는 값이 두 개 포함되는 것을 알 수 있습니다. 해당 방정식은 안전하게도 $e$, $k$가 모두 변수로 남기 때문에 $s$, $z$, $r$을 안다고 해도 $e$와 $k$를 구할 수는 없습니다.\n\n따라서, $s$와 $r$을 하나로 합쳐서 하나의 서명(Signature)을 이루게 됩니다.\n\n따라서, 전송자는 $z$(보낼 데이터)와 $r$, $s$(서명)를 전송함으로써, 데이터의 수신자가 직접 서명의 적절함을 확인할 수 있습니다.\n\n수신자는 이제 받은 데이터를 통해서 다음 과정을 진행한다고 볼 수 있습니다.\n\n1. $u$와 $v$를 생성합니다. ($u = z / s $, $v = r / s$)\n2. $uG + vP$의 연산을 수행합니다.\n3. 위의 결괏값을 통해서 얻은 좌표값의 x 좌표와 r 값을 비교하여 동일한지를 확인합니다.  \n    $$ uG + vP = R $$\n4. 이것이 동일하다면, 해당 데이터는 인증된 데이터입니다.\n\n이것이 BitCoin에서 사용하는 서명 방식인 ECDSA입니다. 이에 대한 구현은 github에 올려 두었으니, 확인을 원하시면 체크해보시길 바랍니다.\n\n[🔗 GitHub - euidong/bitcoin](https://github.com/euidong/bitcoin)\n\n## Reference\n\n- [🔗 Programming Bitcoin](https://learning.oreilly.com/library/view/programming-bitcoin/9781492031482/)\n- Tumbnail : Photo by [Icons8 Team](https://unsplash.com/@icons8?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@icons8?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n","slug":"bitcoin-1","date":"2022-03-16 18:15","title":"[Bitcoin] 1. ECDSA를 이용한 서명","category":"Tech","tags":["BlockChain","Bitcoin"],"desc":"Blockchain을 공부하게 되었는데, 이번 기회에 제대로 하자는 생각에서 Bitcoin 구현을 직접 수행해볼 생각입니다. 학습에 사용한 책은 위에 나와있는 책을 활용하였습니다.해당 Posting은 Bitcoin이 무엇이고, 이것으로 무엇을 할 수 있는지에 대해서 설명하지 않고 Bitcoin을 구현하는 기술에 대하여 다룹니다. 또한, 책의 모든 내용을 충실히 번역하는 것이 아닌 작성자의 생각이 많이 담겨 있으니 유의 바랍니다.해당 chapter에서는 데이터의 인증을 어떻게 수행할 것인가에 대한 세부적인 내용을 다루겠습니다. (+) 들어가기에 앞 서...Bitcoin에서는 결제가 발생할 때, 이전 거래에서 얻은 Bitcoin을 통해서만 결제가 가능합니다. (거래를 통해 Bitcoin을 받은 적이 없다면, Bitcoin이 없는 것으로 간주합니다.)또한, 우리는 이 거래 내역을 모두가 볼 수 있도록 공개합니다. 이 상황에서 우리가 특정 거래 내역에서 돈을 받은 사람이 자신이고, 그 거래에서 얻은 Bitcoin을 현재 거래에 사용할 것임을 증명하기 위해서는 어떻게 해야할까요?","thumbnailSrc":"https://euidong.github.io/images/bitcoin.jpg"},{"content":"\n## Intro\n\n**해당 Posting은 Bitcoin이 무엇이고, 이것으로 무엇을 할 수 있는지에 대해서 설명하지 않고 Bitcoin을 구현하는 기술에 대하여 다룹니다.** 또한, 책의 모든 내용을 충실히 번역하는 것이 아닌 작성자의 생각이 많이 담겨 있으니 유의 바랍니다.\n\n**해당 chapter에서는 Bitcoin에서 데이터를 어떻게 Serialization 하고, Parsing 하는지에 대해서 다룹니다.**\n\n---\n\n먼저, Serialization이 무엇인지부터 알아보아야 합니다. Serialization이란 현재 programmer가 만들어놓은 data(Class Instance, 등)를 network를 통해서 다른 computer로 옮기거나, 저장 장치 file 등으로 옮겨 담을 때, **연속적으로 표현되는 형태**로 구조화하는 방법을 말합니다. 대게, 이러한 처리는 원본 데이터를 변환하기 때문에, 이를 원래 data로 변환하는 Parsing과 짝을 이룹니다.\n\n데이터마다, 그리고 사람마다 더 좋다고 생각하는 serialization 방식은 매우 많습니다.\n\n대게 고려하게 되는 사항은 다음과 같습니다.\n\n1. **효율성** : 변환하는 데이터가 짧게 표현될 수록 더 효율적으로 전달이 가능하다는 것은 자명하기에 이는 가장 중요한 요소 중 하나입니다.\n2. **보안성** : network로 전달이 될 가능성이 높기 때문에, 이를 전달받은 누구나 이를 변환할 수 있다면, 위험할 수 있습니다. 따라서, 보안성을 위해서, 암호화 또는 hashing을 수행하기도 합니다.\n3. **안정성** : 대게 보안성과 묶어서 설명하지만, 여기서는 분리하였습니다. 즉, 데이터가 중간에 손실되지 않고, 안정적으로 제대로 도착했는지를 확인할 수 있도록 하는 것도 중요합니다.\n4. **표준** : 결국 Serialization을 하더라도, 이를 수신받은 입장에서는 이를 번역한 내용에 관심이 있기에, 이를 번역할 방법이 서로 공유가 되어있어야 합니다. 그렇기에 많은 경우에, Serialization을 표준으로 정해진 방식을 통해서 수행됩니다. 또는, 새로운 표준을 만들어서 수행합니다.\n5. **가독성** : 대게, serialization된 데이터 자체를 사람 간에 구두로 전달해야 할 경우가 있습니다. 이를 위해서, 인간 친화적인 형태로 데이터를 변조하는 경우도 많습니다.\n\n---\n\n먼저, Bitcoin에서 구체적으로 어떤 식으로 Serialization을 살펴보기 전에 기반 기술을 알아볼 것입니다. 각 기술에 대해서 이미 알고 있다면, 바로 다음으로 넘어가도 좋습니다.\n\n### 1. Byte화\n\n일반적으로, Serialization을 수행한 결과물은 bytes(8bit) 형태로 나타나는 것이 일반적입니다. 왜냐하면, 당연히 일반적인 programming에서 사용되는 integer(4 bytes) 형태로 표현하는 것은 비효율적이기 때문입니다. 또한, 컴퓨터 자체가 byte 단위로 데이터를 알아먹기 때문에, 컴퓨터 친화적으로 데이터를 변환한다고 생각하면 될 거 같습니다. 따라서, 데이터를 변환하여 결과물이 byte 단위로 묶이는 것이 일반적입니다. (+ 단순히 좀 더 효율적인 형태로 변환했다고 생각해도 됩니다. 그러기 위해서, 사람이 해당 문자를 보고, 한 번에 무슨 숫자인지 찾아내기는 좀 힘들어집니다.)\n\n```c++\n// c++을 안다면 도움이 되겠지만, c를 잘 모르신다면, 이해할려고 하지말고 넘어가셔도 됩니다.\nint a = 255 // 4 bytes\nchar a = 255 // 1 byte\n```\n\n여기서, byte type을 다룰 때, 항상 발생하는 문제인 **호환성**을 확인해야 합니다. 사람은 일반적으로 수를 쓸 때, 왼쪽에서부터 큰수가 나오며, 오른쪽으로 쓰는 것이 표준처럼 정해져 있습니다. 하지만, computer 세계에서는 그렇지 않기 때문에, 왼쪽이 큰 수 인지, 오른쪽이 큰 수 인지를 정해줄 필요가 있습니다. 따라서, 이를 표준으로 정해서 어떤 데이터를 serialization 할 때 왼쪽이 큰 수가 되는 (Big endian)을 사용할지, 오른쪽이 큰 수가 되는 (Little endian)을 사용할지를 반드시 정해야 합니다.\n\n### 2. Base58\n\n이를 이해하기 위해서는 Base64를 먼저 이해해야 합니다.\n\n이는 특정 데이터를 총 64개의 문자 (10(숫자) + 26(알파벳 소문자) + 26(알파벳 대문자) + 2(기호 +, /))로 이루어진 문자 체계로 변환하는 것을 말합니다. 우리가 하나의 byte(8 bits)로 256개의 데이터를 표현할 수 있지만, 다음과 같이 Base64로 변환하게 되면 6bit을 사용하기 때문에 결과적으로 데이터의 크기가 커지는 현상이 발생하게 됩니다.(결국에는 byte단위로 전송하는데, 그중에 6bit만 사용하기 때문입니다.) 그럼에도 이를 사용하는 이유는 **호환성**을 높이기 위해서 입니다. 국제적인 표준이기 때문에, Base64를 이용한다면, 어떤 시스템에서도 이를 해석하는 데는 문제가 없습니다. 따라서, 이러한 형태로의 변환은 굉장히 빈번히 사용됩니다.\n\n그렇다면, Base58은 무엇인가에 대해서 고민을 해보아야 합니다. Base58이란, Base64에 **가독성**을 높이기 위한 version이라고 생각할 수 있습니다. 바로 사람이 읽었을 때, 헷갈릴 수 있겠다고 판단되는 데이터를 과감하게 제거해버리는 것입니다. 따라서, 기존의 Base64에서 0(숫자 0), O(대문자 o), l(소문자 L), I(대문자 i), +, /를 제거하여 표현하는 것입니다. 따라서, 결론상 58개의 문자 (9(숫자) + 25(소문자) + 24(대문자))로 표현하는 방식입니다. 또한, 부가적으로 **안정성**을 높이기 위해서, base58에서는 hash256을 이용해서 만들어진 데이터를 추가로 전송하여, checksum으로 사용하는 구현도 존재합니다. (checksum이란, 수신을 받은 측에서 데이터의 손실 여부를 확인할 때, 사용할 수 있는 데이터를 말합니다. 여기서는 자세히 다루지 않습니다.)\n\n### 3. DER(Distinguished Encoding Rule)\n\nserialization 기법 중에 하나입니다. 이름에서부터 느껴지다시피 serialization을 수행할 때, 정확한 구분자와 길이를 data 앞에 배치시켜서 변환을 쉽게 하기 위한 방법 중에 하나입니다. 여기서는, Bitcoin에서 사용하는 DER 방식만 다루기에 해당 방식이 어떻게 돌아가는지만 다루겠습니다.\n\nBitCoin에서는 Signature(서명)을 전달할 때, 해당 방식을 사용하는데, 이는 이 전 chapter에서 살펴봤듯이 두개의 integer로 이루어집니다. 그렇기에 여러 개를 보낼 때, 이를 감싸 줄 수 있는 Sequence와 Integer 형을 보낼 때, 사용하는 구분자를 data 앞에 넣어주어야 합니다. (Sequence = 0x30, Integer = 0x02) 또한, data의 사이즈 역시 같이 붙여주어야 합니다. (단위가 byte라는 것을 유의합시다.)\n\n따라서, 형태가 다음과 같습니다.\n\n0x30 + {전체 전송 data의 사이즈} + 0x02 + {보낼 integer data의 사이즈} + {전송할 data(bytes)} + 0x02 + {보낼 integer data의 사이즈} + {전송할 data(bytes)}\n\n예시로 다음을 들 수 있습니다. 만약에 1과 2라는 수를 동시에 보내고 싶을 때에는 다음과 같이 전달된다고 볼 수 있습니다.\n\n0x30\\0x06\\0x02\\0x01\\0x01\\0x02\\0x01\\0x02\n\n아래 링크를 확인하면 더 자세한 방식들을 알 수 있습니다.\n\n[🔗 ASN 형식의 DER 인코딩](https://docs.microsoft.com/ko-kr/windows/win32/seccertenroll/about-der-encoding-of-asn-1-types)\n\n### 4. SEC(Standards for Efficient Cryptography)\n\nserialization 기법 중에 하나이며, 특히 암호화 과정에서 사용되는 표준 정도로 볼 수 있습니다. 대게 ECC(Elliptic Curve Cryptography)의 암호화 시에 생성된 public key 등에 대한 표준화 내용을 포함합니다. Bitcoin에서는 Public key 전송 시에 SEC를 사용함으로 이에 대한 내용만을 다루겠습니다.\n\n먼저, 여기서는 Public key를 두 가지 mode로 표현합니다.\n\n첫 번째로, 압축(compression)을 사용하지 않은 표현법으로 이는 매우 단순합니다.\n\n우선은, 0x04를 데이터 맨 앞에 붙이고, 순서대로 Public key의 X좌표, Y좌표를 붙여주면 됩니다.\n\n0x04 + {public key's x (bytes)} + {public key's y (bytes)}\n\n이는 항상 사이즈가 65(1 + 32 + 32)bytes로 고정된다는 점을 알 수 있을 것입니다. (그렇기 때문에, 위에서 설명한 DER 방식없이도 전송이 가능합니다.)\n\n두 번째로, 압축(compression)을 사용하는 표현법입니다. 전송하는 두 개의 데이터 $x$,$y$가 Elliptic Curve 위에 존재한다는 연관점을 활용하는 것입니다. ($y^2 = x^3 + ax + b$)\n\n$x$만 보내고, $y$를 알기 위해서는 두 가지 문제를 해결할 수 있어야 합니다.\n\n1. 제곱근 연산($\\sqrt{y^2}$)이 가능한가?\n2. 제곱근으로 나온 결과값 중 어떤 것이 근인지 확신할 수 있는가?\n\n일단 제곱근 연산은 다음과 같은 상황에서는 쉽게 구할 수 있습니다. ($p+1$이 4의 배수인 경우)\n\n$$ p \\% 4 = 3$$\n\n$$(p + 1) \\% 4 = 0$$\n\n다행히도, Bitcoin가 사용하는 ECDSA에서는 이를 만족합니다. 그렇다면, 아래의 식을 만족하여 쉽게 제곱근을 구할 수 있습니다. (중간에 $(p+1)/2$ 이 가능한 이유는 Prime number는 2를 제외하고는 모두 홀수 이기 때문입니다.)\n\n$$w^2 = v$$\n\n$$w^{p-1} \\% p = 1$$\n\n$$w=w^{(p+1)/2}=w^{2(p+1)/4} = (w^2)^{(p+1)4} = v^{(p+1)/4} $$\n\n또 하나의 제곱근을 구할 때에는 간단하게 다음을 수행합니다.\n\n$$-w = p - w$$\n\n다음으로, 제곱근으로 나온 값 중 특정하는 방법은 바로 홀수인지 짝수인지를 알려주는 1byte만을 전송해주면 됩니다. 왜냐하면, 위에 식에서 알 수 있듯이 $w$가 짝수이면, 또 다른 근인 $-w$는 홀수일 수 밖에 없기 때문입니다. ($p$ = 홀수)\n\n따라서, 전송 시에는 다음과 같이 더욱 간소해집니다.\n\n우선은, 0x02 또는 0x03 데이터를 맨 앞에 붙이고, 순서대로 Public key의 X좌표를 붙여주면 됩니다.\n\n짝수 : 0x02 + {public key's x (bytes)}\n\n홀수 : 0x03 + {public key's x (bytes)}\n\n이는 항상 사이즈가 33(1 + 32)bytes로 고정된다는 점을 알 수 있을 것입니다.\n\n아래 링크를 통해서 더 자세한 사항을 확인할 수 있습니다.\n\n[🔗 Standards for Efficient Cryptography Group](https://www.secg.org/)\n\n### 5. Hash160, Hash256\n\nhash라는 것 역시 serialization part에서 빈번하게 등장할 수 밖에 없는 내용입니다. hash란 다음과 같은 특징을 가지는 함수를 말합니다.\n\n1. one way function : 역연산이 불가능연산입니다.\n2. return fixed length : 반환된 결과값이 항상 일정한 길이를 가집니다.\n3. collision with very low probability : 반환된 결과값이 충돌될 가능성이 사실상 없다. 즉, 완벽한 1:1 대칭은 아니지만, 이에 매우 근사한다는 것입니다.\n\nhash의 전반적인 설명은 여기서 다루지 않기 때문에, 이정도만 기억해두시면 됩니다. 역연산이 불가능하기 때문에, 대게 데이터를 알 수 없는 형태로 저장하고자 하는 경우에 많이 사용합니다. 대표적인 예시로 MD-5, SHA-1, SHA-2(SHA-256, SHA-512, ...)가 있습니다.\n\nhash는 대게의 경우 매우 제대로 잘 동작하지만, collision에 의해서 망가지는 경우가 있습니다. 따라서, 이를 보안하기 위해서 계속해서 새로운 방법들이 고안 되었습니다.\n\n따라서, Bitcoin에서는 SHA256 이후에 이를 다시 한 번 ripemd160을 수행하는 것을 Hash160이라고 하고, SHA256을 연달아서 두 번 수행하는 것은 Hash256이라고 합니다. 이름에서 알 수 있다시피, Hash160은 결과값이 160bits(20bytes), SHA256은 256bits(32bytes)입니다.\n\n### 6. Varint\n\nVariable + int의 합성어로 variable length로 integer data를 serialization하는 방법을 제시합니다. 최대 수의 범위는 $2^{64} - 1$까지 표현할 수 있기 때문에 매우 유용하며, 불필요한 데이터의 전송을 최소화할 수 있습니다. 내용 자체는 매우 간단합니다.\n\n1. 해당 수가 253보다 작다면 1 byte만 이용해서 바로 표현합니다.\n2. 그렇지 않고, 해당 수가 2^16 - 1 보다 작다면, 253(0xfd)를 prefix로 맨 앞에 붙이고, 2 byte를 이용해서 표현합니다.\n3. 그렇지 않고, 해당 수가 2^32 - 1 보다 작다면, 254(0xfe)를 prefix로 맨 앞에 붙이고, 4 byte를 이용해서 표현합니다.\n4. 그렇지 않고, 해당 수가 2^64 - 1 보다 작다면, 255(0xff)를 prefix로 맨 앞에 붙이고, 8 byte를 이용해서 표현합니다.\n\n즉, 0으로 앞에 남는 byte를 보내는 양을 효과적으로 줄일 수 있기 때문에, 변수 상태의 integer를 전송할 때 많이 사용됩니다.\n\n---\n\n여기서 Bitcoin에서 Serialization를 수행하는 경우를 구체적으로 살펴보겠습니다.\n\n### 1. Public Key\n\n기본적으로 Public key는 모두에게 공개되어야 하는 정보 중에 하나입니다. 따라서, 이를 효율적으로 분배하는 문제 역시 중요하다고 할 수 있습니다. Bitcoin에서는 앞 서 살펴보았던, SEC, Base58를 이용하며, 필요에 따라서 hash160을 이용해서 내용을 감추기도 합니다.\n\n일반적으로, SEC와 Base58을 이용하여, 데이터를 전송하는 이유는 후에 Public Key 역시 사람들에게 쉽게 노출이 되는데, 이를 쉽게 사람들이 알아볼 수 있게 하기 위함이며, hash160을 사용하는 이유는 Public Key를 감추기 위해서 입니다. 이 말이 이상하게 들릴 수 있는데, Public key가 Open 되고 바로 사용된다면, 문제가 되지 않지만, Public Key가 공개되고 오랜 시간이 지난다면, 문제가 발생할 가능성이 생기기 때문입니다. (너무나 오랫동안 노출된다면, private key가 결국은 해독될 수도 있습니다.) 이는 바로 다음 chapter에서 더 알아볼 수 있습니다.\n\n### 2. Signature\n\nSignature 방식 같은 경우는 표준처럼 넓게 사용되는 DER을 사용합니다.\n\n### 3. Private Key\n\nPrivate key를 전송한다는 것은 굉장한 위험을 초래할 수 있습니다. 하지만, 그럼에도 불구하고, 이를 전송해야할 경우가 있습니다. usb에 저장하고 싶다거나 별도의 software로 옮기고 싶은 경우도 존재합니다. 따라서, 이를 위한 Serialization Format도 존재합니다. 우리는 이를 WIF(Wallet Import Format)이라고 부릅니다.\n\n이는 이름에서부터 느껴지듯이 Bitcoin에서 파생된 standard라고 볼 수 있습니다. 또한, 이는 Base58로 encoding된다는 점 정도만 기억하면 충분합니다.\n\n또한, 위에서는 다루지 않았지만, Bitcoin network는 개발용(testnet)과 실제 서비스용(mainnet)을 가지고 있기 때문에, 이를 구분하는 구분자를 각 serialization 앞에 표시하는 것을 원칙으로 합니다.\n\n- mainnet = 0x80\n- testnet = 0xef\n\n### 4. Number of data\n\nbitcoin 상에서도 여러 개의 데이터를 전송해야 하는 경우가 많습니다. 그런데, 만약 해당 데이터의 갯수가 정해져있는 것이 아니라 때에 따라서 변경되는 경우에는 위에서 제시한 Varint를 사용할 수 밖에 없습니다. 이는 바로 다음 Chapter에서 알아볼 Transaction 내부에서 많이 사용되는 것을 알 수 있습니다.\n\n이전 글과 동일하게 구현 사항은 github에 정의해두었습니다.\n\n[🔗 GitHub - euidong/bitcoin](https://github.com/euidong/bitcoin)\n\n## Reference\n\n- [🔗 Programming Bitcoin](https://learning.oreilly.com/library/view/programming-bitcoin/9781492031482/)\n- Tumbnail : Photo by [Icons8 Team](https://unsplash.com/@icons8?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@icons8?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n","slug":"bitcoin-2","date":"2022-03-18 14:51","title":"[Bitcoin] 2. Serialization","category":"Tech","tags":["BlockChain","Bitcoin"],"desc":"해당 Posting은 Bitcoin이 무엇이고, 이것으로 무엇을 할 수 있는지에 대해서 설명하지 않고 Bitcoin을 구현하는 기술에 대하여 다룹니다. 또한, 책의 모든 내용을 충실히 번역하는 것이 아닌 작성자의 생각이 많이 담겨 있으니 유의 바랍니다.해당 chapter에서는 Bitcoin에서 데이터를 어떻게 Serialization 하고, Parsing 하는지에 대해서 다룹니다.","thumbnailSrc":"https://euidong.github.io/images/bitcoin.jpg"},{"content":"\n## Intro\n\n**해당 Posting은 Bitcoin이 무엇이고, 이것으로 무엇을 할 수 있는지에 대해서 설명하지 않고 Bitcoin을 구현하는 기술에 대하여 다룹니다.** 또한, 책의 모든 내용을 충실히 번역하는 것이 아닌 작성자의 생각이 많이 담겨 있으니 유의 바랍니다.\n\n**해당 chapter에서는 Bitcoin이 실제로 어떻게 전달되며, Bitcoin을 이용한 거래는 어떻게 수행되는지를 다룹니다. 또한, 이를 위해 Bitcoin에서 구축한 Script라는 language를 소개하고 여러 인증 방식을 소개합니다.**\n\n---\n\n### 1. Transaction\n\nTransaction은 Bitcoin의 꽃이라고 표현할 수 있을 정도로 가장 중요한 위치를 차지하고 있습니다. 앞서 보았던, Signature, Serialization 역시 이를 위한 토대라고 보시면 됩니다. 우선 Transaction이 무엇인지에 대해서부터 알아봅시다.\n\nTransaction의 뜻을 한국어로 번역하면, 거래라고 할 수 있습니다. **Bitcoin system 상에서는, Bitcoin을 누군가에게 전송하는 행위를 Transaction이라고 정의합니다.** Bitcoin 상에서 Transaction은 여러 **특이한 속성**을 가집니다. 이를 이해하는 것이 Bitcoin을 이해하는 기반이 될 것입니다. (아래 특징은 저의 주관적인 생각을 담은 것입니다. 더 많은 특징이 있지만, 해당 chapter에서 설명할 내용을 이해하기 위해서는 다음 내용을 일단 머릿속에 새기고 가도록 합시다.)\n\n#### 1-1. 특징\n\n1. **공개성 (Public)** : 모든 Transaction은 공유됩니다. 누구나 원한다면, 조회가 가능합니다.\n2. **연속성 (Continuity)** : coinbase에서 직접 생성한 Transaction을 제외하고는 모든 Transaction은 이전 Transaction에 의존하여 정의됩니다. 또한, 해당 chapter에서는 coinbase에서 생성된 Transaction에서는 고려하지 않습니다. (실생활에서 생각해보면, 거래라는 것도 은행에서 직접 전달받은 돈이 아니라면, 모두 다른 사람과의 거래를 통해서 생성되는 것이므로 당연하다고 할 수 있습니다.)\n3. **일회성 (One time)** : 하나의 Transaction이 여러 번 사용될 수 없습니다. 단 한 번만 사용됩니다. (Transaction은 output을 여러 개 가지므로, 이들이 각 각 사용될 수는 있어도, 같은 Transaction의 같은 output은 단 한 번만 사용되어야 한다는 점입니다. 그렇기에 잔돈이 발생한다면, Transaction에 다시 자신에게 보내는 output을 생성합니다.)\n4. **익명성 (Anonymous)** : 해당 Transaction의 output을 사용할 사람을 명시하지 않습니다. 즉, 누구나 해당 Transaction output의 소유권을 주장할 수 있습니다. (실제 세상에서 누가 누구에게 보내는 것인지는 알 수 없습니다. 원한다면, 거래 address를 계속 바꿀 수도 있습니다. 그리고 그렇게 계속 바꾸는 것을 권장하기도 합니다.)\n\nTransaction을 통해서 우리는 Bitcoin을 받을 수도 있고, 전달할 수도 있으며, 해당 Bitcoin이 자신의 소유라는 것을 증명할 수 있습니다.\n\n또한, 기억해두어야 할 점은 Transaction의 Output은 Bitcoin을 포함한다는 사실을 기억합시다. 그리고, 모든 Bitcoin은 Transaction에 의해서 존재한다는 것을 기억하는 것입니다.\n\n이것이 어떻게 가능한지 Transaction의 **구성 요소**를 먼저 살펴보고 알아보도록 합시다.\n\n#### 1-2. 구성요소\n\n1. **Version** : Transaction의 version이 존재합니다. Bitcoin 자체가 계속해서 발전해왔기 때문에, 하나의 version으로 고정되어 있지는 않습니다. 대게는 1이지만, 필요에 따라 다른 version을 써야 하는 경우도 있습니다.\n2. **Outputs** : 여러 개의 output을 가질 수 있으며, 각 output은 다음과 같은 값을 포함합니다.\n   1. **amount** : 해당 output이 가질 bitcoin의 양을 의미합니다.\n   2. **ScriptPubKey** : 해당 output이 후에 사용될 때, 정당한 권한이 있는지를 확인할 수단이 됩니다. 마치 금고의 잠금 장치라고 생각할 수 있습니다. 이를 어떻게 잠그는지에 대해서는 밑에서 Script part에서 설명합니다.\n3. **Inputs** : 하나의 input은 이전 Transaction 중 하나의 output을 가르키고 있으며, 이를 여러 개 가질 수 있습니다. 여기서 각 input은 두 가지 기능을 할 수 있어야 합니다. 첫째로, **특정 Transaction의 하나의 output을 식별**할 수 있어야 합니다. 사용하고자 하는 **Transaction이 자신의 것임을 증명**할 수 있어야 합니다.\n   1. **PrevTxId** : 이전 Transaction을 고유하게 식별할 수 있는 값입니다.\n   2. **PrevTxIndex** : 이전 Transaction의 output 중 하나를 식별하기 위한 값입니다.\n   3. **ScriptSig** : 해당 output이 자신이 사용할 수 있는 데이터임을 증명할 수 있는 수단입니다. 마치 금고의 열쇠로 생각할 수 있습니다.\n   4. **Sequence** : 초기에 Bitcoin 설계 시에는 동시에 서로 간에 너무 많은 Transaction이 생기는 것을 막기 위해서, 여러 Transaction을 하나의 Transaction으로 통합시키기를 원했습니다. 그래서 그때 해당 거래가 몇 번째 인지를 표시하기 위한 수단으로 사용되었으나 현재에는 보안상의 취약점이 발견되어 사용되고 있지 않기에, 4 bytes little endian으로 최댓값(0xffffffff)으로 표기합니다.\n4. **Locktime** : 위에서 설명한 Sequence 처럼, Transaction을 어느 정도 시간이 될 때까지 Transaction의 input으로써 사용되는 것을 막는 것입니다. 이는 다음 chapter에서 설명할 Block의 height가 될 수도 있고, Unix timestamp를 통해서 시간을 지정할 수도 있습니다. 이 또한, 4 bytes를 통해서 표현합니다.\n\n![transaction](/images/transaction.jpeg)\n\n#### 1-3. 추가 개념\n\n1. **Fee**  \n  **일명 거래 수수료**라고 생각할 수 있습니다. 대게, 이 거래를 확인해주는 miner들에게 주어지는 보상으로 생각할 수 있습니다. 송신자는 거래를 할 때, 이를 인증받기 위해서 이를 확인해줄 여러 제3자들에게 일정 수수료를 제시합니다. 빠른 거래를 원한다면, 더 많은 비용을, 천천히 해도 상관이 없다면, 적은 비용을 투자할 수 있습니다.\n2. **UTXO(Unspent Transaction Output) Set**  \n  사용하지 않은 Transaction Output의 집합입니다. 이를 유지할 수 있어야지만, 왜냐하면, 두 번 이상 사용한다는 것 자체를 막아야만 하기 때문입니다. 모든 UTXO를 포함하고 있으며, 이를 계속해서 추적하는 노드를 Full nodes라고 부르며, 이것이 있어야지만 Bitcoin 거래를 빠르게 수행할 수 있습니다.\n\nTransaction이라는 것은 결국 Bitcoin을 전달하는 방법입니다. 이것이 있어야만 우리는 실세계에 있는 물건을 사는 명분을 가질 수 있는 것입니다. 그런데 여기서, 의문점이 가장 크게 생길 수 있는 부분이 있습니다. 뭔가 거래를 하기 위해서는 Transaction을 통해서 Bitcoin을 보내야 하는 것은 이해했는데, 내가 보낼 때 사용하는 Transaction이 모두에게 공개된다고 했는데, 이게 자신의 것이라는 것을 어떻게 증명할 수 있을까요? 이 방법으로 고안된 것이 Script입니다. 이에 대해서 살펴봅시다.\n\n![transaction-relation](/images/transaction-relation.jpeg)\n\n### 2. Script\n\nBitcoin(Transaction의 Output)을 전달할 때, 이를 누구나 쓸 수 없게 **잠그는 과정(lock)**이 필요하고, 후에는 이를 사용할 수 있게 **해제 과정(unlock)**이 필요합니다. Bitcoin에서는 이를 위해서 Script라는 것을 고안해냈습니다. Script는 완성된 형태로 존재할 때, 해당 output의 소유가 자신이라는 것을 **누구나 인정할 수 있는 문서**가 됩니다. 그래서 이를 반으로 잘라서, 하나는 output 쪽에 붙여두고(**ScriptPubkey**), 나머지 하나(**ScriptSig**)는 자신이 소유하고 있다가 사용할 때, 이 조각을 들이 밀어서 자신임을 인정하는 것입니다.\n\n 그렇다면, Script라는 것이 도대체 무엇이길래 **누구나 인정할 수 있는 문서**가 될 수 있는 것일까요? 이는 Script의 해석법을 알면, 이해할 수 있습니다.\n\n#### 2-1. Script (language)\n\nScript라고 쓰기도 하고, Script language라고도 부르는 해당 언어는 영어 같은 사람의 언어로 작성되지도 않고, python이나 c와 같은 **turning complete(=모든 계산 가능한 문제를 표현할 수 있는**, 대게는 loop, condition, memory 제어 기능을 포함하는지를 의미합니다.**)**한 programming language 로 작성하지 않습니다. 왜냐하면, 이러한 Script는 **효율**을 위해서 너무 복잡한 로직을 가져서도 안되고, 보안상의 **취약점**을 만들 수 있는 수단 자체를 막기 위해서 입니다. 따라서, Bitcoin의 Script에서는 loop문을 허용하지 않는 형태를 가집니다.\n\n#### 2-2. 구성요소\n\nScript를 해석하기 위해서는, 구성요소를 먼저 알아야 합니다. 따라서, 각 구성요소에 대해서 알아보겠습니다.\n\n1. **Element** : 일반 programming language에서 variable이 하는 역할을 맡습니다.\n2. **Operation** : 일반 programming language에서 function의 역할을 맡습니다. 이는 element를 받아서 동작을 수행하여, Stack의 변화를 일으킵니다. 만약, 중간의 Operation의 동작이 실패한다면, 해당 Script의 실행은 종료되고, 타당하지 않은 Script라는 결론을 내놓습니다.\n3. **Stack** : 일반 programming language와는 다르지만, 후위 표현법에 기반한 language에서는 흔히 볼 수 있는 특징입니다. element가 존재할 수 있는 공간으로 operation은 stack 안에 있는 element만을 소비하여 동작합니다.\n\n전체 코드는 위에서부터 실행되면서, 마치 하나의 stack처럼 구성되며, 후위 표기식처럼 동작한다고 생각하면 됩니다. 후위 표기식에서는 element가 먼저 나오고 이를 기억해두고 있다가 연산을 수행하는 방식입니다. (따라서, stack이 필요한 것입니다.) 따라서, 위에서 부터 실행하면서 element가 나온다면, stack에 쌓아두고, operation이 나온다면 stack에 있는 데이터를 최신순으로 사용합니다.\n\n#### 2-3. Operation의 종류\n\n앞 서 Script는 turning complete한 언어가 아니라고 했으므로, operation에는 loop를 포함하지 않거나 현재는 사용되지 않습니다. 또한, 보안상 취약점이 밝혀진 Operation 역시 사용되지 않습니다. 여기서는 Script의 특성을 설명할 수 있는 몇 가지의 Operation을 설명하고 동작 방식을 설명합니다.\n\n- **OP\\_DUP** : stack에 있는 element 중 가장 앞에 있는 element를 복사해서 stack에 추가합니다.\n- **OP\\_x**(number) : stack에 x element를 추가합니다. 이때, x는 0 ~ 16까지의 수를 뜻합니다.\n- **OP\\_PUSHDATAx** : 먼저 x byte에 해당하는 값을 받습니다. 이는 이제 stack에 입력할 데이터의 크기를 의미합니다. 그 후 입력받은 길이만큼을 읽어 들인 후에 이를 stack에 추가합니다. x는 1, 2,4가 존재하지만, stack에 입력하는 데이터는 최대 520 bytes 까지만 허용합니다.\n- **OP\\_VERIFY** : stack에서 하나의 값을 꺼낸 후, 1인지를 확인합니다.\n- **OP\\_EQUAL** : stack에서 두 개의 값을 꺼낸 후, 서로 같은지를 확인하고, 같다면 1 다르다면, 0을 추가합니다.\n- **OP\\_CHECKSIG** : stack에서 두 개의 값을 꺼낸 후, 첫 번째 element는 PubKey 그리고, 두 번째 element는 Signature로 하여 ECDSA를 만족시키는지를 확인합니다.\n- **OP\\_MULTI\\_CHECK\\_SIG** : 이는 stack에 PubKey와 Signature가 하나 이상일 때, 이를 모두 확인하는 방법입니다.\n- **OP\\_HASH160, OP\\_SHA1, OP\\_SHA256, OP\\_HASH256** : stack의 하나의 element를 꺼낸 후, hash하여 다시 stack에 추가합니다.\n\n추가적인 Operation에 대해서도 궁금하다면, 아래 link를 참고해주세요.\n\n[🔗 Script - Bitcoin Wiki](https://en.bitcoin.it/wiki/Script)\n\n#### 2-3. Goal\n\nScript의 최종 목적은 **Script의 모든 구성요소를 실행시켜서, 중간에 operation의 에러 없이 stack에 1이라는 숫자를 남기는 것입니다.** 따라서, 해석이 실패하는 경우는 두 가지 입니다. Script의 해석 도중에 operation이 에러를 발생시켰거나, 모든 Script를 해석했음에도 stack에 1이 아닌 값이 있거나 아무 값도 없는 경우입니다.\n\n아까 말했듯이 우리는 이 Script를 두 개의 조각(ScriptPubKey, ScriptSig)으로 나눕니다. 즉, 코드를 중간에 툭 잘라버린다는 것입니다. 그래서, 후반부에 해당하는 내용(ScriptPubKey)을 Transaction의 Output에 넣어서 보관합니다. 그래서, ScriptPubKey에 전반부에 해당하는 ScriptSig를 가진 사람이 있다면, 그 사람이 Transaction의 Output에 있는 Bitcoin을 해당하는 amount만큼 사용할 수 있다는 것입니다.\n\n![transaction-script](/images/transaction-script.jpeg)\n\n#### 2-4. Example\n\n이제 ScriptPubKey가 주어졌다고 가정합시다. 그렇다면, 이는 마치 하나의 문제처럼 느껴질 수 있고, 우리는 이를 만족하는 값을 ScriptSig에 넣어서 만들어주기만 하면 됩니다.\n\n> **2-4-1. $x^2 + x = 6$을 만족하는 x 값 넣기**\n\n완성된 Script에서 x에 무엇이 들어가면 될지를 추측해봅시다.\n\n![transaction-example-2-4-1](/images/transaction-example-2-4-1.png)\n\n결론상 $x^2 + x = 6$을 만족하는 x값이 필요하므로 $ x = 2$여야 합니다.\n\n> **2-4-2. SHA-1의 collision을 발생시키는 두 개의 값**\n\n이번에는 다음과 같은 ScriptPubKey가 주어졌을 때, ScriptSig로 뭐가 들어가야 할지를 추측해봅시다.\n\n`ScriptPubKey`\n\n![transaction-example-2-4-2-goal](/images/transaction-example-2-4-2-goal.jpeg)\n\n다음과 같은 형태가 주어질 때, 이를 역연산하여 필요로 하는 값이 무엇인지 찾아나갈 수 있습니다.\n\n![transaction-example-2-4-2](/images/transaction-example-2-4-2.png)\n\n결론상 다음의 조건을 만족하는 h, k를 **ScriptSig**로 넣어주면 됩니다.\n\n1. $h \\ne k$\n2. $sha1(h) = sha1(k)$\n\n이는 SHA-1이 collision을 발생하게 하는 두 개의 값을 넣어주면 됩니다. (이를 찾을 수 있는지 없는지가 hash함수의 성능을 표시하는데 가장 큰 지표가 됩니다.)\n\n이와 같은 형태로 특정 수학 문제, 또는 hash collision 예시에 대해서 Bitcoin을 통해서 현상금을 걸기도 한다고 합니다.\n\n#### 2-5. 주요 Script\n\n위의 예시를 살펴보았지만, 사실 위와 같은 형태로 Script를 표현한다면, 누구나 해당 Transaction의 Output안에 있는 Bitcoin을 사용할 수 있을 것입니다. 이제 나만 사용할 수 있는 Transaction Output을 만들기 위한 주요 Script 형태를 알아보겠습니다.\n\n> **2-5-1. p2pk(Pay to PubKey)**\n\n**ScriptPubKey**에는 PubKey와 OP\\_CHECKSIG 두 개를 넣어두고, **ScriptSig**에 Signature만 넣어두는 방식입니다. 이 방식 때문에, Transaction Output에 있는 ScriptPubKey의 이름이 이렇게 불려지고, Transaction Input의 ScriptSig의 이름이 정해지게 된 것입니다.\n\n![transaction-p2pk](/images/transaction-p2pk.png)\n\n> **2-5-2. p2pkh(Pay to PubKey Hash)**\n\np2pk에서 문제가 하나 발생할 수 있습니다. 바로 공개키가 모든 이들에게 보인다는 점입니다. 이것이 왜 문제일 수 있냐고 할 수 있지만, 해당 거래 자체가 모두 공개되기 때문에 공개키를 열어두고, 긴 시간 동안 사용하지 않는다면, 언제 가는 무식하게 풀어나가는 과정에서 답을 찾아낼 수도 있습니다. 따라서, 대게는 공개키의 유효시간을 두고 하는 것이 일반적인 경우가 많습니다. 하지만, Transaction의 유효기간을 둘 수 없으므로, PubKey를 바로 공개하지 않는 방식입니다. 따라서, 이름에서부터 느껴지겠지만, **PubKey의 hash를 수행**합니다. 그리고, 결론적으로 거래를 사용할 때, output을 사용하는 입장에서, pubkey와 signature를 모두 사용하는 방식입니다. (여기서 PubKey에 hash160을 수행하고, Base58로 encoding 한 것을 address라고 합니다.)\n\n`ScriptPubKey 와 ScriptSig`\n\n![transaction-p2pkh](/images/transaction-p2pkh.jpeg)\n\n`Script의 성공적인 동작예시 1`\n\n![transaction-p2pkh-2](/images/transaction-p2pkh-2.jpeg)\n\n`Script의 성공적인 동작예시 2`\n\n![transaction-p2pkh-3](/images/transaction-p2pkh-3.jpeg)\n\n> **2-5-3. p2psh (Pay to Script Hash)**\n\np2psh는 여러 개의 key와 signature를 가지는 경우에 사용할 수 있습니다. 여러 개의 PubKey를 포함하고 있는 RedeemScript라는 것을 Hash 하여 ScriptPubKey에 추가시키는 것입니다. RedeemScript라고 불리는 이유는 이것이 후에 다시 하나의 Script로 동작하기 때문입니다. 내부에 들어가는 RedeemScript는 Serialization 해서 element로 넣습니다.\n\n`ScriptPubKey, ScriptSig 과 RedeemScript`\n\n![transaction-p2psh-1](/images/transaction-p2psh-1.jpeg)\n\n`Script의 동작 예시 - 1`\n\n![transaction-p2psh-2](/images/transaction-p2psh-2.jpeg)\n\n`Script의 동작 예시 - 2`\n\n![transaction-p2psh-3](/images/transaction-p2psh-3.jpeg)\n\n`Script의 동작 예시 - 3`\n\n![transaction-p2psh-4](/images/transaction-p2psh-4.jpeg)\n\n> **2-5-0. Signature 생성**\n\n주요 Script를 알아보기 전에 빠트린 부분을 먼저 채우고 가야 합니다. 바로, 이전에 ECDSA에서 사용하던 변수 중 현재 누락된 변수를 채우는 것입니다. 이전에 살펴봤듯이 특정 data의 소유가 자신이라는 것을 인증하기 위해서, ECDSA에서는 공개하는 데이터로 Signature와 data의 hash 값 그리고 Public Key를 이용했고, 공개하지 않고, 자신만 가지는 데이터로 Private Key라는 것을 가졌습니다. 여기서 누락된 것은 바로 **data의 hash 값**과 **Signature의 생성** 방법입니다.(왜냐하면, Signature는 data의 hash값이 존재해야만 수행할 수 있기 때문입니다.) 이는 어떻게 만들어지는 알아봅시다.\n\n1. 현재의 Transaction에서 모든 input의 ScriptSig를 빈 값으로 변환합니다.\n2. 그리고, ScriptSig를 생성해야 하는 input에 ScriptSig 부분에만 이전 Transaction의 ScriptPubKey를 대입합니다. (이해를 돕기 위해서 이렇게 썼지만, 이 방법만 있는 것은 아닙니다. 이런 방법이 몇 개 더 있으면, 이 방법에 대한 식별 값이 4번에서 표시됩니다.)\n3. 이를 이제 Serialization 합니다.\n4. Hash 방법에 해당하는 data의 맨 뒤에 4 bytes로 삽입합니다.\n5. 그리고, 이를 Hash 합니다.\n6. 이렇게 생성된 hash 값을 이용해서 Signature를 생성합니다.\n\n이제, 우리는 z와 signature를 생성했습니다. 이제 Transaction의 생성자는 signature를 포함시킬 수 있게 되었습니다. 또한, Transaction을 볼 수 있는 다른 모든 사람들도 해당 Transaction이 타당한지 확인하기 위해서는 단지 Transaction을 위와 같이 변경하여서, z를 얻을 수 있습니다.\n\n### 3. Transaction Validation\n\n그렇다면, 우리는 Transaction이 언제 타당하다고 말할 수 있을까요? 바로 다음 세 가지를 만족시켜야지 우리는 해당 Transaction이 타당하다고 합니다.\n\n- 사용하고자 하는 Transaction의 output이 진짜 사용된 적이 없는지를 확인해야 합니다.\n  이는 위에서 제시했던 UTXO를 조회하는 방법으로 수행합니다. 지금은 이 정도로 밖에 설명할 수 없지만, 이는 후에서 더 자세히 다룹니다.\n- Transaction의 input들보다 output들이 더 큰 값을 내보내지는 않았는지 확인해야 합니다.\n  이는 이전 Transaction Output을 모두 더한 값이 혹여 현재 Transaction의 Output의 총합보다 큰지를 확인하도록 해야 합니다. 위의 진짜 사용 여부를 확인하는 과정에서 이전 Transaction output의 amount도 알 수 있으므로 이는 쉽게 계산할 수 있습니다.\n- ScriptSig + ScriptPubKey로 만들어진 최종 Script가 타당한지 확인해야 합니다.\n  이는 위에서 진행했던 Script의 Check를 통해서 수행 가능합니다.\n\n이 모든 과정을 통과했을 때, 우리는 해당 Transaction이 타당하다고 말할 수 있습니다.\n\n### 4. Transaction Creation\n\n이제까지의 모든 것을 정리하여, Transaction의 생성 과정을 모두 정리해보겠습니다.\n\n1. Transaction을 통해 Bitcoin을 보낼 대상의 PubKey 또는 address(PubKey를 hash + Base58)를 받아오고, 얼마나 Bitcoin을  보낼지(amount)를 결정합니다.\n2. Transaction의 fee로 얼마나 지출할지를 결정합니다.\n3. Inputs가 사용하는 이전 Transaction Outputs의 합이 (fee + 지출할 Bitcoin) Outputs의 총합보다 크도록 CTXO를 하나 이상 선택합니다. (이 과정에서 CTXO가 정말 사용된 것이 아닌 것인지에 대한 확인도 수행합니다.)\n4. CTXO가 자신의 값임을 증명할 수 있도록 Signature를 생성하고, (이 과정에서 당연히 2-5-0에서 설명된 과정이 수행됩니다.) 이전 Transaction Output에서 제시한 **ScriptPubKey**와 결합했을 때, 타당한 Script가 될 수 있도록 하는 **ScriptSig**를 생성합니다.\n5. 위에서 생성한 ScriptSig와 이전 Transaction Output을 특정할 수 있는 값을 묶어서 Transaction Input들을 작성합니다.\n6. Bitcoin을 보낼 대상의 address를 이용해서, 적절한 **ScriptPubKey**를 생성하여, amount와 함께 Transaction Output들을 만듭니다. 이때 잔돈이 발생한다면, 자신에게 다시 보내는 Transaction Output도 생성해야 합니다.\n7. Transaction에 version, locktime 등을 추가하여, Transaction을 최종으로 생성합니다.\n\n이전 글과 동일하게 구현 사항은 github에 정의해두었습니다.\n\n[🔗 GitHub - euidong/bitcoin](https://github.com/euidong/bitcoin)\n\n## Reference\n\n- [🔗 Programming Bitcoin](https://learning.oreilly.com/library/view/programming-bitcoin/9781492031482/)\n- Tumbnail : Photo by [Icons8 Team](https://unsplash.com/@icons8?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@icons8?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n","slug":"bitcoin-3","date":"2022-03-22 11:22","title":"[Bitcoin] 3. Transaction","category":"Tech","tags":["BlockChain","Bitcoin","ECC","ecdsa"],"desc":"해당 Posting은 Bitcoin이 무엇이고, 이것으로 무엇을 할 수 있는지에 대해서 설명하지 않고 Bitcoin을 구현하는 기술에 대하여 다룹니다. 또한, 책의 모든 내용을 충실히 번역하는 것이 아닌 작성자의 생각이 많이 담겨 있으니 유의 바랍니다.해당 chapter에서는 Bitcoin이 실제로 어떻게 전달되며, Bitcoin을 이용한 거래는 어떻게 수행되는지를 다룹니다. 또한, 이를 위해 Bitcoin에서 구축한 Script라는 language를 소개하고 여러 인증 방식을 소개합니다.","thumbnailSrc":"https://euidong.github.io/images/bitcoin.jpg"},{"content":"\n## Intro\n\n**해당 Posting은 Bitcoin이 무엇이고, 이것으로 무엇을 할 수 있는지에 대해서 설명하지 않고 Bitcoin을 구현하는 기술에 대하여 다룹니다.** 또한, 책의 모든 내용을 충실히 번역하는 것이 아닌 작성자의 생각이 많이 담겨 있으니 유의 바랍니다.\n\n**해당 chapter에서는 Blockchain Network 구조에 대한 이해와 실용성을 향상하기 위한 MerkleTree, Bloom Filter, SigWit에 대해서 정리합니다.**\n\n이전 Chapter에서는 Transaction의 소유 여부를 확인하는 방법에 대해서 자세히 다루었습니다. 거기서 Transaction의 사용 여부를 확인할 때에는 UTXO(Unspent Transaction Output) set이라는 것을 사용한다고 하였습니다. 그렇다면, 이는 어떻게 생성되고, 어떻게 관리되는지를 해당 part에서 한 번 다루어보겠습니다.\n\n---\n\n### 1. Blockchain\n\n우리의 Transaction을 저장하기 위해서 여러 가지 방법을 강구해보았습니다. 모든 Transaction을 표의 형태로 저장해두는 것도 방법이 될 수 있습니다. 하지만, Bitcoin에서는 이를 Block이라는 단위로 저장하였습니다.\n\n#### 1-1. Block\n\n##### 1-1-1. 정의\n\nBlock이란 Transaction을 저장하는 하나의 단위라고 볼 수 있습니다. 하나의 Block의 크기는 1MB로 제한되어있습니다. (물론 지금은 여러 다른 변종에서는 이 제한이 다르기도 합니다.)\n\n##### 1-1-2. 구조\n\n따라서, Block에는 이를 만족하는 Transaction의 갯수만큼만을 저장할 수 있습니다. 이를 이루는 구조는 다음과 같습니다.\n\n1. Header : 해당 Block에 대한 설명을 위한 정보를 포함합니다. 특히, 해당 Block의 정당성을 확인하기 위한 내용을 포함합니다.\n2. Coinbase Transaction : Block에 존재하는 첫번째 Transaction을 의미합니다.\n3. Transactions : 여러 user들의 거래 내용을 포함하는 내용입니다. 이 안에도 Block 생성자를 위한 보상이 포함됩니다. 보상이 없다면, 해당 transaction의 우선순위는 낮을 수밖에 없습니다.\n\n![blockchain](/images/blockchain.jpeg)\n\n##### 1-1-3. Coinbase Transaction\n\n기본적으로 모든 Transaction은 이전 Transaction의 Output을 가르키고 있어야 하며, 이것이 자신의 것이라는 증명을 포함해야 합니다. 그렇다면, 의문이 생기는 부분이 있습니다. 모든 Transaction의 끝으로 갔을 때, 과연 기반 Transaction은 어디서 오는가에 대한 고민을 하게 됩니다. 그것이 되는 것이 바로 이 Coinbase Transaction입니다. 이는 이전 Transaction의 Output 없이도 정의할 수 있습니다. 이는 해당 Block을 만들어낸 생성자에게 보상을 제공하는 의미에서 Bitcoin을 제공합니다. 해당 Transaction은 이전 Transaction을 가리키는 값이 모두 0으로 초기화되어있어 쉽게 식별이 가능합니다. 또한, 특이하게도, Coinbase Transaction의 정당성은 Block 자체가 증명하기 때문에, input의 ScriptSig 부분은 무의미한 데이터가 됩니다. 따라서, 여기에는 자신만의 철학을 담은 문구를 사용할 수도 있었습니다. 하지만, 시간이 좀 흐른 후에는 여기에 Block의 height(제일 첫 번째 Block과의 거리)를 표시하는 용도로 사용합니다.\n\n왜 Block을 생성한 사람에게 Bitcoin을 제공하는 것일까요? 이는 이제 앞으로 살펴볼 PoW에서 다루겠습니다.\n\n##### 1-1-4. Header\n\nHeader는 총 6개의 정보를 포함합니다.\n\n1. Version : BIP(Bitcoin Improvement Proposal)이라는 이름으로 여러 개의 Bitcoin 시스템의 향상을 위한 제안들이 존재합니다. 이를 통해서 실제로 Block의 Version이 바뀌기도 합니다. 그런데, 이것이 이전 Version의 Block과 호환이 된다면, 이를 Soft Fork라고 하고, 이전 Version과 호환되지 않는 독립적인 Chain으로 분리되는 것을 Hard Fork라고 부릅니다.\n2. Previous Block : Blockchain이라고 불리는 이유라고 볼 수 있습니다. 이전에 보았던 Transaction 처럼 Block 역시 이전 Block과 연결되어 있습니다. 이를 통해서 모든 거래 장부의 조회가 가능합니다.\n3. Merkle root : 해당 Block이 소유하고 있는 Transaction의 hash값을 기반으로 만든 트리 구조에서 root에 해당하는 값입니다. 이는 후에 Block 내부에 Transaction 여부를 확인하기 위한 도구로 사용합니다.\n4. Timestamp : 해당 Block의 생성 시점을 의미합니다.\n5. Bits : 앞으로 나올 PoW part에서 다루는 내용으로, 이는 특정 작업의 난이도를 표현합니다.\n6. Nonce : 앞으로 나올 PoW part에서 다루는 내용으로, 이는 특정 작업에서 사용하는 변수값에 해당합니다.\n\n##### 1-1-5. Proof of Work(PoW)\n\n이는 Blockchain에서 최초로 만들어진 개념은 아닙니다. 기존에 Spam mail을 막기 위한 수단으로 사용된 적이 있는 기술입니다. 이 기술의 목적은 무분별한 가짜, 사기, 무의미한 데이터가 빈번하게 네트워크 상에서 공유되는 걸 막는 것입니다. 즉, 누군가 악의적으로 Bitcoin 시스템을 마비시키기 위해서, 악의적으로 데이터를 무차별적으로 보내면, Block의 Transaction을 증명하는 데에만 너무 많은 자원을 소모하게 될 수도 있습니다. 따라서, 이를 막기 위해서 만들어진 것이 PoW입니다.\n\n하나의 Block을 만들고, 공유하고, 검증받기 위해서는 반드시 어떤 특정 목표값에 해당하는 값을 찾도록 하여 이러한 무분별한 Block의 생성을 막도록 하는 것입니다. Bitcoin에서는 하나의 Block을 만드는 데 걸리는 시간을 평균 10분이 될 수 있도록 계속해서, 난이도를 수정하는 Algorithm을 갖고 있습니다. (2016 Block 단위로 난이도는 갱신됩니다.)\n\n이제 여기서 궁금할 수 있는 사항이 몇 개 생길 수 있습니다. 이에 대해서 한 번 준비해보았습니다.\n\n1. 어떻게 평균 10분이 걸리는 문제를 낼 수 있는가?  \n    hash 함수 중 hash256(sha-1 라는 hash 함수를 두 번 연속으로 수행하는 방법)을 사용하면, 이를 수행할 수 있습니다. sha 함수는 결과 값으로 나온 데이터의 각 자리가 1을 가질 확률이 1/2이라고 할 수 있습니다. 또한, 역연산을 통해서 찾을 수도 없기 때문에, 연속해서 0이 n개 나오는 값을 찾으라고 했을 때, 무작정 수행을 반복하면서 찾을 수밖에 없습니다. 이를 한 번 수행하는 데 걸리는 시간을 Block에 담긴 timestamp를 기반으로 계산하여 평균상 10분이 나오도록 값을 조정해준다면, 이것이 가능합니다. 이때 우리가 Block header에서 nonce라는 값을 계속해서 바꿔주고, 이를 포함한 Block header를 hash 하여 연속해서 0이 n개 나오도록 하는 nonce값을 찾게 된다면, 이것이 바로 하나의 Block이 되는 것입니다.  \n2. 난이도라는 것은 어떻게 변경되는 것일까?  \n    Computer의 성능은 실시간으로 계속해서 발전하고 있습니다. 그렇기에 Block을 하나 채굴하는데 걸리는 시간은 계속해서 짧아질 것이라고 추측할 수 있지만, Bitcoin 시스템에서는 이 난이도 값을 bits라는 Block의 header를 통해서 통제할 수 있습니다.\n3. Block에 담긴 Transaction은 어디에서 오는가?  \n    Block에 담기는 Transaction은 모두 채굴자(Block을 생성하고자 하는 자)가 송금한 기록이 아닌 주변 node들로부터 전달받은 Transaction이 대부분입니다. 채굴자는 이를 Block에 담을 수 있는 양만큼 모아서 Block Header를 작성한 후, nonce라는 값을 찾아 떠나는 것입니다. 이때 Block에 담기는 Transaction의 우선순위는 Block을 만드는 이에게 달려 있습니다.\n4. Block을 왜 만들어주는가?  \n    아까도 말했듯이 Coinbase Transaction은 채굴자(Block을 생성하고자 하는 자)에게 향하는 output을 가집니다. 그렇기에 채굴자는 이를 통해서 Bitcoin을 벌 수 있는 것입니다. 또한, Transaction을 Block에 올리기 위해서, 주변 node들에게 Bitcoin 송금자들이 이를 요청하면서, 수수료 일부를 해당 node에게 가는 output으로 지정하기 때문에, Block을 만든다는 것은 Bitcoin을 버는 것과 같은 행위로 볼 수 있습니다. 또한, 올라갈 Transaction의 우선순위는 이 수수료에 기반하여 생성됩니다.\n5. Block을 중간에 누가 바꿔서 자신의 것이라고, 바꾸면 어떻게 되는가?  \n    최초로 발견한 Block에 대해서 누군가 이것을 자신이 발견했다고, 속이는 것은 의미가 없습니다. 애초에 Block을 도용하는 것은 이것을 통해서 발생하는 수수료를 일부 취하겠다는 것인데, 이는 Block 내부의 Transaction을 바꾸어야 하고, 이를 바꾼다는 것은 header의 merkle root 값을 바꾸는 결과를 초래합니다. 그렇게 되면 당연히 이전의 nonce값이 가지는 효과는 모두 사라지기 때문에, 도용한다는 것 자체가 불가능합니다.\n6. Block의 검증은 어떻게 이루어지는가?  \n    위에서 보았듯이 Block을 만들기 위해서는 앞에서부터 연속해서 0이 n개 나오게 하는 Block의 hash값을 찾아야 합니다. 하지만, 우리가 해당 Block을 받고, 이를 hash 한 후에 비교를 통해서, 이 Block이 적절한지 파악하는 것은 단 한 번의 hash로 가능합니다. 그렇기 때문에, 검증은 매우 쉽지만, 생성은 굉장히 어렵게 되는 것입니다.\n7. nonce field의 크기가 정해져있던데 모든 nonce를 모두 사용했는데도 찾을 수 없다면 어떻게 되나요?  \n    이때에는 coinbase transaction의 값을 살짝 조정합니다. 이를 조정하게 되면, merkle root의 값도 변경되기 때문에, hash를 다시 수행할 수 있습니다.\n8. BlockChain에 동시에 여러 Node가 등록을 하게 되면 어떻게 되는가?  \n    일단 Block을 만들게 되면, 해당 채굴자는 이를 전파합니다. 이것이 올바른지를 파악한 다른 Node들은 이를 자신의 Blockchain에 연결하게 되고, 똑같이 전파하기를 반복합니다. 이렇게 다른 모든 Node들이 해당 Block을 포함하는 Blockchain을 갖게 되면, 해당 Block은 이제 타당하다고 할 수 있습니다. 그렇지만 동시에 여러 Block을 받은 경우에는 해당 Block을 여러 개 모두 병렬로 연결해두고 있다가, 가장 먼저 새로운 Block이 연결된 Block을 채택하고, 나머지 기존 Block은 버리게 됩니다. 그렇기에 Block을 채굴했다고 끝인 게 아니라 완전히 선택되기까지는 완벽하게 Bitcoin을 획득했다고는 볼 수 없습니다. 그렇기에 대개의 경우에는 자신을 포함한 Block이 6개 연결되었을 때, 비로소 해당 Block이 Blockchain에 완벽하게 등록되었다고 보는 것이 일반적입니다.\n\n##### 1-1-6. Genesis Block\n\nBlock 내에서도 최초의 Transaction이 존재하듯이, Block 또한, 최초의 Block이 존재합니다. 이를 우리는 Genesis Block이라고 부르고, 모든 Block의 최상단은 해당 Block이 됩니다. 해당 Block의 Coinbase Transaction의 ScriptSig에는 Bitcoin의 창시자 Satoshi의 동기가 담긴 문구를 포함시켰다.  \n(chancellor on brink of second bailout for banks)\n\n#### 1-2. P2P network\n\n우리가 생각하는 Internet과 게임 산업과 각종 서비스들은 대게 큰 규모의 Server를 가지고 있는 업체가 자신들의 서비스를 해당 Server를 통해서 모든 Client(사용자)들에게 제공하는 형태를 띄고 있습니다. 즉, 소프트웨어 개발자가 소프트웨어를 제공함과 동시에 소프트웨어 사용자가 통신하여 얻을 데이터들도 모두 소프트웨어 개발자가 관리한다는 특징이 있습니다. 이것이 대게 일반적인 형태의 서비스입니다. 하지만, 이와 전혀 다른 구조를 가지고 있는 것이 P2P network입니다. 이는 Peer to Peer의 줄임말로, 각 Client(사용자) 간의 연결을 통해서 Service를 제공한다는 점이 매우 특이한 점입니다. 즉, 개발자는 Software를 만들고, 이를 배포하는 역할만을 하고, Software 끼리의 통신은 Server를 통해서 수행되는 것이 아닌 각 Software끼리 연결되어 하나의 거대한 통신 network를 만드는 형식입니다. 이렇게 만든 네트워크는 Software만 무결하게 만들었다면, 서로가 서로를 검증하고, 주체적으로 판단할 수 있는 환경을 만들어서 더 건전한 네트워크 환경을 만들 수도 있습니다. 기존의 Server 구조에서는 모든 Client의 요청을 Server에서 해결하기 때문에, 부담이 매우 크고, 해킹의 타깃이 되는 등 하나의 시스템에 대한 부하가 굉장히 크다는 단점이 있습니다. 하지만, P2P 구조에서는 이러한 부담을 나눠가지기 때문에 오히려 안전해질 수 있다고 볼 수 있습니다.\n\n그래서, Bitcoin에서는 Block을 공개하기 위한 P2P network를 사용합니다. 중앙에 있는 시스템 없이 개인이 언제든지 모든 Blockchain을 보관하고 있을 수 있고, 이를 이용해서 특정 거래에 대하여 검증을 하는 등의 작업을 수행할 수 있도록 합니다. 그렇기에 서로가 서로를 감시하며, 서로가 보내는 데이터에 대한 100%의 신뢰를 갖지 않고, 직접 검증을 통해서 다시 한 번 확인하도록 하는 것입니다. 이것이 Bitcoin에서 추구하는 탈중앙화 된 거래 관리 방식이라고 할 수 있습니다.\n\n![blockchain-client-server-arch](/images/blockchain-client-server-arch.jpeg)\n\n![blockchain-p2p-arch](/images/blockchain-p2p-arch.jpeg)\n\n#### 1-3. Blockchain Data Types\n\nP2P network를 통해서 Block과 Transaction이 공유가 되기 때문에, Bitcoin 시스템 내에서는 데이터를 다음과 같이 3가지로 나누어 보관합니다.\n\n1. mempool : 승인되지 않은 Transaction을 보관하는 pool입니다. miner들은 이를 Block에 담아서 P2P network로 다시 공유하고, 이를 받은 node는 이를 Blockchain에 연결시켜서 Block을 만들어냅니다.\n2. Blockchain : Block을 하나의 긴 chain의 형태로 보관하는 것입니다. 이는 모든 Bitcoin 거래에 해당하는 가계부(원장)이라고 할 수  있습니다.\n3. UTXO set : 이전에도 살펴보았지만, 우리는 Transaction의 검증을 수행할 때 반드시 해당 Transaction의 사용여부를 확인할 필요가 있습니다. 따라서, 해당 Transaction 중에서 사용되지 않은 Transaction Output을 Blockchain에서부터 추출하여 별도로 저장하는 것입니다. 이를 통해서, 전체 Blockchain을 조회하는 것보다 빠르게 사용하지 않은 Transaction output을 찾을 수 있습니다.\n\n![blockchain-data-type](/images/blockchain-data-type.jpeg)\n\n#### 1-4. Blockchain Node Types\n\nP2P network에서는 여러 개의 node가 존재할 수 있습니다. 어떤 Node에서는 Block 자체를 생성해내는 역할을 할 수도 있고, 어떤 Node에서는 최소한의 Transaction 만을 가지는 경우도 존재합니다. 이에 대해서, 알아보도록 합시다.\n\n1. Full Node\n2. Miner Node\n3. Light Node\n\n#### 1-5. Block 내의 Transaction의 존재 여부\n\nBlock 내의 Transaction의 여부를 파악하기 위해서는 간단히 Block에서 Transaction을 찾아서 조회하는 것이 가장 간편합니다. 하지만, 이것이 불가능한 경우가 있습니다. 바로, 모든 Blockchain을 담을 수가 없는 경우입니다. 2022년 현재를 기점으로 Blockchain의 데이터 사이즈는 400GB를 넘어섰습니다. 이를 Smartphone과 같은 장치에서 모두 보관하는 것은 불가능합니다. 따라서, 이를 좀 더 간소화할 수 있는 방법을 찾는 과정에서 만들어진 것이 Header의 Merkle Root입니다. 이것의 원리를 알기 위해서 Merkle Tree에서부터 알아보아야 합니다.\n\n### 2. Merkle Tree\n\n#### 2-1.  배경\n\nBlockchain의 뭐든 Block을 갖고 있는 것은 어떤 Node에게는 굉장히 큰 부담이 될 수 있습니다. 따라서, 우리가 이를 보관함으로써 하고자 했던 행동으로 관심을 돌린 것입니다. 원래 목적인 Block 내의 Transaction의 존재 여부를 확인하는 것이 목표였기 때문에, 이를 모두 유지할 필요는 없습니다. 그래서, 이에 대한 요약본을 가지는 것이 바로 Merkle Tree입니다.\n\n#### 2-2.  정의\n\nMerkleTree는 Proof of Inclusion(포함 여부를 증명)하기 위해 고안된 data structure(자료구조)입니다. 이름에서부터 느낄 수 있겠지만, 구조는 Tree 형태를 갖고 있습니다. 또한, 이는 두 개의 핵심 개념에 의해서 구현됩니다.\n\n1. Ordered List\n2. Hash Function\n\n구조화하는 방법은 매우 간단합니다.\n\n1. Ordered List를 leaf 노드 갯수로 갖는 complete binary tree(leaf node를 제외하고는 모든 node가 채워져 있으며, 왼쪽에서부터 데이터가 채워지는 형태입니다.)를 만드는 것이 목표이므로, 모든 Ordered List를 포함할 수 있는 leaf node를 가지는 complete binary tree를 생성합니다.\n2. 이제 leaf노드에 각 ordered list의 element들을 hash function을 적용하여, 채워넣습니다.\n3. 이제 각 leaf 노드에서부터 차근차근 위로 올라가면서, tree 구조의 모든 node의 값을 채울 것입니다. 여기서 parent의 값은 left node의 hash 값과 right node의 hash값을 이어 붙여서(더하는 것이 아니라 이어서 붙입니다.) 다시 한번 hash function을 적용하는 식으로 구합니다.\n4. 여기서, 만약 왼쪽 node는 있지만, 오른쪽 node가 없는 경우, 왼쪽 node를 복사하여 오른쪽 node에 붙여 넣습니다.\n5. 이 과정을 반복하면서, root 노드에 있는 값까지 구해냅니다.\n\n이렇게 만들어진 것이 merkle tree입니다. 이 구조가 왜 포함 증명을 하기에 적합한지를 알아보도록 하겠습니다.\n\n![blockchain-merkle-tree-1](/images/blockchain-merkle-tree-1.jpeg)\n\n#### 2-3. **동작원리**\n\n$H\\_6$ 라는 Transaction이 Merkle Tree의 포함되어있는지를 확인하기 위해서 다음과 같은 방식으로 사용될 수 있습니다. Light Node가 Blockchain에서 Transaction의 존재 여부를 확인하고자 할 때 다음과 같은 연산을 수행할 수 있습니다. 먼저, 근처의 Full Node에게 Flag Bit와 Hash 값을 요청하는 것입니다. 그리고, 이를 이용해서, 정말 $H\\_6$가 포함되었는지를 확인할 수 있습니다. Flag Bit와 보낼 Hash 데이터는 다음과 같이 선정됩니다.\n\n1. 먼저 Merkle Tree를 위해서 설명한 대로 제작하고 이를 보관합니다.\n2. 그리고 해당 Transaction Hash 값에 해당하는 Block에서 해당 Transaction Hash를 찾습니다. 아래에서는 노란색입니다.\n3. 그렇다면, 만약 우리가 파란색으로 표시된 데이터만 있다면, 보라색 값을 유추할 수 있다고 할 수 있습니다.\n4. 또한, 우리는 Merkle Root 값을 갖고 있기 때문에, 이를 통해 유추해낸 Merkle Root값과 Merkle Root이 같다면, 해당 Transaction이 해당 Block에 있다는 것은 증명되었다고 할 수 있습니다.\n\n![blockchain-merkle-tree-2](/images/blockchain-merkle-tree-2.jpeg)\n\n따라서, 우리가 가지고 있어야 할 데이터는 우리가 보낸 파란색 hash의 값과 위치를 유추할 수 있는 값만 있으면 됩니다.\n\n따라서, 우리는 다음과 같은 형태로 이 과정을 수행합니다.\n\n![blockchain-merkle-tree-3](/images/blockchain-merkle-tree-3.jpeg)\n\n이제 Flag Bits와 Hashes만을 갖고 있으면, 이제 우리는 이를 역연 산하는 것도 가능합니다.\n\n### 3. BloomFilter\n\n#### 3-1. 배경\n\nBlockchain의 기반은 뿌리 깊은 불신에서부터 시작됩니다. 여기서, 이전에, 내가 가지고 있는 Transaction에 대해서 조회하는 것은 자신의 자산을 노출하는 것이 될 수도 있습니다. 따라서, 자신의 자신을 감추기 위해서 사용하는 것이 Bloom Filter입니다. Bloom Filter는 완벽하게 감추는 것은 아니지만, 다른 데이터와 중첩되도록 하여 쉽게 추측할 수 없도록 하는 데 있습니다.\n\n#### 3-2. 정의\n\nBloom Filter란 데이터를 hash 하고, 이를 Bit field라는 영역으로 나누어 담는 것입니다. 나누어 담은 데이터는 1개의 Bucket이라는 영역에 담기게 됩니다. 이때 Bucket은 하나의 Bit가 될 수도 있고, 여러 개의 Bits가 될 수도 있습니다. 또한, 동일한 Bucket에 담기는 데이터의 양은 평균적으로 \"$ \\text{# of data} \\div \\text{# of bucket} $\"가 됩니다.\n\n여러 개의 Bits를 하나의 Bucket으로 쓰는 경우에는, 다음과 같이 많은 양의 Bucket이 만들어질 수 있습니다.\n\n![blockchain-bloom-filter-1](/images/blockchain-bloom-filter-1.jpeg)\n\n![blockchain-bloom-filter-2](/images/blockchain-bloom-filter-2.jpeg)\n\n#### 3-3. 동작원리\n\n먼저, 데이터를 hash 하여 임의의 값을 생성해냅니다. 그리고 해당 값을 Bit Field의 크기로 modulo 연산(%)을 수행해주어 나온 결과를 넣어주면 됩니다. 만약, Bucket의 크기를 1 이상으로 하고 싶다면, 다른 hash 함수를 수행하거나 다시 한번 연산을 수행하여 만들도록 합니다.\n\n### 4. SegWit\n\n#### 4-1. 배경\n\n먼저 거래의 양이 급격히 증가하면, Block에 담을 수 있는 Transaction의 양을 늘리는 것에 대한 토의가 빈번했습니다. 이 상황에서 어떻게 하면 더 효율적인 Transaction의 저장을 할지에 대한 고민이 깊어졌습니다. 또한, Transaction의 ScriptSig Part는 ScriptPubKey와 결합하여 안정적인 결과만 내놓을 수 있으면 되기 때문에, Transaction의 ScriptSig는 하나의 고정된 데이터가 아닌 여러 다른 형태를 가질 수 있었습니다. 또한, 이를 바꾸게 되면, Transaction의 값을 Hash 하여 얻는 Transaction의 ID가 변경되기 때문에, 다른 Transaction으로 여기고 Bug가 발생하기도 하였습니다.\n\n#### 4-2. 정의\n\nSegrete Witness의 줄임말로, Block에서 부터 서명 부분을 분리하는 것을 목표로 만들어졌습니다. 이렇게 하게 되면, 두 가지 장점을 가질 수 있습니다. 바로, 하나의 Block에 더 많은 Transaction을 포함할 수 있을 뿐만 아니라 서명 부분의 코드가 조금씩만 바뀌어도 Transaction ID가 바뀌어 혼란이 발생하는 Transaction Malleability 위협을 차단할 수 있다는 것입니다.\n\n#### 4-3. 동작원리*\n\n바로 기존 ScriptSig 부분을 비워두는 것이 핵심입니다. 이를 통해서, 변화하지 않는 형태로 두고, 이전에 보았던 p2psh의 redeemScript처럼 후에 변환할 수 있는 ScriptSig를 별도로 저장하도록 하는 것입니다.\n\n원리는 Simple 하지만, 여기서 기억해야 될 것은 SegWit가 Soft-fork를 통해서 구현될 수 있다는 점입니다. 즉, 이전에 SegWit를 사용하지 않는 Node들과도 호환이 된다는 점입니다. Soft-fork를 유지하기 위해서, 구조는 더 복잡해지고, 이해할 수 없는 형태가 될 수 있습니다. 하지만, 이것이 Bitcoin 시스템에서 호환성이 큰 문제가 될 수 있다는 것을 보여주는 아주 대표적인 예시이기 때문에 이를 알아두면 좋습니다.\n\n이전 글과 동일하게 구현 사항은 github에 정의해두었습니다.\n\n[🔗 GitHub - euidong/bitcoin](https://github.com/euidong/bitcoin)\n\n## Reference\n\n- [🔗 Programming Bitcoin](https://learning.oreilly.com/library/view/programming-bitcoin/9781492031482/)\n- Tumbnail : Photo by [Icons8 Team](https://unsplash.com/@icons8?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@icons8?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n","slug":"bitcoin-4","date":"2022-03-25 17:59","title":"[Bitcoin] 4. Blockchain","category":"Tech","tags":["BlockChain","Bitcoin"],"desc":"해당 Posting은 Bitcoin이 무엇이고, 이것으로 무엇을 할 수 있는지에 대해서 설명하지 않고 Bitcoin을 구현하는 기술에 대하여 다룹니다. 또한, 책의 모든 내용을 충실히 번역하는 것이 아닌 작성자의 생각이 많이 담겨 있으니 유의 바랍니다.해당 chapter에서는 Blockchain Network 구조에 대한 이해와 실용성을 향상하기 위한 MerkleTree, Bloom Filter, SigWit에 대해서 정리합니다.이전 Chapter에서는 Transaction의 소유 여부를 확인하는 방법에 대해서 자세히 다루었습니다. 거기서 Transaction의 사용 여부를 확인할 때에는 UTXO(Unspent Transaction Output) set이라는 것을 사용한다고 하였습니다. 그렇다면, 이는 어떻게 생성되고, 어떻게 관리되는지를 해당 part에서 한 번 다루어보겠습니다.","thumbnailSrc":"https://euidong.github.io/images/bitcoin.jpg"},{"content":"\n## Intro\n\n점점 다양한 언어들이 생겨나고, 객체 지향에 대한 관심이 시들해지고 있는 환경이라고 생각합니다. 하지만, 그럼에도 불구하고, 여러 시스템에서도 거의 고유 명사로 쓰이고 있기에 객체 지향의 대표적인 디자인 패턴을 익혀두는 것은 필수적이라고 생각해서 제가 봤을 때 가장 빈번하게 사용되는 용어에 대해서 정리를 좀 해보고자 합니다.\n\n해당 글에서는 일단 introduction에 대한 내용을 정리합니다.\n\n## Design Pattern\n\nsoftware적으로 특정 상황에서 일반적인 문제를 해결하기 위해서 반복되어 사용되는 pattern을 말합니다. 이는 특정 문제를 해결하기 위한 algorithm이 아닌 이런 구조가 더 경험상 안정적인 구조를 이룰 수 있다는 template를 제공하는 것입니다.\n\n이러한 pattern들은 4개의 요소를 가집니다.\n\n1. **Pattern name** : pattern의 실제 이름을 의미합니다.\n2. **Problem** : 언제 해당 pattern을 적용하는지를 표기합니다. 하나의 pattern으로 여러 문제를 해결할 수 있다면, 당연히 list 형태로도 표기합니다.\n3. **Solution** : design을 이루는 요소들과 관계, 역할(책임)을 명시한다. 하나의 문제에 정확하게 대치되는 해결책을 보여주는 것이 아니라 구조를 파악할 수 있는 template를 제공합니다.\n4. **Consequences** : 해당 pattern을 적용하게 되었을 때 얻게 되는 결과로, 대게 유연하게 확장이나 재사용을 할 수 있는지에 대한 관점에서 장점과 단점을 표기합니다.\n\n이 책에서 말하는 design pattern들이 추가하는 가장 큰 목표는\n\nObject Oriented Programming을 100% 활용할 수 있는 방법을 찾는 것입니다.\n\n<mark>**이는 Maintainable 하기 위해서, 가독성이 높고 유연하며, 재사용이 좋은 system을 구축하기 위한 방법을 찾는 것이라는 말과 같습니다.**</mark>\n\n이를 항상 머릿속에 두고, 이어 나갑시다.\n\n### Example) MVC\n\ndesign pattern에 대하여 이해를 돕기 위한 예시입니다. 만약, MVC 자체가 생소하다면, 넘어가는 것이 좋습니다.\n\n가장 일반적으로 UI 작업을 하게 될 때 많이 사용되는 design pattern입니다. 이를 구성하는 Model / View / Controller의 앞 글자를 하나씩 가져와서 이를 지은 것입니다.\n\n여기서, Model은 application의 data를 표현하는 객체입니다.  \nView는 model을 user들에게 보여주는 방법을 정의한 객체입니다.  \nController는 user input에 대하여 model 또는 view를 어떻게 변경할지를 정의한 객체입니다.\n\n여기서, 흔히 사용되는 design pattern 3가지를 발견할 수 있습니다.\n\n> **1. Observer pattern**\n\n이는 model과 view를 분리하고, subscribe/notify 형태를 갖게 한 구조입니다.(view는 model의 변경이라는 event를 구독하고 있고, model은 자신이 변경되면, view에게 이를 알려서, view가 변경될 수 있도록 한다.)\n\n이렇게 분리함으로써 얻는 효과는 우리는 하나의 model에 대해서 여러 개의 view를 가질 수 있다는 점이다. 또한, 새로운 view를 추가할 때에도 model을 변경하지 않아도 됨으로 쉽게 확장이 가능하다.\n\n> **2. Composite pattern**\n\nView는 중첩해서 사용이 가능하다. 즉, View안에 View를 중첩해서 쌓음으로써 재사용을 수행하는 것이다.\n\n> **3. Strategy pattern**\n\nView는 user input을 받는 장치(button) 등을 포함하고 있고, Controller instance를 포함하고 있기 때문에, 해당 instance를 교체함으로써 쉽게 동작을 변경하는 것도 가능하다.\n\n### Type\n\n해당 책에서는 총 23가지의 design pattern을 제시합니다. 그들을 분류하는 체계를 어느 정도 나눈다면 쉽게 이해가 가능할 겁니다.\n\n> **1. Purpose**\n\n실제로 해당 pattern이 하고자 하는 바를 나타냅니다. 총 3 가지의 목적으로 design pattern을 나눈 것이 가능합니다.\n\n1. **Creational** : object의 생성 시에 특정 부분을 자식 class 또는 다른 object로 옮기는 방법을 제공합니다.\n2. **Structural** : class 또는 object를 구조화하는 방법을 제공합니다.\n3. **Behavioral** : class 또는 object가 특정 행동을 구현하기 위한 각 요소의 관계를 정의합니다.\n\n> **2. Scope** : 구현이 기본적으로 class 단위인지, object 단위 인지를 나타냅니다.\n\n1. **Class** : class들과 subclass들 간의 관계를 다루기 때문에, 상속에 의해서 정의되며, compile time에 고정되어서 바뀌지 않습니다.\n2. **Object** : object들 간의 관계를 의미하며, run time에 유동적으로 바뀔 수 있습니다.\n\n![design-pattern-category](/images/design-pattern-category.jpeg)\n\n### Basic Skill\n\ndesign pattern이 해결하기 위해서 사용하는 일반적인 기술들을 먼저 이해하면, 이를 조합해서 우리는 design pattern을 구성할 것이므로, 이 일반적인 기술부터 알아보고 가도록 합시다.\n\n#### <mark>Object Oriented Programming</mark>\n\n이 책의 가장 기본이 되는 객체 지향에 대한  내용입니다. 이를 읽고 아래를 읽으시는 것이 이해가 더 쉬울 것입니다. 이미 알고 있다면, 바로 다음부터 읽으시면 될 거 같습니다.\n\n일반적으로 object oriented program에서 <mark>object</mark>란 data와 해당 데이터를 조작하는 여러 operation를 묶은 것을 말합니다. 이때, 우리는 해당 object 안의 data를 직접적으로는 접근할 수 없고, object에게 operation의 동작을 요청함으로써 output으로써 data를 얻거나 변경할 수 있습니다. 이를 우리는 encapsulated 되었다고 합니다.\n\nobject에 의해서 선언된 모든 operation은 이름과 input parameter, output value를 명시한 signature를 가집니다. 이러한 signature를 모아놓은 것을 해당 object의 <mark>interface</mark>라고 합니다. 따라서, interface에 있는 내용을 만족하는 request만이 object로 보내진 다고 할 수 있습니다. 여기서 중요한 것은 interface는 절대로 구현을 포함하지 않습니다. 단지 해당 operation에 대한 이름과 input, output을 알려줄 뿐입니다. 그렇기에 같은 이름이며, 들어가는 데이터, 나오는 데이터는 같지만 전혀 다른 구현을 가지도록 만들 수도 있는 것입니다. 이처럼 run time에 interface를 implementation 한 object 중에서 무엇을 실행시킬지를 선택할 수 있도록 하는 기술을 dynamic binding이라고 합니다. interface가 runtime에 정확하게 어떻게 동작할지 여러 형태를 가지는 것을 우리는 polymorphism이라고 합니다.\n\n이 구조가 가지는 장점은 다음과 같습니다.\n\n> **1. 대체 가능하다.**\n\n\"우리가 글을 쓰기 위해서는 반드시 연필이 필요하다.\"는 규칙을 정했다면,\n\n우리는 샤프나 다른 볼펜이 있더라도 이 규칙에 어긋나므로 우리는 기존 규칙을 다시 바꾸거나 연필을 가져와야 할 것입니다.\n\n하지만, 애초에 규칙을 \"우리가 글을 쓰기 위해서는 반드시 검은색을 표시할 수 있는 도구가 필요하다.\"는 규칙을 정했다면, 더 유연한 규칙이 될 수 있습니다.\n\n우리의 코드도 마찬가지로 interface를 통해서 검은색 글자를 쓰는 함수를 정의한 interface로 선언하고 이를 type으로 지정해둔다면, 이를 실행하는 object가 연필, 샤프, 볼펜 무엇이 되어도 되기 때문에 대체 가능한 구조를 가질 수 있는 것입니다.\n\n> **2. 유연하다.**\n\n위의 처럼 규현 할 수 있기 때문에 우리는 유연하게 구조를 만들 수 있습니다. 모든 관계가 느슨하게 연결된다고 SW 업계에서는 자주 표현합니다.\n\n가능한 한 최소한의 기능만을 통해서만 대상을 정의한다면, 더욱더 유연한 구조가 된다고 할 수 있습니다.\n\n> **3. 가독성이 좋다.**\n\n우리는 해당 object를 사용할 때 이것이 어떻게 돌아가는지 모르더라도 사용할 수 있기를 바랍니다. 스마트폰을 가동시키기 위해서 이것의 부팅 절차와 여러 algorithm을 이해하는 것은 우리가 문자를 보내는 과정에서 불필요한 내용입니다. 따라서, 우리는 최대한 최소한의 내용만을 알면 됩니다. 가령 \"오른쪽  전원 버튼을 누르면(input) 화면이 켜진다(output)\"는 이러한 내용입니다. 이는 우리가 더 복잡한 문자 메시지 보내기를 쉽게 할 수 있는 토대를 제공합니다.\n\n> **4. 문서화가 용이하다.**\n\n이제 우리가 시스템을 판매하거나 이를 통해서 같이 일해야 하는 경우가 생긴다면, 이에 대한 설명서가 필요합니다. 만약, 여러 방식으로 구현을 해두었다면, 통일성 있는 문서를 기대할 수는 없습니다. 하지만, interface를 통해서 구현했다면, 이 interface가 요구하는 동작만을 정확하게 적어둔다면, 쉽게 이해할 수 있고 구조화된 문서를 만들기가 용이합니다.\n\n그렇다면, 실제로 programming에서 이 interface와 object를 구현하는지를 살펴보아야 합니다.\n\n대게의 언어에서는 interface, abstract class라는 것을 포함합니다. 이들을 각 각 이들을 구현 또는 상속할 대상들이 반드시 가져야 할 요소(name, input parameter, return value)에 대한 내용을 기술합니다.\n\n그러면 우리는 class를 통해서 이에 대한 구현을 수행합니다. 따라서, 우리는 하나의 interface에 대하여 여러 개의 구현을 가지게 됩니다. (이를 구현을 defer(미루었다)고 표현합니다.) 그리고, 이제 실제로 만들어지는 object들을 우리는 class를 <mark>instantiating</mark>(틀을 기반으로 복사)하여 생성하는데 이때 만들어진 대상을 우리는 특별히 <mark>instance</mark>라고 합니다.\n\n또한, class를 선언한다는 것은 우리에게 두 가지 효과를 불러옵니다. class라는 instantiating 하기 위한 틀을 만들 뿐만 아니라 <mark>type</mark>을 생성합니다. 즉 우리가 일반적으로 instance를 만들기 위해서 다음과 같은 과정을 거치게 될 때 앞에 있는 Class는 class의 type을 의미하는 것이고, 뒤에 있는 것은 instance를 만들기 위한 틀을 의미합니다.\n\n```c++\nSimpleClass sc = new SimpleClass();\n```\n\n그렇습니다. 만약 우리가 class를 interface의 구현으로 만든 것이 아니라면, interface type을 만들면서, class 틀까지 같이 만든 것으로 이해할 수 있는 것입니다. 하지만, interface와 다른 점이라면, 이를 상속하게 되면, 이 안의 구현도 같이 subclass로 전달된다는 점이 있겠습니다. 따라서, 우리가 더 유연한 시스템을 만들고자 한다면, 당연히 일반 class를 통해서 만들어지는 type를 사용하기보다는 abstract class 또는 interface를 통해서 만들어지는 type을 활용하는 것이 더 유연하고, reusable 한 구조를 만드는 핵심이 될 수 있습니다.\n\n마지막으로 다룰 내용은 class의 구성 방식입니다.\n\n만약, 특정 시스템이 무언가를 구현한다고 했을 때, \"A는 B다\"를 통해서 구현하는 것이 좋을까 아니면, \"A는 B를 갖고 있다\"를 통해서 구현하는 것이 좋을 가입니다.\n\n일반적으로 우리는 상속을 통해서 표현되는 관계를 \"inheritance\" 또는 \"is a\" 관계라고 합니다. 즉, A가 B라는 클래스를 상속한다면, A는 B이다.라고 말할 수 있습니다. 왜냐하면, B를 상속하는 A는 당연히 B의 하위 관계이기 때문입니다. (ex. 코끼리는 동물이다.) 하지만, 상속이 아닌 변수로서 이를 포함할 때 우리는 이를 \"composition\" 또는 (\"has\" or \"use\") 관계라고 합니다. 즉, A가 B를 갖고 있다로 보는 것입니다. (ex. 코끼리는 동물의 속성을 가진다.)\n\n이 중에서 어떤 식으로 구현하는 것이 유연한 구조를 만들 수 있을지는 자명합니다. 당연히 composition입니다.\n\n이를 알아보기 위해서 구현이 바뀌는 예시를 들어봅시다.\n\n- 만약, 코끼리 중에서 코가 짧은 개체가 발견되어 더 이상 코끼리는 코가 크다는 속성을 쓸 수 없는 경우\n  - inheritance, composition : 둘 다 구현부에서 쉽게 변경이 가능합니다.\n- 코끼리 중에서 외계에 존재하는 종이 발견되어 외계종의 특징을 추가해야 하는 경우\n  - inheritance : 외계 생명체라는 interface를 추가로 상속합니다. 하지만, 이 과정에서 충돌되는 속성들(ex. 겹치는 operation 이름, 서로 반대되는 성질) 등에 의해서 최악의 경우 interface를 수정해야 할 수도 있습니다. 그렇게 되는 경우 이 interface를 구현한 모든 class들 역시 변경이 필요합니다\n  - composition: 해당 외계 생명체라는 속성을 가져와서 필요로 하는 속성만을 확인하고 구현합니다.\n- 코끼리라는 식물이 새로 발견된 경우 => 모두 크게 변경해야 함.\n  - inheritance : 상속을 식물로 변경하고, 식물의 속성에 구현된 것을 새로 정의합니다.\n  - composition : 가지고 있던 변수를 식물로 변경하고, 변수에 의존성이 있던 부분을 직접 바꾸어 구현합니다.\n\n따라서, 대개의 경우 상속은 interface를 직접적으로 구현할 때에만 사용하고, 그 외에 경우에 composition을 통해서 의존성을 형성하는 것을 선호합니다.\n\ncomposition은 해당 관계가 run-time에 생성되는가 아니면, compile-time에 생성되는가에 따라서 두 개로 나뉠 수 있습니다.\n\n만약, class 내부에서 해당 변수를 생성 시부터 소멸 시까지 갖고 있는다면, 이는 <mark>aggregation</mark>(have)로 볼 수 있습니다. (즉, compile time에 관계가 형성됩니다.) 그렇지 않고, run time에 생성되어 잠깐 사용되는 정도의 관계라면, 이는 <mark>acquaintance</mark>(use) 관계로 봅니다.\n\n#### Finding Appropriate Objects\n\n우리가 해결하고자 하는 문제를 위해서 어느 정도까지의 object들이 필요하고, 이를 어떻게 정의할 것인지를 결정하는 것을 도와줄 수도 있습니다.(Composite, Strategy,...)\n\n#### Determining Object Granuality\n\nObject를 무엇으로 결정했다면, 당연히 이 Object의 크기를 어느 정도로 할지에 대한 내용도 필요하게 될 것입니다. 이를 정의하는 design pattern(Facade, FlyWeight,...)도 존재합니다.\n\n#### Specifying Object Interfaces\n\n무엇을 interface에 추가해야 하는지 아니면 포함시켜서는 안 되는지에 대한 내용을 서술한 design pattern(Memento), interface 간의 관계를 표현하는 것(Decorator, Proxy)도 있습니다.\n\n#### Delegation\n\ndelegation은 자신의 operation의 구현을 composition 한 instance에게 맡기는 방식입니다.\n\n![delegation](/images/delegation.jpeg)\n\n보는 바와 같이 자신의 Area라는 함수의 실행을 Rectangle의 Area 함수로 대체함으로써 더 유연한 구조를 만들 수 있습니다. 만약에 Window가 Circle로 바뀐다면 간단히 Circle의 instance를 생성해서 이 instance의 Area를 호출하도록 하면 될 것입니다.\n\n이는 굉장히 유용하고, 유연한 개발이 가능하지만, 다른 instance의 요소를 실행시키니 만큼 run-time 중에 비효율적인 동작을 막을 수는 없습니다. 따라서, 이를 유의하고 사용해야 합니다.\n\n실제로도 State, Strategy pattern에서도 사용됩니다.\n\n## Reference\n\n- Design Patterns: Elements of reusable object oriented software.\n- Thumbnail : Photo by [MagicPattern](https://unsplash.com/es/@magicpattern?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/s/photos/design-pattern?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n","slug":"design-pattern-1","date":"2022-02-20 16:48","title":"[Design Pattern] 1. Intro","category":"Tech","tags":["DesignPattern","OOP"],"desc":"점점 다양한 언어들이 생겨나고, 객체 지향에 대한 관심이 시들해지고 있는 환경이라고 생각합니다. 하지만, 그럼에도 불구하고, 여러 시스템에서도 거의 고유 명사로 쓰이고 있기에 객체 지향의 대표적인 디자인 패턴을 익혀두는 것은 필수적이라고 생각해서 제가 봤을 때 가장 빈번하게 사용되는 용어에 대해서 정리를 좀 해보고자 합니다.해당 글에서는 일단 introduction에 대한 내용을 정리합니다.","thumbnailSrc":"https://euidong.github.io/images/design-pattern.jpg"},{"content":"\n## Intro\n\nobject의 instantiation을 추상화하는 방법입니다.\n\n즉, instance를 만들 때, 어떻게 하면 재사용과 변경에 유용한 구조로 만들 수 있을까에 대한 고민의 결과로 나온 pattern이라고 볼 수 있습니다.\n\n일반적인 순서로는 Abstract Factory, Builder, Factory Method, Prototype, Singleton이지만, 제가 이해하기 쉬운 순서대로 정리하겠습니다.\n\n모든 가정은 App이라는 main class에서 product1과 product2라는 object가 필요하다는 가정하에서 이를 어떻게 얻어오는지에 대해서 살펴보겠습니다.\n\n## Creational Pattern\n\n### <mark>1. Singleton<mark>\n\n![singleton](/images/singleton.jpeg)\n\n가장 먼저 알아볼 것은 Singleton 입니다. 가장 기본이기에 가장 중요한 design pattern 중에 하나라고 생각합니다.\n\n우리가 특정 object가 필요할 때, 해당 대상을 단 하나만 만들어서 이를 전역에서 접근하도록 하여 구현하는 방식을 의미합니다.\n\n당연히 이 방식을 이용하게 되면, zero copy라는 측면에서 효율이 굉장히 좋을 것입니다. 하지만, 이러한 pattern을 남용하게 된다면, 누가 이 product에 접근하고 있는지 그리고 누가 변경했는지 알기 어려워집니다. 따라서, **해당 Singleton에서 중요한 점이라면, 변하지 않는 값만 가지도록 하는 것입니다.**\n\n이를 통해서, 누가 이를 사용하더라도 시스템에는 영향을 안 주면, zero copy로 사용하기 때문에 굉장히 효율상으로도 훌륭하게 사용할 수 있습니다.\n\n하지만, maintainable의 입장에서는 큰 약점이 될 수 있습니다. 하나의 구현을 바꾸게 된다면, 전체 시스템이 어디서 어떻게 영향을 받는지 알 수 없기 때문에 이 점에서는 약점을 가지고 있습니다.\n\n하지만, 우리가 다루는 object에 변화가 필요하고, 능동적인 조작이 필요한 경우에 object 자체로 singleton으로 만드는 것에는 제한이 생깁니다. 따라서, 우리는 object의 instance를 대신해서 생성해주는 factory라는 개념을 사용하게 됩니다. (이들을 singleton으로 만드는 것이 좋습니다.)\n\n이는 저번 챕터 1에서 보았던 delegation을 활용한 것입니다. 자신이 사용하고자 하는 object의 instantiation을 다른 object에게 맡기는 형식입니다. 이를 통해서, 본연에 하고자 하던 행동에 좀 더 집중할 수 있습니다.\n\n---\n\n다음으로 넘어가기 전에, 한 번 더 머릿속에 정리합시다. 지금의 App이 알고 있는 사항은 무엇일까요?\n\n어떤 내용도 추상화를 통해서 감추지 않았기 때문에, 우리는 productA, productB라는 object가 정확하게 무엇인지 알고 있고, 이를 만드는 방법까지도 완벽하게 알고 있는 상태입니다.\n\n### 2. Builder\n\n![builder](/images/builder.jpeg)\n\n가장 쉽게 object의 생성을 맡긴다고 했을 때, 상상할 수 있는 구조입니다. IBuilder라는 interface를 통해서 builder를 묶어줄 수도 있지만, 단순히 각 object(product)에 대한 builder를 생성해줄 수도 있습니다.\n\n**여기서 중요한 개념은 각 product에 대한 전문 생성자를 구축한다는 점입니다.** 내가 만들고자 하는 object에 대해서 이것만을 전문적으로 만들 수 있는 class를 singleton으로 생성함으로써, 쉽게 무언가의 제품을 만들고 싶다면, 이 builder에게 맡기면 되겠다는 식의 발상으로 이어질 수 있습니다.\n\nbuilder는 얻고자 하는 product에 대한 모든 내용을 추상화해버리기 때문에, 내부의 코드가 정교하게 만들어지고 변화가 없다면, 매우 좋게 작동할 수 있습니다. 하지만, product 하나를 여러 object들이 사용한다면, 후에 변경이 매우 어려워질 수 있습니다.\n\n---\n\n자 이번에도 넘어가기 전에, 한 번 더 머릿속에 정리합시다. 지금의 App이 알고 있는 사항은 무엇일까요?\n\n우리는 현재 builder라는 대상에게 object의 생성을 넘겼습니다. 그렇기 때문에 우리는 productA, productB라는 object가 정확하게 무엇인지 알고 있지만, 이를 만드는 방법은 모르는 상태입니다.\n\n### 3. Abstract Factory\n\n![abstractFactory](/images/abstractFactory.jpeg)\n\n이제 그림이 조금 복잡해집니다. 여기서는 좀 더 복잡한 상황을 고려한다는 것을 직감적으로 받아들이시면 됩니다.\n\n이제 우리는 만들고자 하는 object도 어떤 부류 중에 하나다 정도로만 알 수 있습니다. 이 상황에서 우리는 이를 만들고자 하는 object 마저 추상화를 한 것을 볼 수 있습니다.\n\n또한, 우리는 Factory를 Singleton으로 만들어야 한다는 점에도 주목해야 합니다.\n\n결국 모든 생성의 대한 권한은 factory에게 넘어갔고, 필요에 따라서 우리는 특정한 factory를 골라서 사용하면 됩니다. 마찬가지로 product 역시 필요에 따라 골라서 사용하면 됩니다.\n\n하지만, 이 pattern은 굉장히 비싼 pattern이라고 볼 수 있습니다. 후에 지원하고자 하는 product 자체를 하나 더 만든다면, (ProductC) 이를 추가하기 위해서 모든 Factory는 이를 생성할 수 있도록 변경이 되어야 할 것입니다.\n\n---\n\n그럼 이번에는 어떨까요?\n\n우리는 현재 factory라는 대상에게 object의 생성을 넘겼습니다. 또한, product 또한 추상화를 통해서 이것이 무슨 기능을 하는지는 어렴풋하게 알고 있지만, 이것이 정확하게 무엇인지는 모릅니다.(예전에는 정확하게 구두라고 지정했다면, 이번에는 두루 뭉술하게 신발이라고 쓰고 이를 사용하고 있다고 생각하시면 됩니다.) 그렇기 때문에 우리는 productA, productB라는 object가 정확하게 무엇인지도 모르고, 이를 만드는 방법 또한 모르는 상태입니다.\n\n### 4. Prototype\n\n![prototype](/images/prototype.jpeg)\n\nPrototype의 뜻부터 알고 가면 좋습니다. 이는 하나의 type을 대표할 수 있는 전형적인 예, 원래의 형태 정도로 해석할 수 있습니다. 즉, 특정 부류를 설명할 수 있는 전형적인 예에서 부터 확장을 시작한다는 개념으로 받아들이는 것이 좋습니다.\n\n기존의 Interface를 이용하는 방식은 대상이 정확하게 무슨 기능을 할 수 있는지에 대한 엄격한 선언이 있었다면, 해당 방식에서는 다소 느슨하다고 할 수 있습니다. 전형적인 예인 prototype에서부터 시작하여 이를 확장하여 표현한다는 것이 일반적인 견해라고 할 수 있습니다. 따라서, 구현도 Factory에서 Prototype을 가지고 이를 Clone 하여서 instantiating을 수행하거나 이를 확장하여서 또 다른 object를 생성하는 Factory를 구현하는 식으로 확장해나갈 수 있습니다.\n\n그렇기에 Prototype 방식에서는 clone이라는 method가 굉장히 중요합니다. (또한, 이 Prototype은 Singleton이라는 것도 아시겠지요?) 기존의 abstract factory 방식과는 다르게 Factory 자체에서 Prototype을 가지고 있는 것입니다. 그리고, 이를 이용해서 object를 생성한다고 볼 수 있습니다.\n\n이 방식은 과거 해당 책이 나오기 전까지만 해도 다소 비주류로 (물론 지금도 주류는 아닙니다.) 여겨졌었지만, 이제는 immutable이라는 말도 계속해서 사용되고 있고, Modern Java, javascript 등 여러 언어에서도 이 pattern을 기본으로 받아들였습니다.\n\n---\n\n여기서는 어떨까요?\n\n이 또한 factory에게 생성을 맡겼고, product 또한 이를 대표할 수 있는 전형적인 예 정도를 알고 있다고 볼 수 있습니다. 그렇기 때문에 우리는 productA, productB라는 object가 정확하게 무엇인지도 모르고, 이를 만드는 방법 또한 모르는 상태입니다.\n\n### 5. Factory Method\n\n![factoryMethod](/images/factoryMethod.jpeg)\n\n이번에는 조금 다른 구현입니다. 이번에는 생성을 위한 대리자를 두지 않고, 다른 Product를 쓰고 싶다면, App 자체를 새로 작성하자는 흐름입니다. 이렇게 하게 되면, App 자체가 특정 Product와 의존성이 생기게 됩니다. 하지만, 정확하게 Product를 알고 있다는 것은 type 검사에 시간을 낭비하지 않을 수 있다는 뜻이고, 그로 인해 더 빠른 개발이 가능하다는 뜻으로 받아들일 수 있습니다.\n\n이 방법론은 대게 개발 초기에 매우 많이 쓰인다고 합니다. 왜냐하면, 아직 어떤 Product까지 지원할지 모르지만 어느정도의 추상화를 통해서 해당 object가 가져야 할 최소한의 기능을 지정해놓고, 바로 특정 object에 대한 개발을 시작함으로써 해당 시스템의 검증을 빠르게 수행할 수 있는 것입니다. 그리고, 후에 maintain의 시간이 오면, code를 refactoring 하고 위에서 보았던 다른 design pattern을 검토하며 선택하는 시간을 가진다고 볼 수 있습니다.\n\n해당 시스템에 대한 구현은 제 Github에 별도의 Branch를 통해서 구현해두었습니다. 언어는 typescript로 작성하였고, 참고할 수 있으면 좋겠습니다. :)\n\n[🔗 GitHub](https://github.com/euidong/oop-design-pattern/tree/creational-pattern)\n\n## Reference\n\n- Design Patterns: Elements of reusable object oriented software.\n- Thumbnail : Photo by [MagicPattern](https://unsplash.com/es/@magicpattern?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/s/photos/design-pattern?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n","slug":"design-pattern-2","date":"2022-02-22 16:54","title":"[Design Pattern] 2. Creational Pattern","category":"Tech","tags":["DesignPattern","AbstractFactoryPattern","BuilderPattern","Creationalpattern","FactoryMethodPattern","PrototypePattern","SingletonPattern"],"desc":"object의 instantiation을 추상화하는 방법입니다.즉, instance를 만들 때, 어떻게 하면 재사용과 변경에 유용한 구조로 만들 수 있을까에 대한 고민의 결과로 나온 pattern이라고 볼 수 있습니다.일반적인 순서로는 Abstract Factory, Builder, Factory Method, Prototype, Singleton이지만, 제가 이해하기 쉬운 순서대로 정리하겠습니다.모든 가정은 App이라는 main class에서 product1과 product2라는 object가 필요하다는 가정하에서 이를 어떻게 얻어오는지에 대해서 살펴보겠습니다.","thumbnailSrc":"https://euidong.github.io/images/design-pattern.jpg"},{"content":"\n## Intro\n\n앞 서 살펴본 creational pattern이 object의 생성에 대한 방법들을 제공하였다면, 해당 object들의 관계를 어떻게 연결할 것인가에 대한 고민에서 만들어진 pattern이라고 생각하시면 됩니다.\n\n예를 들어서, 외부 라이브러리와 내부 모듈 간의 상호작용이나 이들을 연결하는 방식을 정의하는 것이 일반적으로 가장 많이 사용되는 경우라고 볼 수 있습니다.\n\n## Structural Pattern\n\n### 1. Adapter\n\n![adapter](/images/adapter.jpeg)\n\nobject와 object간의 상호작용을 돕는 가장 기본적인 방법입니다. 제 생각에는 **Converter로** 표현할 수 있을 거 같습니다. 예를 들어, pdf를 필요로 하는 module이 있다고 했을 때, 우리가 가진 것이 이미지밖에 없다면, 우리는 이를 변환해줄 수 있는 converter를 중간에 설치함으로써 이들을 수정해주지 않고, 합칠 수 있을 것입니다. 이러한 방식이 바로 Adapter pattern의 핵심이라고 할 수 있습니다.\n\n일반적인 구현은 adapter라는 class를 변환 결과물의 class의 확장(상속)으로 둡니다. 이렇게 하면, 해당 class의 속성을 모두 가집니다. 여기서 adapter의 생성 시에 변환 전의 class를 전달하여, 내부 구현을 overriding 하는 방식을 취하도록 하는 방법입니다. **즉, adapter 자체가 원하는 제품의 변환 완료 상태라고 보시면 됩니다.**\n\nrefactoring.guru 사이트에서 예시를 든 상황을 봅시다.\n\n원형 구멍에 원기둥을 넣으면서, 원형 구멍보다 반지름이 큰 원기둥은 filtering하는 코드가 있었다고 합시다. 이때, 원기둥이 아닌 직육면체를 넣고 싶다면, 어떻게 해야 할까요? 직육면체를 마치 원기둥처럼 받아들일 수 있도록 직육면체의 밑변의 변의 길이를 통해서 반지름을 생성해내는 로직을 가진 adapter를 만들어내면 될 것입니다.\n\n---\n\n여기서 adapter의 특징을 살펴보고 갑시다.\n\n- 기존의 변환 결과물로 돌아가는 코드를 그대로 사용하는 것이 가능합니다.\n- 대게 data의 변환 시에 많이 사용됩니다. (ex. XML -> JSON)\n- 사실 임시 방편이라고 볼 수도 있습니다. 위에 원형 구멍에 넣을 수 있는 것을 원형기둥으로 제한한 상황에서 직육면체를 넣었다는 것에서부터 가독성이 떨어지고, 복잡도가 높아질 수 있는 것입니다.\n\n### 2. Bridge\n\n> before\n\n![bridge-1](/images/bridge-1.jpeg)\n\n> after\n\n![bridge-2](/images/bridge-1.jpeg)\n\n하나의 class의 크기가 너무 비대해지거나 각 class들 간의 의존성이 높아지는 경우에 이를 두 개의 계층 구조로 나누어 의존성을 제거하면서 개별적으로 개발하는 환경을 만드는 방식입니다.\n\n개발을 진행하다 보면, 하나의 class의 크기가 굉장히 비대해지는  경험을 할 수 밖에 없습니다. 예를 들어서 처음에는 단순히 버튼이라는 class를 만들었었는데, 디자인의 detail을 위한 내용에 의해서 코드가 굉장히 비대해지고, 이를 click 했을 때, hover 했을 때와 같은 로직도 계속해서 추가되면서 class가 비대해지는 것을 볼 수 있습니다. 따라서, 여기서 design 부분을 별도의 class로 분리시키고 이를 기존 button class가 변수로 포함하는 방식이라고 생각할 수 있습니다.\n\n**즉, 여러 구현 method, attribute를 하나의 attribute type으로 통합하고, 이를 interface로 만들어 사용하는 것입니다.** 이렇게 함으로써 좀 더 유연한 구조를 가질 수 있습니다. 사실 우리의 main application이 module을 직접 구현하지 않고, 여타 module을 install하여 사용하는 것도 이와 유사하다고 할 수 있겠습니다.\n\n---\n\n여기서 bridge의 특징을 살펴보고 갑시다.\n\n- 대게 design(css style)/platform(ios, android, web)과 logic을 분리하여 서로간 의존성을 분리할 때, 유용합니다.\n\n### 3. Composite\n\n![composite](/images/composite.jpeg)\n\n**object들을 tree 구조로 만들어**서 마치 하나의 object 인 것처럼 동작시키는 방법입니다. 그렇기에 만들고자 하는 구현 목표 자체가 tree 구조로 표현 가능할 때에만 사용 가능합니다. tree는 자신의 기능을 담는 root와 다른 subtree들로 이루어지며, 이들을 가리키는 pointer를 가진다.(subtree는 없을 수도 있다.)\n\n대게 구현을 위해서, 가장 기반이 되는 기능을 interface type으로 생성하면, leaf처럼 사용될 class와 이를 담을 수 있는 형태의 class로 나누어 구현합니다.\n\n예를 들면, file system을 예로 들 수 있습니다. file system은 크게 file과 folder로 나뉘어집니다. folder는 마치 하나의 subtree가 되는 것이고, file은 하나의 leaf가 되는 것이라고 생각할 수 있습니다. 각 leaf마다 알맞은 구현을 할 수 있고, folder에도 알맞은 구현을 쉽게 구현하는 것이 가능합니다.\n\n---\n\n여기서 composite의 특징을 살펴보고 갑시다.\n\n- 계층으로 이루어지는 복잡한 구조를 쉽게 구조화할 수 있습니다.\n- 새로운 요소를 추가할 때에도, 기존 코드에 영향을 주지 않습니다.\n- 그러나, 억지로 도입하기 위해서, 과도하게 일반화한 구조를 가지게 되면, 이해하기 어려운 구조가 될 수 있습니다. 즉, tree를 구조를 가진다는 것이 명확할 때에만 사용하는 것이 좋습니다.\n\n### <mark>4. Decorator</mark>\n\n![decorator](/images/decorator.jpeg)\n\n**새로운 기능들을 object에 추가하기 위해서 기존 object는 그대로 두고, 새로운 기능을 포함하는 wrapper로 감싸주는 방식입니다.**\n\n만약, 핸드폰 push 알림 기능을 구현해놓았고, 이를 여러 업체에게 배포하였다고 가정합시다. 그런데, 어떤 업체에서는 Facebook 알림, 또 다른 업체에서는 Slack 알림을 추가로 전송하기를 원한다면, 어떻게 해야 할까요? 가장 쉽게 생각 나는 방법은 각 notification 기능을 수행할 수 있는 class를 생성하고, app에서 여러 개를 생성해서 보내는 방법일 것입니다. 하지만, 단 하나의 object만 받을 수 있도록 구현이 되어 있고, 이를 실행시키는 app code를 변경할 수 없다면, 우리는 결국 3 가지의 알림을 하나의 class로 구현하기 위해서, 7개의 class가 필요합니다.\n\n1. push 알림만 있는 class\n2. facebook 알림만 있는 class\n3. slack 알림만 있는 class\n4. push + facebook 알림 class\n5. push + slack 알림 class\n6. slack + facebook 알림 class\n7. push + slack + facebook 알림 class\n\n이러한 구조를 가지는 거는 굉장한 중복 코드를 만들어낼 가능성이 있습니다. 그래서 나온 pattern이 decorator입니다. 기존 object에 새로운 기능을 하는 object를 감싸는 방법입니다. 실행 시에는 밖 or 안부터 실행을 시키면서 진행합니다.\n\n---\n\n여기서는 decorator의 특징을 살펴봅시다.\n\n- 이 역시 기존 코드의 수정이 필요 없습니다.\n- runtime에 쉽게 새로운 구현을 추가하거나 삭제할 수 있습니다.\n- 각 wrapper가 하나의 기능만 하도록 구현하여, responsibility를 하나만 갖도록 할 수 있습니다.\n- 그러나, 때로는 wrapper간 의존성으로 인해 특정 wrapper를 제거할 수 없는 경우가 생길 수도 있습니다.\n\n### 5. Facade\n\n![facade](/images/facade.jpeg)\n\n**간소화된 interface를 복잡한 class 구조(library, framework)에 간단한 interface를 제공하는 pattern입니다.** 즉, third party를 사용할 때, 직접적으로 호출하는 것이 아닌 facade라는 object를 통해서 추상화한 method를 사용하도록 함으로써 실제 시스템과 third party와의 의존성을 줄이는 방식입니다.\n\n---\n\nfacade의 특징은 위에서 말한 바와 같고, 주의사항이 하나 존재합니다.\n\n- facade가 모든 object들의 구현을 아는 a god object가 될 수도 있습니다. 이렇게 되면, 사실상 이를 이용하는 application도 결코 system에 독립적일 수 없습니다.\n\n### 6. Flyweight\n\n> before\n\n![flyweight-before](/images/flyweight-before.jpeg)\n\n> after\n\n![flyweight-after](/images/flyweight-after.jpeg)\n\nobject를 유지하는데 비용을 너무 많이 사용하기 때문에, **일반적으로 사용되는 동일한 부분을 별도로 object에 포함시키지 않고 공유하도록 함으로써 object를 경량화하기 위해서 나온 pattern입니다.**\n\n---\n\nFlyweight의 특징은 다음과 같습니다.\n\n- RAM의 사용량을 줄인다는 것은 그만큼 CPU 사용량이 늘어난다는 것을 의미합니다.\n- 또한, Computer를 위한 설계이니 만큼 사람이 이해하기에 가독성이 떨어질 수 있습니다.\n\n### <mark>7. Proxy</mark>\n\n![proxy](/images/proxy.jpeg)\n\n대체 object를 제공하거나 또 다른 object를 위한 placeholder를 제공하는 pattern이다. original object에 접근을 제어하면서, 요청의 처리 전 후로, 특정 동작을 수행하도록 할 수 있습니다.\n\n가장 많이 사용되는 사례는 당연하게도 Database에 접근하는 로직을 정의하는 API를 만드는 경우를 예로 들 수 있습니다. API server는 사실상 database에 접근하기 이전에 수행해야 할 동작들을 미리 정의하고, 요청이 들어오면 이를 처리하여 client에게 전송하는 방식으로 구현되어 있습니다. 이것이 필요한 이유는 민감정보의 보호와 서비스 데이터를 안전하게 보장하기 위함이라고 할 수 있습니다.\n\n따라서, 해당 object만으로도 사용이 가능하지만, 요구에 따라서, object 접근 전후로 처리가 필요한 경우 proxy pattern을 통해서 구현하는 경우가 많습니다.\n\n---\n\nProxy의 특징은 다음과 같습니다.\n\n- service와 이를 이용하는 client와 독립적으로 구현이 가능합니다.\n- 일반적으로 service에 직접 접근하는 것보다 delay가 발생할 수 밖에 없습니다.\n\n## Reference\n\n중간에 좋은 reference를 찾았기 때문에 여기서부터는 출처가 바뀝니다. 저도 해당 사이트의 도움을 많이 받았기 때문에 해당 사이트 한 번 직접 가보는 것을 추천드립니다.\n\n- Design Patterns: Elements of reusable object oriented software.\n- Refactoring GURU : [https://refactoring.guru/design-patterns/structural-patterns](https://refactoring.guru/design-patterns/structural-patterns)\n- Thumbnail : Photo by [MagicPattern](https://unsplash.com/es/@magicpattern?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/s/photos/design-pattern?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n","slug":"design-pattern-3","date":"2022-03-09 15:12","title":"[Design Pattern] 3. Structural Pattern","category":"Tech","tags":["DesignPattern","AdapterPattern","BridgePattern","CompositePattern","DecoratorPattern","FacadePattern","FlyweightPattern","ProxyPattern"],"desc":"앞 서 살펴본 creational pattern이 object의 생성에 대한 방법들을 제공하였다면, 해당 object들의 관계를 어떻게 연결할 것인가에 대한 고민에서 만들어진 pattern이라고 생각하시면 됩니다.예를 들어서, 외부 라이브러리와 내부 모듈 간의 상호작용이나 이들을 연결하는 방식을 정의하는 것이 일반적으로 가장 많이 사용되는 경우라고 볼 수 있습니다.","thumbnailSrc":"https://euidong.github.io/images/design-pattern.jpg"},{"content":"\n## Intro\n\nAlgorithm과 object 간의 책임 분배에 관한 pattern입니다.\n\n즉, object의 사용 목적에 따라서 method를 정의할 때, 많이 사용되는 구현 pattern을 의미합니다.\n\n## Behavioral Pattern\n\n### 1. Chain of Responsibility(CoR)\n\n![cor](/images/cor.jpeg)\n\n**request를 여러 handler들을 하나의 chain으로 연결한 object에 전달하여 request를 처리하는 방식입니다.** 여기서 각 각의 handler는 스스로 작업을 끝내고 response를 보낼 수도 있고, 이를 다음 handler로 전달할 수도 있으며, 해당 request를 이용해서 side effect를 만들 수도 있다.\n\n이는 대게 request를 처리하는 module을 설계하는 과정에서 많이 사용됩니다. 예를 들어, REST API 를 구현하고자 할 때, 여러 request에서 공통적으로 사용되는 logic을 별도의 middleware라는 것으로 분리하여 구현하고 재활용하는 것을 많이 볼 수 있습니다. (ex. nodeJS express, Go http.Handler, etc...)\n\n---\n\n여기서 CoR의 특징을 살펴보고 갑시다.\n\n- Request의 처리 순서도 제어할 수 있습니다.\n- 각 handler가 하나의 역할만 하도록 하여, 유연성과 가독성을 높일 수 있습니다.(Single Responsibility)\n- 새로운 handler의 추가가 기존 code의 영향을 주지 않습니다. (Open/Close)\n\n### <mark>2. Command</mark>\n\n![command](/images/command.jpeg)\n\n**모든 request를 하나의 queue에 저장하고, 처리자는 queue의 순서에 따라서, request를 처리하는 pattern입니다.** 이러한 방식은 request를 마치 하나의 method paratemer로 받아들이도록 하고, request의 실행을 queue로 관리함으로써, 쉽게 되돌리기 기능도 지원하도록 할 수 있습니다.\n\n쉽게 예를 들면, 식당에서 웨이터는 주문을 받아서, 영수증을 순서에 따라서 order board에 붙이면, 주방장은 이를 보고, 순서에 따라서 요리를 내보내는 형식이라고 보면 되겠습니다.\n\n구현 시에는 Command라는 Interface를 구현하는 각각의 Command class를 작성합니다. 여기서 각 Command는 생성 시에 receiver를 전달받아서, 호출 시에 이를 Receiver에게 전달할 수 있도록 합니다. 그리고, Command Interface를 호출하는 Invoker를 선언해줍니다.\n\n---\n\nCommand의 특징은 다음과 같습니다.\n\n- Command 단위로 class를 구분할 수 있기 때문에 유연성이 높아집니다. (Single Responsibility)\n- 새로운 Command의 추가가 기존 code에 영향을 주지 않습니다. (Open/Close)\n- 되돌리기와 다시 재생 등의 동작의 구현이 쉽습니다.\n\n### 3. Iterator\n\n![iterator](/images/iterator.jpeg)\n**내부의 구현물을 들어내지 않은 상태에서 구성요소를 순환하기 위해 고안된 pattern입니다.**\n\n기본적으로는 iterator는 다음과 같은 요소로 이루어집니다.\n\n1. 현재 자신의 구성요소를 retuern하는 method\n2. 다음 iterator를 반환하는 method\n3. 다음 iterator가 존재하는지를 체크하는 method\n\n해당 object를 통해서 전체 구조를 순환할 수 있도록 하는 방식입니다. 주요 예시는 file 입출력을 예를 들 수 있습니다. 대게 while 문을 통해서 더 이상 읽을 문자가 없을 때까지 line 단위로 받아오며, next를 호출하는 식의 구현을 많이 보았을 것입니다. 이를 사용하는 이유는 두 가지로 들 수 있습니다.\n\n1. object 내의 자세한 구현을 감추기 위해서\n2. 필요에 따라 여러 iterator를 생성하기 위해서\n\n대게 object가 하나 이상의 동일 object를 포함하게 된다면, 이 object를 순환할 수 있는 방법은 여러 가지가 존재하게 됩니다. 예를 들어 tree를 구현했다고 했을 때, 기본적으로 depth first search, breadth first search을 생각할 수 있습니다. 하지만, 상황에 따라서 효율적인 방식이 다르기 때문에, 각기 다른 순환 방식을 지원하는 것이 좋습니다.\n\n---\n\niterator의 특징을 살펴보고 갑시다.\n\n- Iterator 각 각에 필요로 하는 algorithm을 구현할 수 있기 때문에 유연한 구조를 가질 수 있습니다. (Single Responsibility)\n- 새로운 iterator의 추가가 기존 code에 영향을 미치지 않습니다. (Open/Close)\n- object로부터 생성된 각 iterator는 서로 독립적으로 동작할 수 있습니다.\n- 하지만, 해당 구현은 다루고자 하는 데이터의 양이 적은 경우 지나칠 수도 있고, 직접 접근하는 것보다 속도가 느릴 수 밖에 없습니다.\n\n### 4. Mediator\n\n![mediator](/images/mediator.jpeg)\n\nobject 간의 혼란스러운 의존성을 줄이기 위해서 고안된 pattern으로, **object 간의 직접적인 사용을 제한하고, mediator라는 중계자를 통해서만 동작할 수 있도록 하는 pattern**입니다.\n\n---\n\n여기서 adapter의 특징을 살펴보고 갑시다.\n\n- 디양한 object 간의 communication을 추출할 수 있기 때문에, object 본연의 작업에 집중하여 편리하고 유지하기 쉽게 만듭니다. (Single Responsibility)\n- 새로운 mediator를 추가할 때, 기존 code의 변경이 필요 없습니다. (Open/Close)\n- 각 Object 간의 의존성을 제거할 수 있습니다.\n- 개발이 진행될수록 mediator가 전체 시스템을 관리하는 a God Object가 되고, mediator를 사용하는 모든 object가 이에 의존성이 생기게 됩니다.\n\n### 5. Memento\n\n![memento](/images/memento.jpeg)\n\nobject의 상태 변경에 이전 상태가 큰 영향을 미치거나 history에 대한 구현이 필요한 경우 구현할 수 있습니다. **object의 구체적인 구현에 대한 내용을 제외하고, 이전 상태를 저장하고, 필요에 따라 이를 다시 불러와서 사용하는 pattern**입니다.\n\n구현을 하기 위해서는, 본래의 object를 그대로 두고, 필요로 하는 private variables를 포함하는 memento를 구현하여 state를 받을 수 있는 method를 포함하게 해서, 이 memento들만 caretaker라는 object에서 list형태의 history로 저장할 수 있도록 합니다.\n\n---\n\nmemento의 특징은 다음과 같습니다.\n\n- 기존 object의 encapsulation을 유지하면서, 기능을 구현할 수 있습니다.\n- 기존 code를 그대로 유지한 채로 caretaker를 통해서, history logic을 작성할 수 있습니다.\n- 그러나, memento를 유지하기 위한 추가적인 공간이 필요하며, 오래된 데이터 삭제를 위한 원본을 향한 추적이 필요로 됩니다.\n\n### <mark>6. Observer</mark>\n\n![observer](/images/observer.jpeg)\n\n가장 많이 쓰이면서, 중요한 pattern 중에 하나라고 생각합니다. **subscription 로직을 정의하고, subscription을 수행한 모든 object에게 특정 event의 발생을 전달하는 방식입니다.**\n\n즉, object에서 특정 event가 발생하면, 이를 계속해서 broadcasting 하는 방식입니다. 따라서, 이를 구독하고 있는 각 object가 이에 따른 처리를 수행하는 방식입니다.\n\n구현을 하기 위해서는,\n\nCommand Pattern과 굉장히 유사하다고할 수 있습니다. Command Pattern은 Queue에 Command를 차곡차곡 쌓아두고, 이를 사용하기를 원하는 Object가 이를 찾아가는 방식이라면, Observer Pattern은 저장하기보다는 이를 필요로 하는 Object에게 전달하는 방식입니다.\n\n---\n\n여기서 adapter의 특징을 살펴보고 갑시다.\n\n- 새로운 Subscriber, Publisher가 기존 code에 영향을 미치지 않습니다. (Open/Close)\n- 실행 중에 object간의 관계를 생성하는 것이 가능합니다.\n- 그러나, Subscriber 간의 순서를 정의하거나 각 event의 순서를 엄밀히 구현하는 것은 별도의 구현체를 필요로 합니다.\n\n### 7. State\n\n![state](/images/state.jpeg)\n\n**object의 내부 상태가 변화할 때마다 동작을 바꾸도록 하는 pattern입니다.** 마치 object가 이것의 class를 바꾸는 것과 같은 효과를 볼 수 있습니다.\n\n가장 일반적으로 볼 수 있는 예시가 게시글 작성이다. 엄격한 절차를 따르는 글 작성에는 다음 세 가지의 과정을 거치게 됩니다.\n\n1. 제출 전\n2. 제출 완료 (검토 중)\n3. 배포 (업로드 완료)\n\n각 단계마다 사용할 수 있는 method와 각 method의 동작이 달라질 수 있습니다. 이를 별도의 class로 나누지 않고, 하나의 class로 만들면서 state를 포함하도록 함으로써, 이를 내부에서 control 할 수 있도록 하는 pattern입니다.\n\n구현 시에는 각 State를 별도의 Class로 분리하고, 그 내부에서 변경되는 method를 직접 구현하도록 합니다. 따라서, 실제 state를 포함한 원본 class는 이 state에 정의된 method를 호출하도록 할 수 있습니다.\n\n---\n\nstate의 특징을 살펴보고 갑시다.\n\n- 별도의 state를 class로 분리하기 때문에, 유연한 구조를 만들 수 있습니다. (Single Responsibility)\n- 새로운 state의 추가가 기존 code에 영향을 주지 않습니다. (Open/Close)\n\n### 8. Strategy\n\n![strategy](/images/strategy.jpeg)\n\n동일한 method에 대해서 여러 algorithm을 정의하고, 각각을 별도의 class로 나누어 상호 호환이 가능하도록 하는 pattern입니다.\n\n**즉, object의 method 자체를 별도의 interface로 분리하는 방식이라고 이해할 수 있습니다.** 앞서 보았던 state는 context(문맥)에 따라서, 상태가 바뀌지만 Strategy Pattern에서는 행위 자체가 바뀐다고 생각하면 됩니다.\n\n대게 게임에서 쉽게 예시를 생각할 수 있습니다. player의 skill을 interface화 시키고, 해당 동작에 따른 damage와 mp 변화 등을 각 skill마다 직접 계산하여 player object로 전달할 수 있다고 생각하면 쉽습니다.\n\n---\n\nstrategy의 특징을 살펴보고 갑시다.\n\n- 실행 중의 특정 strategy를 선택하여 실행시키는 것이 가능합니다.\n- 각 strategy에 대한 자세한 구현을 감출 수 있습니다.\n- 대게 상속 형태를 대체하여 사용하는 것이 가능합니다.\n- 새로운 strategy의 추가가 기존 code에 영향을 미치지 않습니다. (Open/Close)\n\n### 9. Template Method\n\n![templateMethod](/images/templateMethod.jpeg)\n\n**algorithm의 skeleton을 상위 class에 정의하고, 전체적인 구조는 바꾸지 않으면서 각 단계에 대한 구현을 override 하는 pattern입니다.**\n\n따라서, 전공과목 과제를 하다 보면 교수님들이 skeleton 코드를 준다고 했을 때, 대게 구조만 있고, 각 함수의 내부가 비어 있는 것을 볼 수 있었던 거 같습니다. 따라서, 해당 class를 inherit 하여 구체적인 구현을 하는 식으로 class를 만들면 됩니다.\n\n---\n\ntemplate method의 특징은 다음과 같습니다.\n\n- 구현의 내용을 줄이고, 중복되는 코드의 사용을 줄일 수 있습니다.\n- 그러나, skeleton에 의한 제한으로 불가피하게 code의 변경이 발생할 수 있습니다.\n\n### 10. Visitor\n\n![visitor](/images/visitor.jpeg)\n\n**특정 object에 접근하려는 object에 따라 별도의 algorithm을 적용하는 pattern입니다.**\n\n즉, 사용하고자 하는 object를 하나의 interface로 추상화하고, 각 object는 이를 사용할 client(visitor)를 허용할 것인지 그리고 어떤 algorithm을 수행할 것인지를 정의해둡니다. 사용할 수 있는 예시는 사용할 수 있는 Element의 종류가 매우 다양하며 계속해서 추가될 가능성이 높을 때 사용할 수 있습니다. 그렇지만, Visitor의 추가는 매우 어렵기 때문에 이에 유의해야 합니다.\n\n---\n\n여기서 adapter의 특징을 살펴보고 갑시다.\n\n- 새로운 algorithm의 추가가 기존 code의 변경없이 가능합니다. (Open/Close)\n- 동일한 class 내부에서 동일한 동작을 여러 version으로 정의할 수 있어 유연합니다. (Single Responsibility)\n- 그러나, visitor의 추가는 기존 algorithm의 수정을 불러올 수 있습니다.\n\n## Reference\n\n- Design Patterns: Elements of reusable object oriented software.\n- Refactoring GURU : [https://refactoring.guru/design-patterns/structural-patterns](https://refactoring.guru/design-patterns/structural-patterns)\n- Thumbnail : Photo by [MagicPattern](https://unsplash.com/es/@magicpattern?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/s/photos/design-pattern?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n","slug":"design-pattern-4","date":"2022-03-10 11:22","title":"[Design Pattern] 4. Behavioral Pattern","category":"Tech","tags":["DesignPattern","CommandPattern","CoRPattern","MediatorPattern","MementoPattern","ObserverPattern","StatePattern","StrategyPattern","Template\"MethodPattern\"","VisitorPattern"],"desc":"Algorithm과 object 간의 책임 분배에 관한 pattern입니다.즉, object의 사용 목적에 따라서 method를 정의할 때, 많이 사용되는 구현 pattern을 의미합니다.","thumbnailSrc":"https://euidong.github.io/images/design-pattern.jpg"},{"content":"\n## Intro\n\nDocker Swarm을 docker stack을 이용하여 실행시키게 된다면, 무엇이 생성되는가? 우리는 서비스가 생성되기도 전에 network가 생성되는 것을 볼 수가 있다. container와 container간 그리고, host를 통해 외부 internet환경에 container를 연결 시키는 모든 과정을 알아보자.\n\nDocker를 사용하다보면, host와 통신을 위해 외부로 port를 열어주는 것과 container 간의 통신을 헷갈려 하는 사람들이 생각보다 많은 것 같다. 심지어는 container간 통신을 위해서 localhost로 정보를 주고받을려고 하는 몹쓸 시도를 하는 관경도 몇몇 봐왔다.\n\n따라서, 우리는 한 번 Docker의 network에 대해서 한 번 공부해보는 것이 좋을 것이다.\n\n해당 차시에서는 우선 전체적인 docker network를 설명하는 기본적인 키워드를 알아볼 것이고,\n\n2 차시에서는 주로 사용되는 docker network driver를 알아볼 것이고,\n\n3 차시에서는 libnetwork의 핵심 기능 중 service discovery, load balancing에 대해서 알아보겠다.\n\n## Docker Networking Base\n\n우리가 기억해야 할 것은 CNM, libnetwork, Driver 이렇게 3가지다. 각 각이 무엇인지는 차례차례 알아보자.\n\n### Container Network Model (CNM)\n\ncontainer간의 network를 구현하기 위한 design을 제시한 내용입니다. 따라서, idea일 뿐입니다. 자세한 내용은 하위 링크를 통해서 확인 가능합니다.\n\n[🔗 Github - moby/libnetwork](https://github.com/moby/libnetwork/blob/master/docs/design.md)\n\n하지만, 이를 좀 더 요약해봅시다. 일단 핵심 요소 3가지를 먼저 이해해봅시다.\n\n- **Sandbox** : 고립된 하나의 Network 공간을 의미합니다. 해당 공간에는 ehternet interface나 port 그리고 routing table같은 구현이 포함됩니다.\n- **Endpoints** : Virtual Network를 서로 연결하는 interface의 역할입니다. (veth라고도 불립니다.) CNM에서는 Sandbox 내부에서 이와 Network를 연결하는 역할을 합니다.\n- **Networks** : Virtual Switch로 여기면 됩니다. 이를 통해서 여러 개의 endpoints를 연결할 수 있습니다.\n\n자 이제 이렇게 3개의 네트워크를 정리하면, 이제 Container 내부에 Sandbox가 존재하고, 그 Sandbox 내부의 endpoints를 연결하는 Network를 통해서 결론적으로 Container 간의 연결을 수행하게 됩니다.\n\n![cnm](/images/cnm.jpeg)\n\n### libnetwork\n\n위에서 이야기한 것처럼 CNM은 단순히 idea일 뿐입니다. 이를 구현허여 표준화된 것이 바로 libnetwork라고 생각하면 됩니다. 이는 Go를 이용하여 작성된 open source로 위에서 제시한 링크를 통해서 해당 open source에 접근할 수 있습니다. 위에서 언급한 CNM을 구현하였고, 추가적으로 service discovery, ingress-based container load balancing, network control plane 및 management plane 기능을 구현하였다. 현재에는 docker에서 network 구현에 사용된다.\n\n\\* control & management plane : 직접적으로 network의 흐름을 제어하는 단계로, routing과 같은 제어를 수행한다.\n\n### Drivers\n\n즉, libnetwork가 전체적인 network의 control plane과 management plane 기능을 구현하였다면, driver는 data plane을 구현한다. 즉, 직접적으로 데이터를 전달하는 역할을 수행한다. 이러한 기능들은 docker에서 여러 개의 driver라는 submodule을 통해서 구현하였다. docker pub를 통해서 default보다 나아간 driver 역시 설치가 가능하다. 하지만 기본적으로, host, bridge, overlay, ipvlan, macvlan 등을 포함하고 있다.\n\n여기까지가 docker network에 대한 overview이다. 다음 차시에 계속...\n\n## Reference\n\n- [🔗 Docker Deep Dive](https://www.oreilly.com/library/view/docker-deep-dive/9781800565135/), Nigel Poulton\n- Tumbnail : Photo by [Michael](https://unsplash.com/@michael75?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/s/photos/cargo-ships?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n","slug":"docker-network-1","date":"2021-07-10 21:21","title":"[Docker] Network(1)","category":"Tech","tags":["Docker","Container","Network"],"desc":"Docker Swarm을 docker stack을 이용하여 실행시키게 된다면, 무엇이 생성되는가? 우리는 서비스가 생성되기도 전에 network가 생성되는 것을 볼 수가 있다. container와 container간 그리고, host를 통해 외부 internet환경에 container를 연결 시키는 모든 과정을 알아보자.Docker를 사용하다보면, host와 통신을 위해 외부로 port를 열어주는 것과 container 간의 통신을 헷갈려 하는 사람들이 생각보다 많은 것 같다. 심지어는 container간 통신을 위해서 localhost로 정보를 주고받을려고 하는 몹쓸 시도를 하는 관경도 몇몇 봐왔다.따라서, 우리는 한 번 Docker의 network에 대해서 한 번 공부해보는 것이 좋을 것이다.해당 차시에서는 우선 전체적인 docker network를 설명하는 기본적인 키워드를 알아볼 것이고,2 차시에서는 주로 사용되는 docker network driver를 알아볼 것이고,3 차시에서는 libnetwork의 핵심 기능 중 service discovery, load balancing에 대해서 알아보겠다.","thumbnailSrc":"https://euidong.github.io/images/docker-picture.jpg"},{"content":"\n## Intro\n\n저번 글에 이어서 이번에는 docker network의 driver들에 대한 자세한 내용을 다루겠다.\n\n- bridge networks\n- overlay networks\n- host networking\n- IPVlan networks\n- MacVlan networks\n\n## Bridge Network\n\ncontainer간의 통신을 위해서 필요한 것이 bridge 네트워크이다. 하지만, 여기서 주의해야할 것은 오직, single host에서만 동작한다는 점이다. 즉, 다른 docker host에 존재하는 container와는 연결이 불가능하다.\n\n그렇다면, bridge가 무엇인가? 이는 두 개의 network 장치를 연결하는 L2 switch를 말한다. 즉, container를 연결하는 도구라고 보면 되겠다. 이를 통해서 연결된 container는 해당 container의 모든 port에 접근이 가능해진다.\n\n![docker-bridge-network](/images/docker-bridge-network.png)\n\n위는 `$ docker network ls`를 입력하면 기본적으로 볼 수 있는 내용이다. 위에 세개는 처음부터 끝까지 docker에 존재하는 default network입니다. host는 직접적으로 host에 연결하는 경우의 network이고,(후에 설명합니다.) none은 아무 네트워크에도 연결되지 않아 외부로 어떤 traffic도 보내지 않을 container들이 속하게 된다. 여기서 bridge는 default bridge라고 불리며, network를 설정하지 않고, container를 생성하게 되면 기본적으로 해당 bridge로 연결되게 된다. 이를 통해서 container 간의 연결도 구현하는 것이 가능하다.\n\n하지만, 일반적으로 단일 기기에서 container 간의 연결을 수행할 때에는 bridge를 직접 생성하여 연결하는 것이 일반적이다. (그 이유는 도메인 네임 설정을 자동으로 해준다는 점에서 이점이 있기 때문 -> [🔗 참고](https://docs.docker.com/network/bridge/#differences-between-user-defined-bridges-and-the-default-bridge))\n\n아래는 이를 이용한 간단한 예시이다.\n\n```bash\n# bridge 생성\n$ docker network create -d bridge eui_bridge\n\n# container 생성\n$ docker container run -d --name c1 \\\n  -network eui_bridge \\\n  alpine sleep 1d\n  \n# container2 생성\n$ docker container run -it --name c2 \\\n  -network eui_bridge \\\n  alpine sh\n   \n# ping을 통해 c1과 연결 여부 확인\n$ ping c1\n```\n\n위의 과정을 처음부터 설명하자면,\n\n1. eui\\_bridge라는 network를 bridge로 생성한다.\n2. container에 eui\\_bridge를 연결하고, alpine 이미지를 기반으로 생성한다. 이때 시작 시에 sleep을 하루 동안 시행한다.(sleep 하는 이유는 꺼지지 않게 하기 위함)\n3. 마찬가지로 eui\\_bridge에 연결하고, alpine 이미지로 container를 생성한 후에 shell을 실행시킨다.\n4. c2에서 실행된 shell에서 c1으로 ping을 전송한다. (이때 같은 network bridge끼리는 container name으로 domain이 생성된다.)\n\n참고로 여기서 기억해야할 것이 있다면, bridge는 container간의 연결을 위한 것이고, container의 특정 port를 host와 mapping하고자 할 때에는 `--publish` 를 활용해야 한다.\n\n```bash\n$ docker run -p 5000:80 nginx\n```\n\n이를 통해서 host의 5000번과 container의 80번 port를 연결할 수 있다.\n\n## Overlay Network\n\n위에서 설명한 것이 단일 호스트 내부에서 container 간의 연결이었다면, 여러 host가 존재하는 cluster 환경에서 docker의 container간 통신을 위한 driver가 overlay이다. 현재에는 docker swarm을 통해서 application을 여러 host에서 제공하는 경우에 사용하게 된다.\n\n먼저 원리를 알아보자면, VXLAN을 활용한다는 것이다. 이는 L3 network 상위에서 다른 두 기기 간에 L2 통신을 지원하는 것인데, 이를 통해서 우리는 다른 node간에 존재하는 container 끼리도 통신할 수 있도록 할 수 있다. docker swarm에 의해서 관리되어 L3로 연결된 두 node의 위에서는 VXLAN Tunnel EndPoint(VTEP)이 각 각 존재한다. 이들을 통해서, tunnel이 형성되고 통신이 가능해지는데, 기존에 container에 존재하고 있던 CNM에서 정의한 Sandbox 속에 virtual switch가 생성되고 이와 VTEP이 연결되어 다른 기기에 있는 container간에도 통신이 가능해지는 것이다.\n\n예시를 든다면, docker stack을 통해서 시스템을 구성해본 적이 있다면, container를 생성하는 과정에서 network가 먼저 생성되는 것을 확인할 수 있을 것이다. 이때 생성되는 것이 overlay 네트워크로 이를 통해서 여러 container가 replica가 어느 node에 생길지 확정할 수 없음에도 통신을 자유롭게 하는 것을 볼 수 있다.\n\n## Host Networking\n\n해당 방식은 docker를 한 번이라도 써본 사람이라면 다음 명령어는 익숙할 것이다.\n\n```bash\n$ docker run -p 80:80 nginx\n```\n\nnginx image를 기반으로 container를 실행시키고, container 내부의 80번과 host의 80번 port를 mapping하겠다는 것이다. 이를 통해서 container는 host의 network에 관여하는 것이 가능하다.\n\n하지만, host networking을 이용하게 되면 container 내부에 network stack이 생성되지 않고, 해당 container의 모든 network 설정이 해당 host의 설정에 그대로 mapping되는 것이다. 이를 이용하면 성능상의 이점은 있겠지만, 상당히 설정이 난잡해질 수 있다.\n\n## IPVlan Network\n\nMAC address와 IP adress를 부여하여, 실제 네트워크에 container를 직접 연결하는 방식이다.\n\n장점은 별도의 port forwarding이나 bridge를 사용하지 않으므로 당연히 빠르지만, NIC를 이용하기에 promiscuous mode를 open해야 한다는 단점이 있다. 이는 switch가 데이터를 전송할 대상을 찾지 않고, 연결된 모든 대상에게 보내는 모드로, sniffing에 취약하고 이 때문에 public cloud system에서는 이를 막아 놓기에 사용할 수 없다.\n\n![docker-ip-vlan](/images/docker-ip-vlan.png)\n여기까지 말했을 때, 이해했다면, 이미 설정하는 것을 알아보러 떠나면 될 것이고, 이해하지 못했다면, 아마 쓸 일이 없을 것이니 넘어가시면 될 것이다.\n\n자세한 사항은 공식 페이지를 참고하자.\n\n[🔗 IPvlan networks](https://docs.docker.com/network/ipvlan/)\n\n## MacVlan Network\n\nipvlan과 동일하지만 차이점은 MAC 주소를 할당한다는 점이다. 그 외에는 다를 것이 없다.\n\n[🔗 macvlan networks](https://docs.docker.com/network/macvlan/)\n\n## Reference\n\n- [🔗 Docker Deep Dive](https://www.oreilly.com/library/view/docker-deep-dive/9781800565135/), Nigel Poulton\n","slug":"docker-network-2","date":"2021-07-11 00:04","title":"[Docker] Network(2)","category":"Tech","tags":["Docker","Container","Network"],"desc":"저번 글에 이어서 이번에는 docker network의 driver들에 대한 자세한 내용을 다루겠다.- bridge networks- overlay networks- host networking- IPVlan networks- MacVlan networks","thumbnailSrc":"https://euidong.github.io/images/docker-picture.jpg"},{"content":"\n## Intro\n\n여태까지 docker의 driver를 통한 networking 기술을 알아보았고, 이제 libnetwork로 1/3에서 제시했던 기본 routing과 같은 기능 외에 구현되어 있는 기능들에 대해서 알아봅니다.\n\n- service discovery\n- load balancing\n\n## Service discovery\n\n모든 container들과 swarm의 서비스들이 이름을 통해서 각 각을 찾을 수 있도록 하는 것이다. Docker는 자체적으로 내부의 DNS 서버를 이용하여 이를 수행한다. 과정을 요약하자면 다음과 같다.\n\n1. container가 이름을 통해서 특정 container를 찾아야 함을 인식한다.\n2. 먼저 Local 내부에서 이에 대한 정보를 갖고 있는지를 탐색한다. -> 있다면, 종료\n3. Docker DNS server에 이를 요청하는 query를 전송한다.\n4. Docker DNS server는 모든 container의 name과 network alias(별칭)를 알기 때문에 이를 찾을 수 있다.\n5. 이때, DNS server는 먼저 동일한 network에 해당 container가 존재하는지를 확인한다. -> 없다면, 외부 DNS server로\n6. 존재한다면, 이를 요청을 보낸 resolver에게 전달하고, 이게 다시 container로 전달된다.\n\n## Load balancing\n\ndocker swarm은 기본적인 load balancer를 지원하여, 아래 그림과 같이 구현되어진다.\n\n```bash\n$ docker service create \\\n  --name my-web \\\n  --publish published=8080,target=80 \\\n  --replicas 2 \\\n  nginx\n```\n\n![docker-ingress-network](/images/docker-ingress-network.png)\n\n즉, 어디로 요청을 보낸다고, 할지라도 load balancer는 어디에 해당 서비스가 존재하는지를 파악하고, 이를 전달하는 것이 가능해진다. 따라서, 어느 노드로 요청을 보내더라도 정상적으로 요청이 전달될 수 있는 것이다. 이를 Ingress load balancing이라고 부른다.\n\n만약, 특정 node로 전달된 요청은 해당 node에 있는 container로 전달되기를 바란다면, host모드를 이용하여 진행할 수도 있다.\n\n여기까지가 network에 대한 전반적이 내용입니다.\n\n## Reference\n\n- [🔗 Docker Deep Dive](https://www.oreilly.com/library/view/docker-deep-dive/9781800565135/), Nigel Poulton\n","slug":"docker-network-3","date":"2021-07-11 00:40","title":"[Docker] Network(3)","category":"Tech","tags":["Docker","Container","Network"],"desc":"여태까지 docker의 driver를 통한 networking 기술을 알아보았고, 이제 libnetwork로 1/3에서 제시했던 기본 routing과 같은 기능 외에 구현되어 있는 기능들에 대해서 알아봅니다.- service discovery- load balancing","thumbnailSrc":"https://euidong.github.io/images/docker-picture.jpg"},{"content":"\n## Intro\n\n해당 글은 Linux에서 docker를 동작시킨다는 가정하에 작성하였다. (Window도 대부분 동일하다고 한다.)\n\ndocker는 여러 개의 보안 정책을 포함한다.\n\n이를 크게 누가 관리하느냐에 따라서 두 개의 부류로 나눌 수 있다.\n\n1. OS system (Linux)\n2. Docker\n\n이전 가상화와 반가상화를 비교한 글에서 보았듯이 Container 기술을 결과적으로 반가상화에 해당하며, 이를 위해서 OS의 지원이 필요하다. 따라서, 이를 Linux 자체에서 구현해주는 것이 존재하고, Docker에서 Application 단에서 구현한 부분으로 나뉘어지는 것이다.\n\n먼저, Linux에서 지원하는 각종 security에 대해서 알아봅시다.\n\n## Linux's Security for Docker\n\n전체적인 디테일 사항은 정리하지 않는다. 해당 내용은 간단히 살펴보는 정도이다.\n\n### Namespaces\n\nnamespace는 container 기술에서 매우 핵심적인 위치에 존재한다고 할 수 있다. 이를 통해서, OS를 여러 개로 나누고, 마치 완전히 고립된 형태의 OS처럼 느끼도록 만든다. (키워드는 isolation) 그렇다면 하나의 host 내에서 어떻게 여러 개의 container가 완벽하게 독립되어 있다고 느낄 수 있게 할 수 있을까? 이는 다음과 같은 종류의 namespace를 분리함으로서 가능하다.\n\n- **process ID (pid)** : process는 tree 형태로 이루어지게 된다. 따라서, 하나의 process (즉, PID 1)에 의해서 여러 개의 process가 동작을 시작하는 것이다. 그런데, namespace를 통해서 우리는 여러 개의 완벽하게 독립적인 process tree를 구축하게 된다.\n- **Network (net)** : 각 각의 container마다 network stack을 구현한다. 즉, network interface 부터 시작해서, IP Address, port, routing table 등을 구축하게 되는 것이다.\n- **Filesystem / mount (mnt)** :모든 container가 각자의 root filesystem을 가지고, 다른 모든 container들은 이것에 접근할 수 없다.\n- **Inter process Communication(ipc)** : process간의 통신을 위해서 우리는 shared memory를 사용하게 되는데 이 또한 고립적으로 구현되도록 한다.\n- **User** : 각 container마다 다른 user group을 구축하고 사용할 수 있도록 한다.\n- **Unix Time sharing (uts)** : hostname을 container마다 제공하는 것으로, 이를 통해서 network 상에서 ip가 아닌 hostname으로 접근하는 것이 가능해진다.\n\n즉, 해당 절에서는 이 한 마디를 기억하면 편해집니다. \"하나의 Docker의 container는 namespace들의 집합으로 이루어져있다.\"\n\n### Control Groups(C group)\n\nnamespace가 각 container간의 isolation을 보장한다면, cgroup은 한계를 설정하는 것이 역할이다. container들이 하나의 machine에서 동작한다면 어쩔 수 없이 그들이 사용할 수 있는 총 자원의 양은 한정될 수 밖에 없다. 그리고, 자칫 잘못하면 하나의 container가 너무 많은 자원(CPU, Memory, Storage, ...)을 소모하여 다른 container의 동작을 방해할 수 있다. 이를 막기 위한 것이 바로 cgroup이다. 이를 통해서 우리는 각 container에게 자원을 나누어 할당하는 것이 가능하다.\n\n### Capabilities\n\n어떤 작업을 하더라도, Machine을 root 권한으로 작업을 하는 것은 굉장히 위험하다. 따라서, container에서 application을 동작시키기 위한 최소한의 권한만을 부여하여 사용하는 것이 올바르다. 이를 수행할 수 있도록, 권한을 지정하는 것이 가능하다.\n\n### Mandatory Access Control(MAC) system\n\nMAC은 파일이나 특정 데이터에 대한 접근 제어를 수행하는 것을 의미한데, 이는 AppArmor나 SELinux 등에 의해서 구현되어지는데, 기본적으로 Docker는 container에 AppArmor를 각 container에 적용하여 이를 구현한다. customizing이 가능하지만, 이에 대한 이해를 충분히 하기를 권한다.\n\n### seccomp\n\nseccomp의 filter mode를 활용하면, container에서 발생하는 syscall을 제한하는 것이 가능하다. 이는 MAC 처럼 직접 customizing도 가능하지만 이에 대한 깊은 이해가 뒷받침되어야 한다.\n\n## Docker Engine's Security for Docker\n\n### Secure Swarm Mode\n\n기본적으로 Docker Swarm은 manager와 worker로 구분되어 동작한다. manager는 기본적으로 control plane을 제어하고, 전체 적인 cluster 환경을 구성하며, 작업을 적절하게 전달한다. 그리고, 전체적인 application code를 동작시키는 것이 worker들이 수행하는 역할이다. 기본적으로 manager와 worker들은 모두 다른 Node이다. 따라서, 이들간의 통신을 수행할 때에 인증과 같은 작업을 필수적이다. 따라서, Docker Swarm에서는 이를 지원하기 위해서 manager로 임명된 node를 CA로 하여 TLS 인증을 수행한다. 이를 통해서, 서로를 인증하고, 전송 데이터 암호화를 수행한다.  \n  \n\\* control plane vs data plane : 통신을 일상에서의 교통흐름이라고 본다면, control plane은 신호등과 같은 규칙을 의미하고, data plane은 실제로 이동하는 차량들로 비유할 수 있다. 즉, control plane은 cluster 환경에서의 제어를 위한 데이터이고, data plane은 실제로 주고 받는 데이터라고 볼 수 있다.\n\n### Image Scanning\n\nDocker는 이미지에서 보안상의 취약점 여부를 scan하는 기능을 기본적으로 탑재하고 있다. 이를 통해서, 이미지가 가진 취약점 등을 파악하는 것이 가능하다.\n\n### Docker Content Trust\n\nDocker는 download 또는 실행할 이미지의 제공자를 식별하고 무결성을 쉽게 체크할 수 있도록 하기 위해서 Docker Content Trust를 제공한다. registry에 이미지를 업로드할 때, 직접 서명이 가능하고, 이를 통해서 특정 사용자에 의해서 생성되었음을 확정할 수 있다. 이렇게 서명이 존재해야만 pull이 가능하도록 설정하는 것 역시 가능하다.\n\n### Docker Secrets\n\nDocker에서 보안 정보를 안전하게 보관하기 위해서 고안된 것으로, 특정 타겟에서 안전하게 SSH key와 같은 정보를 안전하게 전달하는 것 이 가능합니다.\n\n## Reference\n\n- [🔗 Docker Deep Dive](https://www.oreilly.com/library/view/docker-deep-dive/9781800565135/), Nigel Poulton\n","slug":"docker-security","date":"2021-07-10 19:52","title":"[Docker] Security","category":"Tech","tags":["Docker","Container","Security"],"desc":"해당 글은 Linux에서 docker를 동작시킨다는 가정하에 작성하였다. (Window도 대부분 동일하다고 한다.)docker는 여러 개의 보안 정책을 포함한다.이를 크게 누가 관리하느냐에 따라서 두 개의 부류로 나눌 수 있다.1. OS system (Linux)2. Docker이전 가상화와 반가상화를 비교한 글에서 보았듯이 Container 기술을 결과적으로 반가상화에 해당하며, 이를 위해서 OS의 지원이 필요하다. 따라서, 이를 Linux 자체에서 구현해주는 것이 존재하고, Docker에서 Application 단에서 구현한 부분으로 나뉘어지는 것이다.먼저, Linux에서 지원하는 각종 security에 대해서 알아봅시다.","thumbnailSrc":"https://euidong.github.io/images/docker-picture.jpg"},{"content":"\n## Intro\n\n`gRPC`와 `Protocol Buffer`라는 것에 대해서 설명한다. `gRPC`는 `Protocol Buffer`를 교환 가능한 형태의 IDL(Interface Definition Language)과 message를 기술하기 위해서 사용한다.\n\n## gRPC\n\n`gRPC`에서 client application은 전혀 다른 machine의 server application에 존재하는 method를 마치 local object로 존재하는 것처럼 직접적으로 호출할 수 있다. 이는 실제로 distributed application(ex. Web 개발에서의 BackEnd, FrontEnd | Micro Service Architecture)과 service들을 제작할 때 굉장히 유용하다. 다른 RPC System과 마찬가지로, `gRPC`는 원격으로 parameter를 제공하여 호출할 수 있는 method와 return type을 기술하여 service를 정의한다. Server 측에서는 interface를 구현하고, 실제로 client의 호출을 처리할 `gRPC` server를 실행시킨다. Client 측에서는, server의 method와 동일한 method를 제공하는 `stub`(`gRPC` client)를 가진다.\n\n![gRPC overview](/images/grpc-overview.jpeg)\n\n`gRPC` client와 server는 다양한 환경(Cloud, Server, Desktop, etc...)에서도 실행이 가능하며, 서로 의사소통이 가능하고, `gRPC`를 지원하는 어떤 언어로도 구현이 가능하다. 즉, Server와 Client에서 어떠한 언어를 사용해도 상관이 없다. 또한, 최신 Google API들을 `gRPC`로도 제공하고 있기 때문에 쉽게 이용이 가능하다.\n\n기본적으로, `gRPC`는 구조화된 데이터의 Serialization을 위한 Google의 Open Source인 `Protocol Buffer`를 사용한다.\n\n`Protocol Buffer`의 데이터의 구조는 `.proto` 로 끝나는 일반적인 텍스트 파일(proto file)에 정의한다. `Protocol Buffer` data는 `message`라는 형태로 작성되며, 각 `message`는 여러 name-value 쌍으로 구성된 `field`들로 구성된 작은 정보 record이다. 아래는 message의 간단한 예제이다.\n\n```proto\nmessage Person {\n  string name = 1;\n  int32 id = 2;\n  bool has_ponycopter = 3;\n}\n```\n\n일단 data 구조를 정의하면, 선호하는 language를 통해 `Protocol Buffer Compiler`(protoc)를 사용해서 data access class들을 생성할 수 있다. 이는 각 field에 대한 간단한 접근자(`name()`, `set_name()`)와 전체 구조를 raw bytes로 serialization/parsing할 수 있는 method를 제공한다. 예를 들어 C++를 선택하였다면, `protoc`은 `Person`이라는 class를 생성할 것이고, 이를 이용해서 `Person`에 대한 message를 얻거나, serialization, 또는 parsing을 수행할 수 있다.\n\n또한, `gRPC` service를 `proto file`에 paramter, return type와 같이 정의할 수 있다.\n\n```proto\n// The greeter service definition\nservice Greeter {\n  // Sends a greeting\n  rpc SayHello (HelloRequest) returns (HelloReply) {}\n}\n\n// The request message containing the user's name.\nmessage HelloRequest {\n  string name = 1;\n}\n\n// The response message containing the greetings\nmessage HelloReply {\n  string message = 1;\n}\n```\n\n`gRPC`는 `protoc`와 특별한 `gRPC` plugin을 사용하여 `proto file`에서 code를 생성한다. 이를 통해, message type들을 얻고, serialization할 수 있는 일반적인 `Protocol Buffer` code와 `gRPC` client 와 server code를 얻을 수 있다.\n\n## Protocol Buffer\n\n`gRPC`를 제대로 활용하기 위해서는 `Protocol Buffer`에 대해서 자세히 알아두어야 하기에 별도의 섹션으로 분리하여 설명한다. `Protocol Buffer`는 구조화된 데이터를 Serialization(구조화된 데이터를 byte형태로 변환하는 과정 또는 이를 통해서 생성된 결과물)하고, 다시 Parsing(Serialization을 통해서 생성된 데이터를 원래의 구조화된 데이터로 변환하는 과정)하는 과정을 언어 중립적(어떤 프로그래밍 언어에서도 사용가능한), 플랫폼 중립적(어떤 플랫폼에서도 사용가능한)으로 확장한 메카니즘이다. **이는 JSON과 유사하지만, 더 작고 더 빠르며, 실제 언어와의 연결을 자동으로 생성해준다.**\n\n`Protocol Buffer`는 다음과 같은 도구의 집합이다.\n\n1. Definition Language(.proto file을 작성하는 언어이다.)\n2. data의 interface, language에 따른 runtime library들, data를 위한 serialization format `Proto Compiler`에 의해 생성된 code\n\n### 핵심 Idea\n\n**`Protocol Buffer`는 megabyte 정도 크기의 구조화된 data를 위한 Serialization format을 제공한다. 이는 단기간의 Network Traffic에서부터 장기간 data 저장에 모두 유리하다. `Protocol Buffer`는 기존 data를 무효화거나 update하는 추가적인 code 작업없이 새로운 정보로 확장되어질 수 있다.** 뿐만 아니라 **하위 호환성(이전 version의 data의 요청에도 대응하는 것)을 유지하는 것이 중요하기 때문에 이들을 장기간 유지한다. `Protocol Buffer`는 새로운 field의 추가/삭제에도 서비스의 중단 없는 환경을 제공한다.**\n\n`Protocol Buffer`들은 구글에서는 굉장히 일반적으로 사용되는 format이다. 이는 대게 광범위한 server간 통신에 사용될 뿐만 아니라 disk에 data를 기록하는데에도 사용되어진다. `Protocol Buffer` message와 service들은 `.proto` 파일에 기술자에 의해 정의되어진다.\n\n`Proto Compiler`는 build time에 `.proto` file에 기반하여 이에 적힌 `Protocol Buffer`를 조작하기 위한 다양한 language의 코드를 생성하기 위해서 실행되어진다. 각각에 생성된 class들은 각 field에 접근하기 위한 간단한 접근자들을 포함하며, serialization과 parsing을 위한 method를 제공한다.\n\n### 장점\n\n`Protocol Buffer`는 구조화된 data를 어떤 언어에서든, 어떤 platform에서든 광범위한 상황에서 serialization/parsing할 필요가 있을 때 굉장히 유용하다. gRPC로 통신도 가능할 뿐만 아니라 이를 위한 data storage도 제공하기 때문이다. 또한 다음과 같은 장점을 포함한다.\n\n1. 적은 data 저장공간\n2. 빠른 parsing\n3. 많은 programming 언어와의 호환성  \n   - C++, C#, Java, Kotlin, Go, Dart, Python, Ruby, Javascript(Node), PHP\n4. 자동으로 생성된 class를 통한 최적화된 기능성\n\n### 한계점\n\n`Protocol Buffer`가 항상 모든 데이터에 대해서 적절한 것은 아니다.\n\n- `Protocol Buffer`는 전체 message들이 memory에 모두 load될 수 있고, object graph보다는 크기가 작다고 가정한다. 따라서, 1~2 megabyte 내외의 크기를 넘어선다면, 여러 개의 copy를 만들게 될 것이고, 이는 memory 사용의 비효율을 초래할 것이다.\n- `Protocol Buffer`가 serialization되었을 때, 동일한 data는 다양한 형태의 binary serialization 형태를 갖는다. 그렇기에 이들을 직접적으로 parsing하기 전까지는 이것이 서로 동일한지 알 수 있는 방법이 없다.\n- Message는 JPEG, PNG와 같은 전용 압축 알고리즘이 존재하지 않는다. (하지만, zip, gzip 등은 가능하다.)\n- `Protocol Buffer` message들은 float 및 다차원 배열을 많이 포함하는 과학 및 공학 용도에서 크기와 속도 면에서는 최대 효율보다 낮은 성능을 보인다. 이러한 요구가 많은 경우에는 overhead를 줄이기 위해서 `FITS` 또는 이와 유사한 방식을 활용해야한다.\n- `Protocol Buffer` Object Oriented Language가 아닌 경우(Fortran, IDL) 지원이 어렵다.\n- `Protocol Buffer` message들은 자체적으로 data를 정의할 수는 없고, 사용자에 의해서 정의된 schema에 기반한다. 따라서, data에 상응하는 `.proto` file이 없다면, 이를 완벽하게 해석하는 것은 불가능하다.\n- `Protocol Buffer`는 여러 organization의 표준은 아니다. 따라서, 일반적인 사용 환경에서는 적절하지 않을 수 있다.\n\n### 작동 방식\n\n1. data 구조를 정의하기 위해서 `.proto` file을 생성한다.\n2. `.proto` file을 기반으로 `protoc`는 code를 생성한다.\n3. 생성된 code와 project code를 같이 compile한다.\n4. 이를 통해서 생성되는 `Procotol Buffer` class들을 활용하여 serialization, 공유 및 parsing이 가능하다.\n\n`Protocol Buffer` class들은 다양한 method를 포함한다. 예를 들어, 특정 데이터를 stream, file로 부터 받아오거나 개별적으로 value를 추출하거나 해당 데이터가 존재하는지 확인하거나 다시 serialization하여 stream 또는 file로 만드는 과정이 가능하다.\n\n### Definition Syntax\n\n`.proto` file을 정의할 때, 먼저 optionality를 설정한다. 이는 `optional` 또는 `repeated` 또는 `singular` 중에 하나를 선택할 수 있다. (v2에는 `required`도 존재하지만 이를 사용하는 것을 좋지 않은 pattern으로 여긴다.)\n\n위의 사항을 정한 후에는 data type을 기술해야 한다. `Protocol Buffer`는 보편적으로 사용되어지는 data type(Integer, Boolean, Float)을 제공한다.\n\nfield는 아래와 같은 것도 포함한다.\n\n- `message` : data의 설정을 반복하는 경우 이를 사용할 수 있다.\n- `enum` : 해당 type의 종류를 value들의 집합으로 표현할 수 있다.\n- `oneof` : message가 여러 optional field를 포함할 때, 단 하나의 field만 가지도록 할 수 있다.\n- `map` : key-value 형태로 기술할 수 있다.\n\noptionality와 field type을 설정한 후에, field number를 할당해야 한다. 이는 다른 목적으로 사용하거나 재사용되어서는 안된다. 특정 field를 제거했다면, 이 숫자를 재사용하지 않도록 반드시 유의해야 한다.\n\n### 추가적인 Data Type\n\n`Protocol Buffer`는 다양한 scalar value type을 제공한다. 또한, 자신만의 합성 data type을 message를 정의함으로써 생성할 수 있다. 또한 보편적으로 사용되어지는 다음과 같은 type들도 추가적으로 정의되어있다.\n\n- `Duration` : 시간을 의미한다. (ex. 42s)\n- `Timestamp` : 시각을 의미한다. (ex. 2017-01-15T01:30:15.01Z)\n- `Interval` : 시간 사이 거리를 의미한다. (ex. 2017-01-15T01:30:15.01Z - 2017-01-16T02:30:15.01Z)\n- `Date` : 달력에서의 전체 날짜를 의미한다. (ex. 2025-09-19)\n- `DayOfWeek` : 일주일에 요일을 의미한다. (ex. Monday)\n- `TimeOfDay` : 하루에서 시간을 의미한다. (ex. 10:42:23)\n- `LatLng` : 위도와 경도를 의미한다.\n- `Money` : 화폐 단위를 의미한다.\n- `PostalAddress` : 우편주소를 의미한다.\n- `Color` : RGBA color 값을 의미한다.\n- `Month` : 년에 따른 월을 의미한다. (ex. April)\n\n## Outro\n\n현재까지 사용해본 RPC는 ReST API, GraphQL이 있었다. ReST는 워낙 유명하고, JSON, xml기반으로 많이 사용하기 때문에 누구나 알법하다. 그리고, graphQL은 더 유동적인 구현 방식을 제공했기 때문에 Gatsby와 같은 platform이나 Github에서도 사용할 정도로 유명해졌다. 앞 서 얘기한 두 개는 BackEnd에서 FrontEnd로 제공하는 시스템에서 주로 이용된다는 것을 이번 기회로 깨달은 것 같다. 그렇기에 좀 더 사람이 이해하기 쉬운 구조로 되어있을 뿐만 아니라 굉장히 친숙하다. 하지만, `gRPC`는 성능 향상에 좀 더 초점을 두었고, `Server`간 통신에 더 방점을 둔 것이라는 것이 와닿았다. 여러 Virtual Machine이 많아지는 가운데에 이들간에 빠른 통신과 각 Machine간의 호환을 위한 여러 기능들에 좀 더 초점을 맞추고 있다는 것을 알게 되었다. 아마 앞으로 `gRPC`를 사용한다면 이러한 용도로 가장 많이 사용할 것 같다. 아마 이래서 주요 사용처가 Network Vender(CISCO, Juniper), CNCF, Netflix 등인 것일 수도 있겠다. 끝으로 이를 이용한 구현을 직접해보아야 더 나은 설명이 가능할 것 같으므로 후에 이에 대해서 더 자세히 다루겠다.\n\n## Reference\n\n- <https://grpc.io/docs/what-is-grpc/introduction/>\n- <https://grpc.io/docs/what-is-grpc/core-concepts/>\n- <https://developers.google.com/protocol-buffers/docs/overview>\n","slug":"grpc","date":"2022-06-12 14:11","title":"gRPC","category":"Tech","tags":["API","RemotePrecedure","gRPC","ProtocolBuffer"],"desc":"gRPC와 Protocol Buffer라는 것에 대해서 설명한다. gRPC는 Protocol Buffer를 교환 가능한 형태의 IDL(Interface Definition Language)과 message를 기술하기 위해서 사용한다.","thumbnailSrc":"https://euidong.github.io/images/grpc-hero.png"}],"Web":[{"content":"\n## Intro\n\n해당 글은 manifest version 3을 기반으로 작성된 글입니다. 혹여 version 2를 이용하셨다면, version 2에서 version 3로 migration 하면서 제가 적어놓은 글이 있으니 그것을 참고 하시기 바랍니다.\n\n[Chrome Extension version migration from V2 to V3](/posts/chrome-extension-migration-v2-to-v3)\n\n## 1. chrome 확장 앱의 구성\n\nchrome extension에서 manifest version이 3이 되어 이를 한 번 정리할 겸,  \nchrome 확장앱을 구성하는 component는 크게 5가지로 나눌 수 있습니다.\n\n1. Background scripts => 대게 event를 등록하는데 사용합니다. (bookmark 등록, message 등과 같은 기능)\n2. Content scripts => 현재 열려 있는 페이지를 기준으로 이들을 바꿀 수 있습니다.\n3. an options page => options page에 의해 제공되는 세부 동작을 usesr가 사용할 수 있도록 합니다.\n4. UI elements => 브라우저 우상단에 존재하는 아이콘 or 클릭 시 열리는 popup, 검색창, contextmenu 등과 관련된 요소를 관리합니다.\n5. various logic files => 추가적으로 사용할 logic 등을 포함하는 것이 가능합니다.\n\n기본적으로 모든 요소는 HTML, CSS, Javascript를 이용해서 구성됩니다. 모든 확장 component가 필요로 되는 것은 아닙니다.\n\n## 2. Manifest 만들기\n\n모든 extension은 반드시 하나의 manifest 파일을 포함합니다. 이는 JSON 형식으로 되어있고, manifest.json이라는 이름으로 저장됩니다.  \n기본 형태는 다음 제시한 내용처럼 구성됩니다. required 부분에는 반드시 들어가야 하는 내용을 포함합니다.  \n또한, app을 구성함에 있어 거의 필수적으로 들어가야 하는 action과 icon과 같은 내용과 설명 등이 포함됩니다.\n\n```json\n{\n  // required\n  \"manifest_version\": 3,\n  \"name\": \"app test\",\n  \"version\": \"0.0.1\",\n\n  // recommended\n  \"action\": {},\n  \"default_locale\": \"ko\",\n  \"description\": \"chrome extension test\",\n  \"icons\": {}\n}\n```\n\n자세한 사항은 하단 링크를 참고해주세요.\n\n[Chrome extension Manifest](https://developer.chrome.com/docs/extensions/mv3/manifest/)\n\n## 3. Background script 구성하기\n\n확장앱은 event에 기반을 둔 크롬 브라우저 환경을 향상 또는 변경 시키기 위한 프로그램이다. event(새로운 page로의 이동, 북마크 삭제, 탭 닫기, 등)는 browser에 의해서 등록되어집니다. 확장앱은 background (service worker) scripts를 이용하여 이러한 event를 모니터링하며, 특정 지시사항을 명시합니다.  \nbackground service worker는 필요에 의해 언제든지 load되고, 사용되지 않으면 unload됩니다.\n\n- 확장앱이 최초로 설치되거나 업데이트 되었을 경우\n- background page가 전송된 event를 들었을 경우\n- 다른 script 또는 extension에서 message를 전송했을 경우\n- 확장앱의 다른 view에서 runtime.getBackgroundPage를 호출한 경우\n\n한번 load되면, service worker는 이것이 action을 수행하는 동안은 종료되지 않습니다. 따라서, service worker는 모든 view 그리고 message port가 닫힐 때까지 unload되지 않습니다.\n\n`view를 여는 것은 service worker를 불러오지는 않지만, 종료되는 것을 막을 수는 있습니다.`\n\n효율적인 background scripts는 event가 발동되기 까지는 정지상태로 존재하고, 이에 응한뒤에 종료된다.\n\n### 등록\n\nservice worker를 등록하기 위해서는 manifest에 이를 명시해주어야 합니다.  \n아래 예제에서는 명시된 background.js 파일이 service_worker들의 main이 됩니다.\n\n```json\n{\n    \"manifest_version\": 3,\n    ...,\n    \"background\": {\n          \"service_worker\": \"background.js\"\n    }\n}\n```\n\n### 구성하기\n\nruntime.onInstalled event를 listen한다면, 확장앱 설치 시에 초기화가 가능합니다. 초기 상태를 정의할 때 이를 사용합니다.  \n아래 예시에서는 event를 등록하는 과정입니다. 여기서 유의해야 할 것은 event의 등록은 page의 시작 시에 동기적으로 모두 설치해주어야 한다는 것입니다. 만약, event가 발생했을 때, event를 등록하는 것과 같은 동작을 하기 위해서는 다른 방식을 이용해야 합니다.\n\n```javascript\nchrome.runtime.onInstalled.addListener(function() {\n  chrome.contextMenus.create({\n    \"id\": \"sampleContextMenu\",\n    \"title\": \"Sample Context Menu\",\n    \"contexts\": [\"selection\"]\n  });\n});\n\n// This will run when a bookmark is created.\nchrome.bookmarks.onCreated.addListener(function() {\n  // do something\n});\n```\n\n추가적으로 요청을 filtering 하거나, trigger를 재등록하는 과정과 같은 내용은 하단 링크를 추가로 참고하기 바랍니다.\n\n[Background pages](https://developer.chrome.com/docs/extensions/mv3/background_pages/)\n\n## 4. Content scripts 만들기\n\ncontents scripts는 web page에서 동작할 내용에 대한 내용을 담습니다. DOM을 사용하여, scripts는 현재 웹 페이지의 세부사항을 조회, 변경 또는 정보를 전달하는 것이 가능합니다.  \ncontens scripts는 확장앱의 message 교환을 통해서 부모 확장앱에 의해 사용되는 chrome API에 접근하는 것이 가능합니다. 또한, URL을 통해서 확장앱의 파일에 접근하여, 이를 사용하는 것이 가능합니다. 기본적으로 i18n, storage, runtime(connect, getURL, id, onMessage, sendMessage, etc...) 과 같은 API에 바로 접근해서 사용하는 것이 가능합니다.\n\n```javascript\n// Code for displaying <extensionDir>/images/myimage.png:\nvar imgURL = chrome.runtime.getURL(\"images/myimage.png\");\ndocument.getElementById(\"someImage\").src = imgURL;\n```\n\n### 고립\n\n다른 확장앱, 또는 page와 충돌을 막기 위해서 기본적으로 content script는 고립됩니다. (browser의 tab간에 서로 독립적인 것처럼)  \n예를 들어, 다음과 같은 코드가 있다고 가정합니다.\n\n```html\n<html>\n  <button id=\"mybutton\">click me</button>\n  <script>\n    var greeting = \"hello, \";\n    var button = document.getElementById(\"mybutton\");\n    button.person_name = \"Bob\";\n    button.addEventListener(\"click\", () =>\n      alert(greeting + button.person_name + \".\")\n    , false);\n  </script>\n</html>\n```\n\n여기에 content scripts를 이용해서 아래 코드를 inject한다면,\n\n```javascript\nvar greeting = \"hola, \";\nvar button = document.getElementById(\"mybutton\");\nbutton.person_name = \"Roberto\";\nbutton.addEventListener(\"click\", () =>\n  alert(greeting + button.person_name + \".\")\n, false);\n```\n\nbutton을 클릭했을 때, 두 개의 alert 창을 만날 수 있습니다.\n\n### Inject scripts\n\ncontent scripts는 3가지의 방법으로 삽입되어질 수 있습니다.\n\n> **1. statically**\n\nmanifest.json 파일에 정적으로 선언하면, 자동적으로 page가 setting될 때 실행됩니다. 이는 \"content\\_scripts\"라는 부분에 정의됩니다. 여기에는 javascript, css 등을 포함할 수 있습니다.\n\n```json\n{\n\"manifest_version\": 3,\n...\n\"content_scripts\": [\n  {\n    \"matches\": [\"http://*.nytimes.com/*\"], // 해당 injection을 수행할 URL을 명시합니다. 필수입력입니다.\n    \"css\": [\"myStyles.css\"], // 추가할 css파일 입니다.\n    \"js\": [\"contentScript.js\"] // 추가할 js파일 입니다.\n  }\n]\n}\n```\n\n> **2. dynamically**\n\n2021.04.01 시점에서는 아직 완전 제공하지는 않는 기능입니다.  \nhost를 알지 못하거나 아는 host로 부터 script가 추가 또는 삭제될 필요가 있는 경우에 사용합니다.\n\n`chrome.scripting.registerContentScript(optionsObject, callback);`\n\nor\n\n`chrome.scripting.unregisterContentScript(idArray, callback);`\n\n> **3. programmatically**\n\n구체적인 상황 또는 event에 대한 반응으로 실행하기 원할 때 사용합니다.  \n이를 수행하기 위해서는, 해당 페이지에 대한 host의 permission이 필요합니다. 이는 확장앱의 host\\_permissions 부분 or 일시적으로 activeTab을 이용해서 승인을 받을 수 있습니다.\n\n```json\n{\n  \"manifest_version\": 3,\n  ...\n  \"permissions\": [\n    \"activeTab\"\n  ]\n}\n```\n\n```javascript\n// 1. 파일 전체를 실행 주입 시키는 방법\nchrome.runtime.onMessage.addListener((message, callback) => {\n  if (message == \"runContentScript\"){\n    chrome.scripting.executeScript({\n      file: 'contentScript.js'\n    });\n  }\n});\n\n// 2. 특정 함수를 주입하는 방법\nfunction injectedFunction(color) {\n  document.body.style.backgroundColor = color;\n}\n\nchrome.runtime.onMessage.addListener((message, callback) => {\n  if (message == \"changeColor\"){\n    chrome.scripting.executeScript({\n      function: injectedFunction,\n      arguments: ['orange']\n    });\n  }\n});\n```\n\n추가적으로 matck 범위를 세부 정의하는 부분과 frame 및 rum time 시점 관련 사항은 아래 링크를 참조해주세요.\n\n[Content scripts](https://developer.chrome.com/docs/extensions/mv3/content_scripts/)\n\n## 5. option Page 만들기\n\n사용자에게 option을 선택할 수 있는 page를 customise하여 제공할 수 있습니다. 이는 chrome 확장앱을 관리할 수 있는 chrome://extensions에서 Detail을 눌렀을 때 보이는 option과 관련된 page입니다.  \n이는 필요에 따라 구현하는 것이 알맞기 때문에 링크만 달아두겠습니다.\n\n[Options](https://developer.chrome.com/docs/extensions/mv3/options/)\n\n## 6. UI elements 만들기\n\n확장앱은 UI 요소를 몇 가지 제공하는 것이 가능합니다. 여기서는 일부만 소개합니다.\n\n### 1. Badge\n\n확장앱의 icon을 결정하거나, 활성화 / 비활성화 등을 구분할 때 사용됩니다. => 상세 내용은 하단 링크 참고  \n여기서는 icon을 설정하는 방법만 적습니다.\n\n```json\n{\n  \"manifest_version\": 3,\n  ...\n  \"icons\": {\n    \"16\": \"extension_icon16.png\", // favicon\n    \"32\": \"extension_icon32.png\", // 관리창 Icon(window에서 가끔 요구함)\n    \"48\": \"extension_icon48.png\", // 관리창 Icon\n    \"128\": \"extension_icon128.png\" // chrome webstore Icon\n  }\n}\n```\n\n### 2. Popup\n\nbrowser 창의 tooltip을 클릭 시에 보여주고 싶은 내용을 명시하는 것이 가능합니다.\n\n```json\n{\n  \"manifest_version\": 3,\n  ...\n  \"browser_action\": {\n    \"default_popup\": \"popup.html\"\n  }\n  ...\n}\n```\n\npopup.html\n\n```html\n<html>\n  <head>\n    <title>Water Popup</title>\n  </head>\n  <body>\n      <img src='./stay_hydrated.png' id='hydrateImage'>\n      <button id='sampleSecond' value='0.1'>Sample Second</button>\n      <button id='15min' value='15'>15 Minutes</button>\n      <button id='30min' value='30'>30 Minutes</button>\n      <button id='cancelAlarm'>Cancel Alarm</button>\n    <script src=\"popup.js\"></script>\n  </body>\n</html>\n```\n\n### 3. Contextmenu\n\n우클릭 시에 나오는 상자에 추가 내용을 추가하는 것이 가능합니다.\n\n```json\n{\n  \"manifest_version\": 3,\n  ...\n  \"permissions\": [\n    \"contextMenus\"\n  ],\n  \"background\": {\n    \"service_worker\": \"background.js\"\n  }\n}\n```\n\n`background.js`\n\n```javascript\nconst kLocales = {\n  'com.au': 'Australia',\n  'com.br': 'Brazil',\n  'ca': 'Canada',\n  'cn': 'China',\n  'fr': 'France',\n  'it': 'Italy',\n  'co.in': 'India',\n  'co.jp': 'Japan',\n  'com.ms': 'Mexico',\n  'ru': 'Russia',\n  'co.za': 'South Africa',\n  'co.uk': 'United Kingdom'\n};\n\nchrome.runtime.onInstalled.addListener(function() {\n  for (let key of Object.keys(kLocales)) {\n    chrome.contextMenus.create({\n      id: key,\n      title: kLocales[key],\n      type: 'normal',\n      contexts: ['selection'],\n    });\n  }\n});\n```\n\n추가적으로, override page, command, 검색창 디자인 등 추가적인 요소를 보려면 아래 링크를 참조해주세요.\n\n[Design the user interface](https://developer.chrome.com/docs/extensions/mv3/user_interface/)\n\n## 7. Boilerplate\n\n만약, react, typescript에 익숙하다면, 필자가 만들어놓은 boilerplate를 추천합니다.\n\n[euidong/chrome-extension-boilerplate](https://github.com/euidong/chrome-extension-boilerplate)\n","slug":"chrome-extension","date":"2021-04-01 17:27","title":"Chrome Extension","category":"Web","tags":["ChromeExtension"],"desc":"해당 글은 manifest version 3을 기반으로 작성된 글입니다. 혹여 version 2를 이용하셨다면, version 2에서 version 3로 migration 하면서 제가 적어놓은 글이 있으니 그것을 참고 하시기 바랍니다.[Chrome Extension version migration from V2 to V3](/posts/chrome-extension-migration-v2-to-v3)","thumbnailSrc":"https://euidong.github.io/images/chrome-extension.jpeg"},{"content":"\n## Intro\n\n최근 3일 정도를 chrome extension version 2에서 version3로 migration하면서 보낸 거 같습니다. ㅠㅠ\n\n현재 side project로 진행하고 있는 내용을 chrome extension store에 배포할려고 하는 순간에 경고창이 뜨며, 이제부터는 version 3만 업로드를 지원한다는 경고를 받았습니다.ㅠㅠㅠㅠㅠ\n\n그래서 이전 셋업을 완전히 뜯어고쳐야 된다는 결론에 도달했고, 이전에 열심히 투닥투닥 만들었던 결과물을 다시 뜯어고쳐야했습니다.\n\n이 내용은 제가 진행하면서 바꾼 내용을 정리한 내용입니다. 저와 같이 version migration을 진행하시는 분들에게 도움이 되었으면 좋겠습니다.\n\n## 1. manifest에서 바뀌어야 하는 부분\n\n위에가 기존 version 2라면 아래가 version 3로 바뀌었을 때의 내용입니다. 일단 용어적인 부분에서 엄청 변경된 것은 없습니다. (하지만, API call이라든지 기타 여러 부분에 관해서는 정책이 매우 강력해진 편입니다. 이는 바로 다음에 살펴봅니다.)\n\n```json\n// manifest.json\n{\n  \"manifest_version\": 2,\n  \"name\": \"chrome-ext-boiler-plate\",\n  \"version\": \"0.0.1\",\n  \"description\": \"This project is chrome extension boiler plate\",\n  \"icons\": {\n    \"16\": \"icon/16.png\",\n    \"32\": \"icon/32.png\",\n    \"48\": \"icon/48.png\",\n    \"128\": \"icon/128.png\"\n  },\n  \"background\": { \"scripts\": [\"background.js\"] },\n  \"content_scripts\": [{ \"matches\": [\"<all_urls>\"], \"js\": [\"content.js\"] }],\n  \"options_page\": \"option.html\",\n  \"browser_action\": { \"default_popup\": \"popup.html\" },\n  \"permissions\": [\"storage\", \"tabs\"],\n  \"content_security_policy\": \" script-src 'self' 'unsafe-eval'; object-src 'self'\"\n}\n```\n\n```json\n// manifest.json\n{\n  \"manifest_version\": 3,\n  \"name\": \"chrome-ext-boiler-plate\",\n  \"version\": \"0.0.1\",\n  \"description\": \"This project is chrome extension boiler plate\",\n  \"icons\": {\n    \"16\": \"icon/16.png\",\n    \"32\": \"icon/32.png\",\n    \"48\": \"icon/48.png\",\n    \"128\": \"icon/128.png\"\n  },\n  \"background\": { \"service_worker\": \"background.js\" },\n  \"content_scripts\": [{ \"matches\": [\"<all_urls>\"], \"js\": [\"content.js\"] }],\n  \"options_page\": \"option.html\",\n  \"permissions\": [\"storage\", \"tabs\"],\n  \"action\": { \"default_popup\": \"popup.html\" }\n}\n```\n\n> **요약**\n\n- manifest\\_version : 2 => 3\n- background.scripts => background.service\\_worker  \n  배열에서 하나의 단일 service\\_worker로 변경되었습니다. 기존에 permanent관련 설정을 하신 분들은 이를 사용할 수 없습니다.\n- browser_action => action  \n  기존에 있던 다른 action과 통합되어 하나의 action이라는 이름으로 명칭이 변경되었습니다. 사실 여기까지는 화가나지 않습니다.\n\n## 2. 보안 설정\n\nversion 3로 올라오면서 보안정책이 정말 강화가 되었습니다.\n\n특히 CORS 부분에서 1차 멘붕을 겪을 수 있습니다.\n\n만약, server에서 기존의 CORS accept를 단순히 \"\\*\"로 설정하였다면, 저처럼 개고생을 할 수 있습니다. 일단, popup에서 요청을 보내는 경우에 저는 \"chrome-extension://\\*\" 로 설정을 직접적으로 해주어야 제대로 통신을 하는 것을 확인할 수 있었습니다. 이거 진짜 너무 힘들게 찾았습니다. ㅠㅠ (서버 단에서 라이브러리 문제인지 아니면, 다른 설정 문제인지는 체크는 안했습니다. ㅎ 여러분도 조심하시기 바랍니다.)\n\n또한, websocket 설정도 굉장히 빡세졌습니다. 기존에는 wss 요청을 보낼 때, INVALID CERTIFICATE를 확인하지 않았기 때문에 인증서 대충 설정하고 진행했었는데, 이제는 background에서 connection 생성 시에 이를 반드시 확인합니다. 따라서, https 생성 하실 때 서명 확실하게 하시고, 설정하시는게 좋을 겁니다. (저는 traefik을 이용하는데 알아서 인증서 발급 해주는 게 너무 편리합니다.)\n\n![chrome-ext-mig-01](/images/chrome-ext-mig-01.png)\n\n## 3. Webpack 설정\n\n요즘 같은 시대에 생 javascript, jQuery로 front를 개발하지 않기 때문에, webpack을 통해서 vue나 react를 사용하실 가능성이 높으실 겁니다. 놀라운 사실은 우리의 webpack이 아무 설정을 해주지 않으면 development mode에서는 build file로 eval이 잔뜩 덕칠되어 있는 코드를 return 합니다.\n\n![chrome-ext-mig-02](/images/chrome-ext-mig-02.png)\n\n그런데, 이번 v3에서는 eval을 사용하는 것을 보안상의 위협으로 체크하고, 개발상황에서도 허용하지 않습니다. (물론 sandbox로 설정해서 할 수 있지만, 이렇게 되면 manifest.json file을 development, production 구분해야하고, 일단 이에 대한 예제를 제가 찾지 못했기 때문에 이를 통한 설정은 저는 포기했습니다. ㅠ) 기존에는  manifest에서 content\\_security\\_policy에서 eval을 허용해주면 끝이였는데, version 3로 바뀌면서 sandbox라는 기능이 추가되면서, 저희를 곤혹스럽게 합니다. 일단 찾기 쉬운 예제로 sandbox에 적용하니 chrome API가 막히거나, http API call이 막히는 등 저를 너무나 힘들게 했습니다. 따라서, 저는 webpack 설정을 만져서 다시 고쳐쓰자는 결론을 내렸고, 검색과 검색과 더 검색을 거친 결과로 webpack.config.js에서 eval을 사용하지 않는 mode를 찾아냈습니다. 그래서 적용한 결과 진짜로 eval이 사라졌고, build 속도도 굉장히 빨랐기에 아주 기분 좋게 설정을 마쳤습니다. 껄껄..\n\n아래는 devtools를 cheap-module-source-map으로 설정했을 때 나오는 결과물입니다. 정말 다행히도 eval이 없습니다.\n\n![chrome-ext-mig-03](/images/chrome-ext-mig-03.png)\n\n마무리하면서, 다 나쁜점만 있었던 것은 아니라는 점을 짚어보고 넘어갑니다. 기존에는 webpack plugin인 webpack-chrome-extension-reloader 를 이용해서 hot reloading을 구현했었는데, version3로 넘어가면서 code가 바뀌면 자동으로 해준다는 것을 확인했습니다. 따라서, webpack --watch 만 설정해줘도 쉽게 reloading이 됩니다. 아마 chrome에서 파일 변환이 생기면 자동으로 reloading 하는 거 같습니다. 따라서 해당 설정은 지워주었습니다.\n\n이렇게 해서 거의 한 3일 정도 골머리를 앓으면서 migration한 내용을 정리해보았습니다. 다른 분들에게도 도움이 되었으면 좋겠네요.\n\n마지막으로 github link입니다. 이거 보고 참고 하시는게 가장 빠를 거 같습니다.\n\n[🔗 GitHub](https://github.com/euidong/chrome-extension-boilerplate)\n","slug":"chrome-extension-migration-v2-to-v3","date":"2022-02-14 21:25","title":"Chrome Extension Migrantion V2에서 V3","category":"Web","tags":["ChromeExtension"],"desc":"최근 3일 정도를 chrome extension version 2에서 version3로 migration하면서 보낸 거 같습니다. ㅠㅠ현재 side project로 진행하고 있는 내용을 chrome extension store에 배포할려고 하는 순간에 경고창이 뜨며, 이제부터는 version 3만 업로드를 지원한다는 경고를 받았습니다.ㅠㅠㅠㅠㅠ그래서 이전 셋업을 완전히 뜯어고쳐야 된다는 결론에 도달했고, 이전에 열심히 투닥투닥 만들었던 결과물을 다시 뜯어고쳐야했습니다.이 내용은 제가 진행하면서 바꾼 내용을 정리한 내용입니다. 저와 같이 version migration을 진행하시는 분들에게 도움이 되었으면 좋겠습니다.","thumbnailSrc":"https://euidong.github.io/images/chrome-extension.jpeg"},{"content":"\n## Intro\n\nBlog를 검색 엔진들에 노출하기 위한 일지를 기록한다.\n\n먼저 내가 원하는 것은 구글, 네이버, 다음에 나의 블로그의 태그, 카테고리, 타이틀로 검색어가 노출이 되는 것이다.\n이를 위해서 무엇을 해야 하는지를 정리한다.\n\n## robots.txt\n\nrobots.txt는 CRA로 React Project를 생성했을 때도, 자동으로 생성해줄만큼 가장 기본적인 요소이다. 이는 가종 검색 엔진의 Posting을 Crawling하는 장치들에게 해당 Posting에 대한 접근 권한을 명시해놓는 곳이다. 따라서, 작성 시에는 간략하게 다음과 같이 표현하는 것이 일반적이다.\n\n```text\nUser-agent: *\nDisallow:\n```\n\n이는 어떠한 검색 엔진 봇의 접근을 허락하며, 모든 하위 uri에 대한 접근을 허락한다는 것이다.\n더 알고 싶다면 공식 문서를 참고하자. <https://www.robotstxt.org/robotstxt.html>\n\n## sitemap.xml\n\n웹 페이지 내의 모든 페이지 목록을 나열한 파일이다. 이는 site에 해당하는 모든 url을 등록하고, 어느곳에 어느 컨텐츠가 존재하는지를 알려주는 mapping table이라고 볼 수 있다. 이를 명시해두어야만 후에 bot들이 작업을 할 때, 조회를 하여 사용할 수 있다. \n\n`next-sitemap`이라는 도구를 이용해서 자동 생성하도록 설정을 해두었다.\n\n이에 대한 설명은 다음 자료들을 확인해보도록 하자.\n\n1. [🔗 next-sitemap](https://www.npmjs.com/package/next-sitemap)\n2. [🔗 현재 블로그 설정](https://github.com/euidong/euidong.github.io/blob/dev/next-sitemap.config.js)\n3. [🔗 현재 블로그의 사이트맵](/sitemap.xml)\n\nNaver에서는 sitemap을 등록해주어야만 정상적으로 수집하는 것을 볼 수 있었는데 구글에서는 바로바로 Crawling하는 것을 확인할 수 있었다.\n\n> **Google Search Console**\n\n![google-search-console-indexing](/images/google-search-console-indexing.png)\n\n> **Naver Search Advisor**\n\n![naver-search-advisor-indexing](/images/naver-search-advisor-indexing.png)\n\n---\n\n## Metadata\n\n결론적으로 말하면, SEO에서 가장 필요한 것이 Metadata의 정리이다. 그 중에서도 가장 핵심이 되는 것이 두 가지이다.\n\n1. **title** : 말 그대로 Posting의 제목이다.\n2. **description** : 말 그대로 Posting에 대한 요약 또는 소개 정도라고 보면 되겠다.\n\n이를 적절히 설정해주면 이를 수집해가는 bot이 쉽게 이를 인식할 수 있고, 검색이 안정적으로 수행되어진다. 이를 위해서 해당 Blog에서는 NextJS를 통해서 **title**를 Posting 제목으로 지정하고, **description**은 본문의 Intro part를 기반으로 작성하도록 설정해두었다.\n\n### Open Graph\n\nMetadata의 항목에 포함되는 OG를 제대로 설정하지 않으면 Naver에서는 이를 제대로 인식하지 않는다고하니 이 또한 제대로 입력해주도록 하자. 테스트 할 때에는 간단하게 Kakaotalk, Facebook 등으로 보내보며 제대로 노출이 되는지를 확인하면 된다.\n\n## Reference\n\n- Tumbnail : Photo by [NASA](https://unsplash.com/@nasa?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/s/photos/website?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n","slug":"seo","date":"2022-04-20 09:00","title":"SEO","category":"Web","tags":["SEO","GoogleSearchEngine","검색어 노출","구글 검색어 노출"],"desc":"Blog를 검색 엔진들에 노출하기 위한 일지를 기록한다.먼저 내가 원하는 것은 구글, 네이버, 다음에 나의 블로그의 태그, 카테고리, 타이틀로 검색어가 노출이 되는 것이다.이를 위해서 무엇을 해야 하는지를 정리한다.","thumbnailSrc":"https://euidong.github.io/images/web.jpg"},{"content":"\n## Intro\n\n해당 포스팅은 블로그를 직접 만드는 과정에서 겪은 시행착오를 정리한 내용이다.\n\n나의 블로그 포스팅을 향한 일대기는 2019년도에서 부터 시작된다.\n\n## JSP / Servlet\n\n2019년도에 군대를 막 전역하고, 학점을 잘 챙기면서 여러가지 행사에 참여했다. 그 과정에서 기술 블로그를 제작하겠다는 꿈을 꾸고 작업에 착수한다.\n그 당시에는 JSP와 Servlet을 이용한 방법을 통해서 Posting하는 것을 시도했다.\n\ngithub : [euidong/blog](https://github.com/euidong/blog)\n\n해당 방식은 markdown file을 그대로 가져와서 rendering하여 만들었다. 하지만, jar file을 실행해야 한다. 따라서, JAVA Virtual Machine이 필요하기에 결론적으로 이를 호스팅할 machine이 필요하다. 따라서, AWS free tier를 이용해서 배포했지만, 다소 배포 관리가 귀찮고, 당시에는 frontend & backend 등 아직 개념이 제대로 스지 않았기 대문에 중간에 포스팅을 조기 종료했다.\n\n결국 JSP + Servlet을 이용한 시도는 종료된다.\n\n## Gatsby\n\n후에 2021년도 1월에 다시 새롭게 블로그를 쓰겠다는 포부를 갖고, 블로그 작성 방법을 찾는다. 당시에는 React를 이용해서 다수의 Application을 제작해본 경험이 있었기 때문에 이를 이용한 Blog를 만들려고 했다. 자세히 기억은 안나는데 Gatsby Showcase에 있는 source code를 이용해서 Blog를 제작했다. 하지만, Gatsby에 대해 아는게 없고, 시간을 쓸 여유가 없어서 결국에는 중도에 멈춘다. 추가적으로 Github action으로 CI/CD 구현을 수행하는 작업까지도 진행하였다. 하지만 결국 제대로 진행된 것 없이 종료되었다.\n\ngithub : [euidong/euidong.github.io/dev@deprecated](https://github.com/euidong/euidong.github.io/tree/dev%40deprecated)\n\n## Tistory\n\n2021년도 3월에 결국 직접 제작을 하는 것을 포기하고, Tistory를 이용해서 블로그에 포스팅을 시작한다. 해당 시기부터 시작해서 몇 개의 포스팅을 작성하였다. 대략 35개 정도의 포스팅을 작성했고, 최근에 이르러서 작성의 한계를 느끼며 갈아타야겠다고 생각했다.\n\n다음은 직접 커스텀을 해야겠다고 생각했던 이유이다.\n\n1. 호환성이 떨어진다. => Markdown으로 변환도 가능하지만, Github와 완벽한 호환이 안된다.\n2. 가끔 모바일에서 문자가 깨진다. => 아마 MAC으로 작성하는 경우 문자가 깨지는 것 같다. 근데, 이를 매번 모바일로 켜서 확인하기에는 너무 번거롭다.\n3. 커스텀을 할 때 다른 Library를 맘대로 가져와서 쓸 수 있지만, pure js, jquery 기반으로만 가능하고, 유지보수가 쉽지 않다.\n4. 가끔 작성 결과가 너무 예측 불가능하다.\n5. tag 관리가 불편하다.\n6. 기본 UI가 안이쁘다.\n\n몇 가지 이유가 더 있었던 거 같은데, 아마 이정도가 문제였던 거 같다. 암튼 내가 관리하지 못하는 것으로 인한 스트레스가 있었기 때문에 이를 해결하기 위해서 완전 커스텀을 다시 결정하였다.\n\ntistory: [justlog](https://justlog.tistory.com)\n\n## 완전 커스텀\n\n### 생 React\n\n처음에는 생 React를 통해서 Blog를 만들어야겠다고 생각했다. 가장 일반적으로 할 수 있는 작업이고, 다른 static page generating 기능을 수행하는 react framework를 다시 공부하는 workload를 지고 싶지 않았고, 굳이 필요하지 않은 의존성을 만들고 싶지 않아서 결국 생 React로 바로 작업을 시작한다.\n\n당시에는 Tistory에서 한계를 느꼈던 부분을 고치면서, Tistory에서 갖고 싶었던 장점을 가져가고자 했다.\n\n1. 호환성이 떨어지던 점은 Markdown을 이용해서 작성하고, Github viewer style(GFM, Github Flavor Markdown)을 사용하기로 한다. 따라서, 해당 블로그의 모든 글을 Github에 올려도 이미지 경로 빼고는 매우 잘 작동할 것이다. (이는 후에 이미지 호스팅 CDN을 따로 설정하면 해결됨.)\n2. Tistory에서 장점이라고 생각했던, Category로 작성글을 묶고, Tag들로 다시 한 번 더 분류한다.\n3. Posting을 보기 쉽게 정리되어있어야 한다.\n4. Dark Mode를 지원해야 한다.\n5. 조회수 관리를 위해서 Google Analytics 설정을 해야한다.\n6. 구글 / 네이버 검색에 노출되어야 한다.\n7. 광고를 게시할 수 있어야 한다.\n8. Github에 Push하는 것만으로 Posting이 게시될 수 있어야 한다. (Github Action)\n9. Category와 Tag들은 Markdown안에 작성하지만, 이를 조회할 수 있어야 한다. 따라서, code를 build할 때 json으로 generating 할 수 있는 로직을 설계한다.\n10. UI는 최대한 Simple 하고 깔끔하게 만드는 것을 목표로 하였다.\n\n따라서, 모든 Button 부터 모든 UI를 직접 제작(여타 디자인 사용 x - material, ant 등)하고, Routing 설정하고, 작업을 모두 마무리한다.\n\n여기까지는 모든 작업이 순조롭게 진행되고, 마무리가 되었다. 하지만, SEO(검색 엔진 최적화) 작업을 진행하면서, 결국 static page가 필요함을 깨닫는다. 왜냐하면, 기존의 React Router를 사용하게 되면, <https://euidong.github.io/posts/dfs1> 를 찾을 수가 없다. 왜냐하면, github에서는 page를 직접 접근할 때에는 배포 branch에서 해당 파일을 찾게 되는데 해당 파일이 없으면 결국 404 Not Found를 노출하게 된다. 이를 해결하기 위해서, dummy redirect로 root로 돌려보내줄 수도 있지만, 결코 좋은 방법은 아니다. 검색엔진 최적화에도 좋지 못하다. 따라서, static file을 각 각의 url마다 생성해주는 Static Page Generating이 필요하다고 느낀다. 따라서, Gatsby와 NextJS 중에서 선택을 하기로 한다.\n\n이제 추가된 요구사항은 다음과 같다.\n\n1. 기존 코드를 그대로 활용할 수 있어야 한다.\n2. Static Page Generating을 지원해야 한다.\n\ngithub : [euidong/euidong.github.io/dev@pure-react](https://github.com/euidong/euidong.github.io/tree/dev%40pure-react)\n\n### 다시 Gatsby\n\n다시 돌아와 Gatsby를 시도하기로 한다. 애초에 GraphQL과 React 모두 경험이 있기 때문에 쉽게 할 수 있을 거라고 생각했다. 하지만, 생각보다 GraphQL Query의 제한점이 많아서 결국 Gatsby는 포기하기로 한다. 물론 Gatsby의 확장 도구들은 유용했지만 위에서 제시한 9번을 구현하기에 한계를 느꼈다. (내 딴에는 GraphQL로 만들고 싶었는데 사실 포기하고 JSON으로 만들었으면 가능했을 듯하다.)\n\n### NextJS\n\n그래서 다음으로 시도한 것이 NextJS이다. NextJS는 생성 시에 내부 API를 정의하여 이를 기반으로 미리 compile을 완료한 html 파일들을 생성해두고, 제공하면서도, 그 내부에서는 SPA 처럼 동작할 수 있도록 돕는 방식이다. React를 이용한 Framework인 만큼 기존의 code를 그대로 사용할 수 있어서 쉽게 사용이 가능했다. 하지만, Gatsby와 마찬가지로 어느정도의 한계는 존재했기 때문에 결국은 react만 생성하던 방식처럼 JSON file을 generating하여 category와 tag들을 수집하였다.\n\n그 결과 지금과 같은 형태의 블로그를 완성하였다. 현재 포스팅을 계속해서 진행할 예정이며, 광고 및 여타 설정들도 추가로 진행할 예정이다.\n\n![blog-view](/images/blog.png)\n\ngithub : [euidong/euidong.github.io/dev](https://github.com/euidong/euidong.github.io/tree/dev)\n\n최종으로 만들어진 Blog는 다음과 같은 요구사항을 만족한다.\n\n- [x] Markdown을 통해서 작성이 가능하고, 이는 DB 즉, BackEnd를 필요로 하지 않는다.\n- [x] Category로 작성글을 묶고, Tag들로 다시 한 번 더 분류하는 것이 가능하다.\n- [x] Dark Mode를 지원한다.\n- [x] 조회수 관리를 위해서 Google Analytics를 사용한다.\n- [x] 구글 / 네이버 검색에 노출되어있다.\n- [x] 광고를 게시하였다.\n- [x] Github에 Push하는 것만으로 Posting이 게시된다. (Github Action)\n- [x] Build 시에 SEO에 필요한 sitemap을 자동 생성한다.\n- [x] Theme는 Github의 color palette에 기반하여 설정하여, 친숙하다.\n- [x] 모바일을 지원한다.\n- [x] 이미지 크기를 재설정할 수 있는 command를 포함한다.\n","slug":"making-blog","date":"2022-05-05 21:54","title":"블로그 제작기","category":"Web","tags":["frontend","react","gatsby","nextjs","github"],"desc":"해당 포스팅은 블로그를 직접 만드는 과정에서 겪은 시행착오를 정리한 내용이다.나의 블로그 포스팅을 향한 일대기는 2019년도에서 부터 시작된다.","thumbnailSrc":"https://euidong.github.io/images/blog.png"}],"Paper":[{"content":"\n## Intro\n\nEthereum의 TPS를 Client 단에서 향상 시키기 위한 노력으로, LMPT는 Layered Merkle Partical Trie의 약자이다. 이는 기존 Ethereum에서 사용하던 MPT의 성능 향상을 위하여 제기된 아이디어로 Computer Architecture에서 흔하게 사용되는 cache를 접목한 방법이다. (해당 논문 ICBC 2022의 논문 중 LMPT를 기반으로 한 요약글이다.)\n\n## Terms\n\n- **ERC-20**  \n  Ethereum과 호환이 가능한 token에 대한 표준을 제시한 문서이다. 즉, 이 표준을 만족하는 token은 Ethereum을 통해서 교환이 가능하며 그 반대도 가능하다.\n- **Tether token**  \n  Tether token은 ERC-20에 기반한 대표적인 token으로, 미국 달러와 1:1로 대응하는 USDT로 유명하다. 실제 거래에서도 빈번히 사용되는 ERC-20 token이다.\n- **Trie**  \n  Trie는 sequence로 이루어진 데이터의 빠른 검색을 위해서 만들어진 tree의 일종이다. 데이터를 저장할 때 sequence 데이터의 검색을 최적화하는 것을 목표로 한다. 원리는 다음과 같다. sequence의 검색 시에 sequence의 앞에서부터 맞는 node를 root에서부터 검색하며 찾아나간다. 이 덕분에 검색 시에는 sequence의 길이만큼의 시간이면 충분히 데이터를 찾는 것이 가능하다. 하지만, 저장 sequence를 풀어서 저장하는 방식이기 때문에 경우의 수가 엄청 많아진다. 이는 sequence를 하나의 데이터로 보는 것보다 저장 공간을 많이 차지한다는 단점도 있다.\n- **Patricia Trie**  \n  Trie에서는 기본적으로 모든 sequence를 요소 하나를 node로 보았다면, Patricia Trie에서는 각 nnode가 두 개로 나뉘어진다. branch node, leaf node이다. leaf node는 각 sequence의 끝을 의미하며 각 sequence는 반드시 하나의 leaf node로 종결되어지고, branch node는 저장한 데이터 중에서 중복이 발생하는 경우 중간 지점으로 저장해두는 방식이다. 따라서, Trie에서는 각 노드가 sequence의 하나의 값을 의미했다면, Patricia Trie에서는 path가 sequence의 요소들을 의미한다. 이에 대한 이해를 위해서는 아래에 제시된 그림을 보는 것이 좋을 것이다.(좌. trie, 우. patricia trie)  \n  ![patricia-trie](/images/patricia-trie.png)\n- **Merkle Tree**  \n  Bitcoin에서 사용된 자료구조로 Blockchain의 모든 Block을 저장하는 것은 특정 node에게는 부담이 될 수 있기 때문에 이에 대한 인증을 쉽게 하기 위해서 요약본만을 저장하는 방식이다. 자세한 내용은 [🔗 bitcoin-4](/posts/bitcoin-4)의 2. Merkle Tree 부분에서 자세히 다루었다. 간단히 설명하자면, Block을 serialization하고 hash하여 결과값을 저장한 후 이를 leaf node로 하는 형태의 binary tree를 만드는 것이다. 그렇기에 우리는 Merkle Tree의 hash값 몇개만 갖고도 해당 transaction을 포함하는 block이 유효한지를 파악할 수 있다.  \n- **MPT**  \n  Merkle Patricia Trie의 줄임말로 기존 Bitcoin에서 사용하던 Merkle Tree와 Patricia Trie의 결합을 통해 만들어낸 자료구조이다. 이에 대한 설명은 아래에서 더 자세히 다룬다.\n- **Latency bound issue**  \n  Memory에서 너무 많은 데이터를 얻어오려고 할 때를 의미하는 Memory Bound 중의 하나로 data를 Memory 만으로는 가져올 수 없을 때, secondary storage에서 불러오는데 발생하는 latency를 의미한다.\n\n## Problem\n\nBitcoin에서 시작된 Blockchain에 대한 응용은 의료, 공급망 관리 등으로 확장되며 계속해서 발전되고 있다. 그럼에도 불구하고 아직까지 **transaction의 빠른 처리**는 challenge한 부분으로 남아있다. 이는 P2P 환경에서 안전한 transaction의 생성 및 조회 그리고 검증을 위해서 어쩔 수 없는 trade off로 받아들여졌다. 그 결과 7~30 tps(transaction per second)정도에 그치는 성능을 보여주고 있다. 주류인 중앙 처리 방식은 수 천개의 transaction을 처리하는 것과 비교했을 때에는 굉장히 낮은 수준이다.\n\n이를 해결하기 위해서 다년간 여러가지 접근 방식과 해결책이 제시되었다(AI-gorand, Conflux, Prism, OHIE, etc). 이를 통해서 수 천개의 transaction을 blockchain에서 처리하는 것이 가능하게 되었다. 하지만, 실제로 응용하는데에는 한계가 있었다. 그것은 state를 보관하는 ledger 단에서 발생하는 것이 아닌 실제로 transaction을 처리하는 client 단에서의 문제이다. 이는 바로 **blockchain state를 변경하는 transaction이 빈번하게 발생하는 경우 client 단에서 새로운 bottleneck이 발생한다는 점이다.** 실제로 가장 유명한 Ethereum Client인 GoEthereum과 OpenEtereum에서는 700 tps로 기존 제시된 수 천 transaction보다는 한참 못 미치는 성능을 보여준다.\n\n그 원인은 사실상 state machine이라고 할 수 있는 Ethereum과 이것의 검증을 위해 제안된 MPT의 구조적인 한계로 인해 발생한다(이는 Background에서 제대로 다룰 것이다). 이 구조적인 한계에 의해서 다음과 같은 현상들이 발생한다.\n\n1. key-value 짝으로 이루어지는 데이터의 read/write 연산이 증폭해서 발생한다.\n2. 특히 write operation은 모든 node에 대한 hash를 재계산하도록 한다.\n3. 이러한 동작이 완료되기 전까지 반드시 transaction을 처리하는 thread는 대기해야 한다.\n\n이를 해결하기 위해서, 해당 논문은 LMPT라는 새로운 자료구조를 제시한다. 이는 기존 Ethereum의 MPT를 기반으로 하는 시스템보다 6배 정도 상승된 tps 성능 지표를 보여주고 있다. 이것의 핵심 아이디어는 MPT를 계층화(layer)하는 것이다. 즉, 최근 update된 내용을 별도의 저장공간을 활용하여 저장해두고 이를 우선적으로 활용하기 때문에 더 빠른 처리 성능을 보여주는 것이다.\n\n## Background\n\n> <mark>**1. Ethereum**</mark>\n\nEthereum은 기존 Bitcoin Blockchain System과 확연히 다른점이 있다. 바로 State Machine이라는 점이다. 기존의 Bitcoin에서는 거래 내역을 모두 공개하고, 이를 통해서 우리는 최초 Block에서부터 이 거래 내역을 읽어들이면서 가진 자산을 확인할 수 있다. 즉, 거래 history를 종합해서 결과값을 얻는 것이다. Transaction의 수정과 삭제 없이 계속해서 추가만 이루어지는 형태라고 볼 수 있다. 하지만, Ethereum에서는 Transaction을 State Machine의 상태를 변화시키는 하나의 action으로 받아들인다. 따라서, Transaction에 의해서 우리는 상태가 변화하도록 하는 방식인 것이다. 따라서, 우리는 해당 State만 보고 자신의 자산을 파악할 수 있는 것이다.\n\n> <mark>**2. MPT**</mark>\n\n결국 Ethereum 시스템을 활용하기 위해서는 모든 것이 공개되는 Network 상에서 안전하게 State와 이를 변경하는 Transaction을 보관하는 것이 중요하다. 이러한 data를 무결하게 그러면서도 수정, 삭제, 검색 등이 용이할 수 있도록 하기 위해서 Ethereum에서는 MPT(Merkle Patricia Trie)를 활용한다. 이는 결국 위에서 설명한 Merkle Tree와 마찬가지로 하위 Node의 Hash값을 상위 Node에서 가지기 때문에 Root Hash만을 비교하여 검증을 할 수 있다는 점에서 강점을 가지고 있다.\n\nMPT는 3가지의 Node로 이루어진다.\n\n1. **Leaf Node**  \n   실제로 value를 저장하는 말단 node이다. 만약, path로 key가 모두 표시되지 않았다면, key-end에 남은 key를 모두 담는다.\n2. **Extension Node**  \n   Leaf Node 이외에 경로의 확장이 필요할 때 사용되어지는 Node로 Branch Node의 hash data를 하나로 합치는 등의 역할을 한다.\n3. **Branch Node**  \n   16개의 pointer를 포함하는 Node로 이를 통해서 Leaf, Extension, Branch Node를 가르키는 데 사용할 수 있다.\n\n따라서, 일반적인 구조는 아래와 같다.\n\n![mpt](/images/mpt.png)\n\n이 구조가 가지는 의의는 결국 우리는 하위 node들을 hash한 데이터를 상위 node에서 포함하고 있기 때문에 필요에 따라 trie에 일부분만을 저장해도 data의 검증은 충분히 가능하다는 점이다. 따라서, 모든 data를 가지는 full node와 달리 light client는 더 적은 데이터만 갖고도 검증이 가능한 것이다. 하지만, light client에서 authenticated read(full node의 도움이 필요한 read)를 수행하고자 하는 경우 full node에서는 read를 수행하기 위해서 path를 따라서 읽기를 반복해나가며, leaf node에 있는 최종 value를 얻어와야 한다.\n\n> <mark>**3. Further Observation**</mark>\n\n해당 논문에서는 OpenEthereum Client를 관측하고, 기존 논문들에서 여러 영감을 얻었다. 다음은 이 논문에서 insight를 얻는 데 중요한 역할을 한 관측 정보이다.\n\n1. Transaction이 Blockchain State에 빈번하게 접근할 수록 Transaction의 처리 성능은 낮아진다.\n2. 실제 Transaction의 실행 시간 중에서 가장 많은 시간을 차지하는 것은 Blockchain State에 접근하는 동작(SLOAD, SSTORE)이다.  \n   [🔗 기반 논문(Securing Smart Contract with Runtime Validation)](https://aoli.al/papers/solythesis-pldi20.pdf)\n3. 한 번의 Transaction은 여러 번의 IO을 유발한다.(IO amplication)  \n   MPT 구조에서 하나의 key 조회를 위해서 한 번에 데이터를 찾을 수 없기 때문에 결국 key를 통해서 Trie를 순회하여야 한다.  \n   이는 key에 대응되는 Node가 많을 수록 많은 IO를 요구한다.\n4. Transaction 실행 thread는 병렬적으로 실행되지 않고, 위에서 제시된 operation이 끝날 때까지 대기한다.  \n   즉, Transaction을 처리하는 Thread는 critical path(section)를 지키기 위해서 단 하나만 존재한다는 것이다.\n5. memory cache size를 늘리는 것은 성능향상에 큰 도움이 되지 않는다.  \n   | Memory Cache size(MB) | Hit Rate | TPS  |\n   | :-------------------- | :------- | :--- |\n   | 50                    | 0.635    | 1238 |\n   | 100                   | 0.758    | 1256 |\n   | 500                   | 0.862    | 1278 |\n   | 1000                  | 0.879    | 1292 |\n\n   위의 표를 보면 알 수 있지만, Cache Size를 늘렸을 때 Hit Rate는 늘릴 수 있지만 TPS의 성능 향상 폭은 5% 수준에 그친다. 이는 memory cache를 제대로 사용하지 못하고 있음을 의미한다.\n\n즉, 해당 논문에서는 하나의 Transaction에 의해서 IO가 빈번히 발생하는데 이를 병렬적으로 처리하는 것도 기존 MPT만으로는 한계가 있기 때문에 이를 해결할 수 있는 방법을 제시한다.\n\n## LMPT\n\nLayered Merkle Patricia Trie의 약자로 기존 Ethereum MPT의 한계를 극복하기 위해서 제안하는 자료구조이다. 이의 핵심적인 목표는 Authenticated Ethereum State를 더 효과적으로 저장하는 것이다. 여기서 사용하는 핵심 아이디어는 바로 기존 Computer Architecture에서 사용했던 Hierarchical Memory의 구조를 그대로 차용하는 것이다. 즉, cache로 사용할 수 있는 MPT를 더 구현해두는 것이다. 이는 결론상으로 MPT의 read시에 IO amplication을 효과적으로 줄일 수 있다.\n\n우선 구성 요소는 다음과 같다.\n\n1. **Delta MPT**  \n   Read access가 요청되면 가장 먼저 조회되는 MPT이다.\n2. **Intermediate MPT**  \n   Delta MPT 이후에 조회되는 MPT이다.\n3. **Snapshot MPT**  \n   원본이라고 할 수 있는 MPT이다. 전체 blockchain data를 저장하며, disk에 존재한다.\n4. **Flat KV Store**  \n   read시에 가장 마지막에 조회된다. 이 역시도 전체 blockchain data를 저장하지만, 차이점이라면 key를 path로 하여 조회하는 MPT와 다르게 key, value store형태이다.  \n   그렇기에 snapshot MPT와 동일하게 disk에 존재하지만, 더 빠르다게 조회가 가능하다는 장점이 있다.  \n   snapshot MPT를 조회하는 대신에 이를 통해서 조회를 한다면, key를 통해서 바로 조회할 수 있는 방식이기 때문에 read IO amplication을 효과적으로 줄일 수 있다.\n\n위의 까지는 read시에 최적화를 수행하였다면, write 시에는 이렇게 계층화를 해두었기 때문에 disk에 write하는 동안의 여유가 생길 수 있다. LMPT에서는 MPT의 적은 변화일 경우에는 delta MPT에 저장하고 있다가 periodic checkpoint를 두고, 해당 시점마다 delta MPT의 변경사항은 intermediate MPT, intermediate MPT의 변경 내용은 snapshot MPT에 합친다. 따라서, write 동작은 시간차를 두고 **batch 단위**로 **verification과는 독립적**으로 진행된다. 이는 결국 병렬적으로 IO 작업을 처리할 수 있는 여지를 만들어준다.\n\n> <mark>**[Design] Structure**</mark>\n\n어떻게 실제로 이를 구현했는지에 대한 outline을 제시하면 다음과 같다. (OpenEthereum은 Rust를 이용하기 때문에 LMPT도 Rust에 기반한 code이다. psuedo code이기 때문에 해당 언어를 몰라도 알아볼 수 있을 것이다.)\n\n```rust\nstruct Trie {\n  root: uint256,\n  kv:   Map\n}\nstruct LMPT {\n  delta, interm:  Trie, // In memory\n  snapshot:       Trie, // In Disk\n  flat:           Map   // In Disk\n}\n```\n\n위에서 제시한 전체 구성요소와 마찬가지로 delta, intermedidate, snapshot mpt를 정의하고 flat를 정의한 것을 볼 수 있다.\n\n> <mark>**[Design] Read/Write**</mark>\n\n실제로 Write와 Read는 아래와 같이 수행되어진다. 코드는 논문을 참조하였지만, 설명은 직접 작성하였다.\n\n```rust\nT := LMPT()\n\nfn write_LMPT(k, v) {\n  root := T.delta.put(T.delta.root, k, v) // put new k, v data and get recomputed root hash\n  T.delta.root := root                    // set new root\n}\n\nfn read_LMPT(k, auth_proof) -> <v, p> {\n  // get value and path from delta mpt with key\n  <v, p1> := T.delta.get(T.delta.root, k)\n  // check whether value is exist or not\n  // if exist, then return value and path\n  // if not exist, then we get a adjacent path from delta MPT and store it in p1.\n  if v is present\n    return <v, p1>\n  // get value and path from intermediate mpt with key\n  <v, p2> := T.interm.get(T.interm.root, k)\n  // check whether value is exist or not\n  // if exist, then return value and path(p1 is adjacent path in delta, p2 is real path in intermediate MPT)\n  // if not exist, then we get a adjacent path from intermediate MPT and store it in p2.\n  if v is present\n    return <v, p1 + p2>\n  // if client want authneticated read(when they can't have authenticity), \n  // then request to snapshot MPT and return result\n  // else then request to flat kv store and return result without path.\n  if auth_proof\n    <v, p3> := T.snapshot.get(T.snapshot.root, k)\n    return <v, p1 + p2 + p3>\n  else\n    v := T.flat.get(k)\n    return <v, dummy>\n}\n```\n\n간단하게 요약하자면, 결국 write의 경우에는 다음 절차가 끝인 것이며,\n\n1. key, value를 받아서 delta MPT에 저장한다.\n2. 변경된 root hash를 delta MPT에 적용한다.\n\nread의 경우에는 다음과 같은 절차가 끝인 것이다.\n\n1. delta MPT를 우선 조회한다.\n2. intermediate MPT를 다음으로 조회한다.\n3. 만약, 출처가 확실한 요청인 경우 auth_proof가 필요없으므로, flat KV store를 조회한다.\n4. auth_proof가 필요하다면, snapshot MPT를 조회한다.\n\n> <mark>**[Design] Merge**</mark>\n\nwrite 과정에서는 delta MPT에만 추가를 수행했었다. 아래에서는 실제로 변경사항을 snapshot MPT와 flat KV store에 적용한 것이다.\n\n```rust\n// merge intermediate MPT to snapshot MPT and flat KV store\nfn merge_compute(T) -> (root, flat) {\n  flat := T.flat            \n  root := T.snapshot.root   \n  for <k, v> in T.interm.kv(T.interm.root)\n    root := T.snapshot.append(root, k, v)\n    flat := flat.set(k, v)\n  return (root, flat) \n}\n\n// reconfigure flat, snapshot root, intermediate MPT, delta MPT\nfn merge_update(T, root, flat) {\n  T.flat := flat\n  T.snapshot.root := root\n  T.interm := T.delta\n  T.interm.root := T.delta.root\n  T.delta := Trie()\n  T.delta.root := None\n}\n```\n\n이 과정도 간단하게 요약하자면 다음과 같다.\n\n1. merge_compute, merge_update가 주기적으로 실행되도록 설정한다.\n2. merge_compute에서는 intermediate MPT의 data를 모두 snapshot MPT와 flat KV store에 추가한다.\n3. merge_update에서는 intermediate MPT는 이미 적용이 완료되었기 때문에 delta MPT를 intermediate MPT로 변경한 후, delta MPT를 비어 있는 MPT로 변경한다.\n4. 매 주기가 될 때마다 merge_compute와 merge_update가 순차적으로 실행된다.\n\n위 method가 중요한 점은 바로 transaction의 write/read와 독립적으로 동작할 수 있다는 점이다. 즉, disk에 data를 write 하기 위해서 실제 transaction 처리에 waiting이 필요없다는 것이다.\n\n> <mark>**[Design] Flush**</mark>\n\n위에서 제시한 Method를 다음과 같이 적용함으로서 다음과 같이 Ethereum state를 update하고, 무결하게 유지할 수 있다.\n\n```rust\nblock_cnt := 0\nmerge_interval := 100     // you can set this constant\n\nT := LMPT(genesis_state)  // setup initial state\n\nwhile Block is processing\n  for transaction in Block\n    T.update_trie(transaction)                  // apply transaction to LMPT\n  block_cnt += 1\n  if block_cnt % merge_interval == 0\n    Wait for last spawned thread to end         // wait until previous thread finished.\n    merge_update(T, root, flat)               \n    spawn_thread(root, flat=merge_compute(T))   // make new thread for merging\n```\n\n이 과정의 요약은 다음과 같다.\n\n1. merge_interval를 원하는 값으로 초기화한다. (이 값에 대해서 논문에서는 제시하지 않음)\n2. 초기 genesis_state를 통해 LMPT를 초기화한다.\n3. blockchain의 block을 처리하도록 한다. 새로운 block에 대한 처리도 이에 포함된다.\n4. 그 과정에서 특정 interval이 되면, 기존 merge_compute를 수행하는 thread가 있는지를 확인했다가 background로 merge_compute를 실행하는 thread를 생성한다.\n\n## Evaluation\n\n본 논문에서는 평가를 위해서 다음과 같은 실험을 수행한다.\n\n|       | data structure | workload              |\n| :---- | :------------- | :-------------------- |\n| Test1 | MPT vs LMPT    | simple payment        |\n| Test2 | MPT vs LMPT    | ETC-20 token (Tether) |\n\n여기서 실험 시에 고려한 사항은 다음과 같다.\n\n1. 실제와 같은 상황을 만들기 위해서 실제 Ethereum transaction 500,000개를 활용한 benchmark를 만들었다.\n2. 또한, 또 다른 insight를 얻기 위해서 각 address간의 고르면서도 random하게 transaction을 보내도록 하는 Random senders traces benchmark도 만들었다.\n3. 또한, 간단한 payment의 경우와 복잡한 smart contract에 의해 동작하는 ETC-20 token 중 가장 많이 사용되는 Tether token을 활용한 비교도 수행하였다.\n\n결과적으로 state로 보관해야할 account의 수가 많아질 수록 LMPT와 MPT 사이의 차이를 명확하게 볼 수 있는 형태를 보여준다. 이 차이는 더 복잡한 ETC-20 token에서 더 명확하게 들어나고 성능 차이는 적게는 1.2배에서 6배 이상까지도 벌어지는 것을 확인할 수 있다. 이를 통해서 결과적으로 cache를 활용하여 더 효율적인 Transaction 처리가 가능하다는 것이다.\n\n## Related Work\n\n해당 논문은 결국 Blockchain의 MPT 구현을 변형하여 효율적인 방법을 제시하였다. 이외에도 TPS를 향상시키기 위한 여러 방법이 제시되었다. 하지만, LMPT는 이러한 연구들보다 앞 선 결과를 보여준다. 그 이유를 들기 위해서 다음과 같은 사전 연구와 비교했을 때 어느 점이 좋은지를 밝힌다.\n\n1. **Distributed MPTs**  \n   LMPT와 가장 유사한 연구 사례들로 MPT의 구현을 변경하여 최적화를 하고자 한 사례이다. 하지만, 이들 중에서도 LMPT가 더 우수하다는 것을 다음을 통해서 알 수 있다.\n   - [🔗 mLSM](https://www.usenix.org/conference/hotstorage18/presentation/raju)  \n     MPT 자체를 여러 개의 MPT로 나누어 저장하는 방식을 택하였다. 이를 통해서 read, write 시에 IO amplication을 막을 수 **있었지만**, 오히려 write 시에는 여러 번의 중복 writing으로 인해서 더 많은 비용이 발생하였다.\n   - [🔗 RainBlock](https://www.usenix.org/conference/atc21/presentation/ponnapalli)  \n     MPT를 sharding하여 분배하여 저장하는 방식을 선택하였다. 이를 통해서 성능을 올리는 것이 가능했지만, 이는 전체적인 Ethereum 구현을 바꾸어야 한다. **하지만**, LMPT는 이러한 변경없이도 client단에서 쉽게 구현 및 변경이 가능하다.\n2. **Consensus protocols**  \n   consensus protocol을 변경하여 최적화를 하려는 시도 역시 많았다(HyperLedger Fabric, Prism, etc). **하지만**, 이를 통해서 storage bottleneck을 해결할 수는 없다. 따라서, 해당 연구와 consensus protocol 관련 연구는 상호 보완적인 관계로, 같이 사용하게 되면 더 좋은 성능을 보일 것이라고 기대하고 있다.\n3. **Sharding in Blockchains**  \n   sharding은 Ethereum v2의 architecture 중 하나로 제시된 내용 중 하나로 이를 이용하게 되면 transaction 실행을 분산하는 효과를 불러올 수 있다. 하지만, shard간의 일관성을 유지하기 위한 protocol과 shard간 cross-shard 통신으로 인한 overhead도 고려해야 한다. 이러한 내용을 제쳐두고도 결국은 sharding과 LMPT는 독립적으로 동작할 수 있기 때문에 consensus protocol과 같이 독립적으로 보아도 무관하다.\n\n## Opinion\n\nTPS를 향상 시키기 위한 방법은 Bitcoin이 처음 생기고 나서부터 계속해서 고려되고 있는 문제라고 생각한다. 해당 논문에서는 기존 논문이 였던 mLSM에서 영감을 얻어서 이를 더 발전시킨 방법을 찾았다고 생각한다. 단순히 여러 개의 MPT를 구현하는 것을 넘어서 실제 문제를 명확하게 정의해서 여러 개의 MPT로 어떻게 이를 해결할 수 있는지를 명확하게 제시한 것 같다. 여러 개의 MPT를 통해서 read 과정에서 locality를 확보했을 뿐만 아니라 merge 과정을 write 과정에서 분리함으로서 기존 transaction이 가지던 bottleneck을 해소한 것이다. 이 점이 명확하게 받아들여져서 해당 분야 전공이 아님에도 쉽게 이해할 수 있었다. 하지만, 아쉽게도 실제 구현 code를 찾을 수는 없었기에 flush단계에서 사용된 merge_interval의 정확한 값이 궁금했지만 찾지는 못했다. 또, 이 임계값이 상황에 따라서 성능에 큰 영향을 미치는 요소라고 파악을 하고 있었는데 이를 알 수 없어서 아쉬웠다.\n\n아마 여기서 후속 연구를 진행할 수 있다면, 해당 임계값을 ML, DL, RL을 이용해서 좀 더 효과적으로 적용할 수 있는 방법을 찾아보는 것도 좋은 연구 방향이 될 수 있을 것이다.\n이러한 주제를 처음 접했고, Ethereum의 구현에 대해서도 전혀 아는게 없었기 때문에 다양한 사전 조사를 요구했던 논문이였다. 하지만, Background에 대한 설명도 자세히 나와있고, Idea 자체가 명확했기에 훌륭하고 가독성이 높은 논문이 된 거 같다.\n\n## Reference\n\n- Jemin Andrew Choi, Sidi Mohamed Beillahi, Peilun Li, Andreas Veneris, Fan Long [`\"LMPTs: Eliminating Storage Bottlenecks for Processing Blockchain Transactions\"`](https://ieeexplore.ieee.org/document/9805484/), May 2022\n- Ao Li, Jemin Andrew Choi, Fan Long [`\"Securing Smart Contract with Runtime Validation\"`](https://aoli.al/papers/solythesis-pldi20.pdf), June 2020\n- Tumbnail : Photo by [Shubham Dhage](https://unsplash.com/@theshubhamdhage?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/s/photos/blockchain?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n- Merkle Patricia Image : <https://ethereum.stackexchange.com/questions/268/ethereum-block-architecture>\n- Pandian Raju, Soujanya Ponnapalli, Evan Kaminsky, Gilad Oved, and Zachary Keener, University of Texas at Austin; Vijay Chidambaram, University of Texas at Austin and VMware Research; Ittai Abraham, VMware Research, [`mLSM: Making Authenticated Storage Faster in Ethereum`](https://www.usenix.org/conference/hotstorage18/presentation/raju), July 2018\n- Soujanya Ponnapalli, Aashaka Shah, and Souvik Banerjee, University of Texas at Austin; Dahlia Malkhi, Diem Association and Novi Financial; Amy Tai, VMware Research; Vijay Chidambaram, University of Texas at Austin and VMware Research; Michael Wei, VMware Research, [`RainBlock: Faster Transaction Processing in Public Blockchains`](https://www.usenix.org/conference/atc21/presentation/ponnapalli), July 2021\n","slug":"lmpt","date":"2022-10-28 17:17","title":"LMPT","category":"Paper","tags":["Blockchain","Ehtereum","MPT"],"desc":"Ethereum의 TPS를 Client 단에서 향상 시키기 위한 노력으로, LMPT는 Layered Merkle Partical Trie의 약자이다. 이는 기존 Ethereum에서 사용하던 MPT의 성능 향상을 위하여 제기된 아이디어로 Computer Architecture에서 흔하게 사용되는 cache를 접목한 방법이다. (해당 논문 ICBC 2022의 논문 중 LMPT를 기반으로 한 요약글이다.)","thumbnailSrc":"https://euidong.github.io/images/blockchain-thumbnail.jpg"},{"content":"\n## Intro\n\n<https://ieeexplore.ieee.org/document/6838228>에 기재된 `OpenNetMon: Network Monitoring in OpenFlow Software-Defined Networks`의 내용에 대한 리뷰이다. 이름에서 알 수 있듯이 OpenNetMon은 POX OpenFlow Controller를 이용하여 수많은 network component로 이루어진 fine-grained Network에서 Traffic Engineering을 위한 QoS Metric을 flow 단위로 제공하는 것을 목표로 한다. 수집하는 데이터는 **Throughput**, **Packet Loss**, **Delay**를 측정한다.\n\n## Monitoring\n\nMonitoring의 종류 그리고 OpenNetMon 이전의 Monitoring 방법론에 대한 소개를 먼저한다.\n\n> **Type of Monitoring**\n\n세 가지 기준에서 Monitoring 방법들을 구분한다. 그 중에서 첫 번째로 제시된 것이 **Active**, **Passive**이다.\n\n- **Active** : 추가적인 packet을 Network 상에 삽입하여, 해당 packet의 동작을 통해서 측정을 하는 방법으로 과도한 추가 packet은 Network에 영향을 주기 때문에 이에 유의해야 한다. 반대로 너무 적은 packet을 사용하는 경우에도 정확성과 실시간성이 떨어질 수 있다.\n- **Passiv** : 추가적인 packet의 삽입없이 기존 traffic에 대한 관측만으로 측정하는 방법으로 모든 네트워크에 적용할 수 잇는 범용적인 방법은 사실상 불가능하다고 할 수 있으며 각 Network를 위한 전용 Hardware 장비가 필요할 수도 있다. 또한, Synchronization을 위한 별도의 방법 또한 필요하다.(각 Network 장비에서 관측한 Traffic이 서로 대응되는지 확인할 수 있어야 하기 때문)\n\n두 번째는 어떤 Layer에서 Monitoring을 수행하는가이다. Application Layer에서 측정을 하게 된다면, 활용할 수 있는 데이터가 많아지고, 실제 user 입장에서의 최종 데이터를 얻는 것이 가능하다. 하지만, 실제 서비스 제공자 입장에서 모든 End Device에 대한 접근이 불가능한 경우가 많다. 반대로 Network Layer에서 측정을 수행하는 경우에는 사용할 수 있는 데이터가 각 Switch 와 같은 Network 장비에서 packet이 어느 port로 나갔는지와 같은 간단한 정보밖에 사용할 수 없다는 단점이 있었다.\n\n세 번째로 제시되는 것이 `OpenFlow`를 이용하였는가 아니면 이를 사용하지 않았는가이다. `OpenFlow`가 등장하면서 결국 Network Layer에서의 측정이 더 큰 의미를 가지게 된다. 왜냐하면, **Switch에 설정을 미리 주입하거나 새로운 traffic에 대한 정보를 실시간으로 추가할 수 있으며 Flow 단위로 통계치를 얻거나 임의의 packet을 추가하는 등의 작업을 수행할 수 있었기 때문에 Network Layer에서의 더 많은 Monitoring이 가능해졌다.** 이것이 해당 논문이 OpenFlow를 통해서 구현하고자 하는 바이다. Network Layer에서 복잡한 네트워크에서도 보다 정확하고, 실시간의 통계 데이터를 추출할 수 있다는 것이다.\n\n아래는 해당 논문에서 추가로 제시하는 OpenNetMon 이전에 존재했던 Monitoring 방법에 대한 정리이다.\n\n|                 | Active/Passive | Layer   | OpenFlow 여부 | 설명                                                                                                                                                                                                            |\n| :-------------- | :------------- | :------ | :------------ | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| SNMP            | Active         | Network | X             | port 단위의 packet counter 기능 제공 <br/> switch의 통계정보 제공(CPU, RAM)                                                                                                                                     |\n| NetFlow / cSamp | Passive        | Network | X             | switch를 통과하는 n개의 packet마다 임의의 1개의 packet을 선별하여 이를 대표값으로 하여 Network 상태를 측정하지만, 정확도가 많이 떨어질 수 있다.                                                                 |\n| Skitter         | Active         | Network | X             | 전체적인 Network Delay를 측정하기 위해 대표지역에 측정기를 설치하여 실행한 project로, 이를 통해 대략적인 지연을 예측할 수는 있지만 정확하지는 않다.                                                             |\n| IPMON           | Passive        | Network | X             | TCP/IP packet header를 추출하여, timestamp와 함께 중앙 server로 전송하여 이를 분석하는 방식이다. <br /> Passive임에도 Synchronization을 맞추기 위해서 통신은 불가피하며 Network 크기가 커질 수록 비용이 커진다. |\n| OpenTM          | Passive        | Network | O             | 각 Flow의 통계 데이터를 일정 주기로 Query하여 수집한다. Flow의 시작과 끝 지점에서만 측정하는 Last-Switch 방식을 사용한다.                                                                                       |\n| OpenSAFE        | Passive        | Network | O             | SDN의 모든 새로운 Flow가 Controller로 이동하는 것을 이용하여 Monitoring 시스템으로 Controller가 이를 전달하도록 하는 방식이다.                                                                                  |\n| OpenSketch      | -              | -       | -             | Monitoring을 위해 OpenFlow 자체를 재정의하자는 것으로 새로운 Protocol을 정의해서 더 나은 Monitoring을 수행하자는 방법이다. <br /> 하지만, 이렇게 새로운 Protocol을 만드는 것은 Risk가 너무 크다.                |\n\n## OpenNetMon\n\n기존의 Monitoring 방식들은 OpenFlow의 Packet 삽입을 이용한 방식을 제대로 사용하지 않았을 뿐만 아니라 Flow 측정에 있어 최적화에 한계가 있었을 뿐만 아니라 **Throughput**, **Packet Loss**, **Delay**을 통합하고자 하지 않았다. 따라서, OpenNetMon은 이를 수행하는 것을 목표로 한다.\n\n각 측정 요소를 어떻게 수집할 것인지를 각 각 정리한다.\n\n> **1. Throughput**\n\nOpenFlow의 `FlowStatsReq`(Controller에서 각 Switch로 전송하는 Request)를 주기적으로 호출하여 각 Switch에서 전송한 Byte의 양과 각 Flow의 지속 시간을 얻는다. 주기적 호출 싱레는 경로 상의 처음과 끝을 호출하는 Last Switch 방식을 사용하며, 이는 Round Robin이 대규모 네트워크 환경에서 비효율적일 뿐만 아니라 Packet Loss 측정 시에도 Last Switch는 필수적으로 필요한 요소이기에 최적 요소만을 사용하는 것이다.\n\n또한, 이러한 호출 주기는 변동적으로 설정되었는데 이는 Link State Information에 기반한 Routing Discovery 시에 이를 교환 및 동기화하는 것은 Network Throughput에 많은 영향을 미치며 Throughput을 굉장히 큰 범위로 변동되게 한다. 이에 따라 아직 convergence(수렴)이 안된 시점에는 주기를 더 빈번하게 하고, 후에는 이를 되돌리도록 하는 설정이 필요하기에 이 또한 추가되었다.\n\n> **2. Packet Loss**\n\n시작지와 목적지의 Switch에서 해당 Flow에 대한 Packet Counting을 수행하여 계산한다.\n\n> **3. Delay**\n\nPacket을 하나 생성하여 출발 시간과 도착 시간을 통해 측정한다. 따라서, 다음과 같은 식으로 정리할 수 있다. 아래 RTT는 Controller와 각 Switch 간의 RTT를 의미한다.\n\n$$ t_{delay} = (t_{arrival} - t_{sent} - {{1}\\over{2}}({RTT}_{sentSwitch-controller} + {RTT}_{arrivalSwitch-controller})) $$\n\n## Evaluation\n\n실제 실험을 통해서 OpenNetMon에 대한 성능을 테스팅하였다. 이과정에서 총 4개의 OpenFlow를 지원하는 Switch를 일자로 연결하고 각 말단에 Server와 Client를 연결한 후에 각 Switch가 POX OpenFlow Controller에 직접적으로 연결되도록 구성하고, 각 말단과 Server/Client로의 연결은 1Gbps Ethernet로 연결하고, Switch간의 연결은 100Mbps에 1% loss, 1ms delay로 설정을 하였다. 실제 전송 데이터는 video stream traffic을 활용하여 복잡한 traffic 전송을 표현하고자 했다.\n\n실제 그래프와 Topology는 직접적으로 가져오지는 않았다. 아무래도 저작권에 대해서 제대로 알 수 없어서 가져오지 않았다. 하지만, 논문과 같이 비교하면서 보면 도움을 받을 수 있을 것이다.\n\n> **1. Throughput**\n\nApplication Level에서 구현한 `tcpstat`과 비교했을 때, 16KB/s(1.2%) 정도 밖에 차이가 나지 않았다. 하지만, 초기에 17.8%까지 차이가 발생하는데 이는 초기 준비 기간으로 만약 초기 준비 기간을 준다면 해결 가능하다. 또한, 한 번씩 spike가 발생하는데 이는 polling 과정에서 이전 요청보다 현재 요청이 먼저 도착할 때 발생한다. 이를 위해 synchronization을 맞춰주기 위한 로직을 추가한다면 해결이 가능하다. 여기서는 sleep과 mutual exclusion을 이용하기를 권장한다.\n\n> **2. Packet Loss**\n\n정확하지는 않지만 받아들일 수 있을 정도의 오차밖에 발생하지 않는다.\n\n> **3. Delay**\n\nControl Plane에 기반하여 전송하는 방법과 VLAN을 기반으로 Data plane으로 전송하는 법 그리고 실제로 user가 체감하는 delay를 비교했을 때, Control Plane을 그대로 이용하는 경우에는 생각보다 큰 오차가 발생한다. 이는 Controller에서 Software Scheduling 과정에서 발생하는 에러이기에, VLAN을 기반으로 Data Plane을 이용하는 경우에는 실제 데이터와 비교해도 오차가 거의 없는 것을 볼 수 있다.\n\n## Review\n\n해당 논문은 OpenFlow가 나오고 이를 이용해서 Monitoring을 수행하고자 했던 여러 ISP와 연구자들에게 도움을 주었다고 생각한다. 이를 통해서 OpenFlow를 이용한 여러 Monitoring 방식이 연구되었던 것 같다. 그래서 Network 논문임에도 261건 정도의 인용수를 획득한 것으로 보인다. 또한, OpenFlow를 이용한 Monitoring 방식을 사용한다는 것이 흥미로웠고, 기존의 Monitoring 방식을 OpenFlow를 통해서 적용해보는 것이 당시 연구에서 중요했던 포인트였던 것으로 보인다. 새로운 기술에 기존 기술의 아이디어를 접목하는 것도 고려해서 논문을 작성하는 것도 좋은 방법이라고 생각된다. 또한, 구현이 Github로 open되어있기 때문에 신뢰도도 높았던 것으로 보인다. 만약 해당 부분을 좀 더 확인하고 싶다면 인용 논문을 좀 더 탐색해보는 것도 좋은 방법이 될 것 같다.\n\n작성자가 Posting을 작성하는 날짜를 기준으로 261 번의 인용수를 자랑하는 논문을 리뷰한 것이다. 앞으로도 NOMS 논문 중에서 인용수가 많았던 논문들을 위주로 한 번 Review를 진행할 예정이다.\n\n## Reference\n\n- Niels L. M. van Adrichem, Christian Doerr, Fernando A.Kuipers, [`\"OpenNetMon: Network Monitoring in OpenFlow Software-Defined Networks\"`](https://ieeexplore.ieee.org/document/6838228), June 2014\n- Thumbnail : Photo by [Tobias Tullius](https://unsplash.com/@tobiastu?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@tobiastu?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n","slug":"open-net-mon","date":"2022-06-27 14:02","title":"OpenNetMon","category":"Paper","tags":["SDN","Monitoring","OpenFlow"],"desc":"<https://ieeexplore.ieee.org/document/6838228에 기재된 OpenNetMon: Network Monitoring in OpenFlow Software-Defined Networks의 내용에 대한 리뷰이다. 이름에서 알 수 있듯이 OpenNetMon은 POX OpenFlow Controller를 이용하여 수많은 network component로 이루어진 fine-grained Network에서 Traffic Engineering을 위한 QoS Metric을 flow 단위로 제공하는 것을 목표로 한다. 수집하는 데이터는 Throughput, Packet Loss, Delay를 측정한다.","thumbnailSrc":"https://euidong.github.io/images/monitor.jpg"}],"Network":[{"content":"\n## Intro\n\nMPLS는 2계층과 3계층 사이에서 Routing을 가속화하기 위한 방법으로 제시된 방법이다. 뿐만 아니라 기존에 존재하던 Networking의 문제를 보완하기 위해서 고안되었기에 여러 우수한 기능을 가지고 있다.\n\n## MPLS\n\n기존의 Routing에서는 매 hop(router)당 Routing Table을 참조하여 packet을 전송했다. 하지만, 이 과정은 생각보다 많은 시간이 필요하다. 이를 이용해서 화상 통화 등을 한다면, 서비스 품질이 매우 떨어질 위험이 있다. 따라서, MPLS는 Routing를 더 빠르게 하고, 품질 항상을 위해서 만들어졌다. 이는 Multi-Protocol Label Switching(MPLS)이라는 말처럼, 기존의 IP를 이용한 Routing이 아닌 Label(또는 tag)이라는 별도의 data를 이용하여, 3계층을 거치지 않고, Routing을 고속화하는 역할을 할 수 있다.\n\n또한, **MPLS**에서는 사전에 고효율 경로를 설정하고, 이를 통해서 통신하도록 하여 성능 문제를 해결한다. 예를 들어, Packet이 들어오면, 진입점에 있는 Router(Ingress Router)가 해당 Packet에 Label을 표기하고 내부 Network로 전송하게 된다. 이제 내부 Router에서는 Packet을 모두 확인하지 않고, 해당 Label만을 이용하여 Forwarding을 수행한다. 그렇기에 더 빠른 Routing이 가능해지는 것이다.\n\n![MPLS packet](/images/mpls-label.jpeg)\n\n하지만, 그 외에도 추가로 더 많은 장점을 보유하고 있다.\n\n1. 여러 Protocol과 호환이 가능하도록 overlay로 개발되었다. (2.5 Layer라고도 불리는 이유이다.)\n2. TE(Traffic Engineering)를 위한 여러 설정을 제공한다. 따라서, bandwidth, QoS(서비스 품질)에 따라서 Traffic을 제어하는 것이 가능하다.\n\n## 용어\n\n- MPLS Network : **MPLS**를 통해서 구축한 Network를 의미한다. 해당 Network로 진입하는 순간 Packet에는 Label과 부가적인 header가 추가된다.\n- Label : Label은 각 Router에게 하나씩 주어지는 Router의 고유 식별값이다.\n- LER(Label Edge Router) : Network 제공자 입장에서 Edge Router로 두 가지 종류로 나뉜다.  \n  Ingress와 Egress는 항상 고정인 것이 아니라 packet에 입장에서 계속해서 변경된다.\n  - Ingress Router: packet이 Network로 진입하는 Router로 실제 Network를 전체 조회하고, Label을 추가하는 역할을 한다.\n  - Egress Router : packet이 Network를 탈출하는 Router로 Packet의 남아있는 Label을 삭제한다.\n- LSR(Label Switched Router) : MPLS Network 내부에 존재하는 LER이 아닌 Router들로 이들은 Packet의 Label을 Switching하고, Forwarding하는 역할을 수행한다.\n\n![mpls-example](/images/mpls-example.jpeg)\n\n## 동작 원리\n\n`LSP(Label Switched Path)라는 최단 경로를 찾고, 이를 통해서 Packet을 전달시킨다.`가 Protocol의 핵심적인 전략이다. 형성된 LSP에 따라서 labe들을 설정해두면, 이제 내부 Router에서는 자신에게 해당하는 Label을 교환하여 다시 Forwarding을 수행하면 되는 것이다. 따라서, 3계층을 거치지 않고 Routing이 가능하다. 위에서 나온 용어로 정리하자면, Ingress LER에서는 packet의 목적지와 요청지 정보 등을 활용하여 LSP을 구성하고, 이에 알맞는 Label을 packet에 추가한다. 이제 이 packet을 받은 LSR에서는 Label을 하나 빼고, 다음 LSR을 찾아가기를 반복하며, egress LER에 도달한다. egress에서는 Label이 남아있다면, 모두 제거하고, 원래 사용 중이던 Protocol에 맞게 다시 Routing을 수행한다.\n\n![mpls-example](/images/mpls-example-2.jpeg)\n\n### LSP 구성\n\n총 3가지 방법을 통해서 생성이 가능하다. 이는 후에 나올 Configuration에 따라서 어느정도 바뀌게 된다.\n\n1. Best Effort LSP : Label 할당이 알고리즘에 의해서 자동적으로 할당되며, 항상 연결이 지속될 수 있도록 하는 것을 최대 목표로 하기 때문에 여타 방식들에 비해 성능이 떨어질 수도 있지만, 장애 대응에 적절하다고 할 수 있다.\n2. Static LSP : Label을 직접 수작업을 통해서 할당해주며, 경로를 customizing할 수 있지만, 이로 인해서 예상치 못한 문제가 발생할 수도 있다.\n3. Signaled LSP : 일정 이상의 자원(Bandwidth, 등)을 제한하여 경로를 최적화할 수 있다.\n\n### Configuration\n\nMPLS network를 구성하기 위해서는 결국 각 Router에 Label을 나누어주는 것과 LSP를 구성하는 것이 중요하다. 아래에는 대표적인 MPLS의 Topology를 살펴본다.\n\n- LDP : 위에서 설명한 Best Effort LSP를 구성하는 Protocol로 Label을 분배하고, 각 Router에서는 Label의 Push/POP/Swap을 수행한다.\n- RSVP-TE : 특정 제약 조건을 먼저 제시를 하고, 이를 기반으로 이와 일치하는 경로를 찾아서 packet을 Routing하는 방식이다.\n\n## Versus\n\n| 구분                   | ATM       | IP        | MPLS      |\n| :--------------------- | :-------- | :-------- | :-------- |\n| IP Traffic Engineering | 우수      | 보통      | 매우 우수 |\n| 고속 포워딩            | 매우 우수 | 보통      | 우수/보통 |\n| QoS                    | 매우 우수 | 보통      | 우수      |\n| VPN 비용               | 고가      | 저가      | 중가      |\n| 확장성                 | 우수      | 매우 우수 | 매우 우수 |\n| 구축 / 유지 비용       | 매우 고가 | 저가      | 고가      |\n\n## References\n\n- Thumbnail : Photo by [Tyler Farmer](https://unsplash.com/@tylerfarmer?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/s/photos/forwarding?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n- <https://www.itworld.co.kr/tags/6580/MPLS/108621>\n- <https://blog.naver.com/thorong/70147777745>\n","slug":"mpls","date":"2022-05-22 15:25","title":"MPLS","category":"Network","tags":["Routing"],"desc":"MPLS는 2계층과 3계층 사이에서 Routing을 가속화하기 위한 방법으로 제시된 방법이다. 뿐만 아니라 기존에 존재하던 Networking의 문제를 보완하기 위해서 고안되었기에 여러 우수한 기능을 가지고 있다.","thumbnailSrc":"https://euidong.github.io/images/routing.jpg"},{"content":"\n## Intro\n\nmininet은 현실적인 가상 네트워크 환경을 구축해주는 `Network Emulator`, 더 정확히는 `NETOWKR Emulation Orchestration System`이다.  \n이를 통해서, 가상의 End Device(Host), 각종 Switch, Router, 그리고 이를 연결하는 Link를 단 하나의 Linux Kernel로 만들 수 있다. 여기서 그치지 않고, 각 Host에 `ssh` 접근을 수행하여 기본 Linux Kernel 동작을 수행하거나 ethernet을 이용해서 각 device로 packet을 전송하는 것과 같은 효과를 볼 수 있다. (실제 speed와 delay에 기반한 속도를 볼 수 있다.) 또한, SDN과 같은 환경에 필요한 Controller 역시 구성하는 것이 가능하다. 그렇기에 실제로 SDN Network를 Test하고 연구하는 목적으로 많이 사용되고 있다.\n\n## 장점\n\n1. Fast - 가상 네트워크의 구성이 굉장히 빠른 시간 내에 구성된다. 실제로 동작해보면, 이를 알 수 있다.\n2. Customize Topology - 간단한 네트워크에서부터 시작해서, Backborn, Datacenter, Internet 등 모든 네트워크 구성이 가능하다.\n3. Can run every programs in Linux - 간단한 Web Server에서부터 시작하여 Mornitoring Service인 Wireshark 등의 활용이 가능하다.\n4. Progammable - 각 Switch의 동작도 programming이 가능하기에 OpenFlow Protocol을 기반으로 packet forwarding 역시 customizing이 가능하다.\n5. LightWeight - Labtop에서 돌아갈 정도로 가볍다.\n6. Can share results - 각 Topology와 같은 구성은 python code로 구성되고, test code 등도 쉽게 공유가 가능하다.\n7. Easy - Mininet 실행과 구축 그리고 운영이 매우 간단한 CLI, Python code로 작성이 가능하기 때문에 매우 쉽다.\n8. OpenSource - 쉽게 커뮤니케이션이 가능하고, 누구나 해당 프로젝트에 참여가 가능하다.\n\n## 주의사항\n\n1. 만약 10Gbps 이상의 traffic을 처리하기를 원하는 경우, 부하를 적절히 분배하기 위한 구조를 실행자 측에서 구성할 필요가 있다.\n2. Mininet은 하나의 Linux Kernel을 통해 모든 Virtual Host를 제어한다. (다른 Platform, Window 등은 지원하지 않는다. VM 필요)\n3. Mininet에서는 OpenFlow Controller를 사용할 수는 있지만, 이를 직접 제어할 방법은 제공하지 않는다.\n4. 기본적으로는 Host LAN과는 분리되어 있다. (물론 `NAT`를 통해서 연결도 가능하다.)\n5. 기본적으로 Mininet에 의해 생성된 Host는 PID와 file system을 공유한다. (물론 바꿀 수는 있지만, 유의하자.)\n6. Simulator가 아니기 때문에, Virtual Time에 대한 매우 정확한 지표를 제시할 수는 없다.\n\n> Mininet 활용\n\nMininet을 제대로 활용하기 위해서는 다음과 같은 사항을 숙지해야 한다.\n\n0. 설치\n1. Topology 생성\n2. Performance 측정\n3. OpenFlow를 이용해서 Custom Routing\n\n이제부터 위의 내용을 하나하나 수행해 볼 것이다.\n\n## 0. 설치\n\n[Mininet Repo](https://github.com/mininet/mininet)\n\n위의 링크에서 INSTALL이라는 파일에 따라서 설치를 진행해보자. 역시 제일 쉬운 것은 제작자가 직접 만들어놓은 Virtual Machine 이미지를 활용하여 실행하는 것이다.\n\n## 1. Topology 생성\n\n아래의 형태가 가장 기본적인 형태의 Topology이다. 이를 실행시키면, 기본적으로 두 개의 Host가 하나의 Switch에 각 각 연결된 형태로 구성되어진다.\n\n![one-switch-topology](/images/one-switch-topo.jpeg)\n\n```python\nfrom mininet.topo import Topo\n\nclass SingleSwitchTopo(Topo):\n  \"Single switch connected to n Hosts.\"\n  # build function 내부에서 topology를 구성하는 요소에 대해 정의\n  # self.__init__의 parameter가 해당 함수로 그대로 전달된다.\n  def build(self, n=2):\n    # s1이라는 이름으로 Switch 생성\n    switch = self.addSwitch('s1')\n    for h in range(n):\n      # h1, h2, ... 이라는 이름으로 Host 생성\n      host = self.addHost('h%s' % (h+1))\n      # h1, h2, ... 을 s1과 연결\n      self.addLink(host, switch)\n\n# 후에 topology를 생성할 때, 아래 이름을 통해서 지정이 가능\ntopos = { 'singleSwitch': (lambda: SingleSwitchTopo())}\n```\n\n이를 파일로 생성하고, 다음과 같이 실행시키면 된다.\n\n```bash\n$ sudo mn --custom [file명.py] --topo [topology 이름],[build function parameters]\n\n# example\n$ sudo mn --custom mytopo.py --topo singleSwitch,3\n```\n\n하지만, 위와 같이 mininet command를 통해서 실행시키는 것은 자동화에는 적절하지 않을 수 있다.  \n만약, 부가적인 설정을 해주고 싶거나 실행 후에 test 및 실험하고자 하는 상황을 만들고자 한다면 추가적인 programming이 필요하다.  \n아래 코드를 추가적으로 살펴보자.\n\n```python\nfrom mininet.topo import Topo\nfrom mininet.net import Mininet\nfrom mininet.util import dumpNodeConnections\nfrom mininet.log import setLogLevel\n\nclass SingleSwitchTopo(Topo):\n  \"Single switch connected to n Hosts.\"\n  def build(self, n=2):\n    switch = self.addSwitch('s1')\n    for h in range(n):\n      host = self.addHost('h%s' % (h+1))\n      self.addLink(host, switch)\n\ndef simpleTest():\n    \"Create and test a simple network\"\n    topo = SingleSwitchTopo(n=4)\n    # Mininet 생성\n    # 이때, Topology, Host, Switch, Controller, Link 등에 대한 Customizing이 가능하다.\n    net = Mininet(topo)\n    # mininet 실행\n    net.start()\n    print( \"Host의 연결 상태를 출력\" )\n    dumpNodeConnections(net.hosts)\n    print( \"Netowork 연결 상태를 체크\" )\n    # ping to every node with each node.\n    net.pingAll()\n    # mininet 정지\n    net.stop()\n\nif __name__ == '__main__':\n    # Tell mininet to print useful information\n    setLogLevel('info')\n    simpleTest()\n```\n\n```bash\npython [file명.py]\n```\n\n이를 통해서, Mininet를 우리가 정의한 Topology에 따라서 실행하고 테스트를 수행하는 code이다.  \n이러한 기능 뿐만 아니라 host의 성능을 제한하거나 Link 용량을 제어할 수도 있고, Switch를 제어할 수도 있고, 특정 Host에서 Command를 실행시키도록 할 수도 있다.  \n더 자세한 사항은 아래 링크를 통해서 확인해보자.\n[More Example](https://github.com/mininet/mininet/tree/master/examples)\n\n위에서 살펴본 사항은 가장 기본적인 Mininet에서 제공하는 Template에 기반하여 programming을 수행하는 것이다. 만약, 직접적으로 제어를 원하는 경우 더 하위 단계의 API를 활용하여 구현하는 것도 가능하다. [API Doc](http://api.mininet.org)\n\n### 추가 참고사항\n\ncode convention이 후에 버전에서는 좀 변경되었다.\n\n- camelCase 표기가 snake_case형태로 변경되었다. example. `addHost -> add_host`.\n- `build`가 `__init__`으로 바뀌어, 나의 기준에서는 이해하기 쉬워졌다.\n\n변경되었지만, 여전히 기존 버전 표기도 지원하기 때문에 사용하는데는 문제가 없다.\n\n## 2. Performance 측정\n\n해당 사항은 Mininet에서 권장하는 방법이다.\n\n1. Bandwidth - `bwm-ng`, `ethstats`\n2. Latency - `ping`\n3. Queues - `tc`\n4. TCP Congestion Window statistics - `tcp_probe`\n5. CPU usage - for all: `top`, per host: `cpuacct`\n\n## 3. OpenFlow를 이용해서 Custom Routing\n\nMininet 자체만으로도 값지지만 SDN을 구축하기 위한 OpenFlow Protocol을 이용한 Routing을 Emulating할 때에 굉장한 효과를 얻을 수 있다.  \nMininet을 실행시킬 때에 아무 설정을 하지 않으면 기본 Ethernet switch를 사용하는 기본 Controller를 사용한다. 하지만, Open vSwitch(ovs)와 같은 OpenFlow Protocol을 지원하는 Controller를 활용할 수도 있다.  \n기본적인 Switch(대략 4096개)는 이미 지원을 하고 있다. 이를 불러와서 사용하거나 원하는 경우에는 python을 통해서 직접 구현하여도 무방하다. 심지어는 원격에 있는 controller를 사용할 수도 있다.\n\n이렇게 Controller를 정의하고, 외부에서 해당 Controller의 동작을 정의해주면, Mininet에 의해서 정의된 Network가 의도대로 동작하는지를 계속해서 확인할 수 있다.\n\n## NutShell\n\nMininet에서 어떻게 이렇게 빠르게 가상 Network System을 가볍게 구현할 수 있는가에 대한 열쇠는 `container`이다. 이를 통해서, 서로 완전 분리된 Host를 기본적으로 구성하는 Container이기에 이를 쉽게 구현할 수 있을 뿐만 아니라 Virtual Machine을 직접적으로 구현하지 않기 때문에 가볍고 빠를 수 있는 것이다. 또한, Virtual Link 같은 경우에는 Linux Traffic Control(`tc`)를 활용하여, Virtual Ethernet이 각 Virtual Switch와 Interface들을 통해서 전달되는 것을 제어할 수 있다. 마지막으로, Switch는 기본적인 Linux Bridge를 활요하거나 Open vSwitch를 활용하여 구성하여 가상화가 가능하다.\n\n## 결론\n\nMininet은 가상 Network를 Emulating 할 수 있는 Tool이기에 실제로 SDN을 테스트하기 이전에 각종 기능을 체크하기에 용이하다.  \n또한, Network에서 핵심적인 Forwarding에 관한 기술은 다른 기술에게 맡겨서 더 안정적인 구조를 가지고 있다.  \n이에 따라 Open vSwitch를 이용해서 자유롭게 시스템을 제어할 수 있을 뿐만 아니라 ONOS와 같은 도구를 통해서 Network를 구성하는 과정을 테스트하기에 굉장히 유용하다.\n\n## Reference\n\n- Thumbnail : Photo by [Jordan Harrison](https://unsplash.com/@jordanharrison?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/s/photos/network-cable?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n- mininet : <https://github.com/mininet/mininet/wiki/Introduction-to-Mininet>\n","slug":"mininet","date":"2022-05-24 12:58","title":"Mininet","category":"Network","tags":["Emulator","Tool"],"desc":"mininet은 현실적인 가상 네트워크 환경을 구축해주는 Network Emulator, 더 정확히는 NETOWKR Emulation Orchestration System이다.  이를 통해서, 가상의 End Device(Host), 각종 Switch, Router, 그리고 이를 연결하는 Link를 단 하나의 Linux Kernel로 만들 수 있다. 여기서 그치지 않고, 각 Host에 ssh 접근을 수행하여 기본 Linux Kernel 동작을 수행하거나 ethernet을 이용해서 각 device로 packet을 전송하는 것과 같은 효과를 볼 수 있다. (실제 speed와 delay에 기반한 속도를 볼 수 있다.) 또한, SDN과 같은 환경에 필요한 Controller 역시 구성하는 것이 가능하다. 그렇기에 실제로 SDN Network를 Test하고 연구하는 목적으로 많이 사용되고 있다.","thumbnailSrc":"https://euidong.github.io/images/switch-with-cable.jpg"},{"content":"\n## Intro\n\nNetwork는 여러가지 종류가 존재한다. 일반적인 LAN을 제외한 Network의 대표적인 종류(BackBorn, Internet, Datacenter, 등)를 알아본다.\n\n## BackBorn Network\n\nBackBorn은 등뼈, 중추를 의미한다. 즉, 네트워크의 중추라는 것이다. 해당 네트워크는 각 Node와 Node를 직접적으로 연결하기 보다는 이미 구성되어있는 LAN 간의 연결을 수행하는 네트워크이다. 작은 범위에서는 특정 건물 내에서의 LAN간을 연결하는 Network를 의미하기도 하지만 대게의 경우 LAN과 Internet을 연결하는 Internet BackBorn Network를 의미한다. 이러한 BackBorn Network는 앞 서 살펴본 LAN과의 연결 뿐만 아니라 대게 4가지의 역할을 할 수 있어야 한다.\n\n1. 서비스 서버 및 국내 외 타 사업자 연결\n2. 고가용도 스위치 및 라우터를 사용하며, 이중화를 구성\n3. 타 통신사업자와의 연동을 위한 IX(Inter Exchange)를 구성\n4. 데이터센터와 연결되는 Switch를 제공\n\n우리가 Ethernet을 통해서 공유기에 packet을 전달하면, 공유기는 건물 내 Switch로 연결되고, 이것이 BackBorn Network로 packet을 보내면 BackBorn에서 이를 올바른 Network로 다시 옮기는 역할을 수행한다.\n\n대게 이와 같은 일은 통신사업자(국내에는 KT, SKT, LG)가 수행하고 있다. 물론 접속하고자 하는 사이트가 해외에 위치하는 경우 해외 통신사업자의 BackBorn으로 넘어가서 해당 Network를 찾게 되는 것이다. 따라서, 이를 그림으로 나타내면 아래와 같다.\n\n![backborn network](/images/backborn-network.jpeg)\n\n### Topology in Backborn Network\n\n이러한 BackBorn Network를 구성할 때에 주로 사용되는 것은 Star topology이다. 이는 Star topology는 하나 이상의 중심 node로 traffic이 몰리게 되는데 이러한 구조는 관리 및 요금 측정 등과 같은 과정을 쉽게 처리하는 것이 가능하기 때문이다. 하지만, 중심으로 traffic이 집중되는 만큼 재난 발생에 취약할 수 있고, 이로 인한 지연으로 인해 전송 효율이 감소할 수도 있다.\n\n미국의 통신사업자 AT&T는 Mesh Topology를 활용하는데 이는 중앙에 모든 Traffic이 집중되지 않기 때문에 가용성이 높고, 국제적인 Traffic이 많고, 이로 인한 traffic이 많기에 토지가 큰 미국의 특성을 이용해 다른 지역에서 사용하지 않는 장비를 우회해서 traffic을 처리할 수 있다는 장점이 있다. 하지만, 유지 관리 과정이 다소 난해하고 이로 인한 비용이 Star Topology보다 크다고 할 수 있다.\n\n## Internet\n\nInternet은 서로 다른 Network를 연결하는 또 하나의 Network이다. 대게 필연적으로 Internet 통신이라고 하면, BackBorn을 거쳐서 통신하는 것을 Internet이라고 하는 경향이 있다.\n\n### 이동통신\n\n부가적으로 대게의 통신 사업자는 국내 지역에 기지국(Base Station, 대게 전봇대에 설치된 경우가 많다.)을 통해 이동 통신 종량제 네트워크 서비스를 제공한다. 이 역시 BackBorn Network와 연결되어 각종 서비스를 제공한다.\n\n### 이중화\n\nBackBorn Network의 가장 중요한 특징 중 하나가 고가용성을 제공해야 한다는 것이다. 즉, 끊기지 않는 Network를 지향한다는 것이다. 이를 위해서 망 자체를 이중화하고, BackBorn과 연결되는 Router에서의 Link 사용률을 40%로 제한함으로써 일부 장애시에도 문제가 발생하지 않도록 하는 것이다. 또한 Star Topology의 경우 Core Router로 향하는 Link를 삼중화하여 특정 Link에 에러가 발생하여도 최대한 통신이 가능하게 하고자 노력하고 있다.\n\n## Datacenter Network\n\nDatacenter는 Service를 제공하는 업체들에서 다양한 Application을 제공하기 위해서 여러 machine을 모아두고 저장해놓은 기관이다. 이러한 Datacenter Network의 규모가 Backborn Network의 규모를 넘어서고 있는 시점에서 중요성이 더 커지고 있다.\n\n### Term\n\n- Rack : 수 많은 machine을 효율적으로 저장하기 위해서 층별로 machine을 저장하여 보관하는 수납 공간 또는 수납된 모든 machine을 의미한다.\n- ToR Switch : Top of Rack Switch의 약어로 Rack의 machine에게 Network를 제공하기 위해서 Rack의 최상단에 존재하는 Switch를 말한다.\n\n### Topology in Datacenter Network\n\n- Tree : 매우 직관적인 구조의 Topology이다. 각 ToR Switch가 더 상위 Switch인 Access(=Edge) Switch에 연결되고, 해당 Access Switch가 Aggregation Switch/Router로 연결되고, 최종에는 Core Router에 연결되어 해당 Core Router를 통해서 Internet에 연결되는 형태를 가지고 있다. 이와 같은 경우 3가지 큰 특징을 가진다.\n  - 특징\n    - Over Subscription : 상위 Switch/Router/Link의 bandwidth가 하위 Switch/Router의 bandwidth보다 크도록 설계하는 것\n    - Same Distance with Core : Core와의 거리가 모든 rack에서 동일하기 때문에 효율적인 Networking이 가능하다. 이러한 Traffic을 North-South Traffic이라고 한다.\n    - No Loop : Tree 구조 자체가 Loop가 없는 형태이기 때문에 Loop로 인한 Traffic 혼잡을 막을 수 있다. 만약, East-West Traffic을 위해서 link를 중간에 증설하였다면, 이를 해결하기 위하여 Spanning Tree Protocol을 활용하여, Loop를 없애기 위한 설정을 한다.\n  - 단점\n    - East-West Traffic의 낮은 효율 : 좌우 Traffic이 빈번하게 발생한다면, 이로 인한 비효율이 크게 발생할 수 있다. Virtual Machine이 굉장히 많이 사용되고 있는 상황에서 어느 Physical Machine에 Virtual Machine이 존재하더라도 동일한 IP를 유지한다거나 동일한 수준의 가상화를 제공하기 위해서 이러한 East-West Traffic이 많아지고 있다(80% 이상을 차지하고 있다). 따라서, 현재에 사용이 많이 줄었다.\n    - 확장이 어려움 : 상위 계층이 하위 계층의 BandWidth에 의존하기 때문에 초과량을 넘은 경우 확장이 모든 구간에서 수행되어야 한다.\n- Spine-Leaf(=Clos, Leaf-Spine) : 상위 Spine Switch/Router에 모든 하위 Leaf Switch/Router가 연결되어 있고, 이 Leaf Switch/Router에 ToR Switch가 연결되어 있는 구조이다. 이러한 구성을 갖추게 되면, East-West Traffic의 처리가 매우 용이하다.\n- Fat-tree : Tree의 Edge/Aggregation Switch/Router의 수를 k개로 Group을 만들고, 해당 Group을 k개 만들어서 여러 개의 Core를 두어 구성하는 형태이다. 마찬가지로 East-West Traffic의 처리 역시 매우 용이하다.\n\n## Edge Computing Network\n\n통신 사업자 입장에서 가입자와 인접한 전화국에 서버 pool(소규모 datacenter)을 구축하고, 이를 통해서 보안 또는 요금 측정 등과 같은 Network 기능을 구현하고자 하는 네트워크를 구축하고 있다.\n\n## Optical Transport Network(광통신망)\n\n광케이블을 이용하여 구축한 Physical Network로 고속 통신을 지원하기 위해서 고안되었다. 이는 후에 Posting에서 자세히 다룰 예정이다.\n\n[🔗 광통신망](/posts/optical-transport-network)\n\n## Digital Subscriber Line(DSL)\n\nADSL부터 시작되어 여러가지 형태로 변화되어온 Network 형태이다. 종류는 다양하게 ADSL/HDSL/SDSL/RADSL/VDSL 등으로 존재한다.\n\nADSL은 Asymmetric Digital Subscriber Line의 약자로 전화선을 이용한 통신 방식이다. 1988년 미국에서 최초 개발되었고, 현재에도 저가형 인터넷 서비스에 사용 중이다. 또한, VDSL은 주파수 대역을 확장하여 속도 향상을 꾀하였다.\n\n## Reference\n\n- Thumbnail: Photo by [Markus Spiske](https://unsplash.com/@markusspiske?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/s/photos/internet?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n\n인터넷이 처음 세상에 등장한 이래로 다양한 종류의 네트워크 구조가 만들어졌다. 작게는 우리가 사용하는 Wifi를 구성하는 LAN 영역에서 부터 전체 세상을 연결하는 Internet와 같은 광범위한 네트워크가 존재한다.\n","slug":"types-of-network","date":"2022-05-27 09:59","title":"Network의 종류","category":"Network","tags":["BackbornNetwork","Internet","DatacenterNetwork","EdgecomputingNetwork","AccessNetwork"],"desc":"Network는 여러가지 종류가 존재한다. 일반적인 LAN을 제외한 Network의 대표적인 종류(BackBorn, Internet, Datacenter, 등)를 알아본다.","thumbnailSrc":"https://euidong.github.io/images/base-station.jpg"},{"content":"\n## Intro\n\nSDN의 본격적인 시작이 OpenFlow라고 보아도 무방하다. OpenFlow는 2007년 Stanford 대학에서 개발이 시작되었고, 지금도 de facto standard(사실상의 표준)으로 받아들여지고 있는 Protocol이다. 해당 Protocol의 핵심은 기존 Switch/Router를 data plane(데이터 평면)과 control plane(제어 평면)으로 나누고, 제어 평면을 OpenFlow Protocol에 따르는 Controler로 대체하면서, OpenFlow Protocol을 따르는 Switch는 data plane만을 포함하여, 둘 간의 통신을 통해서 제어 평면을 구성하자는 것이다. 여기서 데이터 평면은 실제로 interface로 packet이 들어오고, 내보내는 역할을 하는 계층이라고 보면 되고, 제어 평면은 packet에 어떤 동작을 수행시킬지 그리고 어느 interface로 내보낼지를 결정하는 역할을 하는 계층이라고 보면 된다. 이러한 구성을 통해서, 결국 SDN을 구축할 수 있는 토대를 제공하게 된 것이다.\n\n## OpenFlow Switch\n\nOpenFlow Switch는 다음과 같은 형태로 구성되어진다.\n\n![OpenFlow Switch](/images/openflow-switch.jpeg)\n\n## OpenFlow Protocol\n\n해당 사항은 reference에 기반한 version 1.3.1의 기능을 요약한 내용이다.\n\n기본적으로 OpenFlow Protocol을 지원하는 Switch의 구조부터 알아보아야 한다. Switch는 기본적으로 외부와 연결이 가능한 Port, Routing을 위한 여러 개의 Table, 그리고 Controller와의 의사소통을 위한 Channel을 가진다. 각 요소의 역할을 간략히 하나하나 알아보도록 하자.\n\n> **1. Port**\n\nOpenFlow에서 packet이 Switch로 왔다갔다하는 통로라고 볼 수 있다. 대게 Switch를 가르키거나 packet의 진입 위치를 식별할 때 사용된다. 이는 실제로 존재하는 것이 아닌 추상화된 개념으로, 총 3가지의 Port를 통해서 Switch를 가르킬 수 있다. 각 Switch는 여러 개의 Port를 가지고 이를 통해서 다른 Switch들과도 연결되어진다.\n\n- Physical Port : 실제 Switch의 interface와 일대일로 대응되는 가상 Port이다. 즉, 해당 interface로 packet이 들어왔다면, OpenFlow에서는 이와 대응되는 port로 packet이 들어왔다고 판단한다.\n- Logical Port : OpenFlow를 쓰지 않고, Switch 자체적으로 정의한 Tunnel과 Loopback과 같은 가상 Port이다.\n- Reserved Port : OpenFlow Protocol에 의해서 정의된 Port이다. 이를 통해서, Controller, All, Table의 맨 처음, IN_PORT 등을 쉽게 가르킬 수 있다.\n\n> **2. Table**\n\nSwitch는 여러 개의 Table을 가지고 있다. Table을 통해서 Switch는 Routing을 수행하는 것은 기본적인 Switch의 동작과 동일하다. Switch의 특정 Port로 packet이 들어왔을 때, packet의 목적지와 진입한 Port, 그 외에 metadata에 기반하여 matching을 수행하여 일치하는 대상을 찾아서, 해당 Table에 기술된 동작을 수행하는 것이다. 대게 무슨 동작을 수행할 것인가에 따라서 종류가 나뉘어지며, v1.3.1에는 총 3가지의 종류가 존재한다.\n\n1. Flow Table : 대게 어떻게 Packet을 어느 Port로 Routing할 것인가를 다룬다. 뿐만 아니라 Packet의 Header를 변경하거나 MPLS Label과 같은 추가 정보를 더하는 등의 동작을 수행할 수 있다. (각 Switch는 하나 이상의 Flow Table을 소유한다.)\n2. Group Table : 패턴과 일치하는 packet에 대해서 여러 동작을 수행하게 하거나 상황에 따라 다르게 적용하도록 하기 위해서 사용할 수 있다. (각 Switch는 1개 이하의 Group Table을 소유한다.)\n3. Meter Table : packet의 빈도(rate) 조절과 측정을 수행할 수 있다. (Meter Table은 Controller에 의해서 관리된다.)\n\n> **3. OpenFlow Channel**\n\nOpenFlow Switch 내부에서 Controller를 연결하는 Interface로 Switch의 상태를 Controller에게 알리거나 Controller로 부터 변경사항을 전달 받기 위한 통신 채널이다.\n\n---\n\n이렇게 이루어진 OpenFlow Switch들은 서로 연결되어 있으며, 하나 또는 여러 Controller와 각 각 연결되어 있다. Controller는 각 OpenFlow Switch로 부터 상태 정보와 인접 Switch 정보 등을 전달받아서 내부적으로 Flow Table을 구축한다. 그리고, Controller에서 중앙 통제를 통해서 전체 네트워크를 관리할 수 있는 것이다. 이를 수행할 때에는 Controller에서 각 Switch의 Table을 지정함으로써 구현이 가능하다. 그렇다면, Switch에 Table을 설치하였을 때, 어떻게 Packet을 처리하는지에 대해서 알아보자.\n\n### Pipeline\n\nSwitch 내부에는 여러 개의 Table이 존재하는데, Packet이 Switch의 특정 Port로 들어오면, 먼저 Flow Table을 거치게 된다. Switch 내부의 여러 Flow Table 중에서 index($\\ge 0$)가 작은 값부터 시작하여 Flow Table에서 일치하는 pattern의 Flow Entry를 찾게 된다(Flow Table의 하나의 열). 해당 Entry에 적힌 `Instruction`에 따라 `Action`을 바로 수행하거나 `Action Set`에 추가한 후에 다음 Table 또는 Port를 통해서 다음 Switch로 이동하게 된다. 이때 Port 밖으로 나가기 이전에 Action Set에 모아둔 Action을 한 번에 수행한다.  \n만약, Flow Table의 어떤 pattern과도 일치하지 않는다면, 이를 `Table Miss`라고 하고, 미리 지정해둔 miss flow entry에 따라 Action을 수행한다. 아무 설정도 하지 않았다면 default로 해당 packet을 drop한다.\n\n그렇다면, 각 Table을 구성하는 요소(entry)들이 어떻게 구성되는지를 확인해보자.\n\n> **1. Flow Entry**\n\n- Match Field : 일치하는 Packet을 찾기 위하여 Ingress Port / Egress Port / Packet Header / 다른 Table에서 생성된  Metadata 등을 사용한다.\n- Priority : 일치하는 대상이 많을 경우, 높을 수록 조회 시에 우선시 되어진다.\n- Counters : match가 수행된 횟수를 마킹한다.\n- Instructions : packet에 대해서 특정 Action을 수행시키거나 Action Set을 변경한다.\n- Timeout : 최대 처리 시간 또는 남은 시간 등을 표시한다.\n- Cookie : Controller에 의해 설정된 데이터로 대게 해쉬 / 암호화 되어진다. 이는 Controller에서 Flow 관측 및 조절 시에 사용한다.\n\n> **2. Group Entry**\n\n- Group Identifier : Group 식별자\n- Action Buckets : 여러 개의 action과 이에 해당하는 parameter를 담은 bucket들을 정렬 후 보관\n- Group Type : Group의 동장 방식을 선택\n  - all :  모든 bucket을 실행\n  - select : bucket을 번갈아가면서 실행하여 Load Balancing을 실행\n  - indirect : bucket 하나만 실행하며, bucket을 여러 개 두는 것을 허락하지 않는다.\n  - fast failover : 가장 먼저 켜져있다고 판단되는 port를 가진 bucket 하나만 실행\n- Counters : Group에 의해 처리된 packet의 수\n\n> **3. Meter Entry**\n\n- Meter Identifier : Meter 식별자\n- Meter Bands : packet rate와 이에 따른 packet 처리 방법을 가진 여러 meter band를 순서없이 저장. band를 선택할 때에는 측정된 rate보다 작으면서 가장 큰 rate를 가진 band를 선택한다. 각 band는 아래와 같이 구성된다.\n  - Band Type : rate를 넘긴 후의 packet 처리 방식을 선택\n    - drop : packet을 버린다.\n    - dscp remark : IP header에 drop 우선순위를 높인다.\n  - Rate : packet rate의 하한선\n  - Couter : 처리된 packet의 수\n  - Type Specific Arguments : 부가 정보\n- Counters : Meter에 의해 처리된 packet의 수\n\n---\n\n마지막으로, Instruction과 Action 그리고 Action Set의 구성을 살펴보자.\n\n> **1. Instruction**\n\nInstruction은 다음과 같은 종류가 있다. 이를 통해서 명령을 적용하거나 Table을 이동하고, ActionSet을 변경하는 것이 가능하다.\n\n1. `meter meter_id` : packet에 특정 meter를 적용\n2. `apply-actions action(s)` : packet에 해당 action(s)를 즉각적으로 수행\n3. `clear-actions` : `Action set`을 바로 비우기\n4. `write-actions action(s)` : Action Set에 해당 action(s)를 추가\n5. `write-metadata metadata/mask` : metadata를 추가\n6. `goto-table next-table-id` : 특정 table로 이동. 단, 반드시 현재 Table index보다 더 큰 index로 이동해야 한다.\n\n> **2. Action Set**\n\npipeline이 종료 된 후에 실행되는 action이 저장되어 있다.\n\naction은 기본적으로 아래 순서대로 실행되지만, 동일한 action은 들어온대로 실행되는 것이 아닌 임의로 실행된다.\n\n1. `copy TTL inwards` : TTL을 체크하는 action을 실행\n2. `pop` : 만약, packet에 tag가 존재한다면, 모두 제거한\n3. `push MPLS` : MPLS tag(=label)을 추가\n4. `push PBB` : PBB tag를 추가\n5. `push VLAN` : VLAN tag를 추가\n6. `copy TTL outwards` : TTL을 체크하는 action을 실행\n7. `decrement TTL` : TTL을 감소시키는 action을 실행\n8. `set` : `set-field`에 해당하는 action을 실행\n9. `qos` : `qos` 관련 action을 실행\n10. `group` : 연관된 group bucket의 action을 실행\n11. `output` : `output` action으로 명시된 port로 packet을 forwarding\n\n> **3. Action**\n\n실제로 packet을 처리하는 방법에 대한 방법이다.\n\n1. `output` : OpenFlow port 중 어디로 forwarding할지를 지정\n2. `set-queue` : QoS 지원을 위해 packet을 내보낼 Switch의 queue Id를 지정\n3. `drop` : 직접 호출할 수는 없지만, output이 없거나 `clean-actions` 수행 시에 내부적으로 수행한다.\n4. `group` : group을 통해 packet을 처리하도록 group table로 packet 전달\n5. `push-tag` : MPLS / VLAN 등의 tag를 추가\n6. `pop-tag` : MPLS / VLAN 등의 tag를 삭제\n7. `set-field` : header의 가장 끝에 특정 값을 추가\n8. `change-ttl` : ttl값을 수정\n\n## 표준화 현황\n\n| version | 발표일  | 주요 기능 추가                                  | 기관                |\n| :------ | :------ | :---------------------------------------------- | :------------------ |\n| OF 1.0  | 2009.12 | MAC, IPv4, Single Table                         | OpenFlow Consortium |\n| OF 1.1  | 2011.2  | MPLS/tunnel, Pipeline(Multi Table), Group Table | OpenFlow Consortium |\n| OF 1.2  | 2011.12 | IPv6, Of-Config, 다중 Controller 지원           | ONF                 |\n| OF 1.3  | 2012.9  | Meter Table(QoS), Controller 별Event Filtering  | ONF                 |\n| OF 1.4  | 2013.10 | Optical port monitoring, Flow 삭제 원인         | ONF                 |\n| OF 1.5  | 2014.12 | Egress Table 추가                               | ONF                 |\n\n현재에는 OpenFlow 표준화는 중단된 상태이다. 모든 요구사항을 받아들이다보니 match field의 크기가 너무나 커졌기 때문이다. 따라서, 이용자의 요구에 따라서 programming 할 수 있는 환경을 제공하기 위한 P4(Programmable Protocol-Independent Packet Protocol)을 제작하였다.\n\n즉, 기존에는 Protocol과 이를 지원하는 Switch를 주요 서비스로 삼았다면, 이제는 Programming이 가능한 언어와 이를 이용할 수 있는 Switch를 제공하는 방향으로 전환하였다.\n\n## Reference\n\n- [Openflow specification](https://opennetworking.org/wp-content/uploads/2013/04/openflow-spec-v1.3.1.pdf), ONF, 2012\n- Thumbnail: Photo by [Maksym Tymchyk 🇺🇦](https://unsplash.com/@maksym_tymchyk?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/s/photos/flow?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n","slug":"openflow","date":"2022-05-25 22:23","title":"OpenFlow","category":"Network","tags":["SDN","ONF"],"desc":"SDN의 본격적인 시작이 OpenFlow라고 보아도 무방하다. OpenFlow는 2007년 Stanford 대학에서 개발이 시작되었고, 지금도 de facto standard(사실상의 표준)으로 받아들여지고 있는 Protocol이다. 해당 Protocol의 핵심은 기존 Switch/Router를 data plane(데이터 평면)과 control plane(제어 평면)으로 나누고, 제어 평면을 OpenFlow Protocol에 따르는 Controler로 대체하면서, OpenFlow Protocol을 따르는 Switch는 data plane만을 포함하여, 둘 간의 통신을 통해서 제어 평면을 구성하자는 것이다. 여기서 데이터 평면은 실제로 interface로 packet이 들어오고, 내보내는 역할을 하는 계층이라고 보면 되고, 제어 평면은 packet에 어떤 동작을 수행시킬지 그리고 어느 interface로 내보낼지를 결정하는 역할을 하는 계층이라고 보면 된다. 이러한 구성을 통해서, 결국 SDN을 구축할 수 있는 토대를 제공하게 된 것이다.","thumbnailSrc":"https://euidong.github.io/images/flow.jpg"},{"content":"\n## Intro\n\nOverlay Network란 기존의 Network 위에 만들어진 가상의 Network를 의미한다. 그렇기에 물리적인 광통신 네트워크에 구성된 모든 네트워크를 Overlay Network라고 볼 수도 있지만, 일반적으로는 Public Internet 위에 구성된 가상의 Network라는 의미로 사용된다.\n\n대표적인 예시로 P2P, VPN을 들 수 있다. 그 외에도 VLAN, MPLS 등도 들 수 있지만 Application 계층에서 구현한 P2P와 VPN을 해당 Posting에서 중점적으로 다룰 것이다. Overlay Network는 상위에 계층에 의해서 만들어지기 때문에 하위 계층에서는 해당 data를 분석하는 것은 사실상 불가능할 뿐만 아니라 이렇게 데이터의 크기가 더 커지기 때문에 네트워크의 과부하를 초래하기도 한다. 하지만, 이러한 기술은 구현이 하드웨어단에서 진행하는 것보다 간략할 뿐만 아니라 유연한 구성이 가능하기 때문에 여러 분야에서 활용되고 있다. 이로인해서 이러한 서비스를 구현하는 업체를 `Free Rider`라고 부르기도 한다. 통신 사업자 입장에서는 traffic 증가로 운영 비용이 증가하는데 비해 이에 대한 이득은 서비스 제공업체에서만 가져가는 현상때문이다.\n\n## P2P\n\nPeer To Peer의 약자로 여러 client 간의 통신을 수행할 때, 가장 기본적인 모델로 모든 Client가 서로 동등하게 연결되는 Network이다. 이는 `Client-Server` 구조와는 반대되는 개념으로, 하나의 Server로 모든 Client가 연결되어 이를 통해서 서로 정보를 주고 받는 구조와는 형태가 매우 다르다. 특히 파일 공유, 통신, VoIP, Instance Message, CDN과 같은 분야에서 많이 사용된다. 이는 P2P의 다음과 같은 **장점** 덕분이다.\n\n1. Scalability : `Client-Server` 구조에서는 Client의 증가는 곧 Server의 부하 증가를 의미한다. 하지만, P2P에서는 노드 수의 증가는 전체 Network의 크기 증가를 의미하지만, 각 Node에게 부과되는 부하의 증가를 야기하지는 않는다.\n2. Low Cost : Service 제공자 입장에서는 값비싼 Server를 유지하지 않아도 되기 때문에 이로 인한 비용적 이득을 볼 수 있다. 하지만, 통신 사업자 입장에서는 이것이 더 신경쓰이는 부분이다.\n3. Availability : 일부 노드에 장애가 발생해도 전체 네트워크 연결에 미치는 영향은 적다.\n\n하지만, P2P는 여러 인터넷 문제를 야기할 수도 있다. 대표적으로 제기되는 것이 다음과 같은 문제이다.\n\n1. 과도한 인터넷 대역폭 소모  \n   P2P에 참여하는 Node는 Bandwidth의 대부분을 P2P에 사용한다. 이를 통해서 P2P 전송의 효율을 최대화하고자 한 것이다. 하지만, 이로 인해 여타 다른 Network 장비들의 성능에 영향을 줄 수 있다.\n2. 통제가 어려움  \n   P2P를 통해서 공유되는 자료가 부정적인 컨텐츠(음란물, 불법 저작물 유통)를 포함하더라도 이를 통제할 수단이 없을 뿐만 아니라 과도한 Traffic에 대한 차단을 수행하려고 해도 P2P port를 주기적으로 바꾸거나 VPN 등을 활용하며 이러한 차단마저도 우회하고있다.\n3. 낮은 보안성  \n   P2P software는 각 client에서 동작하며, 각 Client는 Host의 기능도 수행해야 하는데 이에 대한 책음은 원래 Service 제공자에서 Client로 전과되었으며, 이는 Client에서 직접적으로 방어해야 한다. 그렇기에 보안성이 낮고 악성코드에 무방비하다.\n\n2000년대 중반까지만 해도 이러한 P2P Traffic이 전체 인터넷의 60~80%를 차지하여 큰 문제가 되었지만, 현재에는 2.4%로 감소하였다. 이는 Streaming Platform의 성장이 컸다고 보고 있다. 다음은 대표적인 P2P Service에 대한 예시이다.\n\n> **Napster**\n\n최초의 P2P service로 유명하며, 무료 음원 MP3 파일을 공유하는 서비스를 제공하였다. `Login Server`만을 유지하고, 이곳에서 각 node의 MP3 file 정보와 user 정보를 mapping하여 관리하고 이들을 통해서 조회를 수행하면 Download는 P2P에 의해서 수행되는 원리이다. 그런데 이 단계에서 문제가 발생할 수 있다. 바로 Client 간의 P2P를 수행할 때에 NAT로 인해서 실제 Client의 주소를 알아내는 것이 어려울 뿐만 아니라 방화벽에 의해서 막힐 수 있기 때문이다. 이를 해결하기 위해서 `STUN`이라는 개념을 활용한다. 여기서는 자세히 다루지 않지만 NAT에 의해서 만들어진 Public Address와 Private Address를 저장하여 이를 저장하고 있다가 NAT 내부에 Node를 식별할 수 있도록 돕는 기술로 별도의 Server를 구성하여 해당 장소에 저장해두는 것이 일반적이다. 또한, file을 갖고 있는 Node에서 방화벽이 존재한다면, 이를 우회하기 위해서  외부 Server가 file을 보유한 Node에서 오히려 요청을 보내고 파일을 전송하는 것처럼 우회를 수행하기도 한다.\n\n> **Torrent**\n\nBitTorrent와 uTorrent에 대해서만 알아볼 것이다. BitTorrent는 가장 초기 버전으로 OpenSource로 공개되었고, version 6인 uTorrent부터는 비공개로 개발되었다. 32, 64, 128, 256 KB 단위로 file을 나누고 조각 단위로 전송하는 방식이다. Torrent Network를 구성하는 요소는 다음과 같다.\n\n- Web Server : Torrent는 별도의 File 공유 Web Service를 제공하지 않기 때문에 사용자들은 자신이 파일을 가지고 있음을 `X.torrent` 라는 file에 담아서 Web Service에 업로드해야 한다. 이를 다운로드하여 Torrent Application을 실행시키면 file download가 진행되는 것이다.\n- Tracker : Torrent에서 제공하는 Server이다. P2P에서 각 peer들의 상태정보를 수집하고, 이를 통해서 통신을 중계한다.\n- Seed : 완전한 파일을 가지고 있는 Peer\n- Leech : 해당 파일을 일부 가지고 있는 Peer\n- Downloader : Leech와 같은 의미로 사용되기도 하며, 다운로드가 완료되면 Leech 또는 Seed가 된다.\n\nDownloader가 Download를 `X.torrent` file을 기반으로 수행하기를 Tracker에게 요청하면, Tracker는 해당 파일을 소유한 Peer List를 반환하고 이를 통해서 각 Peer로 부터 파일 조각을 다운 받아 결합하여 최종 file을 완성한다는 원리에 기반하고 있다. uTorrent는 기존 TCP에서 UDP로의 변경 뿐만 아니라 STUN 기능 등을 포함하여 성능을 향상시켜 출시되었다.\n\n> **Skype**\n\nVoIP를 기반으로 하여 파일 전송 등을 제공하는 P2P 서비스이다. 2003년에 처음 시작되어 현재는 MicroSoft에 인수되었고, 2012년 이후로는 `Client-Server` 구조로 전환하였다. 시스템을 구성하는 요소는 다음과 같다.\n\n- Login Server : 회원가입 및 사용자 정보를 저장하는 Server로 Skype에 의해서 관리된다.\n- SN(Super Node) : 실제 Skype Client가 연결되는 Node로 이들은 각자 연결되어 각 Client에게 통신을 제공한다. 초기에는 항상 켜져 있고, 공인 IP 주소를 가지고 있는 고성능 고대역 장비이면 어떤 Skype Client도 Super Node가 될 수 있었다. 하지만, 2012년 대규모 장애가 발생한 이후 MicroSoft에서 운용하는 Machine(Azure)으로 대체되었다.\n- SC(Skype Client) : 일반 Skepe 이용자를 의미한다.\n\nSkype의 Code가 공개되지 않았기 때문에 자세히 알 수 없지만 다음과 같이 추측은 가능하다. Login Server를 거쳐서 Login을 수행하며, 이 과정에서 적절한 Super Node를 통해서 먼저 연결 상태 체크 등을 수행한다. 이제 사용자가 통화를 시작한다면, 해당 Super Node를 기반으로 UDP 음성 packet이 오고 갈 것이다.\n\n### STUN\n\nSession Traversal Utilities for NAT 의 약어로 UDP hole punching이라고도 부른다. Network Address Translation으로 번역되는 내부망의 node의 Private Address를 Public Address와 Mapping하여 관리한다. 원래는 NAT 내부에 존재하는 Node를 식별할 수 없지만, 이를 통해서 NAT 내부에 존재하는 대상에게 Request를 보내는 것이 가능해지는 것이다. 이와 유사한 개념으로 TURN이 존재하는데 이는 직접적으로 Traffic을 전달받아서 중계를 수행하는 역할을 맡는다.\n\n## VPN\n\nVirtual Private Network의 약어로 90년대 말에 기업의 사설망 구축 시에 사용되던 기술이 공용화된 것이다. 이는 OSI 7계층에서 2 계층 이상에서 적용이 가능하며, 어느 계층에서 수행하냐에 따라 목적이 조금씩 다르지만, packet을 Encapsulation하여 도청, 감청, 탈취 등의 작업을 수행할 수 없도록 막는 것이 주 목적이다. 이를 통해서 개인정보를 암호화하고, 인터넷을 사용하는 것이 가능하다. 통신 사업자에 의해서 구성된 VPN이 아닌 경우 대역폭이 보장되지는 않는다. IPSec에서 부터 시작하여, SSL과 같은 기술이 이에 포함되고, 우리가 일반적으로 생각하는 VPN은 응용 계층에서의 활용이다. 이 경우에는 Proxy Server를 먼저 거쳐서 Traffic 자체를 우회시키는 방식이다.\n\n## Reference\n\n- Thumbnail : Photo by [Mark McGregor](https://unsplash.com/@mmcgregor?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/s/photos/peer?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n","slug":"overlay-network","date":"2022-05-30 09:23","title":"Overlay Network","category":"Network","tags":["P2P","VPN"],"desc":"Overlay Network란 기존의 Network 위에 만들어진 가상의 Network를 의미한다. 그렇기에 물리적인 광통신 네트워크에 구성된 모든 네트워크를 Overlay Network라고 볼 수도 있지만, 일반적으로는 Public Internet 위에 구성된 가상의 Network라는 의미로 사용된다.대표적인 예시로 P2P, VPN을 들 수 있다. 그 외에도 VLAN, MPLS 등도 들 수 있지만 Application 계층에서 구현한 P2P와 VPN을 해당 Posting에서 중점적으로 다룰 것이다. Overlay Network는 상위에 계층에 의해서 만들어지기 때문에 하위 계층에서는 해당 data를 분석하는 것은 사실상 불가능할 뿐만 아니라 이렇게 데이터의 크기가 더 커지기 때문에 네트워크의 과부하를 초래하기도 한다. 하지만, 이러한 기술은 구현이 하드웨어단에서 진행하는 것보다 간략할 뿐만 아니라 유연한 구성이 가능하기 때문에 여러 분야에서 활용되고 있다. 이로인해서 이러한 서비스를 구현하는 업체를 Free Rider라고 부르기도 한다. 통신 사업자 입장에서는 traffic 증가로 운영 비용이 증가하는데 비해 이에 대한 이득은 서비스 제공업체에서만 가져가는 현상때문이다.","thumbnailSrc":"https://euidong.github.io/images/climb-the-rock.jpg"},{"content":"\n## Intro\n\nP4는 Programmable Switch, 즉 Hardware에 묶여있는 Software를 통해 DataPlane을 사용하는 것이 아닌 필요에 따라 Switch의 DataPlane을 직접 Programming하여 사용하는 새로운 방법론을 제시한다.\n\n## History\n\n예전 Posting에서 [🔗 OpenFlow](/posts/openflow)와 [🔗 SDN](/posts/sdn)에 대해서 다룬 적이 있다. 이때, P4에 대해서 간략히 알아보고 지나갔었는데, 해당 Posting에서는 이를 자세히 다룰 것이다. 만약, 이에 대한 개념이 잡혀있지 않다면, 해당 Posting을 이해하기 어렵다. 따라서, SDN과 OpenFlow 관련 Posting을 먼저 읽고 다시 돌아오기를 바란다.\n\n먼저, P4의 초기 시작은 OpenFlow의 성장과 연관이 있다. OpenFlow는 기존의 Switch를 Data Plane과 Control Plane으로 나누어 Control Plane을 외부 Server(Controller)로 옮기고 이들은 OpenFlow Protocol을 통해서 Switch의 Data Palen을 제어하고자 했다. OpenFlow의 사용이 가속화되면서 계속해서 새로운 version이 update되었고, 1.0에서 1.5까지 도달하게 되었다. 그런데, 여러 Usecase와 Protocol을 지원하기 위해서 점점 비대해지는 Header를 마주치게 된다. 이는 통신 속도의 저하를 야기할 뿐만 아니라 기존의 유연한 시스템을 만들고자한 OpenFlow의 탄생 배경과도 거리가 있게 된다. 따라서, Data Plane을 필요에 따라 Protocol, Header, Algorithm을 포함하여 Programming으로 구현하여 사용하면 좋지 않을까라는 발상에서 시작된 것이 P4이다. 그렇기에 P4의 full name이 **Programming Protocol-independent Packet processors**인 것이다.\n\n이렇게 시작된 Project는 점점 비대해지며, 원래는 Programmable Switch를 위한 언어를 목적으로 했다면 현재에는 여러 목적의 장비(target)을 지원하는 언어로 확장되었다. 따라서, P4를 한 문장으로 정의하라고 하면, **Programmable Target의 Data Plane을 Programming하는 언어**라고 할 수 있다.\n\n## 동작원리\n\nP4를 통한 Programming을 통해서 우리가 최종적으로 만드는 것은 두 가지이다. 첫번째로, `DataPlane runtime`은 Table과 Action 그리고 적절한 Alogrithm을 통해 실제로 Packet을 처리 및 Forwarding할 Software를 제작하고, Control Plane에서 Data Plane을 제어 및 설정을 하기 위한 API를 제작한다.\n\n![p4-overview](/images/p4-overview.jpeg)\n\n이를 위해서 Target을 제작하는 Vender는 다음과 같은 3가지를 제작한다.\n\n1. P4 Architecture : 해당 Target에서 작동이 가능한 Interface와 extern object를 정의해놓은 명세서이다. 후에 P4 programmer는 이를 참고하여 해당 Interface에 해당하는 Package를 작성하면 된다.\n2. P4 Compiler : Programmer가 작성한 Code를 Compile하여 API와 DataPlane Runtime을 생성한다.\n3. Target(Hardware) : 실제로 동작하는 Hardware이다.\n\n이제 P4 개발자(Programmer)는 P4 Architecture를 기반으로 하여 원하는 동작을 구현한다. 이를 Compiler를 통해서 실행시켜 정상동작 여부를 확인하여 최종적으로 동작하는 P4 Target을 완성할 수 있다.\n\n이렇게 보았듯이 P4 Programming 과정은 Target 디자이너(Vender)에 의해서 만들어진 객체 지향 Architecture에 기반하여 Implementation을 수행하는 것이 핵심이다. 아마 객체 지향에 익숙하다면 굉장히 친숙한 개념일 것이다.\n\n## 구성요소\n\nP4 programming을 통해서 실제로 작성하거나 사용하는 구성요소들은 아래와 같다.\n\n- **Architecture** : P4를 지원하는 지원하는 Switch의 구성요소들의 interface(객체지향에서의 interface)를 작성한 명세서로 이는 Programmer가 아닌 해당 Target을 제작한 Vender가 작성한다. 이를 기반으로 P4 Programmer는 Implementation을 수행한다.\n- **Header Type** : 해당 Data Plane에서 사용할 각각의 Packet의 Header의 형태를 의미한다. 즉, Packet의 Header 부분을 정의한 것이다.\n- **Parser** : 연속으로 들어오는 Packet에서 Header를 식별하고 추출하는 역할을 한다.\n- **Table** : Programmer에 의해서 정의된 key와 이에 대응하는 Action이 저장된다. 이를 통해서, Routing Table, Flow Lookup Table, ACL 등과 같은 일반 Switch의 Table도 구성이 가능하며, 더 복잡한 형태의 새로운 Table을 구성하는 것도 가능하다.\n- **Action** : Header와 Metadata에 특정한 조작을 가할 수 있다.\n- **Match-action unit** : 실제로 Table을 조회하여, Action을 수행하는 Unit으로 동작순서는 다음과 같다.\n  1. Packet의 field와 metadata를 활용하여 key를 생성한다.\n  2. 생성한 key로 Table에서 조회(Lookup)한다.\n  3. 조회된 key에 대응하는 action이 존재한다면, 이를 수행한다.\n- **User-defined metadata** : Programmer(user)에 의해서 정의된 data 구조로 각 packet에서 추출이 가능하다.\n- **Intrinsic metadata** : 기본적으로 정의된 data 구조로 각 packet에서 추출이 가능하다.\n- **Extern object** : 일반적인 Programming Language에서 Library와 같은 역할을 하며, P4가 실행될 Hardware에서 제공하는 기능들이 여기에 포함된다. P4에서 이를 이용하여 Programming이 가능하지만, 이는 P4를 지원하는 Hardware Switch 제작자가 지정하는 것이기에 P4를 통한 구현은 불가능하다.\n- **Deparser** : Packet의 Header와 Payload를 다시 결합하여 output port로 내보낼 Packet을 생성한다.\n- **Control flow** : target의 packet 처리를 기술하는 필수적인 program 요소이다. Deparsing과 Match-action 등을 이를 통해서 기술할 수 있다.\n\n## Example\n\n가장 기본적인 Siwtch(Very Simple Switch, **VSS**)를 구현하며 P4의 programming 절차를 익혀보자. 아래 그림은 VSS를 분석한 그림이다.\n\n![Very Simple Switch](/images/vss.jpeg)\n\n### Flow\n\n총 3가지의 Flow가 존재한다. 하나는 일반적인 데이터 Packet을 의미하며 Target의 **Physical Ethernet**을 통해서 들어온 packet이 이에 해당한다. 또 다른 하나의 Control Flow로 대게 SDN의 Controller를 통해서 들어온 Packet이다. 대게 이는 CPU를 통해서 전달되기 때문에 **From CPU**라고 표기한다. 마지막은 **Recirculate**인데 이는 동일 Target 내부에서 재처리를 위해서 다시 Arbiter로 전달된 Packet을 의미한다. 이는 한 번의 순환으로는 제대로 된 처리가 어려운 경우에 사용한다.\n\n### Component\n\n주황색 박스의 요소는 Hardware로 정의된 요소(Arbiter, Parser Runtime, Demux/Queue)를 의미하고, 검은 박스의 요소(Parser, Match-action Pipeline, Deparser)는 Software로 구현되는 요소를 의미한다. 각 요소를 먼저 알아보도록 하자.\n\n1. **Arbiter**  \n    한국어로는 중재자라는 뜻을 가지며, Input을 일차적으로 가공하는 Block(장치)으로 아래와 같은 기능을 수행한다.\n    - 총 16개의 Port를 가지며, 3가지 종류의 Input을 입력받는다. (1)Physical Ethernet Input, (2)Control Flow(from CPU), (3)Recirculate Input을 받는다.\n    - **Ethernet Input인 경우**, checksum을 추출하고 검증한다. 만약, 올바르지 않은 checksum이라면 packet이 버려지고, 올바르다면 packet의 payload에서 checksum을 추출하여 다음 단계로 전달한다.\n    - 여러 packet을 동시에 수신한 경우에는 이를 scheduling하는 Algorithm을 실행시킨다.\n    - Arbiter가 Busy 상태이고, 대기 queue가 꽉 찬 경우에는 도착한 packet을 Drop한다.\n    - packet을 받은 port를 `inCtrl.inputPort`에 저장하여, Match-action Pipeline으로 전달하여 packet이 어디서부터 왔는지를 marking한다. 여기서는 Physical Ethernet port는 0 ~ 7번까지를 의미하고, 13은 recirculation port, 14는 CPU port를 의미한다.\n2. **Parser**\n   Packet을 가공하여 Input Header를 추출하고, user defined metadata를 생성하여 이를 Match-action Pipeline으로 전달한다.\n3. **Parser Runtime**\n   Parser와 협력을 하며 실행되는 장치이다. Parser에 정의된 action에 기반하여 Match-action Pipeline으로 error code를 Match-action Pipelien, packet payload에 대한 정보(payload 길이 등)를 Demux로 전달한다.\n4. **Match-action Pipeline**\n   Parser로 부터 전달받은 Input Header와 Parser Runtime으로 부터 받은 error, Arbiter를 통해 받은 `inCtrl.inputPort`를 기반으로 하여 key를 구성하고, 이를 통해서 Table을 조회하여 적절한 Action을 조회하여 실행한다. 이를 통해서 결론적으로 Output Header와 `outCtrl.outputPort`를 생성한다.\n5. **Deparser**\n   Deparser의 역할은 output Header를 다시 재조립하는 장치이다. 온전한 header 형태를 완성해서 Demux에서 Packet을 최종으로 생성할 수 있도록 돕는다.\n6. **Demux/Queue**\n   밖으로 전달할 packet의 header는 Deparser로부터, payload는 Parser로 부터 전달받아서 이를 재결합하여 새로운 packet을 생성하여 올바른 output port로 내보내는 역할을 하는 장치이다. output port는 Matc-action Pipeline의 `outCtrl.outputPort`를 통해서 전달된다. 세부적인 동작은 아래와 같다.\n   - packet 삭제를 원하는 경우 drop port로 packet을 내보낸다.\n   - Physical Ethernet으로 나가는 packet인 경우 해당하는 output interface로 전달한다. 만약, 해당 interface가 Busy 상태라면 Queue에 저장된다. output interface에서는 packet의 checksum을 계산하여 packet의 끝에 붙여서 내보낸다.\n   - CPU를 통해서 전달하는 Control plane packet의 경우에는 Deparser에서 생성된 Header를 사용하지 않고, original packet 그대로만 전송할 수 있다.\n   - `outCtrl.outputPort`가 올바르지 않다면, 해당 packet은 drop된다.\n   - 만약, Demux가 Busy 상태이고, queue에 빈 공간이 존재하지 않는다면, `outCtrl.outputPort`를 무시하고 packet을 drop한다.\n\n### Architecture.p4\n\n아래는 위의 내용을 기반으로 Vender가 작성한 Architecture의 내용이다.\n\n```c++\n// File: \"very_simple_switch_model.p4\"\n// Core Library로 packet_in과 packet_out을 사용하기 위해 필요하다.\n#include <core.p4> \n\n// Port는 4bit로 표현 가능하다.\ntypedef bit<4> PortId;\n\n// 4 width(bit)로 표현하는 8, 생략해서 8만 써도 무방\nconst PortId REAL_PORT_COUNT = 4w8; \n\n// Input packet에 동반되는 metadata로 Match-action Pipeline에서 사용된다.\nstruct InControl {\n  PortId inputPort;\n}\n\n// Special Input Port\nconst PortId RECIRCULATE_IN_PORT = 0xD;\nconst PortId CPU_IN_PORT = 0xE;\n\n// Match-action Pipeline에서 생성되는 Output packet에 동반되는 metadata\nstruct OutControl {\n  PortId outputPort;\n}\n\n// Special Output Port\nconst PortId DROP_PORT = 0xF;\nconst PortId CPU_OUT_PORT = 0xE;\nconst PortId RECIRCULATE_OUT_PORT = 0xD;\n\n// 공통으로 사용되는 H는 header로 programmer에 의해서 정의된다.\n\n/**\n * Parse\n * @param b             input_packet\n * @param parsedHeaders headers contructed by parser\n */\nparser Parser<H>(packet_in b, out H parsedHeaders);\n\n\n/**\n * Match-action Pipeline\n * @param headers     Parser로 부터 받고, Deparser에게 보낸다.\n * @param parseError  parsing 도중에 생성된 error\n * @param inCtrl      packet을 받은 input port를 포함한 정보\n * @param outCtrl     packet을 보낼 output port를 포함한 정보\n */\ncontrol Pipe<H>(inout H headers, \n                in error parseError, \n                in InControl inCtrl, \n                out OutControl outCtrl);\n\n/**\n * Deparser\n * @param outputHeaders programmer에 의해서 정의된 output header\n * @param b             밖으로 내보낼 packet\n */\ncontrol Deparser<H>(inout H outputHeaders, packet_out b);\n\n/**\n * Top level Packet\n */\npackege VSS<H>(parse<H> p, Pipe<H> map, Deparser<H> d);\n\n/**\n * Extern block\n * 이는 Target vender가 내부적으로 구현한 block이다.\n * programmer는 아래 선언된 block을 자유롭게 사용가능하다.\n */\nextern Checksum16 {\n  Checksum16();\n  void clear();\n  void update<T>(in T data);\n  void remove<T>(in T data);\n  bit<16> get();\n}\n```\n\n이렇게 작성된 architecture를 기반으로 하여 programmer는 코드 작성이 가능하다.\n\n### Programming.p4\n\n먼저 어떤 동작을 수행하게 할지를 정의하자.\n\n<!-- TODO 채우기 -->\n1. Ethernet/IPv4 header를 활용하여 Forwarding을 수행할 것이다.\n2. CheckSum을 확인하여 정당성 여부를 확인한다.\n3. TTL 값을 확인하여 정당성 여부를 확인한다.\n4. Destination IPv4를 활용하여 Next Hop의 IPv4를 찾는다.\n5. 추출했던 Packet의 Header를 다시 Ethernet/IPv4로 재구성한다.\n\n이를 코드로써 구현하면 아래와 같다.\n\n```c++\n// File: \"very_simple_switch_impl.p4\"\n# include <core.p4>\n# include \"very_simple_switch_model.p4\"\n\n// 해당 program은 packet에서 IPv4와 \n// ethernet header를 가져와\n// destination IP에 기반하여 packet을 \n// forwarding하는 것을 목적으로 한다.\n\ntypedef bit<48> EthernetAddress;\ntypedef bit<32> IPv4Address;\n\n// Standard Ethernet header\nheader Ethernet_h {\n  EthernetAddress dstAddr;\n  EthernetAddress srcAddr;\n  bit<16>         etherType;\n}\n\n// IPv4 header (without option)\nheader IPv4_h {\n  bit<4>      version;\n  bit<4>      ihl;\n  bit<8>      diffserv;\n  bit<16>     totalLen;\n  bit<16>     identification;\n  bit<3>      flags;\n  bit<13>     fragOffset;\n  bit<8>      ttl;\n  bit<8>      protocol;\n  bit<16>     hdrChecksum;\n  IPv4Address srcAddr;\n  IPv4Address dstAddr;\n}\n\n// packet에서 추출한 header형태의 구조체\nstruct Parsed_packet {\n  Ethernet_h ethernet;\n  IPv4_h     ip;\n}\n\n/* Parser Section */\n\n// Programmer에 의해서 정의된 error로 \n// parsing 도중에 이를 발생시킬 수 있다.\nerror {\n  IPv4OptionsNotSupported,\n  IPv4IncorrectVersion,\n  IPv4ChecksumError\n}\n\n/**\n * @param b 들어오는 packet\n * @param p parsing해서 나갈 packet Header\n */\nparser TopParser(packet_in b, out Parsed_packet p) {\n  Checksum16() ck; // checksum block을 instantiating\n\n  state start {\n    b.extract(p.ethernet); // p의 ethernet 부분을 b에서 추출\n    transition select(p.ethernet.etherType) {\n      0x800: parse_ipv4; // forward packet to parse_ipv4\n      // default rule이 없기 때문에 0x800(ethernet)을 \n      // 제외한 packet을 모두 rejected 된다.\n    } \n  }\n\n  state parse_ipv4 {\n    b.extract(p.ip);\n    verify(p.ip.version == 4w4, error.IPv4IncorrectVersion);\n    verify(p.ip.ihl == 4w5, error.IPv4OptionsNotSupported);\n    ck.clear();\n    ck.update(p.ip);\n    verify(ck.get() == 16w0, error.IPv4ChecksumError);\n    transition accept; // 다음 block으로 out을 forwarding\n  }\n}\n\n/* Match-action Pipeline Section */\n\ncontrol TopPipe(inout Parsed_packet headers, \n                in error parseError,\n                in InControl inCtrl,\n                out OutControl outCtrl) {\n  IPv4Address nextHop;\n\n  action Drop_action() { outCtrl.outputPort = DROP_PORT; }\n\n  action Set_nhop(IPv4Address ipv4_dest, PortId port) {\n    nextHop = ipv4_dest;\n    headers.ip.ttl = headers.ip.ttl - 1;\n    outCtrl.outputPort = port;\n  }\n\n  table ipv4_match {\n    // lpm : longest-prefix match\n    key = { headers.ip.dstAddr: lpm; }\n    // 해당 테이블에서 key에 대응할 수 있는 action의 list이다. \n    // 해당 table은 후에 controller에 의해서 채워진다.\n    // 즉, 테이블은 p4 prgramming을 통해서 채우는 것은 아니다.\n    actions = {\n      Drop_action;\n      Set_nhop;\n    }\n    size = 1024;\n    default_action = Drop_action;\n  }\n\n  action Send_to_cpu() {\n    outCtrl.outputPort = CPU_OUT_PORT;\n  }\n\n  table check_ttl {\n    // exact : 정확히 일치하는지 여부를 확인\n    key = { headers.ip.ttl: exact; }\n    actions = { \n      Send_to_cpu;\n      NoAction;\n    }\n    const default_action = NoAction;\n  }\n\n  action Set_dmac(EthernetAddress dmac) {\n    headers.ethernet.dstAddr = dmac;\n  }\n  \n  table dmac {\n    key = { NextHop: exact; }\n    actions = {\n      Drop_action;\n      Set_dmac;\n    }\n    size = 1024;\n    default_action = Drop_action;\n  }\n\n  action Set_smac(EthernetAddress smac) {\n    headers.ethernet.srcAddr = smac;\n  }\n  \n  table smac {\n    key = { outCtrl.outputPort: exact; }\n    actions = {\n      Drop_action;\n      Set_smac;\n    }\n    size = 16;\n    default_action = Drop_action;\n  }\n\n  apply {\n    if (parseError != error.NoError) {\n      Drop_actrion();\n      return;\n    }\n\n    ipv4_match.apply();\n    if (outCtrl.outputPort == DROP_PORT) return;\n\n    check_ttl.apply();\n    if (outCtrl.outputPort == CPU_OUT_PORT) return;\n\n    dmac.apply();\n    if (outCtrl.outputPort == DROP_PORT) return;\n\n    smac.apply();\n  }\n}\n\n/* Deparser Section */\n\ncontrol TopDeparser(inout Parsed_packet p, packet_out b) {\n  Checksum16() ck;\n  apply {\n    b.emit(p.ethernet);\n    if (p.ip.isValid()) {\n      ck.clear();\n      p.ip.hdrChecksum = 16w0;\n      ck.update(p.ip);\n      p.ip.hdrChecksum = ck.get();\n    }\n    b.emit(p.ip);\n  }\n}\n\n// VSS packet를 Instantiate\nVSS(TopParser(), TopPipe(), TopDeparser()) main;\n```\n\n여기까지가 기본적인 P4에 대한 설명이다. 후에 전반적인 문법과 작성법에 대한 가이드를 작성하도록 하겠다.\n\n## Reference\n\n- Thumbnail: [🔗 P4 공식홈페이지](https://p4.org)\n- [P4 specification](https://p4.org/p4-spec/docs/P4-16-v1.2.2.pdf)\n","slug":"p4","date":"2022-06-09 17:29","title":"P4","category":"Network","tags":["SDN","P4","ProgrammableSwitch","DataPlane","OpenFlow"],"desc":"P4는 Programmable Switch, 즉 Hardware에 묶여있는 Software를 통해 DataPlane을 사용하는 것이 아닌 필요에 따라 Switch의 DataPlane을 직접 Programming하여 사용하는 새로운 방법론을 제시한다.","thumbnailSrc":"https://euidong.github.io/images/p4-icon.png"},{"content":"\n## Intro\n\nRouting은 우리가 주고 받고자 하는 데이터를 전달하기 위해서 목적지를 찾아나가는 과정이다. 어떻게 해서 IP를 통해서 목적지를 찾아 데이터가 이동할 수 있는지를 알아볼 것이다.\n\n## Routing Vs Switching Vs Forwarding\n\n매우 유사한 개념이지만 이에 대해서 알아두고 가는 것이 중요하다.\n\n- `Switching` : Inbound Interface에서 Outbound Interface로 packet들을 전송 시키는 것을 의미한다. 즉, 하나의 기기 내부에서 발생하는 일을 의미하는 경우가 많다.\n- `Forwarding` : 한 장치가 목적지로 가는 경로에 있는 다음 장치로 packet을 전송하는 것을 의미한다. 하지만, Switching과 동일한 뜻으로도 많이 사용된다.\n- `Routing` : 논리적으로 Network Topology를 학습하여, 이를 기반으로 최적의 경로를 찾아 이동하는 것을 의미한다. 따라서, 전체적인 길을 찾는 것과 이를 따라가는 과정을 의미한다.\n\n## Switch\n\nSwitch를 부르는 명칭 역시 다양하고, 상황에 따라 역할도 어느정도 다르기 때문에 정리를 한다. 대게 OSI 7계층에 기반하여 분류를 하는 것이 일반적이다.\n\n- `L2 Switch` : Ethernet Switch를 대게 의미하며, 일반적으로 Switch라고 부르는 장치가 이를 의미한다. MAC 주소에 기반한 Forwarding을 수행하는 장치이다.\n- `L3 Switch` : Router라고도 불리는 장치로, IP 주소에 기반하여 최적의 경로를 학습하는 알고리즘을 포함한 Switch이다.\n- `L4 Switch` : Port 번호를 기반으로 Switching을 수행하는 장치로 대게 Machine 내부에서 Software적으로 구현하는 Switch일 가능성이 높다.\n- `L7 Switch` : Application Level에서 모든 Traffic을 관리 및 URL, Cookie 기반으로 자유롭게 Switching을 수행할 수 있다. 일반적으로 생각하는 Load Balancing과 같은 작업도 쉽게 구현이 가능하다. 마찬가지로 Software적으로 구현되어진다.\n\n## Routing 영역\n\n우리가 Routing을 수행하는 경우에 case는 크게 두 가지로 나뉘어진다. **AS 내부인가? 외부인가?** 이다. `AS`란 Autonomous System의 약자로 하나의 기관에서 관리하는 IP subnet들과 Router들의 집합을 의미한다. 각 AS는 고유 식별값인 ASN(AS Number)에 의해서 식별되며 각 기업, 통신 사업자, 대학, 언론 기관 등이 이를 갖고 있다. 이렇게 같은 AS 내부에 존재하는 기기 간의 Protocol을 Interior Gateway Protocol(**IGP**)이라고 하고, 그렇지 않은 경우 Exterior Gateway Protocol(**EGP**)라고 한다.\n\n## Base\n\n각 Routing Protocol에 대해서 자세히 살펴보기에 앞 서 기본적인 Network 환경에 대한 이해가 필요하다. 그러기 위해서 아래 개념에 대한 숙지 여부를 확인하자.\n\n1. MAC/IP  \n   MAC은 특정 Network 연결 단자(Network Interface Card, NIC)에게 주어지는 고유값으로 볼 수 있다. 그렇기에 하나의 기기는 하나 이상의 NIC를 가진다면, 하나 이상의 MAC address를 갖게 되고, 이에 따라 특정 기기를 정확하게 가르키기 위해서 IPv4 주소를 사용한다. 그러나, IP 부족 현상으로 인해 현재에는 내부 네트워크에서는 private IP라는 별도의 영역으로 표기를 하고, 네트워크의 대표 IP를 내세우는 방식으로 변화하였다. 아직까지는 큰 문제가 발생하고 있지 않지만, 후에는 IPv6로 넘어가야할 수도 있다.\n2. Broadcast Address  \n   Network에서 Traffic을 Network에 연결된 모든 Node에게 보내야할 경우가 있다. 이때, 만약 모든 IP address를 1로 표기한다면, 이는 모든 Network를 향한 Broadcast Request로 받아들여진다. 초기에 Network에서는 모든 요청이 Broadcast되고 이를 받은 사용자가 취사 선택하는 구조를 가졌었지만, Broadcast 요청이 loop가 생기면서, Network 전체를 마비시키거나 보안상/성능상의 문제로 인해 Broadcast되는 영역을 줄이고자 한다.\n3. Subnet  \n   Broadcast Traffic이 많아진다는 것은 Network의 혼란을야기할 수 있다. 따라서, 이러한 Broadcast의 영역을 최소한으로 표현하고자 Subnet을 정의하였다. 즉, Network를 더 작은 Subnetwork로 나누자는 것이다. 이를 표시하기 위해서 Subnet Mask라는 것을 활용하며, Network prefix를 이용하여, 영역을 명확하게 구분한다. 그리고 이를 통해서 나뉘어진 Network 끼리는 다른 Broadcast 영역을 가지게 되고, 서로 Broadcast message가 전파되지 않는다. 이에 따라 나뉘어진 Network의 가장 끝(All One Address)는 Broadcast address가 되고, 가장 처음(All Zero Address)는 Network의 주소를 가르키는 값으로 사용된다.  \n   현대에는 이러한 Subnet을 표기할 때, 별도의 Public IP를 사용하지 않고, Private IP를 사용하는 것이 일반적이다. 이를 통해서 더욱 IP address를 절약할 수 있다. 이를 위해서는, 송신 시 Router IP로 Private IP를 바꾸고, 응답이 돌아왔을 때 원래 Node로 돌려주기 위한 번역 과정이 필요한데 이때 NAT(Network Address Translation) 기술이 사용된다.\n4. CIDR  \n   Subnet을 나눌 때, 위에서 IP를 구분할 때 사용하는 A(8bits prefix), B(16bits prefix), C(24bits prefix) class로 나누어 사용했었는데, 이러한 범위가 Subnet에게는 너무 컸기 때문에 이를 임의의 bit 단위로 구분할 수 있도록 하는 방법이다. 이를 통해서, Subnet 범위를 더 세분화할 수 있다.\n5. Loopback Address  \n   자기 자신을 가르키는 addrsss로 대게 `127.0.0.1`을 사용하는데, 필요에 따라 특정 IP를 별도로 자기 자신을 가르키도록 설정하는 것도 가능하다. 이는 Network Testing을 수행할 때 사용되는데, Router의 Loopback Address와 외부 장치 IP Address에 ping을 보내며 통신 상태를 확인할 수 있다.\n6. Default Gateway  \n   Node에 가장 근접한 Router의 주소를 의미하며, 이를 통해서 Internet에 연결된다.\n7. Collision Domain / VLAN  \n   하나의 hub(Switch 이전에 널리 쓰이던 L2 장치, Switch Hub라고도 부름)로 연결된 장치는 전달되는 모든 packet을 해당 hub의 모든 port로 flooding(forwarding)하는데, 이는 Broadcasting과 같다고 볼 수 있다. 이러한 Broadcasting은 성능상으로도 보안상으로도 치명적이기 때문에, 이를 방지하기 위해서 나온 것이 VLAN이다. 기존의 Subnet의 L3에서의 Broadcasting을 막았다면, VLAN은 L2에서 이를 막기 위한 시도이다. Virtual LAN의 약자로 하나의 Switch가 각 Port마다 Collision Domain(L2 Broadcasting이 수행되는 영역)을 분리시킬 수 있는 방법이다. 이를 통해서, Broadcast의 범위를 더 잘게 조갤 수 있다.\n8. ARP  \n   Address Resolution Protocol의 약어로, 하나의 Subnet 내에서 Broadcast를 이용해, 기기의 IP 주소를 통해서 해당 기기의 MAC address를 알아내는 Protocol이다. 예시로, Default Gateway의 IP 주소를 통해서 해당 Router의 MAC address를 찾을 때 사용할 수 있다. 또한, 일반 Node에서 Server로 Request를 보낼 때에도 MAC address는 모르기 때문에, 이를 통해서 MAC address를 찾는다. 이러한 Traffic은 최소화하는 것이 좋기 때문에 이를 위한 응용 기술도 존재한다.\n   - ARP Cache : 데이터를 전송할 때마다 ARP를 수행하는 것은 비효율적이기 때문에, IP와 대응하는 MAC 주소를 저장한 Mapping table을 저장해두는 것을 의미한다. PC 환경에서는 Network의 변경이 적기 때문에 20분 단위로 재실행하지만, mobile 장치에서는 30초 단위로 단축되었다.\n   - Proxy ARP : Router가 수신 Host까지의 경로를 이미 알고 있는 경우에, 송신 Host에게 수신 Host에 대한 MAC address가 아닌 Router의 MAC address를 전송하는 방식으로 Router에게 전적인 대리 작업을 맡기는 것이기에 보안상에서는 좋지 않을 수 있다.\n\n## Routing Protocol\n\n가장 기본적으로 모든 Routing 장비에서 기본적으로 적용되는 Protocol(STP)를 적용하여 Topology에서 Loop를 제거하는 과정을 거친다. 이후에는 Routing Table(RIB)와 Forwarding Table(FIB)을 구축하는 것이 가장 큰 목표가 된다. Routing Table은 특정 Router 와 연결된 Router의 정보를 Protocol마다 정의하여 보관하는 것이다. Router에서 Routing Table은 사용하는 Routing Protocol의 수 만큼, 즉 여러 개 존재할 수 있다. 이러한 Routing Table들에 기록된 정보를 통해서, 단 하나의 Forwarding Table을 각 Router에서 구성하게 된다. (이때에 각 Protocol의 우선순위에 따라서 Forwarding Table이 구성된다.) 이는 실제로 어떤 Port로 어떤 packet이 들어왔을 때, 어떤 Port로 Forwarding 할 것인지를 기록해둔다.\nRouting의 종류는 위에서 보았던 IGP/EGP 뿐만 아니라 언제 설정 방법에 따라서 2 가지로 나뉘어진다. Traffic이 전달되기 이전에 관리자에 의해서 사전에 직접 Routing을 정의(Static Routing Protocol)하는 방법과 스스로 규칙에 따라 학습을 통해 최적 경로를 찾는 방법(Dynamic Routing Protocol)이 있다.\n\n각 Routing Protocol을 알아보기 이전에 기본적으로는 다음과 같은 원칙을 따라야 한다.\n\n1. Longest match Rule : Subnet mask가 긴 Protocol을 우선시한다.\n2. AD(Administrative Distance) : Protocol간의 우선 순위에 따라서 우선 적용한다. 대게 Static Routing이 Dynamic Routing보다 우선시되어진다.\n3. *Spanning Tree Protocol에 기반하여 먼저, Topology 내에 Loop를 제거해야 한다.\n\n### STP(Spanning Tree Protocol)\n\n2계층 Protocol로 Collision Domain 내부에서 Broadcast Storm을 방지하기 위해서 Loop를 막는 것을 목표로 한다.\n\nGraph 형태로 구성된 Network 장비 간의 연결을 Tree 형태로 재구성 해주면, Loop를 해결할 수 있으므로, 특정 Port를 Block하거나 Traffic이 오가는 것을 막는 등의 작업을 수행한다.\n\n설명하기 앞서 기본적인 용어를 먼저 정의해야 한다.\n\n1. Root Switch  \n   Tree를 구성할 때, 어떤 Switch를 root로 할 것인지에 대한 결정\n2. Root / Designated / Alternated Port  \n   Root Switch로 선택되지 못한 모든 장비들은 Root Switch로 연결되는 port를 선정해야 한다. 이를 Root Port라고 하고, 그 반대 방향에 해당하는 Designated Port를 선정한다. 그리고, 이 둘에 포함되지 않는 Port는 Alternated Port로 분류되어서 일반 통신 시에는 Block되어 사용이 차단된다. 여기서 Root Port가 된다는 것은 해당 Port로 내보내면 결국에는 데이터를 성공적으로 보낼 수 있다는 확신을 가질 수 있다.\n\n이제 Root Switch와 각 Port를 분류하기 위한 BPDU(Bridge Protocol Data Unit)을 알아야 한다. 이는 Spanning Tree를 구성하기 위해서 실제로 각 Switch가 주고 받는 Frame으로, Switch에 연결된 모든 Port에서 전송 또는 수신된다. 초기 Configuration을 수행하거나 Network 상태가 바뀌었을 때, 재합의 과정을 수행할 때 이 Data Unit을 각 Switch 간에 전송한다. 이때 포함되는 가장 중요한 정보가 **Bridge ID**이다. 이는 해당 Switch의 `VLAN 번호`, `MAC address`, `임의의 값`에 의해서 결정된다. 여기서 **Bridge ID**가 가장 낮은 Switch가 Root Switch가 된다. 이것이 완료되면 이제 각 Switch의 각 Port를 식별하는 과정을 거쳐야 한다. 과정은 다음과 같다.\n\n1. Bridge ID가 작은 Switch부터 Root Switch까지의 거리가 가장 짧은 Port는 Root Port가 된다. 만약 동일하다면 Bridge ID, Port ID를 비교하여 선택한다.\n2. 하나의 `Segment`(Switch간의 연결)에 반드시 하나의 Designated Port가 존재하도록 한다. 즉, 두 개의 Switch가 연결되었고, 한 Switch에서 특정 Port를 Root Port로 정했다면, 다른 Switch에서는 이와 연결된 Port를 Designated로 지정해야 한다.\n3. 어떠한 Port도 존재하지 않는다면, 남는 Port를 Designated Port로 지정하고, 이 반대 Port는 Alternated Port로 지정한다.\n\n이 과정이 끝나면, 이제 각 Port는 5가지 상태로 분류되어진다.\n\n1. Listening State(청취)  \n   Switch가 최초에 전원이 켜지면, 모든 Port는 Listening 상태에 들어간다. 그리고, 해당 Port가 만약 Alternated Port로 지정된다면, 이는 Block State로 변경된다. 그렇지 않고 Root/Designated Port로 지정된다면, 15초 정도의 여유를 두고 Learning State로 변경된다.\n2. Learning State(학습)  \n   전송을 수행하기 이전에, 연결된 Switch들의 MAC address를 학습하는 단계이다. 해당 단계가 15초 지속된 뒤에, Forwarding State로 넘어간다. 이 과정에서 갑자기 Port가 Alternated Port로 변경된다면, 이 또한 Block State로 바로 넘어간다.\n3. Forwarding State(전송)  \n   실제로 Data를 전송하는 단계이다. 이때에는 실제로 각 장치 간에 데이터가 이동할 수 있다.\n4. Blocking State(차단)  \n   이 상태에서도 해당 Port가 Root/Designated Port가 될 수 있다. 그럴 경우 Listening State로 변경되고, 통신 준비를 한다.\n5. Disable State(비활성)  \n   해당 Port가 고장 또는 비연결 등으로 비활성화되어 있는 상태이다.\n\n이렇게 결국은 Forwarding State에 도달하게 되었을 때 실제로 데이터를 주고 받는 것이 가능해지게 된다. 중간에 연결이 끊기더라도 유기적으로 계속해서 BPDU를 주고 받으면서 Root/Designated/Alternated Port로 역할이 계속해서 바뀌면서, 지속적인 연결을 추구한다. 하지만, 이 합의 과정이 생각보다 길기 때문에(Block -> Forwarding 45초 소요) 이를 해결하기 위한 RSTP, MSTP, SPB 와 같은 방법론도 있다.\n\n### Static Routing Protocol\n\ndata의 Route를 사전에 관리자가 직접 정의하는 방법이다. 이는 인터넷 가입자 구간에서 설정 시에 사용하며, 대표적인 예시가 Default Gateway 등을 지정하는 과정이다. 장애가 발생하더라도 계속해서 동일한 곳으로 요청을 보내기 때문에 장애에 대한 책임은 온전히 설정을 수행한 관리자에게 달려있다. AS에 상관없이 각 Router에서 직접적으로 다음 Link를 선택하기 때문에 AS에 상관없이 동일하게 설정한다.\n\n### Dynamic Routing Protocol\n\nRouter가 실행 중에 계속해서 장애에 대응하면서, 가용성 높은 Routing을 제공하기 위해서 경로를 최적화하는 방식이다. 이는 AS에 따라서 설정 방법이 상이하기 때문에 이에 따라서 분류한다.\n\n- **Interior(IGP)** : AS 내부에서의 Routing Protocol이며, Link의 상태를 기반으로 하는지 hop 수(중간 Router의 수)를 기반으로 하는지에 따라서 두 가지 종류로 나누어진다.\n  - **Distance Vector**  \n    Distance(Router 간의 Hop 수)와 Vector(방향)만을 고려하여 Routing Table을 구성한다. 인근 Router에 의해서 받은 정보를 통해서 구성하게 되며, Link의 Bandwidth, 현재 상태를 알지 못하기 때문에 최적화와는 거리가 멀다. 심지어는 반대 방향으로 돌아가는 현상도 발생할 수 있다. 종류는 대표적으로 아래 두 가지가 있다.\n    1. **RIP(Routing Information Protocol)**  \n       최초의 Dynamic Routing Protocol로 각 Router간의 Hop 수를 기반으로 Distance를 추정한다. 소규모 네트워크를 구축할 때는 매우 간단하게 설정이 가능하지만, Hop 수 만을 활용하기 때문에 복잡한 네트워크 구성에는 적절치 않다. 또한, 30초 단위로 업데이트가 발생하기 때문에, 빠른 장애 회복이 되지 않는다. 또한, 최대 Hop 수를 15로 제한하였고, 그 이상은 Network가 연결되지 않았다고 인식한다. version은 1,2가 존재하고, 2 역시 1과 대동소이 한다.\n    2. **IGRP(Interior Gateway Routing Protocol)**  \n      RIP와 유사하고, 기존 90초 단위로 Routing Table을 갱신하며, Hop 수를 255까지 확장하였다.\n  - **Link State**  \n    Link(통신선) 상태 역시 고려하는 Protocol이다. 단순한 기기 간의 거리 뿐만 아니라 bandwidth 등과 같은 정보도 활용한다. 또한 Network 전체의 정보를 포함하고 있다. 즉, **Routing Table의 크기가 굉장히 커질 수 있다. 이는 Router의 Memory 소모와 CPU 소모를 급격하게 늘린다.** 또한, Routing Table을 동일하게 유지해주는 Convergence(이것이 제대로 수행되지 않으면 통신 실패가 발생할 수도 있다.)를 수행하기 위해 소모되는 시간인 `Convergence Time`이 과도하게 커질 수도 있다. 이러한 문제를 해결하는 것이 해당 Link State 방식의 주요 목표이다.\n    1. **OSPF(Open Shortest Path First)**  \n      Network를 Area라는 단위로 나누고, 각 Area에서는 해당 Area에 해당하는 Routing Table을 보관하게 하여 전체 Routing Table의 크기를 줄인 방식이다. 같은 Area 내에서는 모든 Router가 동일한 Routing Table을 소지한다. 만약, 두 개 이상의 Area에 속한다면, 해당 Router는 두 개의 Routing Table을 소지하게 된다. Area가 하나일 경우에는 임의의 Area No을 사용해도 상관이 없지만, Area가 여러 개일 경우에는 Area 0이 반드시 존재해야 하며, 해당 Area 0를 중심으로 Topology가 구성되기 때문이다. 가장 대중적으로 많이 사용되는 Routing Protocol로 IGP 내에서는 Conversionce Time이 짧고 효율적이다. 최단 거리를 찾을 때에는 Dijkstra Algorithm을 활용하여 최단거리를 탐색한다.\n    2. **ISIS(Intermediate System - Intermediate System)**  \n       Intermediate System은 Router를 의미하며, 같은 Area에 속하는 Router간의 Routing Table을 공유하는 개념으로 Router를 총 두 가지로 나눈다. 하나는 여러 Area에 걸쳐 있는 Level 2, 하나의 Area에 속하는 Level 1이다. 대게 모든 Router가 Level 2에 속하기 때문에 굉장히 큰 Routing Table을 가지게 된다. Routing Table이 커질 수 있지만 Conversionce Time이 줄어들고, Backborn을 Area 0으로 제한하지 않기 때문에 OSPF보다 더 유연한 네트워크 구조를 구축할 수 있다.\n  - **Hybrid**\n    - **EIGRP(Enhanced Interior Gateway Routing Protocol)**  \n      Hop 수를 256개로 늘리고, 주기 없이 Network 환경이 변화되면 바로 적용되도록 바꾸었다. 또한, Hop 수 외에도 Bandwidth, Delay, Load, MTU 등을 추가적으로 계산하여 Link State 역시 활용하는 방식이다.\n- **Exterior(EGP)**  \n  나뉘어진 AS 간의 통신을 지원하기 위한 방법이다.\n  - **BGP(Border Gateway Protocol)**  \n    서로 다른 AS를 연결하는 Protocol로 TCP에 기반하며, IGP와 같이 연동하여 전체 네트워크를 구성할 수도 있고, 자체적으로 정의한 Interior BGP를 활용하여 BGP만으로 네트워크를 구성하는 것도 가능하다. 따라서, BGP는 iBGP(interior BGP), eBGP(exterior BGP)로 나눌 수 있다. BGP는 여타 IGP들과는 다르게 AS간의 Routing을 중계하기 때문에 Routing Table의 크기가 매우 크고, 이에 대한 처리에 특화되어있다. 하지만, 대게 BGP라고 하면 eBGP를 의미한다. 특이하게 BGP는 기존의 Link State나 Hop 수에 기반하지 않고 Attribute(Hop, Bandwidth, ACL, Weight 등)라는 것을 별도로 활용한다. Dynamic Routing 방식이지만, 각 Link에 대한 정보는 앞에서 언급한 Attribute를 이용하여 수동으로 설정해주어야 한다. 하지만, BGP는 Broken Gateway Protocol이라는 별명이 있을 정도로 현재 많은 문제를 야기하고 있다. BGP Table의 크기가 102.4만 개를 초과할 시에 일부 Router의 Memory가 부족해지는 현상이 발생할 수 있다. 현재 해당 크기에 도달 시점을 2023년 말 정도로 예측하고 있다. 또한, 이렇게 커진 Table의 크기로 인해 Convergence Time도 굉장히 많이 소모하고 있다.(완전 수렴까지 15분 소요)\n\n## Reference\n\n- Thumbnail : Photo by [Nick Seagrave](https://unsplash.com/@seagrave?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/s/photos/route?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n","slug":"routing","date":"2022-05-30 12:28","title":"Routing","category":"Network","tags":["Routing","RIP","EIGRP","OSPF","BGP","ISIS"],"desc":"Routing은 우리가 주고 받고자 하는 데이터를 전달하기 위해서 목적지를 찾아나가는 과정이다. 어떻게 해서 IP를 통해서 목적지를 찾아 데이터가 이동할 수 있는지를 알아볼 것이다.","thumbnailSrc":"https://euidong.github.io/images/routing-hero.jpg"},{"content":"\n## Intro\n\nSDN(Software Defined Network)은 기존에 Hardware단에 결합되어 있던 각종 Routing, Forwarding 방식을 별도의 Controller를 통해서 제어하는 방식을 제시한 것이다. 현재 이러한 기술에 대한 연구가 꾸준히 이루어지고 있는데, 이유를 알기 위해서는 기존의 Network 구성 방식의 문제점을 먼저 짚어보자.\n\n## Internet의 문제\n\n> **Traffic 과증가**\n\nTraffic의 매년 20% 이상으로 굉장히 가파르게 성장하고 있다. 이것 자체도 문제가 될 수 있지만, 이로 인한 문제가 더 큰 문제가 되고 있다.\n\n> **통신사업자의 고민**\n\n계속해서 늘어나는 traffic 대비 수익의 정체가 발생하였다. 즉, 증가하는 traffic을 수용하기 위한 link, switch 등의 투자 비용은 계속해서 요구되는 한편 신규 가입자 수는 거의 존재하지 않기 때문에 통신사업자가 가져가는 수익은 현재 매우 정체되어있다. 반면에 늘어난 traffic에 대한 이득은 고스란히 대규모 service 업체에서 가져가고 있다. (ex. Google, Netflix, etc..)\n\n이러한 관점에서 통신사업자와 서비스 사업자 간의 아래와 같은 대립이 계속되고 있다.\n\n- 공정성(Fairity) : traffic 증가는 서비스 사업자도 같이 부담하자.\n- 망중립성(Neutrality) : traffic 증가는 서비스 사업자가 상관할 영역이 아니다.\n\n> **느린 표준화**\n\n표준화라는 절차는 호환성 검사 및 성능 확인 등을 거치면서 굉장히 많은 시간을 요구한다. 하지만, 신기술은 계속해서 쏟아지고 있기 때문에 표준화가 이 속도를 못따라가고 있는 것이 실황이다. 이를 실제 상용에서 적용하는 것 역시 더 많은 시간이 들게 될 수 있다.\n\n> **Vender 의존성**\n\n통신 장비(Switch, Router, Ethernet, etc...)를 제작하는 Vender(Cisco, Juniper, etc...)가 만든 platform에 의존하는 설정 방법이 혼란을 야기했다. 즉, 각 vender마다 다른 시스템과 configuration 방법이 존재하기 때문에 human error를 야기할 가능성이 높았다.\n\n또한, Switch/Router의 동작을 제어하는 것이 해당 vender가 제공하는 API에 제한되기 때문에 사용자가 Programming을 통해 Routing을 제어하는 것이 불가능했다. 그렇기에 신기술에 대한 테스트를 수행할 수 없을 뿐만 아니라 Vender에서 해당 신기술을 적용하기를 기다리는 수 밖에 없었다.\n\n> **Router/Switch의 복잡도 증가**\n\ntraffic의 증가만큼 Router, Switch의 성능적인 향상 및 양적 증가는 많은 문제를 야기하고 있다. 먼저, 성능을 만족하기 위하여 점점 가격이 급격하게 상승하고 있다. 양적으로의 증가는 결국 Routing Table의 크기를 크게 증가시키고 있다. 이는 Table Lookup, Convergence Time 증가를 야기한다.\n\n> **초기 인터넷의 구조적 문제**\n\n초기 인터넷인 ARPANET은 설계 자체가 절대 연결이 끊기지 않는(autonomous, Best Effort) Network를 추구했다. 그렇기에 사람에 의한 개입이 쉽지 않고, 통제가 어려운 구조이다. 따라서, 각 장비에게 부여되는 책임이 커졌다.\n\n> **TCP/IP 기반의 수 많은 Protocol**\n\n지연보다는 연결에 초점을 맞춘 안전한 TCP/IP 기반의 통신은 Network의 성능면에서 많은 어려움을 겪고 있다. 물론 새로운 TCP 방식도 제시되고 있지만, 이를 교체하는 것은 전체 Network를 변경해야하는 경우가 많기에 이에 대한 교체는 사실상 불가능하다고 간주되고 있다(호환성 문제). 또한, IoT 디바이스에서는 해당 TCP/IP가 다소 무거운 구현이기에 이를 포함할 수 없는 경우가 많다. 따라서, 별도의 Protocol을 지원하는 시스템이 필요하다.\n\n### 요약\n\n즉, Traffic은 계속해서 증가하고 있는데, 이를 해결하기 위한 신기술들은 계속해서 적용이 느려지고 있으며, Vender들 마다 다른 표준으로 인해 너무나 복잡한 네트워크 구성은 운영비용의 최적화가 어렵고, 유연한 네트워크 구조를 만드는데 굉장한 부담으로 다가왔다. 따라서, 이를 해결할 방법이 필요해졌다.\n\n## SDN\n\n위에서 제시한 문제들은 결국 각 Switch/Router와 같은 Hardware 장치에 Software가 귀속되어서 발생한다. 따라서, Switch/Router는 단지 Hardware의 기능을 수행하도록하고, Software는 최소한의 기능만을 남긴 후 이들이 수행하는 Forwarding/Routing 등의 동작을 별도의 Generic Computer에 Controller라는 역할을 부여하고, 이 Controller에 의해서 Forwarding/Routing을 제어할 수 있도록 구성한 Network를 통해서 기존 문제를 해결하자는 것이다.\n\n이를 통해서, 결국 각 장치들은 Routing이 어떻게 정해졌는지에 대한 내용은 알지 못한다. 하지만, Hardware적으로 packet의 입력을 받을 수 있을 뿐만 아니라 Controller로부터 어디로 packet을 forwarding 해야할지에 대한 정보는 알고 있고, 이에 따라 packet을 내보내는 것도 가능하다. 따라서, 전체 네트워크가 Controller를 분리함으로써 추상화가 되는 것이다. 이러한 추상화의 장점은 결국 유연한 네트워크를 만들 수 있다는 것이다.\n\n이것이 SDN이 추구하는 사상이다. 이것을 가능하게 한 것이 OpenFlow의 등장이다. OpenFlow에 대한 설명은 별도의 [Posting](/posts/openflow)에서 다룬다.\n\n### Google의 SDN 활용 사례\n\n> **문제 상황**\n\nGoogle에서는 매년 40\\~45%의 Traffic의 증가가 발생하였다. 이를 대비하기 위해서, Google에서 전용 해저 케이블을 설치하였다. 이를 통해서, Google의 각 DataCenter 간의 연결 품질을 올리고 싶었다. 하지만, 실제로 DataCenter간의 통신에는 30\\~40% 수준으로만 케이블을 사용했다. 기존의 Routing으로 DataCenter간 서비스의 Traffic을 적절하게 분배하고 싶었지만 이를 수행할 수 없었다.\n\n> **해결책**\n\n자체 개발한 OpenFlow Protocol을 지원하는 Switch를 개발하여, 이를 이용하여, 다음과 같은 서비스에 weight를 부여하여 적절하게 traffic을 분배하였다.\n\n- User data copy : 각 데이터 센터간의 e-mail, video 등의 파일 동기화\n- 검색어 ranking을 위한 데이터 copy\n- Datacenter간 상태 동기화\n\n해당 service에서 발생하는 traffic을 적절하게 weight를 부과하여 SDN을 활용하여 분배하여 결국 Datacenter간의 통신에서 광케이블 활용률이 90%까지 상승했다.\n\n### 주요 OpenSource\n\nSDN 구축에 많이 활용되는 주요 OpenSource를 정리한다. 그전에, OpenSource의 구성 형태를 알아볼 필요가 있다. 아래와 같은 형태로 각 OpenSource를 구분하여 살펴볼 수 있다.\n\n![SDN Architecture](/images/sdn-arch.jpeg)\n\n- North : 실제 SDN Controller와 communication을 통해 SDN configuration을 변경한다던가 GUI로 현재 상태를 체크하는 등의 동작을 수행할 수 있다.\n- North Bound Interface : SDN Controller와 communication을 가능하게 하는 Protocol이다.\n- SDN Controller : 실제 SDN에서 Routing을 제어할 Controller\n- South Bound Interface : SDN Controller와 Network Node들(실제 또는 가상 Switch)과의 communication을 가능하게 하는 Protocol이다.\n- South : Physical / Virtual Switch\n\n각 OpenSource에 대해서는 자세히 다루지 않는다. 세부적으로는 시간이 주어지면 하나씩 해나갈 생각이다.\n\n> **ONOS**\n\n위에서 설명한 영역에서 North, North Bound Interface, SDN Controller의 역할을 모두 수행할 수 있는 Open Source이다.\n\nOpen Network Operating System의 약자로, ONF에서 관리하며 SDN Controller를 구성하는 방법을 제시한다. 이를 통해서, 유연하고 안정적인 Network Service를 구축하는 것을 목표로 한다. 유연하다는 것은 간단한 program을 구현할 수 있는 interface를 제공하며, 네트워크 상태를 정의하고, 이를 실시간으로 업데이트할 수 있는 환경을 제공한다. 안정적이다의 기준을 ONOS에서는 99.999 % Availability를 제공하는 것을 목표로 한다.\n\n본 목적은 Controller를 구성하는 것이지만, REST API(NIB)에서부터 Web을 통한 Dashboard GUI(North)와 CLI(North)를 제공하고 있다. 또한, 내부적으로 OpenFlow의 동작을 추상화하여\n\n[🔗 공식 사이트](https://wiki.onosproject.org/display/ONOS/ONOS)\n\n> **Open DayLight**\n\nONOS와 가장 많이 비교되어지는 OpenSource로 마찬가지로 North, North Bound Interface, Controller 기능을 제공한다.\n\nCisco와 Network Vender를 모아서, ONOS를 견제하기 위해서 초기에 시작된 Project로 ONOS는 SDN Controller에 좀 더 집중하는 한편, Open DayLight는 SDN 시스템을 구축하는 환경을 제공하는 것을 강조한다. 또한, Vender에 의해서 관리되기 때문에 ONOS와 비교하였을 때, SBI가 케이블tv 및 IoT Protocol까지 확장되었다. 자세히는 아래 표를 통해서 살펴보도록 하자.\n\n|                 | ONOS                    | Open DayLight            | 비고                    |\n| :-------------- | :---------------------- | :----------------------- | :---------------------- |\n| 라이선스        | Apache 2.0              | Eclipse Public License   |                         |\n| 개발자          | 제한 없음               | Vender                   |                         |\n| SBI 지원        | 여러 SBI 지원           | ONOS보다 다양한 SBI 지원 |                         |\n| 주요 고객       | 통신 및 클라우드 사업자 | 데이터 센터              |                         |\n| 보안성          | 약함                    | 중간                     | 아직 모두 보완성이 낮음 |\n| OpenFlow 호환성 | 1.0 ~ 1.5               | 1.0 ~ 1.3                | ONF 표준                |\n| P4              | 지원                    | 지원                     |                         |\n| Network 가상화  | 지원                    | 지원                     |                         |\n\n[🔗 공식 사이트](https://www.opendaylight.org)\n\n> **ONAP**\n\nONAP은 Open Network Automation Platform의 약자로 SDN의 Life Cycle을 관리하는 도구로 이해하면 쉽다. 위의 제시한 Controller로 부터 각 각의 Switch에 이르는 장치들의 상태를 확인하고, 적절하게 orchestration하는 도구이다. 이는 AT&T의 ECOMP project와 중국 네트워크를 위한 Open-O가 결합하여 Opensource화를 진행한 프로젝트이다.\n\n[🔗 공식 사이트](https://www.onap.org)\n\n> **P4**\n\nProgrammable, Protocol-Independant Packet Processor의 약자로 기존의 제한된 기능만 수행하던 Fixed Function Switch를 필요에 따라 기능을 다르게 구현할 수 있는 Programmable Switch로 대체하고, P4를 이용하여 programming할 수 있는 환경을 제공하는 것을 목표로 한다. 현재에는 Switch 내부의 Packet Forwarding과 Access Control 기능 개발용으로 특화된 상태이다. 아직까지는 Queue의 Scheduling과 같은 기능은 제공하지 않는다.\n\n[🔗 공식 사이트](https://p4.org)\n\n> **DPDK**\n\n고성능 packet 처리를 위한 Library와 Driver의 집합이다. Virtual Switch의 가장 큰 문제는 OS Kernel을 통과하면서 발생하는 Overhead이다. 이를 해결하기 위해서, DPDK에서는 Kernel을 통과하여 수행하는 Kernel bypass라는 기능을 제공한다. 이를 통해서 Packet 처리를 가속화하였다.\n\n[🔗 공식 사이트](https://www.dpdk.org)\n\n> **FD.io**\n\nDPDK와 마찬가지로 packet 전송의 가속화를 목표로 한다. 기존 하나의 Packet을 보낼 때, 그래프 연산이 끝날 때까지 다음 packet이 무기한 기다리는 것을 방지하고자 병렬 또는 동일 목적지 packet을 빠르게 식별하여 packet 전송을 최적화하는 것을 목표로 한다.\n\n[🔗 공식 사이트](https://fd.io)\n\n> **OpenStack**\n\nOpenStack은 범용 Cloud를 구축하는 Solution을 제공한다. 즉, 여러 Node를 가진 사용자라면, 여타 Vender(AWS, GCP)를 이용하지 않고, Cloud 환경을 구축하는 것이 가능하다. 이를 통해서 구축한 Cloud에 Controller를 구성하고 SDN를 제공하는 경우도 많다.\n\n[🔗 공식 사이트](https://openstack.org)\n\n### 주요 SBI\n\nSouth Bound Interface란 실제로 Switch와 Controller가 어떻게 communication을 수행할 것인지에 대한 Protocol을 의미한다. 현재 사실상 표준이라고 여겨지는 Protocol은 다음과 같다.\n\n> **OpenFlow**\n\n앞 서 계속해서 설명해왔기에 생략한다.\n\n> **NetConf**\n\nNetwork 장비(Switch, Router)의 Configuration을 위한 Protocol로 기존 Vender마다 다르던 Configuration 과정을 이를 통해서 간략화하고, 기초적인 Programming을 통해서 이 과정을 자동화하는 것도 가능하다.\n\n> **I2RS**\n\nOpenFlow를 통해서 기존 Network 장비의 데이터 평면과 제어 평면의 완전 제거에 대한 반발로 인해 생겨나 Protocol이다. 이는 Cisco에서 만들어졌으며, 기존 Switch/Router의 제어 평면을 그대로 유지하면서 외부 Controller로부터의 제어를 일부 수용하는 형태의 Protocol이다.\n\n> **BGP-LS / PCE-P**\n\nSDN Controller와 Network 상태 정보를 공유하기 위해 개발된 Protocol이다.\n\n> **LISP**\n\nIP에 의한 네트워크 주소와 단말기 주소가 완벽하게 구분되지 않는 문제에 의해서 만들어졌다. 즉, 단말이 이동 시에 네트워크 주소를 재설정해주는 등의 번거로움이 발생할 수 있다.따라서, IP header에 LISP header를 추가하여 실제 기기 주소와 네트워크 주소를 식별하는 정보를 추가하는 것이 핵심 아이디어인 Protocol이다.\n\n### 주요 연구 동향\n\n> **1. CORD**\n\n현재까지는 DataCenter, Cloud에 한정되어 있는 SDN의 적용을 실제 전화국 및 가입자 통신 시설의 가상화까지 이어가고자 하는 것이 목표이다. 현재 프로젝트는 총 4개의 세부 프로젝트로 나뉘어져서 진행중이다.\n\n1. E-CORD : 기업용 최적 인터넷 구성 시간 단축\n2. R-CORD : 광가입자 서비스 장치의 가상화\n3. A-CORD : 데이터 수집 기능을 프로그래밍 가능하게 구현하여 이를 통한 제어를 목표\n4. M-CORD : 4G/5G 장치의 가상화\n\n> **2. Pronto Project**\n\n네트워크의 모든 동작을 Monitoring하고, 제어하는 Deep Programmable Platform을 구현하여 네트워크 사업자가 제어권을 확보하도록 하는 것을 목표로 한다.\n\n## NFV\n\nSDN과 같이 얘기되어지는 NFV(Network Function Virtualization)도 살펴보고자 한다. 위에서 SDN을 설명하였지만, 결국 아직까지는 DataCenter를 운영하는 서비스 사업자 지향적이다. 대게 닫힌 네트워크 내에서 사용이 용이하다는 것인데, 이는 보안과 관련된 부분도 부족하기 때문이다. 따라서, 통신 사업자들은 SDN을 효과적으로 구성하기 위해서 통신 장비의 하드웨어와 소프트웨어를 분리할 방법을 찾아야 했다. 여기서 나온 방법이 Cloud를 활용하여 소프트웨어 영역을 Cloud 내부에서 구현하고, 통신 장비는 최소한의 소프트웨어만으로 구성하는 것이다. 즉, Network의 특정 기능을 가상화해서 필요에 따라 각 하드웨어 장비가 불러와 사용한다는 개념이다. 결국 통신 사업자 입장에서는 SDN을 구축하기 위해서는 NFV의 구현이 우선시되는 것이다. 이를 수행하게 되면, 당연히 Software의 유연한 구현이 가능하고, 각 장치에서 Software까지 부담해야 하는 비용이 줄기 때문에 설치 및 운영비용(CAPEX / OPEX)에서 큰 이점을 볼 수 있는 것이다.\n\n## Reference\n\n- Thumbnail : Photo by [Nastya Dulhiier](https://unsplash.com/@dulhiier?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/s/photos/network?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n","slug":"sdn","date":"2022-05-25 09:00","title":"SDN","category":"Network","tags":["SDN","NFV","OpenFlow","ONOS","OpenDayLight","P4","DPDK","FD.io","OpenStack","CORD"],"desc":"SDN(Software Defined Network)은 기존에 Hardware단에 결합되어 있던 각종 Routing, Forwarding 방식을 별도의 Controller를 통해서 제어하는 방식을 제시한 것이다. 현재 이러한 기술에 대한 연구가 꾸준히 이루어지고 있는데, 이유를 알기 위해서는 기존의 Network 구성 방식의 문제점을 먼저 짚어보자.","thumbnailSrc":"https://euidong.github.io/images/network-background.jpg"},{"content":"\n## Intro\n\nSDN을 실제 구현하는 것은 굉장히 어려운 일이다. 따라서, Mininet을 활용하여 가상의 Topology를 통해서 먼저 테스팅을 한 후에 실제로 적용하는 것이 일반적이라고 할 수 있다.\n\n따라서, 해당 Posting에서는 `Mininet`, `OpenFlow`, `Open VSwitch`, `ONOS`를 이용하여 간단한 Tutorial을 수행해볼 것이다. 이 Posting을 통해서 남기고자 하는 것은 SDN을 테스팅하는 절차를 익히는 것이다.\n\n## 0. Tools\n\n먼저 작성자의 실행환경은 MAC OS X로 대부분의 설정은 모두 동일하지만 `XTerminal`은 Window/MAC이 다르기 때문에 Window 전용을 설치해야 한다.\n\n- Host Machine\n  - Virtual Box : [🔗 Download](https://www.virtualbox.org/wiki/Downloads) [🔗 공식사이트](https://www.virtualbox.org/)\n    - VM을 실행시키기 위한 도구, OpenSource이며 무료이기 때문에 많이 사용된다.(v6.1)\n  - Vagrant : [🔗 Download](https://www.vagrantup.com/downloads) [🔗 공식사이트](https://www.vagrantup.com/)\n    - Virtual Environment 구축을 자동화하는 도구(v2.2.19)\n  - XQuartz : [🔗 Download](https://www.xquartz.org/releases/index.html) [🔗 공식사이트](https://www.xquartz.org/)\n    - XTerminal 시스템으로 원격으로 Graphic 시스템을 호스팅하는 도구이다. 즉, `ssh`로 접속한 시스템에서 추가적으로 terminal을 생성하거나 GUI를 요구하는 application을 실행시킬 때 이를 host machine에서 실행할 수 있도록 돕는다.(v2.8.1)\n- Virtual Machine\n  - Mininet : [🔗 Download](http://mininet.org/download/) [🔗 공식사이트](http://mininet.org/)\n    - Network Topology를 가상으로 구성할 뿐만 아니라 추가적인 configuration / testing이 가능한 Virtual Environment Emulator(v2.3.0)\n  - OpenVSwitch : [🔗 Download](https://www.openvswitch.org/download/) [🔗 공식사이트](https://www.openvswitch.org/)\n    - Virtual Switch를 실행시킬 수 있는 tool이다. 이를 통해서, Virtual Machine 내부에서 Virtual Switch를 가동시킬 수 있다.OpenFlow Protocol에 기반한 다양한 API를 내재하고 있기 때문에 이를 통해서 Virtual Switch의 Configuration 등과 같은 작업을 수행할 수도 있다.(v2.9.8)\n  - ONOS : [🔗 Download](https://wiki.onosproject.org/download/) [🔗 공식사이트](https://wiki.onosproject.org/)\n    - Open Network Operation System으로 SDN의 Controller 역할을 수행할 수 있다. 뿐만 아니라 WEB Interface도 제공하며, 다양한 API를 추가적으로 제공하기 때문에 유용하다.(v2.5.7)\n\n## 1. Setup\n\n위에 제시한 Tool을 모두 `Virtual Machine` 내부에 설치해야하지만, 자동으로 해당 tool을 설치하는 `Vagrantfile`을 만들어놓았기 때문에 사용해도 좋을 것이다. 해당 VagrantFile로 build하면 시간이 굉장히 소요될 수 있다. (인터넷 상태에 따라 천차만별이지만, 대략 20분?)\n\n```bash\n$ git clone https://github.com/euidong/virtual-sdn-boilerplate\n$ cd virtual-sdn-boilerplate\n$ vagrant up\n# 접속\n$ vagrant ssh\n```\n\n> **Run ONOS**\n\n```bash\n# In Virtual Machine\n$ cd $ONOS_ROOT\n$ bazel run onos-local\n```\n\n## 2. Scenario를 작성\n\n우선 어떤 상황을 **emulation**할 것인지에 대한 구체적인 계획이 필요하다. 따라서, 이를 먼저 구상해보자. 아래 예시는 단순히 내가 생각한 예시이므로 정확성이런 것은 생각하기 보다는 흐름만을 익혀보자.\n\n```plaintext\n💡 Base Scenario\n\n1. 후지산 인근에서 계속해서 화산활동이 감지되고 있다. 또한, 후지산은 100년 단위로 폭발을 해왔는데 최근 170여 년 동안 폭발이 존재하지 않고 있다. 이로 미루어보았을 때 후지산의 화산폭발은 얼마 남지 않았을 것이라고 추측할 수 있다.\n2. 후지산에서 폭발이 발생하는지를 파악하기 위해서 곳곳에 관측기가 필요하며, 이를 분석할 센터가 안전을 위해 후지산 아래에 존재하며 백업 서버를 별도로 다른 공간에 두고 있다.\n3. 각 관측소에서 서로 간 데이터 공유도 계속해서 발생하는 경우가 빈번하다. => Horizontal traffic이 많다 -> datacenter와 유사한 형태의 Network -> Spine-Leaf 구조가 적절.\n```\n\n## 3. Topology 구성 with Mininet\n\n먼저, topology를 작성해야한다. 이를 위해서 `Mininet`을 활용한다. 이에 대한 개념 정리는 [🔗 Mininet](/posts/mininet)애 해두었다. Base Scenario의 3번 사항에서 알 수 있듯이 우리의 Topology는 Spine-Leaf 구조를 갖는 것이 적절하다. 따라서, 이를 먼저 표현해보도록 하겠다.\n\n> **Source Code**\n\n- `/vagrant/example/mt-fuji/topo.py`\n\n```python\nfrom mininet.topo import Topo\n\nclass SpineLeaf(Topo):\n  def build(self):\n    s_num = 2\n    l_num = 5\n    h_num = 2\n    spines = []\n    leaves = []\n    hosts = []\n\n    for i in range(s_num):\n      spines.append(self.addSwitch('s%s%s' % (1, i+1)))\n    for i in range(l_num):\n      leaves.append(self.addSwitch('l%s%s' % (2, i+1)))\n      for j in range(s_num):\n        self.addLink(spines[j], leaves[i])\n      for j in range(h_num):\n        hosts.append(self.addHost('h%s%s' % (i+1, j+1)))\n        self.addLink(leaves[i], hosts[i * h_num + j])\n\ntopos = { 'spineleaf': (lambda: SpineLeaf()) }\n```\n\n- 실행\n\n```bash\n$ sudo mn --mac --controller remote --switch ovs --custom /vagrant/example/mt-fuji/topo.py --topo=spineleaf\n```\n\n- 실행 결과\n  - 빨간색 : `Spine Switch`\n  - 청록색 : `Leaf Switch`\n\n![Spine-Leaf Topology](/images/spine-leaf-topo.png)\n\n## 4. Test 환경구축\n\n주로 사용되는 Test 환경용 도구는 다음과 같다.\n\n1. `ping` : 특정 machine 간의 연결 상태를 확인하기 위해서 많이 사용되어진다.\n2. `trace` : `ping`과 유사하지만 지나쳐간 `hop`을 모두 조회 가능하여 좀 더 세부적인 경로를 확인할 때 유용하다.\n3. `iperf` : client와 server 구조로 이루어지며, `tcp`, `udp` packet을 전송할 수 있다. 특정 machine에서는 `server`로 실행시키고, 다른 machine에서 해당 `server`로 data를 보내도록 할 수 있다. `ping`보다 주기적으로, 대용량의 데이터를 보내고 관측할 수 있다.\n4. `wireshark` : 실젤 traffic의 이동을 GUI로 볼 수 있도록 돕는 도구이다.\n5. `ONOS WEB GUI` : ONOS에서는 Web을 통해서 Network 상태와 Traffic을 관측하는 것이 가능하다.\n\n여기서는 `iperf`를 통해서 데이터를 전송하고, `ONOS WEB GUI`를 통해서 traffic을 관측할 것이다.\n\n아래 command를 통해서 `h51`가 위에서 언급한 후지산 아래의 서버가 되고, `h52`가 백업 서버가 되는 상황을 가정하기 위해서 해당 두 위치를 `iperf server`로 지정한다. 그리고 모든 관측소(`h11`, `h12`, ..., `h41`, `h42`)에서 `iperf client`가 되어 traffic을 주기적으로 보내도록 설정한다.\n\n```bash\nmininet> h51 iperf -s -u &\nmininet> h52 iperf -s -u &\n\n# xterm 명령어는 host에 위에서 설명한 XQuartz가 정상적으로 설치되어있어야 작동한다.\nmininet> xterm h11 h12 h21 h22 h31 h32 h41 h42\n\n# 각 client에서 다음과 같은 요청을 전송한다.\n$ iperf -u -c 10.0.0.9 -i1 -t100000000000\n```\n\n![ONOS에서 확인한 모습](/images/sdn-tuto-example-1.png)\n\n## 5. Flow Control\n\n기본적으로 Flow를 제어할 수 있는 방식은 해당 Setting을 수행핼 때, 3가지 방법이 있다.\n\n1. Open vSwitch CLI : OpenFlow Protocol에 기반한 여러 CLI 명령어를 지원한다. 이를 통해서, Flow Table을 직접 작성하는 것이 가능하다.\n2. ONOS REST API : ONOS REST API를 통해서 제어가 가능하다. 이때에는 ONOS가 high level로 추상화한 flow control 방식을 활용해야 한다.(ex. intent) 이는 ONOS를 실행하고 있다면, 다음 url에서 확인이 가능하다. [http://localhost:8181/onos/v1/docs/](http://localhost:8181/onos/v1/docs/)\n3. ONOS CLI : ONOS CLI 명령어를 통해서 제어가 가능하다.\n\n이제부터 해당 세가지 방식을 적절히 활용하여 설정하여 각 Simulation 별로 수행을 해보도록 하겠다.\n\n### Scenario 1\n\n> **중간에 link가 끊어진 경우 with ONOS CLI**\n\n![sdn-tuto-scenario-1](/images/sdn-tuto-scenario-1.png)\n\n먼저 모든 host에서 server로 traffic을 중계해줄 수 있도록 다음과 같이 intent를 설정해줄 수 있다. 특정 host간의 intent를 설정하면 자동으로 경로를 찾아서 routing을 수행해준다. 또한, 특정 연결이 중간에 사라져도 자동으로 경로를 재설정한다.\n\n```bash\nonos> add-host-intent 00:00:00:00:00:01/None 00:00:00:00:00:09/None\nonos> add-host-intent 00:00:00:00:00:02/None 00:00:00:00:00:09/None\nonos> add-host-intent 00:00:00:00:00:03/None 00:00:00:00:00:09/None\nonos> add-host-intent 00:00:00:00:00:04/None 00:00:00:00:00:09/None\nonos> add-host-intent 00:00:00:00:00:05/None 00:00:00:00:00:09/None\nonos> add-host-intent 00:00:00:00:00:06/None 00:00:00:00:00:09/None\nonos> add-host-intent 00:00:00:00:00:07/None 00:00:00:00:00:09/None\nonos> add-host-intent 00:00:00:00:00:08/None 00:00:00:00:00:09/None\n```\n\n이 후에 mininet에서 특정 link를 비활성화시킨다.\n\n```bash\nmininet> link s11 l25 down\n```\n\n![sdn-tuto-scenario-1-result](/images/sdn-tuto-scenario-1-result.png)\n\n### Scenario 2\n\n> **Load Balancing을 통해서 측정 데이터 고르게 분배 with Open Vswitch CLI**\n\n![sdn-tuto-scenario-2](/images/sdn-tuto-scenario-2.png)\n\n이전 Scenario의 intent를 유지한 상태에서 OpenFlow의 Group Table의 `select` type을 활용하면, Load Balancing이 가능하다. 먼저, ONOS CLI에서 외부 flowRule도 받아들이도록 설정한 후\n\n```bash\n$ onos localhost\nonos> cfg set org.onosproject.net.flow.impl.FlowRuleManager allowExtraneousRules True\n```\n\n다음과 같이 group entry 생성 및 flow추가로 구현이 가능하다.\n\n```bash\n$ sudo ovs-ofctl add-group l21 \\\n  \"group_id=1,type=select,bucket=output:1,bucket=output:2\" -O OpenFlow11\n$ sudo ovs-ofctl add-flow l21 in_port=3,actions=group:1 -O OpenFlow11\n$ sudo ovs-ofctl add-flow l21 in_port=4,actions=group:1 -O OpenFlow11\n\n$ sudo ovs-ofctl add-group l22 \\\n  \"group_id=1,type=select,bucket=output:1,bucket=output:2\" -O OpenFlow11\n$ sudo ovs-ofctl add-flow l22 in_port=3,actions=group:1 -O OpenFlow11\n$ sudo ovs-ofctl add-flow l22 in_port=4,actions=group:1 -O OpenFlow11\n\n$ sudo ovs-ofctl add-group l23 \\\n  \"group_id=1,type=select,bucket=output:1,bucket=output:2\" -O OpenFlow11\n$ sudo ovs-ofctl add-flow l23 in_port=3,actions=group:1 -O OpenFlow11\n$ sudo ovs-ofctl add-flow l23 in_port=4,actions=group:1 -O OpenFlow11\n\n$ sudo ovs-ofctl add-group l24 \\\n  \"group_id=1,type=select,bucket=output:1,bucket=output:2\" -O OpenFlow11\n$ sudo ovs-ofctl add-flow l24 in_port=3,actions=group:1 -O OpenFlow11\n$ sudo ovs-ofctl add-flow l24 in_port=4,actions=group:1 -O OpenFlow11\n```\n\n![sdn-tuto-scenario-2-result](/images/sdn-tuto-scenario-2-result.png)\n\n### Scenario 3\n\n> **h51이 down되어 h52로 traffic redirection with Open Vswitch CLI**\n\n![sdn-tuto-scenario-3](/images/sdn-tuto-scenario-3.png)\n\nserver로 가는 Leaf Switch에서 packet의 IP, MAC 주소를 변경하여 Redirection이 가능하다.\n\n```bash\n$ sudo ovs-ofctl add-flow l25 \\\n  \"in_port=1, dl_dst=00:00:00:00:00:09,\n   actions=mod_dl_dst:00:00:00:00:00:10,mod_nw_dst:10.0.0.10,output:4\"\n$ sudo ovs-ofctl ad-flow l25 \\\n  \"in_port=4, dl_src=00:00:00:00:00:10,\n   actions=mod_dl_src:00:00:00:00:00:09,mod_nw_dst:10.0.0.9,output:1\"\n```\n\n![sdn-tuto-scenario-3-result](/images/sdn-tuto-scenario-3-result.png)\n\n### Scenario 4\n\n> **Meter를 이용해서 관측소로 가는 과도한 traffic 차단 with ONOS REST API**\n\n![sdn-tuto-scenario-4](/images/sdn-tuto-scenario-4.png)\n\n특정 Switch에서 특정 port로 나가는 traffic의 최대값을 `500KB/s`로 제한하는 예시이다.\n\n- Meter를 생성하기 위한 REST API  \n  **`/meters/of:000000000000000c`로 POST 요청**\n\n```json\n{\n  \"deviceId\": \"of:000000000000000c\",\n  \"unit\": \"KB_PER_SEC\",\n  \"burst\": true,\n  \"bands\": [\n    {\n      \"type\": \"DROP\",\n      \"rate\": 500,\n      \"burstSize\": 0,\n      \"prec\": 0\n    }\n  ]\n}\n```\n\n- Meter를 특정 Switch에 적용하기 위한 REST API  \n  **`/flows/of:000000000000000c?appId=meter`로 POST 요청**\n\n```json\n{\n  \"priority\": 40000,\n  \"isPermanent\": true,\n  \"deviceId\": \"of:000000000000000c\",\n  \"treatment\": {\n    \"instructions\": [\n      {\n        \"type\": \"METER\",\n        \"meterId\": \"1\"\n      },\n      {\n        \"type\": \"OUTPUT\",\n        \"port\": \"2\"\n      }\n    ]\n  },\n  \"selector\": {\n    \"criteria\": [\n      {\n        \"type\": \"ETH_TYPE\",\n        \"ethType\": \"0x0800\"\n      }\n    ]\n  }\n}\n```\n\n![sdn-tuto-scenario-4-result](/images/sdn-tuto-scenario-4-result.png)\n\n## Reference\n\n- Thumbnail : Photo by [Alina Grubnyak](https://unsplash.com/@alinnnaaaa?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/s/photos/virtual-network?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n","slug":"sdn-tutorial","date":"2022-06-03 19:54","title":"SDN Tutorial","category":"Network","tags":["SDN","Mininet","OpenFlow","ONOS","OpenVSwitch"],"desc":"SDN을 실제 구현하는 것은 굉장히 어려운 일이다. 따라서, Mininet을 활용하여 가상의 Topology를 통해서 먼저 테스팅을 한 후에 실제로 적용하는 것이 일반적이라고 할 수 있다.따라서, 해당 Posting에서는 Mininet, OpenFlow, Open VSwitch, ONOS를 이용하여 간단한 Tutorial을 수행해볼 것이다. 이 Posting을 통해서 남기고자 하는 것은 SDN을 테스팅하는 절차를 익히는 것이다.","thumbnailSrc":"https://euidong.github.io/images/sdn-tuto-hero.jpg"},{"content":"\n## Intro\n\nSegment Routing은 MPLS의 차세대 버전으로, 초기에는 MPLS의 문제를 해결하기 위해서 제시되었다. 예를들면, TE(Traffic Engineering) 시에 Star Topology에서는 효율이 안나온다던지 ECMP(Traffic을 여러 output interface로 분배시키는 방식)을 활용할 수 없다와 같은 제한을 해결하고자 등장하였다. 그렇지만, 현재에 와서 와서 더 중요시 여겨지는 것은 **네트워크 구조의 단순화**이다. 즉, 기존의 복잡하던 Switch의 설정 방법(통신장비 vender 마다 다른 설정법, 여러 Protocold이 존재)과 운용 방법을 통일하고, 단순화 시킴으로써 사람에 의한 에러(Human Error)를 최소화하고자 하는 노력이라고 볼 수 있다.\n\n## 용어\n\n- **Segment** : 하나의 path가 여러 개의 작은 path들로 구성되는 것에서 유래하였다고 보며, 하나의 명령어(instruction)을 segment라고도 부른다. 명령어는 어디로 전달할 것인가와 packet을 어떻게 변형할 것인가에 대한 내용을 포함한다.  \n  Segment는 SID라는 id값을 통해서 구분하며, 이는 [0, 1,048,575] 까지를 사용할 수 있다. 특별한 목적을 가지는 [0, 15,000) 예약된 SID이고, [15,000 ~ 16,000)는 인접한 egress Router를 가르키는데 사용하는 `Adjacency SID`이고, [16,000, 24,000)는 Segment Routing이 유효한 범위 내에서 각 Router에 임의 설정이 가능한 영역대로 `Prefix SID` 라고 부른다. 그 외에 영역은 동적으로 할당되는 SID로 자동 할당 시에 사용된다. 여기서 중요한 점은 **Adjacency SID와 Prefix SID만 있으면, 모든 경로를 표현하는 것이 가능하다는 것이다.** 추가적으로, SR Policy를 재사용하고 싶은 경우가 발생할 수 있는데 이를 위해서 SR Policy 자체에 SID를 부여하는 것이 BSID(Binding SID)이다.  \n  ![SID-table](/images/sid-table.jpeg)\n- **Headend Router** : Segment Routing 영역으로 들어오는 Ingress Router이다.\n\n## 동작 원리\n\nSegment Routing 영역으로 Packet이 진입하면, 해당 packet의 Destination과 부가 정보를 확인하여, SR Policy(=Segment List, 방문해야할 경로를 순서대로 나열해놓은 리스트)를 MPLS 또는 IPv6의 부가 공간에 삽입한다. 이때에는 Stack 형태로 List를 구성하고, 중간 Router들에서는 Segment에 따라서 동작을 수행하며, packet을 최종 Egress Router까지 전달한다. 여기서 각 경로는 모든 세세한 경로를 표시할 필요는 없다. 만약 A에서 B로 가는 SID를 설정했어도, 그 내부에서 어떤 경로를 선택할지는 System적으로 알아서 Routing하도록 설정하는 것도 가능하다.(`Loose Source Routing`) Ingress에서 SR Policy를 지정하면 이를 `Push`라고 하고, 내부 Router는 가장 아래 Segment를 확인하고 자신과 관련 있는 경우에는 `Pop`을 수행하여 하나의 Segment를 삭제 후 이에 따라 동작을 수행하고, 그렇지 않으면 연결된 Link로 기존 BGP에 따라 알아서 Routing을 수행한다. 이를 `Continue`라고 한다.\n\n## Usecase\n\n다음과 같은 형태로 Routing을 설정하는 것이다. 아래 예시에서는 모두 1 -> 2 -> 3 -> 4 순으로 Routing을 수행하기를 원한다고 생각하자.\n\n`SID 16002`의 경우에는 `1 -> 2`로 이동하는 것이 `1 -> 4 -> 3 -> 2` 보다 IGP cost가 적으므로, `1 -> 2`로 원하는대로 이동할 것이라고 예상할 수 있다.\n이후 `SID 16004`의 경우에도 `2 -> 3 -> 4`로 이동하는 것이 `2 -> 1 -> 4`로 이동하는 것보다 IGP cost가 적으므로, `2 -> 3 -> 4`로 원하는대로 이동하는 것을 예상할 수 있다.\n\n![sr example 1](/images/sr-example-1.jpeg)\n\n하지만, IGP cost가 우리의 바램과는 다른 경우에는 다음과 같은 현상이 발생할 수도 있다.\n아래에서 `SID 16004`를 보면, `2 -> 1 -> 4`가 `2 -> 3 -> 4`보다 IGP cost가 적기 때문에 우리가 원하는 방향과는 반대로 동작할 것임을 예상할 수 있다. 따라서, 이를 해결하기 위해서 우리는 다음과 같은 경로를 채택해야 한다.\n\n![sr example 2](/images/sr-example-2.jpeg)\n\n여기서는 `1 -> 2 -> 3`이 `1 -> 4 -> 3`보다 크기 때문에 원하는대로 `1 -> 2 -> 3`으로 움직일 것이다. 하지만, 여기서 `3 -> 4`로 가는 경로가 어려울 수 있다. 이 경우에는 앞 서 보았던 Adjacency SID를 활용하여야 한다. 이는 마지막으로 가야할 egress Router를 지정하기 때문에 routing 시에 costing을 고려하지 않고, 바로 Static Routing이 가능하다. 따라서, 이를 활용하면 최종으로 `3 -> 4`로 가는 경로를 획득하는 것이 가능하다.\n\n![sr example 3](/images/sr-example-3.jpeg)\n\n## Configuration\n\n- SR-MPLS : MPLS와 같은 방식을 추구하지만, 설정 방식에서 LDP와 RSVP를 사용하지 않고 IGP를 활용해서 이를 수행할 수 있도록 하여 Protocol을 단순화하였다.  \n  Segment List(`SR Policy`)를 전달하는 과정이 MPLS의 Label을 전달하는 방식과 유사하며, 지나야하는 경로를 명시하여 stack 형태로 쌓아서 전달하면, 각 내부 Router는 이를 참고하여 제거 또는 유지하며, Egress Router를 찾는다.\n- SRv6 : IGP와 IPv6 Protocol만을 활용하여 네트워크를 구성할 수 있도록 하는 것이 목표이다. 네트워크 자체를 프로그래밍 하고자 하는 요구 때문에 필요성이 강조되었다. 이는 IPv6의 주소값인 128bit를 topology를 식별할 주소값과 packet 처리를 위한 값(특정 packet에게는 다른 routing table을 적용 등)으로 나누어 사용함으로써 구현이 가능하다. 따라서, IPv4의 짧은 주소 체계로는 이를 수행할 수 없다. 따라서, IPv6 Protocol을 이용하여 수행하는 것이다.  \n  Segment List(`SR Policy`)를 전달하는 과정은 위와 유사하지만, 이를 IPv6 Option 영역에 stack형태로 저장한다.\n\n## Traffic Engineering\n\nTraffic을 제어하고, 해당 제어를 위한 제한사항들을 실시간으로 update하고, 운용 관리하는 것이 가능하다. MPLS에서 수행하던 TE(Traffic Engineering)과 유사하지만, Bandwidth를 사용하지 않는 대신에 delay라는 조건을 갖고 있다. 이는 packet이 도착하는데 걸리는 시간을 측정한 값이다.  \n해당 조건들을 활용하여 Traffic을 입맛에 맞게 변경하는 것이 가능하다.\n\n또한, 장애 대책 시에도 Segment Routing은 강점을 가지고 있다. 일반적인 OSPF를 활용하는 경우에는 LFA(Loop Free Alternate)를 통해서 우회 경로를 계산한다. 하지만, 이는 생각보다 비효율적인 경로 계산을 수행하게 된다. 따라서, 이를 개선하는데 Segment Routing이 적절하다. 다음 예시를 보자.\n\n[그림]\n\n장애 이전에 `1 -> 2 -> 3 -> 5` 그리고 `6 -> 2 -> 3 -> 5` 라는 traffic이 존재할 때, 만약 `2 -> 3` link가 끊어지면, 기존의 LFA를 이용하면 찾게 되는 경로는 다음 경로와 같아진다.\n\n![sr post convergence 1](/images/sr-post-convergence-1.jpeg)\n\n이는 상당히 비효율적인 경로인데, 이렇게 계산을 수행하는 이유는 `1 -> 2 -> 6 -> 7 -> 3 -> 5` 라는 차선 경로로 가는 도중에 `2 -> 6`으로 이동 이후에 기존 Traffic에 영향으로 인해 `6 -> 2`로 다시 돌아오는 현상이 발생하기 때문이다. 따라서, 결론상 더 큰 비용이 발생하는 경로(`2 -> 4`)로 들어가서 오히려 더 많은 비용이 발생하게 된다.\n\n![sr post convergence 2](/images/sr-post-convergence-2.jpeg)\n\n이를 해결하기 위해서는 장애가 발생한 이후에 다시 IGP가 계산하는 최단 경로인 `Post-Convergence Path`를 사용하면 된다. 하지만, 해당 경로는 Loop를 야기할 가능성이 존재한다. 이로 인해, 해당 방식을 사용하지 않았었는데, Segment Routing을 이용하여 경로를 제한함으로써 Post Convergence Path를 사용할 수 있게 되었다. 즉, Segment Routing의 Adjacency SID를 이용해서 나가야할 지점을 명확하게 하며, Loop가 발생할 수 있는 지점에서 Static Routing을 지정하면서, Prefix SID를 통해서 경로를 적절히 지정하여 해결이 가능한 것이다.\n\n![sr post convergence 3](/images/sr-post-convergence-3.jpeg)\n\n## Programmable\n\nSegment Routing의 또 하나의 강점은 SDN 지향적인 구조라는 것이다. 즉, 중앙에서 각 Switch의 동작을 제어하는 Controller를 Segment Routing을 통해서 직접 구현이 가능하다는 것이다. 즉, Segment Routing Network가 특정 Controller에게 자신의 상태 정보 등을 주기적으로 보내면, Controller에서는 이를 이용해서 Database를 구축하고, 이를 바탕으로 Routing Table을 완성하는 것이다. 이를 기반으로, 후에 요청이 Headend 장치로 들어오면, 해당 장치는 Controller에게 처리를 요청하고, 이에 대한 응답을 받은 Headend 장비는 적절하게 SR Policy를 해당 packet에 저장하여 Routing이 가능해지는 것이다.\n\n## Summary\n\n|                   | MPLS                                                               | SR-MPLS                  | SRv6                 | Segment Routing의 장점                                                            |\n| :---------------- | :----------------------------------------------------------------- | :----------------------- | :------------------- | :-------------------------------------------------------------------------------- |\n| 제어 프로토콜     | 기반 : IGP/BGP, 추가 : LDP/RSVP-TE                                 | IGP/BGP                  | IGP/BGP              | LDP/RSVP-TE 와 같은 추가 Protocol이 없음                                          |\n| 데이터 평면       | MPLS 데이터 평면을 정의해서 사용                                   | MPLS 데이터 평면을 활용  | IPv6를 활용          | IPv6를 활용한 경우 추가적인 설정이 필요없음                                       |\n| 경로 계산 및 조정 | 사실 Ingress에서 설정하지만 각 노드가 관여                         | Source(Ingress)에서 결정 | 동일                 | Source Routing으로 명확한 구조                                                    |\n| LSP의 Label 관리  | LSP의 갯수가 많아질 수록 각 노드의 부담 증가                       | 인접 노드, 링크만 관리   | 동일                 | 내부 Router의 부담이 크게 감소                                                    |\n| Operation         | Push, Swap, Pop                                                    | Push, Next, Continue     | 동일                 | Swap 연산이 필요없다.                                                             |\n| 장애 대책         | Fast ReRoute                                                       | TI-LFA, Fast ReRoute     | 동일                 | Fast ReRoute는 convergence time이 길어 실용 사례가 적다.                          |\n| Programmability   | 불가능                                                             | 불가능                   | Network Programmable | IPv6를 이용한다면, Traffic Engineering, VPN을 Programming을 통해 구현이 가능하다. |\n| 네트워크 확장성   | 일반적으로는 높다. 하지만, RSVP-TE를 활용하는 경우 낮아질 수 있다. | 확장성이 높다.           | 동일                 | 확장성이 높다.                                                                    |\n| 네트워크 구조     | 일반적인 분산 제어 구조                                            | SDN 적용이 가능          | 동일                 | SDN 기반의 중앙집중 제어와 기존 방식으로 분산 제어도 가능함                       |\n\n## Reference\n\n- Thumbnail: Photo by [Arno Senoner](https://unsplash.com/@arnosenoner?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/s/photos/forwarding?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n","slug":"segment-routing","date":"2022-05-23 10:41","title":"Segment Routing","category":"Network","tags":["Routing"],"desc":"Segment Routing은 MPLS의 차세대 버전으로, 초기에는 MPLS의 문제를 해결하기 위해서 제시되었다. 예를들면, TE(Traffic Engineering) 시에 Star Topology에서는 효율이 안나온다던지 ECMP(Traffic을 여러 output interface로 분배시키는 방식)을 활용할 수 없다와 같은 제한을 해결하고자 등장하였다. 그렇지만, 현재에 와서 와서 더 중요시 여겨지는 것은 네트워크 구조의 단순화이다. 즉, 기존의 복잡하던 Switch의 설정 방법(통신장비 vender 마다 다른 설정법, 여러 Protocold이 존재)과 운용 방법을 통일하고, 단순화 시킴으로써 사람에 의한 에러(Human Error)를 최소화하고자 하는 노력이라고 볼 수 있다.","thumbnailSrc":"https://euidong.github.io/images/forwarding.jpg"},{"content":"\n## Intro\n\n광통신은 빛에 데이터를 저장하여 광섬유를 통해서 데이터를 보내는 방식이다. 그렇다면, 굳이 왜 빛으로 변환하는 과정을 거치면서 까지 광통신을 사용하고자 하는지를 알필요가 있다. **이는 간단하게 빠르고, 멀리 전달할 수 있기 때문이다.** 그리고, 전자파를 이용하는 무선통신과 다르게 빛은 4가지의 특징을 가지기 때문이다(반사, 굴절, 간섭, 편광). 광섬유 내부에서는 여러 원인에 의해서 상쇄(손실)가 발생하기 때문에 이를 증폭해줄 방법이 필요하며, 광섬유를 어떻게 구성할지에서부터 처음에 데이터를 어떻게 빛으로 변환할지에 대한 방법과 받은 빛을 다시 데이터로 변환하는 방법이 굉장히 중요하다.\n\n---\n\n![광통신](/images/optical-transfer.jpeg)\n\n따라서, 이를 위한 기술과 장비들을 먼저 살펴보고 갈 것이다.\n\n### 광섬유\n\n실제로 빛이 이동하는 통로 역할을 수행한다. 주요 구성요소는 보호용 아크릴, cladding, core이다. 빛은 실제로는 core 내부에서만 이동한다. 내부에서 빛은 지그재그로 이동하며 계속해서 cladding과 접하지만 빛의 굴절률을 이용하여 전반사 시키도록 설계를 해두어 core로만 빛이 통하게 된다. 이때, 이러한 빛의 이동 경로를 하나의 mode라고 하고, 이는 처음 빛의 입사각에 따라 달라진다. 이러한 mode를 여러 개 허용한다면, 이는 multi mode fiber(MMF)라고 하고, 하나만 허용한다면 single mode fiber(SMF)라고 한다. 일반적으로는 SMF가 더 고효율 시스템을 활용하기 때문에 전송 효율은 높지만 비용적인 측면에서 MMF도 자주 사용된다.\n\n![광섬유](/images/optical-fiber.jpeg)\n\n#### 광섬유 손실\n\n광섬유는 다음과 같은 이유에 의해서 빛을 손실한다.\n\n1. 결합 손실(Coupling Loss) : 초기에 Lasor 장치와 광섬유의 core 사이에서 발생하는 손실\n2. 흡수 손실 : 광섬유 제작 과정에서 core에 섞인 어쩔 수 없는 불순물에 의한 손실\n3. 산란손실(Scattering Loss) : 광섬유의 core에서의 비균질성에 의해서 굴절률이 순간적으로 변하여 발생하는 손실\n4. 구부러짐에 의한 복사 손실(Bending Loss) : 광섬유의 일부 구부러짐에 의하여 굴절률이 영향을 받아 발생하는 손실\n5. 접속 손실(Joint Loss) : 광섬유간의 결합 과정에서 발생하는 손실\n\n#### 손실 보상(Dispersion Compensation)\n\n광섬유 내에서 손실을 보상하기 위해서 사용되는 대표적인 방법이 4가지가 있다.\n\n1. DCF(Dispersion Compensation Fiber)를 이용한다. 이는 빛의 파장을 더 길게 변화시키는데 이를 이용하여 중간에 증폭을 가하는 것이다. 이를 이용할 때에는 SMF로 광섬유로 채택하고, 먼저 진행한 후에 해당 길이의 19%만큼을 DCF로 통과시켜서 손실된 양만큼을 보충해주고, 다시 SMF로 진행시키는 것이다. 마치 빛을 오목 렌즈(SMF)로 퍼트리면, 다시 볼록 렌즈(DCF)로 모아주는 것과 유사하다.\n2. EDF(Erbium Doped Fiber), PDF(Pr Droped Fiber) 등을 활용한다. 이는 자체적으로 광을 증폭하는 효과를 갖고 있기 때문에 이를 중간에 통과 시켜서 증폭을 수행한다. 이 방식이 더 짧은 길이의 Fiber로 증폭이 가능하다.\n3. 중계기를 활용한다. 중간에서 빛을 다시 전기로 바꾼 후에 이를 다시 광으로 증폭하여 전달하는 방식이다. 이 방식은 편리하지만, 전기가 필요하며, 처리 과정에서의 지연이 크다는 단점이 있다.\n4. 증폭기를 활용한다. 광섬유 내 모든 신호를 증폭 시킨다. Noise도 같이 증폭될 수 있다는 단점이 있지만, 빠르기에 많이 사용된다. 대표적인 증폭의 방법은 다음과 같다.\n   - EDFA : EDF를 이용한 증폭 방법이다. 원리는 전달되는 빛에 약한 광신호를 섞어서 증폭시키는 것이다. 단점은 C, L band만을 커버할 수 있기 때문에 더 넓은 범위에 대해서는 제한적이다.\n   - Raman 증폭 : 빛의 산란효과를 활용하여 특정 주파수 영역의 빛을 증폭시키는 기능을 한다. 더 넓은 범위를 커버할 수 있고, EDFA보다 덜 빈번하게 설치하여도 무방하다.\n\n### Tranceiver\n\n광송수신기를 의미한다. 대게 광송신을 담당하는 TOSA와 광수신을 담당하는 ROSA를 모두 포함하여 만든 장치로 실제 Switch/Router에서 광케이블(광섬유)이 연결되는 interface 역할을 한다. 해당 기술은 소형화와 저전력화가 핵심이고 현재에는 하나의 Switch/Router에 32개 이상 포함할 수 있을 정도로 소형화/저전력화가 진행되었다.\n\n#### Tranceiver 내부의 변조 기술\n\n> **광변조기술**\n\n기본적으로 데이터를 빛으로 바꾸고자 할 때에는 기존 데이터의 주파수를 그대로 이용(BaseBand)하기 보다는 고주파 대역과 결합하여 해당 고주파 대역(BroadBand)으로 변환하여 보낸다. 이를 수행하면 장거리 통신에 유리하며, 안테나의 길이를 단축할 수 있을 뿐만 아니라 Noise를 개선하기에 유리하다는 장점을 갖고 있다. 이를 기반으로 하여 총 2가지 형태의 변조 기술이 존재한다.\n\n- 직접 변조(Direct Modulation) : 데이터의 0과 1에 따라 광원을 키고 끄고를 수행하도록 하는 방식\n- 외부 변조(External Modulation) : 광원은 계속 켜둔 상태에서 데이터의 0과 1에 따라 빛을 막았다가 통과시켰다를 제어하는 방식\n\n> **신호변조기술**\n\ndata를 신호로 변환하는 기술이다. 대표적인 방식은 4가지가 존재한다.\n\n1. ASK(Amplitude Shift Keying) : 디지털 신호에 고주파 신호를 결합하여 변환 신호를 만드는 방법으로 두 개의 transiter로도 만들 수 잇을 정도로 매우 간단하나 잡음에는 취약하다.\n2. FSK(Frequency Shift Keying) : 디지털 신호에 따라 고주파 신호의 주파수를 변환하여 신호를 보내는 기술로 간단하면서도 잡음에 강하지만, 많은 주파수 대역을 필요로 한다.\n3. PSK(Phase Shift Keying) : 디지털 신호에 따라 고주파 신호의 위상을 역전시켜 변환하여 신호를 보내는 기술로 간단하고 잡음에 강하지만 수신측에 부가적인 위상 추적 장비가 필요하다.\n4. QPSK(Quadrature PSK) : 위상을 더 세분화하여 4단계로 나누어 신호를 보내는 PSK 방식이다. 기존의 PSK보다 전송 효율이 높아진다.\n5. QAM(Quadrature Amplitude Modulation) : ASK와 PSK를 조합한 방식으로 ASK와 PSK를 별도로 수행하고 이에 의해서 생성된 신호를 합쳐서 전송하는 방식이다. 나타나는 위상의 수에 따라서 4-QAM, 8-QAM, 16-QAM, 32-QAM 등으로 나뉜다. 참고로 4-QAM은 사실상 QPSK와 동일하다.\n\n## 광통신망\n\n광 케이블로 구성된 물리 네트워크이다. 크게 3가지 Network로 구성되어진다. 일반적으로는 각 Network가 Ring Topology로 구성된다. 이는 장애에 대비하기 위함이다. OTN이라고도 부르며 중간 Router에서의 변환을 최소화하고 광통신으로 직접적으로 연결하는 하위 네트워크를 구성하는 것이다.\n\n초기에는 SONET/SDH라는 형태가 있었다. 이는 Synchronous Optical Network / Synchronous Digital Hierarchy의 약자로 거의 비슷한 두 기술을 붙여 부르는 말이다. 사실상 표준을 발행한 기관이 미국이냐 국제기관이냐의 차이이다(그래서 세부 용어들은 내부적으로 다르다). TDM으로 다중화 전송을 수행하였고, 이후에는 통계적 다중화라는 TDM의 고정 시간분할을 유동적으로 바꾼 방식이 등장하지만 여기서는 사용되어지지 않았다. 원래는 음성 통신에 초점을 맞추었기 때문에 장애 시 사람이 인식하지 못하는 ~50ms 이내에 자동 절체를 수행하는 작업도 최초 도입되었다. 이로인해 음성 통신에서는 우수한 성능을 보였지만 인터넷 트래픽에서는 위에서 말한 통계적 다중화를 지원하지 않아 대역폭 낭비가 심했다. 이에 따라 아래와 같은 형태의 Network로 구성된 형태로 변화하게 되었다.\n\n1. ROADM : Reconfigurable Optical Add-Drop Multiplexer의 약자로 특정 파장을 Drop하거나 Add하는 장치인 OADM을 발전시킨 장치이다. 원래는 설정을 변경하는 것이 숙력된 기술자들에 의해 하드웨어적으로 가능했는데 이를 원격으로 제어하는 기술을 적용한 것이 ROADM이다. 이는 Backborn에서 광파장을 분리하고 분석해서 적절하게 Routing하는데 사용된다.\n2. MSPP : Multi Service Provisioning Platform의 약자로 SONET/SDH와 ATM, Ethernet을 동시에 지원하는 Module로 여러 Platform의 Interface로 기능한다.\n3. PON : Passive Optical Network 의 약자로 하나의 광통신 지원장치(OLT, Optical Line Terminator)를 통해서 모든 빛을 하나의 Fiber로 합하여 여러 장치들에게 광통신을 지원하는 형태의 Network로 대게 광통신의 End 지점에서 많이 사용되는 Network이다.\n   - TDM-PON : Time Division Mulitplexing의 약저로 수신 시에 OLT를 이용하여 광케이블로 온 빛을 직렬화하고, Splitter를 통해서 네트워크에 Broadcasting하는 방식이다. 송신 시에는 시분할을 통해서 각 장비에서 오는 광 데이터를 전송한다.\n   - CWDM-PON : Coarse Wavelength Division Multiplexing 의 약자로 수신 시에 채널을 최대 18개까지로 나누어 각 채널을 통해서 통신을 수행하도록 하는 방식이다. 이때, RN이라는 장치가 Prizm처럼 빛을 분산시키는 역할을 한다.\n   - DWDM-PON : 각 광가입자마다 별도의 고유 파장을 부여하는 방식이다. 방식은 CWDM과 매우 유사하다.\n   - NG-PON2 : TDM과 WDM을 결합하여 하는 방식이다.\n\n## Reference\n\n- Thumbnail : Photo by [Compare Fibre](https://unsplash.com/@comparefibre?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/s/photos/optical-network?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n","slug":"optical-transport-network","date":"2022-05-28 19:03","title":"광통신망","category":"Network","tags":["OpticalTransportNetwork"],"desc":"광통신은 빛에 데이터를 저장하여 광섬유를 통해서 데이터를 보내는 방식이다. 그렇다면, 굳이 왜 빛으로 변환하는 과정을 거치면서 까지 광통신을 사용하고자 하는지를 알필요가 있다. 이는 간단하게 빠르고, 멀리 전달할 수 있기 때문이다. 그리고, 전자파를 이용하는 무선통신과 다르게 빛은 4가지의 특징을 가지기 때문이다(반사, 굴절, 간섭, 편광). 광섬유 내부에서는 여러 원인에 의해서 상쇄(손실)가 발생하기 때문에 이를 증폭해줄 방법이 필요하며, 광섬유를 어떻게 구성할지에서부터 처음에 데이터를 어떻게 빛으로 변환할지에 대한 방법과 받은 빛을 다시 데이터로 변환하는 방법이 굉장히 중요하다.","thumbnailSrc":"https://euidong.github.io/images/optical-network.jpg"}],"AI":[{"content":"\n## Intro\n\nMachine Learning은 data들로 부터 특정 pattern을 나타내는 function을 만드는 것이라고 할 수 있다. 즉, pattern은 data에 대한 간단한 요약본이라고 볼 수 있다.\n확률/통계 이론 및 선형대수, 미적분, 정보 이론 관련 기본 내용을 해당 포스팅에 정리한다. 여기서 다루는 내용은 대게 많이 추상적인 내용이며, 키워드 중심의 내용이다. 만약, 추가적인 설명이 필요하다면 키워드를 기반으로 더 검색을 하는 것이 좋을 것이다.\n\n## Probability/Statisics\n\n확률과 통계는 대게 거의 동의어처럼 사용되지만, Statistics는 대게 과거를 의미할 때 사용하는 반면 Probability는 미래를 의미하는 용도로 많이 사용되어진다.\n\n### Probability Space\n\n확률 공간을 정의하는 것은 확률을 이해하는 토대가 된다. 확률을 적용하기 위한 공간을 먼저 살펴보자.\n\n- Sample Space($\\Omega$)  \n  가능한 모든 결과값의 집합이다.  \n  ex. 동전을 두 번을 던져서 나올 수 있는 모든 결과값은 $\\Omega = $ $\\{ hh, ht, th, tt \\}$\n- Event($E$)  \n  Sample Space의 Subset이다. Sample Space에서 발생할 수 있는 event라는 의미로 볼 수 있다.  \n  ex. 동전을 두 번을 던져서 모두 같은 면이 나오는 Event는 $E = $ $\\{ hh, tt \\}$\n- Field($\\mathcal{F}$)  \n  Sample Space에서 발생 가능한 모든 Event들의 집합이다.  \n  ex 동전을 두 번 던져서 나오는 결과값의 Field는 $\\mathcal{F} = $ $\\{$ $\\emptyset$, $\\{hh\\}$, $\\{ht\\}$, $\\{th\\}$, $\\{tt\\}$, $\\{hh, ht\\}$, $\\{hh, th\\}$, $\\{hh, tt\\}$, $\\{ht, th\\}$, $\\{ht, tt\\}$, $\\{th, tt\\}$, $\\{hh, ht, th\\}$, $\\{hh, ht, tt\\}$, $\\{hh, th, tt\\}$, $\\{ht, th, tt\\}$, $\\{hh, ht, th, tt\\}$ $\\}$\n- $\\sigma$-field  \n  자신 내부의 원소를 포함하는 합집합을 모두 포함하는 셀 수 있는 field를 sigma field라고 한다.  \n  이 $\\sigma$-field는 일반적인 확률과 특정 domain에서의 확률을 정의하는데 필요하다.  \n  우리가 sample space($\\Omega$)와 $\\sigma$-field $\\mathcal{F} \\subset 2^{\\Omega}$가 주어질 때, 확률P가 다음과 같이 mapping한다고 하자. $P: \\mathcal{F} \\mapsto [0, 1]$ 이때 P는 다음과 같은 특징을 가진다.\n  - $A \\in \\mathcal{F}$인 모든 A에 대해서 $P(A) \\leq 0$ 이다.  \n    $P(\\emptyset) = 0, P(\\Omega) = 1$\n  - $\\{A_i\\}_{i \\in I}$이고, 서로 다른 모든 i, j에 대해 $ A_{i}\\cup A_{j} = \\emptyset$이라면, 아래 식을 만족한다.  \n    $$P(\\cup_{i \\in I}A_i) = \\sum_{i \\in I}P(A_i)$$\n\n### Important properties of Probability\n\n- **Joint Probability**  \n  두 Event의 Joint Probability는 두 Event의 합집합의 확률을 의미한다.\n  $P(A, B) = P(A \\cap B)$\n- **Marginal Probability**  \n  대게 두 개 이상의 Event가 있을 때, 각 각의 Event의 확률을 특정할 때 사용한다.\n  $P(A), P(B)$\n- **Independence**  \n  두 Event가 독립이라는 의미는 서로의 Event가 서로 영향을 받지 않는다는 의미이다. <mark>**주의할 것은 이것이 의미하는 것이 두 Event의 교집합이 없다는 의미가 아니다.**</mark>  \n  예를 들어보면 다음과 같다. 우리가 위에서 예시로 사용한 두 개의 동전을 던진 결과를 보자. 두 개의 동전이 모두 앞면이 나오는 경우와 모두 뒷면이 나오는 경우는 서로 독립일까? 이는 독립이 아니다. 왜냐하면, 동전이 모두 앞면이 나오는 사건은 필연적으로 모두 뒷면이 나오는 사건은 반드시 일어나지 않을 것이라는 증거가 되기 때문이다. 반대로, 모두 앞면이 나오는 사건과 한 번만 앞면이 나오는 사건을 생각해보자. 하나의 사건이 일어났다고, 반드시 그 사건이 일어났거나 안일어났다는 관계를 밝혀낼 수 없다. 따라서, 이러한 경우 두 사건이 독립적이라고 한다.  \n  이를 수학적으로 표현하면, 다음과 같이 표현할 수 있다.  \n  $P(A, B)=P(A)P(B)$  \n  즉 위 공식이 성립하면 독립이며, 독립이라면 위의 식이 성립한다.\n- **Conditional Probability**  \n  두 Event가 있을 때, 하나의 Event가 발생했을 때 다른 하나의 Event가 발생할 확률을 의미한다. 따라서, 이는 다음과 같이 수식으로 표현할 수 있다.  \n  $P(A|B) = {{P(A, B)}\\over{P(B)}}, (P(B) \\neq 0)$  \n  여기서 independence 특성을 더 명확하게 확인할 수 있는데, 만약 A와 B가 독립이라면, $P(A|B) = P(A)$이다.  \n  즉, B가 발생했는지 여부는 A의 결과에 영향을 안준다는 것이다.\n- **Partition**  \n  Sample Space($\\Omega$)를 겹치지 않고, 모두 포함하는 Event의 집합을 의미한다. 따라서, 이를 식으로 다음과 같이 표현할 수 있다.  \n  $\\cup_{i=1}^{n}{P_i} = \\Omega$ 이고, $\\cap_{i=1}^{n}{P_i} = \\emptyset$\n- **Marginalization**  \n  전체 Sample space($\\Omega$)에 대하여 **B**가 이에 대한 partition일 때, 아래 공식이 성립한다.  \n  $P(A) = \\sum_{i=1}^{n}{P(A,B_i)} = \\sum_{i=1}^{n}{P(A|B_i)P(B_i)}$\n- **Bayes' Theorem**  \n  만약 $P(B) \\neq 0$라면, 아래 공식이 성립한다. 간단히 conditional probability를 풀어주면 아래 식을 얻을 수 있다.  \n  $P(A|B) = {P(B|A)P(A)\\over{P(B)}}$  \n  해당 식은 단순히 Joint Probability로 변환하고, 다시 반대 확률로 변경했을 뿐이다. 이 공식이 중요하다기 보다는 이 공식이 가지는 의미를 이해하는 것이 중요하다. 확률을 사건의 발생의 빈도로 이해하는 Frequentist Approach에서는 관측을 통해서 특정 데이터가 발생할 확률을 얻는다. 만약 우리가 원하는 확률이 관측을 통해서는 얻을 수 없는 데이터라고 하자. 이 경우에 우리는 확률의 역연산이 필요하다. 위의 공식을 보면 특이한 것이 보이는데, 바로 $P(A|B)$와 $P(A)$이다. 이는 전체 확률을 통해서 **Conditional Probability**를 찾는 것이다. 그렇기에 우리는 이를 역연산이라고 부르며, 우리가 가지고 있는 기존 **사전 확률**(Priority, 이전까지 맞을 거라고 생각한 확률)을 통해서 데이터가 주어졌을 때의 사건의 확률을 다시 계산해보는 것이다. 이 과정을 **Bayesian Update**라고 하는데 이 과정을 통해서 얻은 $P(A|B)$를 다시 다음 데이터에 대해서는 $P(A)$로써 활용하는 것이다. 이렇게 해서 우리는 점진적으로 $P(A)$를 찾아나갈 수 있다.\n\n### Random Variable\n\nRandom Variable이라는 것은 특정 사건을 수학적으로 표현하기 위해서 변형하는 과정을 의미한다. 우리는 이전 예시에서 두 개의 동전을 동시에 던져서 나온 결과를 Sample Space로 두었고, 이를 $\\Omega = $ $\\{ hh, ht, th, tt \\}$라고 표현했다. 하지만, 이와 같은 표기 방식은 수학적인 연산을 적용하기 어렵다. 따라서, 우리는 앞면이 나온 경우를 $X=1$, 뒷면이 나온 경우를 $X=-1$ 라고 하는 형태로 치환하는 것이다. 여기서 만들어진 X를 우리는 Random Variable이라고 부른다. 이런 치환을 통해서 우리는 확률을 Random Variable에 대한 함수로 표현할 수 있다.\n\n또, Random Variable을 정의하여 다음과 같은 값을 연속적으로 정의할 수 있다.\n\n- **Mean**  \n  Random Variable의 평균 또는 기댓값이라고 부른다.  \n  $\\mu_{X} = E[X] = \\sum_{x}{xP(X=x)}$\n- **Variance**  \n  평균에서 데이터가 떨어진 정도를 표현하는 값으로 분산이라고 부른다.  \n  $\\sigma_{X}^{2} = E[(X-\\mu_{X})^2] = E[X^2] -\\mu_{X}^{2}$\n- **Covariance**  \n  Random Variable X와 Y의 상관관계(Correlation)을 확인하는 척도로 사용한다.  \n  $cov(X, Y) = E[(X-\\mu_{X})(Y-\\mu_{Y})] = E[XY] -\\mu_{X}\\mu_{Y}$  \n  만약, 두 X와 Y가 서로 전혀 상관이 없다(Independent)면, $cov(X, Y) = 0$이다. 그 반대는 성립하지 않지만, 그럴 가능성이 굉장히 높아진다.\n- **Correlation Coefficient**  \n  Covariance보다 더 엄격한 상관관계를 확인하는 척도로 사용되는데, 단순히 Covariance를 각 표준편차($\\sigma$)로 나눈 것이다. 이로 인해 결과 값은 [-1, 1] 사이 값이 된다.  \n  $corr(X, Y) = {cov(X,Y)\\over{\\sigma_{X}\\sigma_{Y}}}$  \n  따라서, <mark>1일 수록 두 Random Variable의 상관성이 높으며 비례하는 관계라는 것을 의미하며, -1일 경우에는 상관이 높지만 반비례하는 관계라는 것을 의미한다. 반대로, 0인 경우는 상관 관계가 아주 낮음으로 독립일 가능성이 높다.</mark> 그렇다고 100%는 아니지만, 단지 그럴 확률이 굉장히 높다는 것이다. 주의할 점은 Correlation Coefficient가 1이라고 X가 Y의 원인이 되는 것은 아니라는 것을 유의해야 한다. 단순히 X가 일어났을 때, Y가 일어날 확률이 높다는 것이다.  \n\n### Law of Large Numbers\n\n경험적 확률과 수학적 확률 사이의 관계를 나타내는 법칙으로, 전체 경우의 수와 이에 따른 확률(모집단)이 있을 때, 관측한 경우의 수와 이에 따른 확률(표본 집단)은 관측 데이터의 크기가 커질 수록 표본 평균이 모평균에 가까워짐을 의미한다.\n\n### 자주 사용되는 Probability Distribution Function\n\n특정 task의 경우 이미 정의된 확률 분포를 통해서 표현할 수 있는 경우가 있다. 따라서, 아래와 같은 대표적인 확률 분포는 알아두는 것은 중요하다.\n\n- **Bernoulli distribution**  \n  하나의 사건이 일어날 확률을 의미한다. 발생하는 경우를 X=1, 그렇지 않은 경우를 X=0으로 random variable로 치환하여 나타낸 확률 분포(probability distribution)이다. 대표적인 사건은 동전 던지기와 같은 두 개의 결과만 갖는 binary event을 표현할 때이다.  \n  따라서, 사건이 일어날 확률을 p라고 할 때, 다음과 같이 Random Variable에 대한 확률을 정의할 수 있다.  \n  $P(X=x) = p^{x}(1-p)^{1-x}$\n  복잡해보이지만, 실상은 X가 0 또는 1이므로, $P(X=0)=1-p$이고, $P(X=1)=p$이다.\n  - 평균\n    $E[X] = p$\n  - 분산  \n    $Var[X] = E[X^2] - \\mu_{X}^2 = p - p^2 = p(1-p)$\n- **Binomial Distribution**  \n  확률이 p인 사건을 n번 수행했을 때, x번 발생할 확률을 의미한다. 따라서, Random Variable X의 범위는 {0, 1, …, n}이 된다. 대표적인 사건은 동전 던지기를 여러 번 던졌을 때, 앞 면이 x번 나올 경우의 수이다.  \n  이에 따라 Random Variable에 대한 확률을 정의하면 다음과 같다.  \n  $P(X=x) = {n \\choose x}p^x(1-p)^{n-x}$  \n  이 또한 복잡해 보이지만, 사실은 독립적인 Bernoulli의 연속 수행으로 볼 수 있다.  \n  - 평균  \n    $E[X] = np$\n  - 분산  \n    $Var[X] = Var[\\sum_{i}X_i]=\\sum_iVar[X_i]=np(1-p)$\n- **Beta Distribution**  \n  $\\alpha, \\beta > 0$를 만족하는 두 parameter를 이용한 probability distribution이다.  \n  이는 [0, 1]에서 continuous한 random variable를 이용할 수 있다. 이에 따른 확률은 다음과 같다.  \n  $P(X=x) \\propto x^{\\alpha-1}(1-x)^{\\beta-1}$  \n  이에 대한 의미를 이해하자면, 확률에 대한 확률 분포이다. 각 $\\alpha - 1$와 $\\beta - 1$를 성공 횟수, 실패 횟수라고 하자.  이는 이미 알고 있는 모집단(전체 집합)의 계산 결과이다. 그리고 random variable을 특정 event의 확률이라고 하자. 예를들면, 동전 던지기를 할 때, 앞면이 나올 확률이 $1\\over2$이라는 것을 이미 알고 있다. 따라서, 우리는 $\\alpha - 1$ = $\\beta - 1$ 라는 것을 알고 있는 것이다. 하지만, 실제로 동전 던지기를 5번 수행했을 때, 4번 앞면이 나왔다고 하자. 그렇다면, 우리가 추측한 해당 event의 확률은 $4\\over5$이 된다. 그렇다면, 실제로 해당 확률이 $4\\over5$일 확률을 얼마나 될까?  \n  이를 측정하기 위한 것이 Beta distribution인 것이다. 이에 따라, Beta distribution을 PDF로 표현하면 ${\\alpha\\over\\alpha+\\beta}$에서 높은 확률값을 가지는 것을 볼 수 있다.\n  - 평균  \n    $E[X] = {\\alpha\\over{\\alpha+\\beta}}$\n  - 분산  \n    $Var[X] = {\\alpha\\beta\\over{(\\alpha+\\beta)^2(\\alpha+\\beta+1)}}$\n\n  위의 평균과 분산을 보면 알 수 있듯이, 만약 이전 모집단에서의 평균값에 대한 믿음이 크다면, 각각  $\\alpha, \\beta$의 비율은 유지하면서 상수배를 수행하여 평균은 동일하지만 분산 값을 더 적게 만들어 뾰족한 형태의 분포를 완성할 수도 있다. 이 경우에는 평균과 맞지 않는 표본집합에서의 평균을 굉장히 확률이 낮은 확률로 식별하는 것이다.\n- **Gaussian Distribution**  \n  $\\mu, \\sigma^2$를 parameter로 갖는 probability distribution이다.\n\n  이는 $[-\\infin, \\infin]$를 구간으로 continuous한 random varible을 이용한다. 이에 따른 확률은 다음과 같다. (단일 random variable인 경우)\n  \n  $P(X) = {1\\over{\\sqrt{2\\pi\\sigma^2}}}\\exp(-{1\\over{2\\sigma^2}}(X-\\mu)^2)$\n\n  이 분포는 굉장히 많은 곳에 사용되는데 <mark>우리가 생각할 수 있는 대게의 자연 발생에 의한 현상들(ex. 사람 키의 분포)이 이 분포를 따르기 때문이다.</mark> 그렇기에 다양한 환경에서 많이 사용되는 분포이다. 뿐만 아니라 (Lindeberg-Levy) **Central Limit Theoriem**에 따르면, 표본에서 얻은 표본 평균을 구하면 구할 수록 점점 Gaussian Distribution을 따라간다. 즉, $n \\rarr \\infin$이면, 표본 평균이 이루는 분포가 Gaussian이라는 것이다.\n  \n  추가적으로 알아볼 것은 바로 여러 개의 Random Variable로 Gaussian Distribution을 더 높은 차원으로 구성할 수 있다는 것이다. 이를 수행하면, Gaussian 분포가 평균과 분산을 포함하기 때문에 두 데이터의 경향성(Covariance)를 어느정도 파악할 수 있다.\n\n## Calculus\n\n일명 미적분학으로, 대게의 미적분 법칙은 모두 알고 있을 것이라고 생각하고 넘어간다.\n\n### Optimization\n\n정말 모두가 알고 있을 거 같지만, 그럼에도 중요하기 때문에 정리하고 넘어가자. 일반적으로 Optimization이란 최적값을 찾는 과정이다. 이 과정에서 대게 사용되는 것이 최솟값 또는 최댓값이다. 우리는 최솟값/최댓값을 미분을 통해서 구할 수 있다.\n\n여기서는 Convex라는 성질에 대해서 자세히 다루지 않는다. 시간이 있다면, 이에대한 개념도 반드시 숙지하기를 바란다.\n\n> **최대/최소 구하기**\n\n모두가 알다시피 함수의 미분은 기울기를 의미한다. 만약 함수의 미분에 특정 값을 대입할 경우 이는 그 지점에서의 기울기를 의미한다.\n\n먼저, 함수의 미분에 대입한 값이 0인 경우에 해당 값(극값)이 가지는 성질을 기억해야 한다. 만약, 값이 0으로 하는 값을 기준으로 좌우 부호가 바뀐다면, 이는 정말 극대, 극소라는 의미를 가진다. 즉, 해당 구간에서 최소와 최대라는 의미를 가지는 것이다.\n\n이를 이해하기 위해서는 함수의 기울기의 부호가 바뀌었다는 의미를 살펴보아야 한다. 이는 함수의 값이 구간 내에서 가장 작은 값(극소) 또는 구간 내에서 가장 큰 값(극대)라는 것을 의미한다. 왜냐하면, 직관적으로 기울기가 0이 되기 전까지는 계속해서 증가/감소해왔다는 것을 알기 때문이다. 따라서, 우리는 기울기가 0인 지점을 모두 찾아 비교하면, 그 안에서 최대/최소를 찾을 수 있을 것이다.\n\n그런데 어떻게 하면, 기울기가 0인 지점이 극대인지 극소인지를 구분할 수 있을까? 이것은 바로 직전의 값을 미분 함수에 대입해보면 쉽게 알 수 있다. 하지만, 이것이 매번 그렇게 쉽게 판별되는 것은 아니다. 따라서, 우리는 이중 미분을 사용한다. 이중 미분 함수에 극값을 대입했을 때 양수라면 이는 극소를 의미하고, 음수인 경우는 극대를 의미한다. 이 또한, 직관적으로 기울기의 변화량이라는 이중 미분의 정의를 알면, 직관적으로 와닿을 수 있다.\n\n이렇게 해서 극대와 극소를 골라내고, 이중에서 가장 큰 값과 가장 작은 값을 찾아내면, 우리는 이것을 함수의 최적화를 수행했다고 한다.\n\n### Constraint Optimization\n\n여기서는 특별한 case를 위한 예시이다. 특정 조건이 주어졌을 때, 이를 만족하면서 특정 함수의 optimization을 수행하는 것이다.\n\n그러면 우리가 최적화하고자 하는 목적함수($\\mathcal{J}(\\bold{x})$)와 등식 제약 조건($h_{j}(\\bold{x})$), 부등식 제약 조건($g_{i}(\\bold{x})$)을 살펴보자.\n\n우리는 모든 최적화 문제를 다음과 같은 형태로 묘사할 수 있다.\n\n$$\n\\begin{align*}\n  \\text{minimize}   \\quad & \\mathcal{J}(\\bold{x}) &\\\\\n  \\text{subject to} \\quad & g_{i}(\\bold{x}) \\leq 0, & i = 1, ..., M \\\\\n                          & h_{j}(\\bold{x}) = 0, & j = 1, ..., L\n\\end{align*}\n$$\n\nmaximization인 경우는 음수를 취해서 결과를 구한 후 변환 시에 다시 음수를 취해주면 된다. 그리고 부등호가 반대인 제약 조건인 경우에도 양변에 음수를 취해서 간단하게 뒤집는 것이 가능하다.\n\n이러한 문제를 풀기 위해서는 우리는 식을 **Lagrangian** 형태로 변환해야 한다.\n\n> **Lagrangian**\n\n이는 조건부식에 있는 조건에 변수($\\nu$, $\\lambda$)를 곱한 값의 합과 원래 목적 함수($\\mathcal{J}(\\bold{x})$)의 합이다.\n\n$$\n\\mathcal{L}(\\bold{x}, \\boldsymbol{\\nu}, \\boldsymbol{\\lambda}) = \\mathcal{J}(\\bold{x}) + \\sum_{i=1}^{M}{\\nu_{i}g_{i}(\\bold{x})} + \\sum_{j=1}^{K}{\\lambda_{j}h_{j}(\\bold{x})}\n$$\n\n여기서 **Lagrangian** 함수의 optimization이 곧 목적함수의 optimization이다. 증명은 수행하지 않는다. 이에 대한 추가적인 설명이 필요한 경우에는 직접 찾아보아야할 것이다.  \n여기서 만약 등식만 있는 식인 경우에 우리는 간단히 모든 변수에 대해서 편미분이 0이 되는 등식을 이용해서, 최적 $\\bold{x}$를 찾을 수 있다. 위에 식에서 부등식 조건($g_{i}(\\bold{x})$)이 사라진다면, 우리는 미분을 통해서 처리해야하는 값은 총 x의 크기(N)와 L이다. 이는 우리가 편미분해서 구할 수 있는 식의 갯수와 똑같다. 즉, 우리가 모르는 변수는 N+M개 우리가 가진 등식은 N+M개이므로 연립해서 각 값을 구할 수 있는 것이다.\n\n하지만, 부등식인 경우에는 추가적으로 고려해줘야할 것이 있다.\n\n> **KKT Condition**\n\n이는 우리가 최적값($\\bold{x}_{*}$)를 찾았을 때, 다음과 같은 $\\boldsymbol{\\nu_{*}}$, $\\boldsymbol{\\lambda_{*}}$가 존재해야 한다는 정리이다.\n\n1. **Optimality**  \n   $\\nabla\\mathcal{L} = \\nabla\\mathcal{J}(\\bold{x}_{*}) + \\sum_{i=1}^{M}{\\nu_{*(i)}\\nabla g_{i}(\\bold{x}_{*})} + \\sum_{j=1}^{L}{\\lambda_{*(j)}\\nabla h_{j}(\\bold{x}_{*})} = 0$  \n   위에서 보았던 최적화를 수행하는 식이다.\n2. **Feasibility**  \n   $g_{i}(\\bold{x}_{*}) \\leq 0,  i = 1, ..., M$  \n   $h_{j}(\\bold{x}_{*}) = 0,  j = 1, ..., L$  \n   조건이 만족하는지를 확인하는 것이다.\n3. **Complementary slackness**  \n   $\\nu_{*(i)}g_{i}(\\bold{x}_{*}) = 0, i = 1, ..., M\\quad(\\nu_{*(i)} \\geq 0)$  \n   위의 식은 다소 헷갈릴 수 있는데 가장 알아듣기 쉬운 형태는 아래이다.  \n   $g_{i}(\\bold{x}_{*}) \\lt 0\\text{, then } \\nu_{*(i)} = 0$  \n   $g_{i}(\\bold{x}_{*}) = 0\\text{, then } \\nu_{*(i)} > 0$\n\n위의 식을 만족하는 $\\bold{x}_{*}$, $\\boldsymbol{\\nu_{*}}$, $\\boldsymbol{\\lambda_{*}}$를 찾으면, 그것이 최적값에서의 $\\bold{x}_{*}$이다.\n\n> **Lagrangian Dual Problem**\n\n여기서 한 발 더 나아가면, Lagrangian에 다시 한번 Lagrangian을 취할 수 있다.\n\n우리가 만약 Lagrangian의 하한을 $\\mathcal{G}(\\boldsymbol{\\nu}, \\boldsymbol{\\lambda})$이라 하고,\n\n$$\n\\mathcal{G}(\\boldsymbol{\\nu}, \\boldsymbol{\\lambda}) = \\inf_{\\bold{x} \\in \\mathcal{X}}\\mathcal{L}(\\bold{x}, \\boldsymbol{\\nu}, \\boldsymbol{\\lambda})\n$$\n\n$\\boldsymbol{f}^{*}$을 최적값이라고 한다면, 아래 식이 성립한다.\n\n$$\n\\boldsymbol{f}^{*} \\geq \\min_{\\bold{x}}\\mathcal{L}(\\bold{x}, \\boldsymbol{\\nu}, \\boldsymbol{\\lambda}) := \\mathcal{G}(\\boldsymbol{\\nu}, \\boldsymbol{\\lambda})\n$$\n\n따라서, 우리는 $\\mathcal{G}$의 최댓값을 찾으면 해당 값이 최적해에 근사한다는 것을 알 수 있다.\n\n이는 우리가 풀고자 하는 문제의 형식을 다시 한 번 바꾸게 된다.\n\n$$\n\\begin{align*}\n  \\text{minimize}   \\quad & \\mathcal{G}(\\boldsymbol{\\nu}, \\boldsymbol{\\lambda}) &\\\\\n  \\text{subject to} \\quad & \\boldsymbol{\\nu}_{i} \\geq 0, & i = 1, ..., M\n\\end{align*}\n$$\n\n이 식을 KKT condition을 이용하여 푸는 것이 기존 식보다 쉽게 풀 수 있는 경우가 많다. 따라서, 이러한 형태로 문제를 풀이할 수도 있다.\n\n## Information Theory\n\n### Entropy\n\n수학에서 정보의 불확실성(uncertainty)을 표현하기 위해서 물리의 entropy 라는 개념을 도입한 것이다. 즉 정보가 가지는 \"surprise\" 정도가 크다면, entropy가 큰 정보를 의미하고, 일반적인 정보라면 이는 entropy가 작은 정보인 것이다.\n\n수학적으로 다시 정의하자면, 다음과 같다.  \nsample space $\\Omega$에서 정의된 random variable $X$와 확률 $p_{X}(x)$이 주어질 때, Entropy를 $H(x)$라 하자.\n\n$$\nH(X) = -\\sum_{x \\in \\Omega}p(x)\\log_{2}p(x)\n$$\n\n위 식에서 log의 밑이 2인 것을 알 수 있는데 computer science에서는 정보가 bit단위로 저장되기 때문에 기본적으로는 2를 사용한다. 하지만, 상황에 따라서는 다른 밑을 사용할 수도 있다.\n\n헷갈릴 수 있는데 표기법이 굉장히 다양하니 유의해서 보도록 하자.\n\n$$\nH(X) = H_{p}(X) = H(p) = H_{X}(p) = H(p_{X})\n$$\n\n> **최댓값과 최솟값**\n\nEntropy는 정보의 불확실성을 나타낸다고 했다. 즉, 정보가 확실할 수록 Entrophy는 0으로 수렴하며, 확실히 아는 정보의 경우 Entropy가 최솟값인 0이 된다.  \n반대로 Entropy의 최댓값의 경우 $|\\Omega| = n$이라고 할 때, $\\log_{2}{n}$이다. 이는 uniform distribution(모든 Random Variable의 확률이 같은 분포)일 경우이다.\n\n$$\n0 \\leq H(x) \\leq log_{2}{|\\Omega|}\n$$\n\n> **$\\bold{\\log_{2}({1 \\over p_{X}(x)})}$의 평균**\n\nEntropy를 random variable x의 확률의 역수의 log를 취한 값으로 해석할 수도 있다.\n\n$$\n\\begin{align*}\nE[\\log_{2}(({1 \\over p_{X}(x)})] &= \\sum_{x \\in X}p_{X}(x)\\log_{2}({1 \\over p_{X}(x)}) \\\\\n&= -\\sum_{x \\in X}p_{X}(x)\\log_{2}(p_{X}(x)) \\\\\n&= H(p_{X})\n\\end{align*}\n$$\n\n여기서 우리는 $\\log_{2}({1 \\over p_{X}(x)})$을 **정보량**이라고 정의한다. 식에서도 알 수 있지만, 정보량과 해당 정보량을 얻을 확률은 반비례한다.\n\n> **Joint, Conditional Entropy**\n\nRandom Variable이 두 개 이상일 때, 이를 적용할 수 있다. 유도 과정은 $H(X)$가 Expectation과 어떤 관계였는지를 떠올려 보면 알 수 있다.\n\n- **Joint Entropy** : $H(X, Y) = -\\sum_{x \\in \\Omega_{X}}\\sum_{y \\in \\Omega_{Y}}p(x, y)\\log_{2}p(x, y)$\n- **Conditional Entropy** : $H(Y|X) = -\\sum_{x \\in \\Omega_{X}}\\sum_{y \\in \\Omega_{Y}}p(x, y)\\log_{2}p(y|x)$\n\n> **properties**\n\n1. **Chain Rule**  \n   $H(X, Y) = H(Y|X) + H(X)$  \n   $H(X, Y) = H(X|Y) + H(Y)$\n2. **Conditional Entropy's Maximum**  \n   $H(Y|X) \\leq H(Y)$  \n   독립일 때 같아지며 그 외에는 항상 Conditional의 Entropy가 더 낮다. 의미를 이해하면 쉽다. 한 마디로 X라는 정보가 Y라는 정보가 발생할 확률에 대한 티끌이라도의 힌트를 준다면, 해당 불확실성은 감소하게 되는 것이다.\n3. **Joint Entropy's Maximum**  \n   $H(X, Y) \\leq H(X) + H(Y)$  \n   동일하게 독립일 때 같아지며, 그 외에는 항상 Joint의 Entropy가 더 낮다. 이 또한, 두 사건이 티끌이라도 겹치는 Event가 있다면, 각 Entropy를 더하는 것보다 당연히 작을 수 밖에 없는 것이다.\n4. **Concave**  \n   Entropy의 그래프는 항상 concave하다.\n\n> **Coding**\n\n정보 이론이 활발하게 사용되는 예시 중에 하나가 바로 데이터의 Encoding/Decoding을 수행하여 bit data로 mapping할 때이다. variable length encoding을 알고 있다면, 이에 대한 이해가 쉬울 것이다. 쉽게 설명하면, 데이터를 bit sequence로 mapping할 때 모든 데이터에게 동일한 bit sequence의 길이만큼을 할당하는 게 아니라 빈도가 높은 데이터부터 짧은 bit sequence 길이를 할당하는 방식이다. 이때 bit sequence의 길이를 Entropy를 이용해서 구할 수 있다. 이 길이는 항상 해당 데이터의 Entropy보다는 커야 한다. 따라서, 해당 Entropy보다 큰 가장 작은 자연수가 해당 데이터의 Bit Sequence 길이의 최적값이다.\n\n### KL divergence(Relative Entropy)\n\nKullback-Leibler Divergence의 약자로, 우리가 구하고자하는 실제 확률(p)과 추측 확률(q) 사이의 오차를 계산할 때 사용하는 지표이다. 따라서, 동일한 Sample Space와 Random Variable에 대한 서로 다른 확률 분포를 비교한다고 생각할 수 있다.\n\n$$\nD(p||q) = KL(p||q) = \\sum_{x \\in \\Omega}p(x)\\log_{2}(p(x)/q(x)) = E_{p}[\\log_{2}({p(x) \\over q(x)})]\n$$\n\n아쉽게도 KL divergence는 거리와 같은 연산을 적용할 수 없다. 즉, 둘 사이의 역연산은 같지 않을 뿐만 아니라($D(p||q) \\neq D(q||p)$), 서로 다른 Random Variable의 KL divergence의 합이 Random Variable의 합의 KL divergence와는 다르다.\n\n### Mutual Information\n\nKL divergence를 활용하여 서로 다른 Random Variable X,Y의 연관성을 유추하는 것도 가능하다.\n\n$$\nI(X, Y) = D(p(x,y) || p(x)p(y))\n$$\n\n$I$값이 의미하는 것은 Y를 아는 것이 X의 추측을 얼마나 쉽게하는지에 대한 지표로 작용한다.\n\n증명 과정은 생략하지만, 위의 식을 정리하면 결국은 아래와 같아지기 때문이다.\n\n$$\n\\begin{align*}\n  I(X, Y) &= H(X) - H(X|Y) \\\\\n  &= H(Y) - H(Y|X)\n\\end{align*}\n$$\n\n### Cross Entropy\n\n우리가 특정 corpus(dataset)를 통해서 확률을 추정했다고 해보자. 그렇다면, 우리는 이 가설을 증명하기 위해서 다른 data에 대해서 해당 추측이 적절한지를 확인하여 정당성을 증명할 수 있다. 그러기 위해서 우리가 만든 확률에서 정보량을 추출하고, 이를 우리가 알고 있는 data의 공간에 넣었을 때의 확률을 추정하기 위해서 Cross Entropy를 사용할 수 있다.\n\n$$\nH_{q}(p) = \\sum_{x \\in \\Omega}q(x)\\log_{2}{1 \\over p(x)}\n$$\n\n간단하게 요약하면, 위 식은 틀릴 수 있는 정보를 갖고 구한 최적의 Entropy로, 정보량에 추측 정보량을 넣고, 확률에는 실제 확률을 넣는 방식이다.\n\n또한, 이는 다음과 같이 변형되기도 한다.\n\n$$\nH_{q}(p) = H(q) + D(q || p)\n$$\n\n또한, 특정 조건이 주어졌을 때의 Conditional Cross Entropy는 다음과 같다.\n\n$$\nH_{q}(p) = - \\sum_{y \\in \\Omega_{Y}}\\sum_{x \\in \\Omega_{X}}q(y,x)\\log_{2}p(y|x)\n$$\n\n하지만, 실제 구현 level에서는 이러한 Cross Entropy를 정석으로 구하는 것은 비용이 크다. 따라서, 이와 근사하는 식을 사용한다.\n\n$$\n\\begin{align*}\n  H_{q}(p) &= - \\sum_{y \\in \\Omega_{Y}}\\sum_{x \\in \\Omega_{X}}q(y,x)\\log_{2}p(y|x) \\\\\n  &= {1\\over{|T_{Y}|}}\\sum_{i=1..|T_{Y}|}{\\log_{2}p(y_{i}|x_{i})}\n\\end{align*}\n$$\n\n위 식을 이용할 때에는 실제 데이터와 비교에 사용해서는 안된다. 대신 두 개의 서로 다른 p,q가 있을 때, s라는 실제 분포에 어떤 것이 더 적절한지를 판명할 때 사용할 수 있다.\n\n## Reference\n\n- Tumbnail : Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n","slug":"ml-base-knowledge","date":"2022-10-14 19:28","title":"[ML] 0. Base Knowledge","category":"AI","tags":["ML","Probability","Calculus","InformationTheory"],"desc":"Machine Learning은 data들로 부터 특정 pattern을 나타내는 function을 만드는 것이라고 할 수 있다. 즉, pattern은 data에 대한 간단한 요약본이라고 볼 수 있다.확률/통계 이론 및 선형대수, 미적분, 정보 이론 관련 기본 내용을 해당 포스팅에 정리한다. 여기서 다루는 내용은 대게 많이 추상적인 내용이며, 키워드 중심의 내용이다. 만약, 추가적인 설명이 필요하다면 키워드를 기반으로 더 검색을 하는 것이 좋을 것이다.","thumbnailSrc":"https://euidong.github.io/images/ml-thumbnail.jpg"},{"content":"\n## Intro\n\nMachine Learning은 특정 목표를 달성하기 위해서 데이터로 부터 pattern 또는 가정 등을 유도해내는 방법이다.\n이를 위한 가장 일반적인 방법은 여러 개의 확률분포와 이것의 parameter의 조합(probabilistic model)들 중에서 측정된 데이터들을 가장 잘 나타내는 하나를 찾아내는 것이다.\n그 중에서, 확률 분포를 결정한 상태에서 parameter를 찾아나가는 형태의 접근법을 우리는 Parametric Estimation이라고 한다. 그 외에도 Nonparametric, Semi-parametric 방식도 존재하지만 이는 여기서는 다루지 않는다.\n\n## Small Example\n\n간단한 예시를 통해서 Parametric Estimation의 흐름을 익혀보자.\n\n한 학급에서 학생들의 형제자매 수에 대한 예측을 하고 싶다고 하자.  \n그렇다면, 우리는 먼저 조사(관측)를 수행해야 한다. 이를 통해서 다음과 같은 데이터를 얻게 되었다고 하자.\n\n| x        | 1    | 2    | 3    | 4    | 5    | 6    | x$\\geq$7 |\n| :------- | :--- | :--- | :--- | :--- | :--- | :--- | :------- |\n| $p(X=x)$ | 17   | 59   | 15   | 6    | 2    | 0    | 1        |\n\n여기서 우리는 여러 사전 지식을 활용하여 해당 데이터를 보았을 때, 해당 분포가 Poisson 분포의 형태라는 것을 알 수 있다.  \n따라서, 우리는 해당 분포를 Poisson이라고 가정한 다음에는 단순히 해당 분포에 대입하며, 가장 적절한 parameter만 찾으면 된다.  \n\n이 과정과 단순히 각 x에서의 확률값을 구하는 방식이랑 무엇이 다른지를 알아야지 해당 과정의 의의를 알 수 있다.\n먼저, 우리가 하고자 하는 일이 형제자매의 평균 수를 구한다고 하자. 이때의 평균 값과 Poisson 분포에서의 확률값은 다를 수 밖에 없다.\n\n이렇게 확률 분포를 구하는 것의 의미는 이것말고도 보지 않은 데이터(unseen data)를 처리함에 있다. 우리가 만약 모든 가능한 경우의 수를 모두 알고 있고, 이를 저장할 공간이 충분하다면,\n이러한 확률 분포를 구할 필요가 없다. 하지만, 우리가 원하는 추측은 unseen data에 대해서도 그럴사해야 한다. 이를 위해서는 결국 확률 분포가 필요하다.\n\n위의 예시에서 만약, 형제자매가 3명인 경우의 데이터가 없다고 하자. 이 경우에도 확률분포를 통한 추측을 한다면, 우리는 유의미한 값을 구할 수 있는 것이다.\n\n## Parametric Estimation\n\n> **정의**\n\nsample space $\\Omega$에서 통계 실험의 관측 결과를 통해서 얻은 sample $X_1$, $X_2$, ... , $X_n$이 있다고 하자. 각 sample에 대한 확률 분포를 우리는 $p_\\theta$라고 한다.\n여기서 $\\theta$는 특정 확률 분포에서의 parameter를 의미한다. 만약, bernoulli 라면, 단일 시행에 대한 확률이 될 것이고, binomial이라면, 단일 시행의 확률과 횟수가 해당 값이 될 것이다.\n\n> **성능 평가**\n\n여기서 우리가 찾기를 원하는 것은 전체 sample space $\\Omega$를 모두 잘 표현할 수 있는 $\\theta_{*}$(실제 true $\\theta$)를 찾는 것이다.(이미 확률 분포의 형태(함수, ex. Bernoulli, Binomial)는 이미 정의되어 있다.)  \n그렇다면, 실제 $\\theta_*$와 추측을 통해 만든 $\\hat{\\theta}$ 사이의 비교를 위한 지표도 필요할 것이다. 즉, 우리가 만든 확률 분포의 예측 성능평가가 필요하다는 것이다. 이를 측정하기 위해서 우리는 **Risk**라는 것을 사용한다.  \n간단하게도 실제 $\\theta_*$와 $\\hat{\\theta}$의 Mean Square Error를 계산한다.\n\n$$\n\\begin{align*}\nRisk &= E[(\\hat{\\theta} - \\theta_*)^2] = E[\\hat{\\theta}^2 - 2\\hat{\\theta}\\theta_* + \\theta_*^2] \\\\\n&= E[\\hat{\\theta}^2] - 2\\theta_*E[\\hat{\\theta}] + \\theta_*^2 \\\\\n&= E[\\hat{\\theta}^2] - 2\\theta_*E[\\hat{\\theta}] + \\theta_*^2 + (E^2[\\hat{\\theta}] - E^2[\\hat{\\theta}]) \\\\\n&= (E[\\hat{\\theta}] - \\theta_*)^2 + E[\\hat{\\theta}^2] - E^2[\\hat{\\theta}] \\\\\n&= {Bias}^2 + Var[\\hat{\\theta}]\n\\end{align*}\n$$\n\n해당 식을 분석해보면, 이와 같은 의미로 해석하는 것이 가능하다. 우리가 특정 확률 분포의 파라미터를 단 하나로 단정하고 Risk를 계산하는 경우는 Variance 값은 0이다. 즉, 해당 확률 분포가 가지는 Risk는 단순히 해당 parameter와 실제 parameter가 얼마나 찾이가 나는가를 의미한다.\n\n하지만, parameter를 특정하지 않고, 범위로 지정한다면, (예를 들어, 주사위를 던져 3이 나올 확률은 1/6 ~ 1/3이다.) 해당 확률의 평균과 Variance가 영향을 미칠 것이다.  \n다소 처음에는 헷갈릴 수 있지만, 해당 식에서 평균이 의미는 잘 확인하자. 특정 확률 분포를 가지도록 하는 $\\theta$가 $\\theta_*$ 에 얼마나 근접한지를 확인하기 위한 식이라는 것을 다시 한 번 기억하자.\n\n> **Estimation**\n\n이제부터는 앞에서 살펴보았던, parameteric estimation에서 어떻게 $\\hat{\\theta}$를 구할 수 있는지를 다룰 것이다. 확률/통계 이론에서는 크게 3가지로 나눌 수 있다고 볼 수 있다. 각 각을 살펴보도록 하자.\n\n<mark>**1. MLE**</mark>\n\nMaximum Likelihood Estimation의 약자이다. 여기서, Likelihood는 가능성이라는 뜻을 가지며, 확률/통계 이론에서 이는 확률을 해당 사건이 발생할 가능성으로 해석하는 것이다. 이를 이용해서 우리가 풀고자 하는 문제, 우리가 추측한 $\\theta$가 우리가 가진 Dataset를 만족시킬 가능성을 확인하기 위해 사용한다. 아래 수식을 보자.\n\n$$\n\\begin{align*}\n\\mathcal{L}(\\theta;\\mathcal{D}) &= p(\\mathcal{D}|\\theta) = p(x_1, x_2, ..., x_n|\\theta) \\\\\n&= \\prod_{i=1}^{n}{p(x_i|\\theta)}\n\\end{align*}\n$$\n\n(위 식을 이해하려면, 먼저 Dataset의 각 data들은 서로 independent하다는 사실을 기억하자.)  \n결국 $\\theta$가 주어졌을 때, Dataset일 확률을 구하는 것이다. 이를 다시 생각하면, $\\theta$가 얼마나 데이터셋의 확률을 잘 표현할 수 있는가와 같다.\n\n이것을 직관적으로 이해하려면 하나의 예시를 보면 좋다.\n\n![MLE example](/images/MLE-example.png)\n\n첫 번째 그래프는 같은 가우시안 분포 함수를 쓰면서, parameter만 다르게 한 경우이고, 아래는 실제 데이터의 분포라고 하자.(빨간색 선 하나 하나가 데이터를 의미)  \n이때, Likelihood를 각 각 구하면 각 x에서의 확률분포의 확률값을 모두 곱하면 된다. 그 경우 어떤 것이 제일 클지는 분명하다. 바로 파란색 분포일 것이다.  \n\n그렇다면, 우리가 원하는 것은 무엇인가? 바로 가장 높은 가능성을 가지게 하는 $\\theta$를 찾는 것이다. 따라서, 이를 식으로 표시하면 아래와 같다.\n\n$$\n\\hat{\\theta}_{MLE} = \\argmax_{\\theta}\\mathcal{L}(\\theta;\\mathcal{D})\n$$\n\n여기서 하나 문제가 있을 수 있다. 바로, 컴퓨터로 연산하게 되면 underflow가 발생하는 것이다. 특정 언어가 계산할 수 있는 소수점 범위를 벗어난다면, 제대로 된 결과를 얻을 수 없다. 이와 같은 문제를 **vanishing likelihood**라고 한다.  \n따라서, 우리는 log를 취했을 때와 log를 취하지 않았을 때의 경향성이 같음을 바탕으로 likelihood에 log를 취한 값을 이용하여 MLE를 구하는 것이 일반적이다. 이 방식을 maxmum log likelihood estimation 이라고 부른다.\n\n$$\n\\mathcal{l}(\\theta;\\mathcal{D}) = \\sum_{i=1}^{n}{\\log{(p(x_i|\\theta))}}\n$$\n\n이 방식을 이용하게 되면, 곱셈이 모두 덧셈으로 바뀌기 때문에 계산에서도 용이하다.\n\n여기까지 살펴보면, 하나의 의문이 들 수도 있다. 바로, $p(\\theta|\\mathcal{D})$도 측정 기준으로 사용할 수 있지 않냐는 것이다. 이 역시도 Dataset이 주어질 때, $\\theta$일 확률이라고 볼 수 있다.  \n어찌보면, 사람의 생각으로는 이게 더 당연하게 느껴질 수도 있다. 이는 바로 다음 MAP에서 다룰 것이다. 우선 MLE를 먼저한 이유는 이것이 더 구하기 쉽기 때문임을 기억해두자.\n\n```plaintext\n 🤔 증명\n\n (*해당 내용은 정보 이론에 기반한 MLE에 대한 추가적인 이해를 위한 내용입니다. 해당 내용은 자세히 알 필요까지는 없습니다.)\n\n 두 확률 분포 간 information Entropy의 차이를 나타내는 KL divergence의 최솟값을 구하는 것이 우리의 목표라고 정의할 수 있다.  \n 따라서, 우리가 결국 얻고자 하는 것은 확률 분포 함수가 주어졌을 때,  \n n이 무한대로 갈 때, 경험적 확률(empirical probability)에 가장 근사하는 parameter를 찾는 것이다.  \n 따라서, 우리는 KL divergence의 최솟값을 구하면 된다.\n```\n\n$$\n\\begin{align*}\n\\argmin_\\theta KL(\\tilde{p}||p_\\theta) &= \\argmin_\\theta \\int\\tilde{p}(x)\\log{\\tilde{p}(x)\\over{p_\\theta(x)}}dx \\\\\n&=\\argmin_\\theta[-\\int\\tilde{p}(x)\\log{\\tilde{p}(x)dx} - \\int\\tilde{p}(x)\\log{p_\\theta(x)dx}] \\\\\n&= \\argmax_\\theta\\int{\\tilde{p}(x)\\log{p_\\theta(x)}dx} \\\\\n&= \\argmax_\\theta\\sum_{i=1}^{n}{\\log{p_\\theta(x_i)}} \\\\\n&= \\theta_{MLE}\n\\end{align*}\n$$\n\n<mark>**2. MAP**</mark>\n\nMaximum A Posteriori의 약자이다. Posteriori는 사후 확률이라고도 부르며, dataset이 주어졌을 때, $\\theta$일 확률을 구하는 것이다.  \n이를 바로 구하는 것은 다소 어렵다. 왜냐하면, Dataset이 조건으로 들어가는 형태이기 때문이다. ($p(\\theta|\\mathcal{D})$)  \n따라서, 우리는 Bayes' Theorem에 따라서 이전에 배운 Likelihood와 parameter의 확률, 그리고 Dataset의 확률을 활용히여 풀어낼 것이다.\n\n$$\np(\\theta|\\mathcal{D}) = {p(\\mathcal{D}|\\theta)p(\\theta)\\over{p(\\mathcal{D})}}\n$$\n\n여기서 주의해서 볼 것은 바로 $p(\\theta|\\mathcal{D})$와 $p(\\theta)$의 관계이다. dataset이 주어질 때의 parameter의 확률을 구하기 위해서 원래 parameter의 확률이 필요하다는 것이다.  \n어찌보면 굉장히 모순되어 보일 수 있지만, 우리가 이것을 사전 확률(priori)로 본다면 다르게 볼 여지가 있다.  \n예를 들면, 우리가 수상한 주사위로 하는 게임에 참가한다고 하자. 이때, 우리는 수상한 주사위의 실제 확률은 알 수 없지만, 주사위 자체의 확률은 모두 1/6이라는 것을 알고 있다. 따라서, $p(\\theta={1\\over6}) = \\alpha, p(\\theta\\neq{1\\over6}) = \\beta$ 라고 할 수 있다. 만약 정말 수상해보인다면, 우리는 $\\alpha$가 점점 작아진다는 식으로 표현할 수 있고, 하나도 수상해보이지 않는 일반 주사위라면, $\\alpha=1, \\beta=0$으로 할 수도 있다. 이 경우에는 likelihood 값에 상관없이 다른 모든 값이 0이기 때문에 결국은 $p(\\theta|\\mathcal{D}) = p(\\theta)$ 가 되는 것을 알 수 있다.\n\n최종적으로, MAP도 결국은 Dataset을 얼마나 parameter가 잘 표현하는가에 대한 지표로 사용할 수 있다.\n따라서, 이를 최대로 만드는 parameter는 $\\theta_*$와 굉장히 근접할 것이다.\n\n$$\n\\begin{align*}\n\\hat{\\theta}_{MAP} &= \\argmax_{\\theta}p(\\theta|\\mathcal{D}) \\\\\n&= \\argmax_\\theta{p(\\mathcal{D}|\\theta)p(\\theta)\\over{p(\\mathcal{D})}} \\\\\n&=\\argmax_\\theta{p(\\mathcal{D}|\\theta)p(\\theta)} \\\\\n&=\\argmax_\\theta{[\\red{\\log{p(\\mathcal{D}|\\theta)}} + \\blue{\\log{p(\\theta)}}]}\n\\end{align*}\n$$\n\nMLE와 마찬가지로 이 또한 연산 및 **vanishing**을 막기 위해서 log를 취한다. 사실상 likelihood와 사전 확률의 합을 최대로 하는 $\\theta$를 찾는 것이다.\n\n<mark>**3. Bayesian Inference**</mark>\n\n이제 마지막 방법으로 제시되는 Bayesian Inference이다. 이는 대게 Bayesian Estimation이라고 많이 불리는 것 같다. 이전까지 MLE, MAP는 결국 주어진 식을 최대로 하는 확정적 $\\theta$ 하나를 구하는 것을 목표로 했다.\n\nBayesian Inference는 Dataset이 주어졌을 때, $\\theta$의 평균값을 활용한다. 더 자세히 말하면, Posteriori(사후 확률)의 평균을 구하는 것이다.  \n이를 구하는 과정을 살펴보면 이해하는데 도움이 될 것이다. 한 번 살펴보자.\n\n$$\n\\begin{align*}\n\\hat{\\theta}_{BE}&= E[\\theta|\\mathcal{D}] \\\\\n&= {\\int_{0}^{1}{{\\theta}p(\\theta|\\mathcal{D})}d\\theta} \\\\\n&= {\\int_{0}^{1}{\\theta}{{p(\\mathcal{D}|\\theta)p(\\theta)}\\over{p(\\mathcal{D})}}d\\theta} \\\\\n&= {{\\int_{0}^{1}{\\theta}{p(\\theta)p(\\mathcal{D}|\\theta)}d\\theta}\\over{p(\\mathcal{D})}} \\\\\n&= {{\\int_{0}^{1}{\\theta}{p(\\theta)\\prod_{i=1}^{n}{p(x_i|\\theta)}}d\\theta}\\over{p(\\mathcal{D})}} \\\\\n&= {{\\int_{0}^{1}{\\theta}{p(\\theta)\\prod_{i=1}^{n}{p(x_i|\\theta)}}d\\theta}\\over{\\int_0^1{p(\\mathcal{D}|\\theta)p(\\theta)}d\\theta}} \\\\\n&= {{\\int_{0}^{1}{\\theta}{p(\\theta)\\prod_{i=1}^{n}{p(x_i|\\theta)}}d\\theta}\\over{\\int_0^1{p(\\theta)\\prod_{i=1}^{n}p(x_i|\\theta)}d\\theta}} \\\\\n\\end{align*}\n$$\n\n이를 구하는 과정은 이전과는 다르게 상대값이 아닌 평균을 구해야하기 때문에 posteriori(사후 확률,$p(\\theta|\\mathcal{D})$)를 구해야 한다.\n\n하지만, 여기서 잡기술이 하나 존재한다. 바로 **Conjugate Prior**이다.\n\n바로 두 확률 분포 함수(likelihood, prior)에 의한 posterior의 형태가 정해진 경우가 있기 때문이다.\n\n| Prior $p(\\theta \\mid \\alpha)$  | Likelihood $p(\\mathcal{D} \\mid \\theta)$                 | Posterior $p(\\theta \\mid \\mathcal{D}, \\alpha)$                                                                                                                                                                                                                   | Expectation of Posterior                                                                                                                                                       |\n| :----------------------------- | :------------------------------------------------------ | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| Beta ($\\alpha, \\beta$)         | Benoulli ($\\sum _{i=1}^{n}x_{i}$)                       | Beta ($\\alpha +\\sum _{i=1}^{n}x_{i},\\,\\beta +n-\\sum _{i=1}^{n}x_{i}$)                                                                                                                                                                                            | ${{\\alpha + \\sum _{i=1}^{n}x_{i}}\\over{\\alpha + \\beta + n}}$                                                                                                                   |\n| Beta ($\\alpha, \\beta$)         | Binomial ($\\sum _{i=1}^{n}N_{i}, \\sum _{i=1}^{n}x_{i}$) | Beta ($\\alpha +\\sum _{i=1}^{n}x_{i},\\,\\beta +\\sum _{i=1}^{n}N_{i}-\\sum _{i=1}^{n}x_{i}$)                                                                                                                                                                         | ${{\\alpha + \\sum _{i=1}^{n}x_{i}}\\over{\\alpha + \\beta + \\sum _{i=1}^{n}N_{i}}}$                                                                                                |\n| Gaussian ($\\mu_0, \\sigma_0^2$) | Gaussian ($\\mu, \\sigma^2$)                              | Gaussian (${\\displaystyle {\\frac {1}{{\\frac {1}{\\sigma _{0}^{2}}}+{\\frac {n}{\\sigma ^{2}}}}}\\left({\\frac {\\mu_{0}}{\\sigma _{0}^{2}}}+{\\frac {\\sum_{i=1}^{n}x_{i}}{\\sigma ^{2}}}\\right),\\left({\\frac {1}{\\sigma_{0}^{2}}}+{\\frac {n}{\\sigma ^{2}}}\\right)^{-1}}$) | ${\\displaystyle {\\frac {1}{{\\frac {1}{\\sigma _{0}^{2}}}+{\\frac {n}{\\sigma ^{2}}}}}\\left({\\frac {\\mu_{0}}{\\sigma _{0}^{2}}}+{\\frac {\\sum_{i=1}^{n}x_{i}}{\\sigma ^{2}}}\\right)}$ |\n\n이를 이용하면, 우리는 간단하게 Posteriori의 평균을 구할 수 있다.\n\n## Reference\n\n- Tumbnail : Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n  ","slug":"ml-parametric-estimation","date":"2022-10-15 11:25","title":"[ML] 1. Parametric Estimation","category":"AI","tags":["ML","MLE","MAP","Bayesian"],"desc":"Machine Learning은 특정 목표를 달성하기 위해서 데이터로 부터 pattern 또는 가정 등을 유도해내는 방법이다.이를 위한 가장 일반적인 방법은 여러 개의 확률분포와 이것의 parameter의 조합(probabilistic model)들 중에서 측정된 데이터들을 가장 잘 나타내는 하나를 찾아내는 것이다.그 중에서, 확률 분포를 결정한 상태에서 parameter를 찾아나가는 형태의 접근법을 우리는 Parametric Estimation이라고 한다. 그 외에도 Nonparametric, Semi-parametric 방식도 존재하지만 이는 여기서는 다루지 않는다.","thumbnailSrc":"https://euidong.github.io/images/ml-thumbnail.jpg"},{"content":"\n## Intro\n\n주어지는 data에 항상 feature, label이 정확하게 매칭되지는 않는다. 이럴 경우 우리는 각 data에 대한 label과 주어진 data와 label을 잘 설명할 수 있는 probability distribution을 모두 구해야 한다. 여기서 label과 probability distribution을 동시에 구하기 위해서는 어떻게 해야할지에 대한 방법 중에서 대표적인 EM Algorithm에 대해서 살펴보도록 하겠다.\n\n## Problem\n\n여태까지 우리가 살펴봤던 supervised learning에서는 학습(learning) 시에는 feature와 label이 모두 동시에 주어지고, 예측/추론(inference)을 수행할 때에는 feature만 존재하는 data가 주어졌다. 따라서, 학습 시에 feature 정보들을 특정 pattern에 녹여냈을 때, label값을 얻는지를 확인할 수 있었다. 하지만, label이 주어지지 않은 data를 학습시킬 때에는 어떻게 해야할까? 우리는 label이 있어야 해당 data가 가진 실제 결과값을 알고 probability distribution을 얼마나 수정할지를 알 수 있었다. 하지만, 이 값을 모르니 probability distribution을 만들 수 없다. 정확한 probability distribution이 있다면, 반대로 label을 생성하는 것도 가능할 것이다. 하지만, 우리는 아무것도 알 수 없다.\n\n이렇게 답답한 상황에서 우리는 다음과 같은 아이디어를 발상해낼 수 있다. 만약, 대략적인 label을 안다면, 이것을 이용해서 최적의 확률 분포를 찾고, 이 확률 분포에 맞는 label을 다시 생성하고 이를 기반으로 다시 확률 분포를 찾는다면 어떨까? 이렇게 반복하면 꽤나 그럴싸한 분포를 만들 수 있지 않을까? 이 과정을 예를 들자면, 다음과 같다.\n\n각 기 다른 나라(label)의 동전 3종류(500원, 100cent, 100엔)를 구분하고 싶다고 하자. 이때, 알 수 있는 정보는 무게(feature) 밖에 없다고 가정하겠다. 이때 우리는 어떻게 구분할 수 있을까? 우리가 길 거리에서 무작위로 동전을 수집했다고 하자. 각 동전은 흠집도 있을 것이고 공장마다 조금씩 무게가 차이있을 수 있다. 그 결과 다음과 같은 분포가 나왔다고 하자.\n\n![ml-em-algorithm-1](/images/ml-em-algorithm-1.jpg)\n\n그래서 우리는 확률 분포가 아마 Gaussian distribution이라고 생각할 것이다. 따라서, 임의의 Gaussian Distribution을 따르는 세 개의 분포를 아래와 같이 가정해보는 것이다.\n\n![ml-em-algorithm-2](/images/ml-em-algorithm-2.jpg)\n\n그렇다면, 우리는 이 분포에 따라 가장 적절한 label을 생성할 수 있다. 아래와 같이 생성할 수 있다.\n\n![ml-em-algorithm-3](/images/ml-em-algorithm-3.jpg)\n\n그러면 결과적으로 우리는 다음과 같은 label된 data를 갖게 되는 것이다.\n\n![ml-em-algorithm-4](/images/ml-em-algorithm-4.jpg)\n\n이렇게 labeling data를 이용해서 우리는 더 효과적인 확률 분포 변수를 찾아보면 아래와 같이 이전과는 사뭇 다른 분포를 가진다는 것을 알 수 있다.\n\n![ml-em-algorithm-5](/images/ml-em-algorithm-5.jpg)\n\n결과적으로 해당 분포가 이전에 임의로 추정했던 분포보다 더 적절하다는 것을 알 수 있다. 이 과정을 계속해서 반복하면 어떻게 될까?\n\n![ml-em-algorithm-6](/images/ml-em-algorithm-6.jpg)\n\n반복을 통해서 우리는 그럴싸한 확률분포를 습득했다. 대략 머릿속으로는 그럴 수 있을 것 같다는 생각이 들 것이다. 그렇다면, 이것이 어떻게 가능하며 수학적으로 표현이 가능할까? 이를 이제부터 자세히 알아보도록 하겠다.\n\n## Base Knowledge\n\n본론으로 들어가기에 앞 서 우리는 두 가지 정의를 알아야 EM Algorithm을 증명하고 설명할 수 있다.\n\n1. Jensen’s Inequality\n2. Gibb's Inequality\n\n이 두 가지를 모두 안다면 바로 다음으로 넘어가는 것이 좋다. 하지만, 알지 못한다면 이 정의에 대해서 먼저 알아보고 가도록 하자.\n\n### Jensen’s Inequality\n\n일반적으로 우리는 다음 성질을 만족하는 집합을 Convex set이라고 한다.\n\n$$\n\\lambda x + (1-\\lambda)y \\in C,\\quad \\forall x, y \\in C \\text{ and } \\forall\\lambda\\in[0,1]\n$$\n\n즉, 집합에서 random으로 고른 두 수 사이의 수도 집합에 포함되는 집합이라는 것이다. convex set이라고 불리는 이유는 결국 이러한 집합을 2, 3 차원상에 그려보면 볼록하게 튀어나오는 형태라는 것을 알 수 있기 때문이다.\n\n또한, 아래와 같은 조건을 만족하는 함수(f)를 Convex function이라고 한다.\n\n$$\nf(\\lambda x + (1-\\lambda)y) \\leq \\lambda f(x) + (1-\\lambda)f(y),\\quad \\forall x,y \\in C(\\text{Convex set}) \\text{ and } \\forall\\lambda \\in [0,1]\n$$\n\n아래로 볼록한 함수에서는 위와 같은 과정이 너무나 당연하게도 성립한다. 사잇값의 함수값보다 함수값의 사잇값이 더 크기 때문이다.\n\n![ml-convex-function](/images/ml-convex-function.jpg)\n\n반대로 concave(위로 볼록) 함수인 경우에는 반대로 다음과 같이 정의된다.\n\n$$\nf(\\lambda x + (1-\\lambda)y) \\geq \\lambda f(x) + (1-\\lambda)f(y),\\quad \\forall x,y \\in C(\\text{Convex set}) \\text{ and } \\forall\\lambda \\in [0,1]\n$$\n\n여기서 Jensen's Inequality는 다음과 같은 수식이 convex에서 성립한다는 것이다.\n\n$$\nE[f(X)] \\geq f(E[X])\n$$\n\nconvex function에서는 어찌보면 당연해보인다. 그렇지만 이는 EM Algorithm에서 토대로 사용되는 아이디어이기 때문에 반드시 기억하자. 반대로 Concave function인 경우에는 다음과 같다.\n\n$$\nE[f(X)] \\leq f(E[X])\n$$\n\n### Gibb's Inequality\n\nKL divergence 식에 Jensen's Inequality를 적용하여 KL divergence가 항상 0보다 크거나 같고, KL divergence가 0이 되기 위해서는 두 확률분포가 같아야 한다는 것을 증명한 것이다.\n\n이에 대한 증명을 간단하게 하면 다음과 같다.\n\n$$\n\\begin{align*}\nKL(p||q) &= \\sum_{i}{p_{i}\\log\\frac{p_{i}}{q_{i}}} \\\\\n&= -\\sum_{i}p_{i}\\log{\\frac{q_{i}}{p_{i}}} \\\\\n&= E_{p}[-\\log{\\frac{q_{i}}{p_{i}}}] \\geq -\\log{E_{p}[\\frac{q_{i}}{p_{i}}]}\\, (\\because \\text{Jensen's Inequality}) \\\\\n&= -\\log{\\sum_{i}p_{i}\\frac{q_{i}}{p_{i}}} = -\\log{1} = 0\\\\\n\\therefore KL(p||q) &\\geq 0\n\\end{align*}\n$$\n\n## EM Algorithm\n\n우리는 parametric estimation 방법을 사용하기 위해서 다음과 같은 Likelihood를 계산했다.\n\n$$\n\\begin{align*}\n\\mathcal{L}(\\theta) &= \\log p(D| \\theta) \\\\\n\\mathcal{L}(\\theta) &= \\log \\prod_{x\\in D} p(x| \\theta) \\\\\n&= \\sum_{x\\in D} \\log{p(x|\\theta)}\n\\end{align*}\n$$\n\n그렇지만 우리가 이 값을 구하는 것이 어렵다는 것을 위에서 제시했다. 따라서, 이를 다음과 같이 바꿔서 풀어보자는 것이다.\n\n$$\n\\begin{align*}\n\\mathcal{L}(\\theta) &= \\sum_{x\\in D} \\log{p(x|\\theta)} \\\\\n&= \\sum_{x\\in D} \\log{\\int_{z \\in K}p(x, z|\\theta)} dz\n\\end{align*}\n$$\n\n이렇게 바꾸게 된다고 무슨 이득이 있을까? 단순히 식이 더 복잡해보인다. 하지만, 이 식을 다음과 같이 바꿀 수 있다.\n\n$$\n\\begin{align*}\n\\mathcal{L}(\\theta) &= \\sum_{x\\in D} \\log{p(x|\\theta)} \\\\\n&= \\sum_{x\\in D} \\log{\\int_{z \\in K} p(x, z|\\theta)} dz \\\\\n&= \\sum_{x\\in D} \\log{\\int_{z \\in K} p(x, z|\\theta) \\frac{p(z|x, \\theta^{\\prime})}{p(z| x, \\theta^{\\prime})} dz} \\\\\n&= \\sum_{x\\in D} \\log{\\int_{z \\in K} p(z|x, \\theta^{\\prime}) \\frac{p(x, z|\\theta)}{p(z| x, \\theta^{\\prime})} dz} \\\\\n&= \\sum_{x\\in D} \\log{E_{z|x, \\theta^{\\prime}}{[\\frac{p(x, z|\\theta)}{p(z| x, \\theta^{\\prime})}]}} \\geq \\sum_{x\\in D} E_{z|x, \\theta^{\\prime}}{[\\log{\\frac{p(x, z|\\theta)}{p(z| x, \\theta^{\\prime})}}]}\\,(\\because \\text{Jensen's Inequality}) = \\mathcal{F}(p_{z|x, \\theta^{\\prime}}, \\theta)\n\\end{align*}\n$$\n\n이를 통해서 우리는 아래와 같은 과정을 수행해볼 수 있다.\n\n$$\n\\begin{align*}\n\\mathcal{L}(\\theta) - \\mathcal{F}(p_{z|x, \\theta^{\\prime}}, \\theta) &= \\sum_{x\\in D} \\log{p(x|\\theta)} - \\sum_{x\\in D}\\{\\int_{z|x, \\theta^{\\prime}}{p(z|x,\\theta^{\\prime})\\log{\\frac{p(x, z|\\theta)}{p(z| x, \\theta^{\\prime})}}}\\} \\\\\n&= \\sum_{x\\in D} \\log{p(x|\\theta)} - \\sum_{x\\in D}\\{\\int_{z|x, \\theta^{\\prime}}{p(z|x,\\theta^{\\prime})\\log{\\frac{p(z|x, \\theta)p(x|\\theta)}{p(z| x, \\theta^{\\prime})}}}\\} \\\\\n&= \\sum_{x\\in D} \\log{p(x|\\theta)} - \\sum_{x\\in D}\\{\\int_{z|x, \\theta^{\\prime}}{p(z|x,\\theta^{\\prime})\\log{p(x|\\theta)}} + \\int_{z|x, \\theta^{\\prime}}{p(z|x,\\theta^{\\prime})\\log{\\frac{p(z|x, \\theta)}{p(z| x, \\theta^{\\prime})}}}\\} \\\\\n&= \\sum_{x\\in D}\\{\\int_{z|x, \\theta^{\\prime}}{p(z|x,\\theta^{\\prime})\\log{\\frac{p(z|x, \\theta^{\\prime})}{p(z| x, \\theta)}}}\\} \\\\\n&= \\sum_{x\\in D}{KL(p_{z|x, \\theta^{\\prime}}, p_{z|x, \\theta})}\n\\end{align*}\n$$\n\n우리가 원하는 것은 결국 해당 값의 minization이다. 따라서, 우리는 모든 $x$에 대해서 KL-divergence의 최솟값을 구해야 한다(모든 사건은 독립이기 때문이다). KL-divergence는 0과 같거나 큰 수이고, KL-divergence는 $p_{z|x, \\theta^{\\prime}} = p_{z|x, \\theta}$일 때, 0이므로 이를 만족할 수 있는 값을 찾는 것이 중요하다.\n\n따라서, 우리는 다음과 같은 insight를 얻을 수 있다.\n\n1. $\\mathcal{F}(p_{z|x, \\theta^{(t-1)}}, \\theta^{(t)}) \\leq \\mathcal{L}(\\theta^{(t)})$ 아래 식에 의해서 이를 증명할 수 있다.  \n   $\\mathcal{F}(p_{z|x, \\theta}, \\theta^{(t)}) \\leq \\mathcal{L}(\\theta^{(t)}) (\\because \\text{Jensen's Inequality})$\n2. $\\mathcal{L}(\\theta^{(t)}) = \\mathcal{F}(p_{z|x, \\theta^{(t)}}, \\theta^{(t)})$ 바로 위에서 살펴보았 듯이 $p_{z|x, \\theta^{\\prime}} = p_{z|x, \\theta}$일 때, 등식이 성립한다. (Gibb's Inequality)\n3. $\\mathcal{F}(p_{z|x, \\theta^{(t)}}, \\theta^{(t)}) \\leq \\mathcal{F}(p_{z|x, \\theta^{(t)}}, \\theta^{(t+1)})$  \n   여기서 $\\theta^{(t+1)}$은 다음과 같이 구할 수 있다.  \n   $\\theta^{(t+1)} = \\argmax_{\\theta}{\\mathcal{F}(p_{z|x, \\theta^{(t)}}, \\theta)}$\n4. $\\mathcal{F}(p_{z|x, \\theta^{(t)}}, \\theta^{(t+1)}) \\leq \\mathcal{L}(\\theta^{(t+1)})$  \n   이는 1번과 동일한 식이다.\n5. $\\mathcal{L}(\\theta^{(t)}) \\leq \\mathcal{L}(\\theta^{(t+1)})$\n\n결론적으로, 5번에 의해서 우리는 매단계가 이전보다 같거나 크다는 것을 알 수 있다. 또한, 각 단계를 차례대로 설명한다면 다음과 같다.\n\n1. 이전 확률과 현재 parameter의 추정치를 이용해서 구한 $\\mathcal{F}(p_{z|x, \\theta^{(t-1)}}, \\theta^{(t)})$는 $\\theta^{(t)}) \\leq \\mathcal{L}(\\theta^{(t)})$보다 작다는 것을 Jensen's Inequality에 의해서 알 수 있다.\n2. 우리는 이제 $\\mathcal{F}(p_{z|x, \\theta}, \\theta^{(t)})$를 최대화하기 위해서 $p_{z|x, \\theta}$를 $p_{z|x, \\theta^{(t)}}$로 업데이트 한다. 그렇다면, 이 결과는 앞 서 보았듯이 이 값은 $\\mathcal{L}(\\theta^{(t)})$와 동일한 결과를 갖는다.\n3. 여기서 우리가 얻은 $ \\mathcal{F}(p_{z|x, \\theta^{(t)}}, \\theta)$를 최대화할 수 있는 $\\theta^{(t+1)}$를 구한다면, 이는 당연하게도 $\\mathcal{F}(p_{z|x, \\theta^{(t)}}, \\theta^{(t)})$ 보다 크다.\n4. 이렇게 얻은 새로운 parameter에 의한 결과는 역시 당연하게도 1번과 같은 결론에 도달하게 된다.\n5. 결국 우리는 1~4번 까지의 과정을 거치면서 $\\mathcal{L}(\\theta)$를 계속해서 증가시킬 수 있다.\n\n결국 우리가 해야할 것은 다음값을 매차시마다 구하는 것이다.\n\n$$\n\\theta^{(t+1)} = \\argmax_{\\theta}{\\mathcal{F}(p_{z|x, \\theta^{(t)}}, \\theta)}\n$$\n\n이를 위해서 먼저 우리는 $\\mathcal{F}(p_{z|x, \\theta^{(t)}}, \\theta)$의 식을 좀 더 정리해볼 것이다.\n\n$$\n\\begin{align*}\n\\mathcal{F}(p_{z|x, \\theta^{\\prime}}, \\theta) &= \\sum_{x\\in D} E_{z|x, \\theta^{\\prime}}{[\\log{\\frac{p(x, z|\\theta)}{p(z| x, \\theta^{\\prime})}}]} \\\\\n&= \\sum_{x\\in D}\\{\\int_{z|x, \\theta^{\\prime}}{p(z|x,\\theta^{\\prime})\\log{\\frac{p(x, z|\\theta)}{p(z| x, \\theta^{\\prime})}}}\\}\\\\\n&= \\sum_{x\\in D}\\{\\int_{z|x, \\theta^{\\prime}}{p(z|x,\\theta^{\\prime})\\log{p(x, z|\\theta)}} + \\int_{z|x, \\theta^{\\prime}}{p(z|x, \\theta^{\\prime})}{\\log{\\frac{1}{p(z|x, \\theta^{\\prime})}}}\\} \\\\\n&= \\sum_{x\\in D}\\{\\int_{z|x, \\theta^{\\prime}}{p(z|x,\\theta^{\\prime})\\log{p(x, z|\\theta)}} + H(p_{z|x,\\theta^{\\prime}})\\}\n\\end{align*}\n$$\n\n위 식에서 우리는 $\\argmax_{\\theta}{\\mathcal{F}(p_{z|x, \\theta^{(t)}}, \\theta)}$를 구하기 위한 과정에서 $H(p_{z|x,\\theta^{\\prime}})$는 필요없다는 것을 알 수 있다.\n\n$$\n\\begin{align*}\n\\mathcal{Q}(\\theta; \\theta^{\\prime}) &= \\mathcal{F}(p_{z|x, \\theta^{(t)}}, \\theta) - H(p_{z|x,\\theta^{\\prime}}) \\\\\n&= \\sum_{x\\in D}\\{\\int_{z|x, \\theta^{\\prime}}{p(z|x,\\theta^{\\prime})\\log{p(x, z|\\theta)}}\\} \\\\\n&= \\sum_{x\\in D}\\{ E_{z|x, \\theta^{\\prime}}[\\log{p(x, z|\\theta)}] \\}\n\\end{align*}\n$$\n\n그 결과 우리는 다음과 같은 결론을 내릴 수 있다.\n\n$$\n\\begin{align*}\n\\theta^{(t+1)} &= \\argmax_{\\theta} \\mathcal{Q}(\\theta; \\theta^{(t)}) \\\\\n&= \\argmax_{\\theta} \\sum_{x\\in D}\\{ E_{z|x, \\theta^{(t)}}[\\log{p(x, z|\\theta)}] \\}\n\\end{align*}\n$$\n\n따라서, 우리는 이를 효과적으로 구하기 위해서 EM Algorithm을 다음과 같이 정의하고, 단계에 따라 수행한다.\n\n1. Expectation Step  \n   앞에서 제시한 $\\mathcal{Q}(\\theta; \\theta^{(t)})$의 식을 구하는 단계이다. 즉, 변수를 $\\theta$ 외에는 모두 없애는 단계이다. Expectation 단계라고 부르는 이유는 $\\mathcal{Q}(\\theta; \\theta^{(t)})$가 $\\sum_{x\\in D}\\{ E_{z|x, \\theta^{\\prime}}[\\log{p(x, z|\\theta)}] \\}$와 같이 Expectation의 합의 형태로 표현되기 때문이다.  \n   이를 좀 더 쉽게 표현하자면 다음과 같이 말할 수도 있다. 이전 parameter $\\theta^{(t)}$가 주어졌을 때, 각 데이터에 대한 latent variable $z$의 확률을 구하는 것이다. 즉, $p(z|x, \\theta^{(t)})$를 구하는 것이다.\n2. Maximization Step  \n   이제 앞 서 구한 $\\mathcal{Q}(\\theta; \\theta^{(t)})$를 $\\theta$에 대해 최대화하여, $\\theta^{(t+1)}$를 구하는 단계이다.\n\n이것이 EM Algorithm의 본질이다.\n\n그래서 앞 선 Clustering에서 살펴보았던 것처럼 EM Algorithm을 다음과 같이 정의할 수도 있는 것이다.\n\n1. 초기 parameter $\\theta^{(0)}$를 설정한다.  \n2. 이를 기반으로 data가 해당 분포에서 $z$일 확률을 구한다.\n3. 구한 확률을 바탕으로 해당 확률과 data를 잘 표현할 수 있는 새로운 parameter $\\theta^{(t+1)}$를 구한다.\n4. 2, 3번 과정을 parameter가 일정 수준에 수렴할 때까지 반복한다.\n\n## Reference\n\n- Tumbnail : Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n","slug":"ml-em-algorithm","date":"2022-11-24 20:15","title":"[ML] 10. EM Algorithm","category":"AI","tags":["ML","EM-Algorithm","JensensInequality","GibbsInequality"],"desc":"주어지는 data에 항상 feature, label이 정확하게 매칭되지는 않는다. 이럴 경우 우리는 각 data에 대한 label과 주어진 data와 label을 잘 설명할 수 있는 probability distribution을 모두 구해야 한다. 여기서 label과 probability distribution을 동시에 구하기 위해서는 어떻게 해야할지에 대한 방법 중에서 대표적인 EM Algorithm에 대해서 살펴보도록 하겠다.","thumbnailSrc":"https://euidong.github.io/images/ml-thumbnail.jpg"},{"content":"\n## Intro\n\nClustering과 같은 Unsupervised Learning으로 Feature Selection 또는 Feature Extraction 등 여러가지 이름으로 불리는 Dimensionality Reduction 기법에 대해서 다룰 것이다. 특정 data에서 유의미한 정보를 얻기 위해서 우리는 data 전체를 볼 필요가 없다. 따라서, feature들을 최소한으로 줄이면서 유의미한 정보를 얻을 수만 있다면 굉장히 효율적인 inferencing과 learning을 할 수 있다.\n\n## Dimensionality Reduction\n\n가장 AI가 활발하게 연구되고 있는 분야는 Vison과 Natural Language 분야일 것이다. 그리고 이들 분야의 공통점은 data의 크기가 굉장히 크다는 것이다. 예를 들어, 숫자를 표현하는 하나의 이미지가 $1920\\times1080$ 정도의 화질이고, 검은 색 또는 흰색으로 구분하는 bitmap 형식이라고 하자. 이 때 우리가 각 image에 존재하는 숫자를 classification하고 싶은 경우, data에 사용되는 feature가 $1920\\times1080=2,073,600$이다. 상당히 큰 숫자이고, 화질이 커질 수록 그리고 색이 생길 수록 이 값은 커질 것이다. Natural Language 분야에서도 마찬가지이다. 영어 단어의 종류만 따져도 170,000개가 넘는다. 즉, 이들 각 각을 단순 one-hot encoding으로 표현한다면, data에 사용되는 feature의 수는 170,000개가 넘는다. 이렇게 feature의 수가 많아지면, 우리는 data를 효율적으로 학습시키기가 매우 어려워진다. 이를 해결하기 위해서는 feature의 수를 줄이는 것이 반드시 필요하다.\n\n이를 위해서, 우리는 하나의 insight가 필요하다. data에서 필요한 부분이 눈으로 보이는 것이 아닐 수도 있다는 점이다. 예를 들어 우리가 $10\\times10$ 크기의 bitmap에 숫자가 쓰여있다고 하자.\n\n![ml-observed-dim](/images/ml-observed-dim.png)\n\n이때 우리가 갖는 경우의 수는 $2^{100}$개일 것이다. 여기서 숫자 형태로 존재하지 않는 data가 사실은 더 많음에도 불구하고 우리는 이 경우의 수도 고려하는 dimension에서 inferencing과 learning을 수행하는 것이다. 이는 매우 비효율적이라고 할 수 있다. 따라서, 우리는 실제로 관측한 observed dimensionality보다는 더 훌륭한 true dimensionality를 찾아내는 것이 필요하다. 이를 위해서, 다양한 Dimensionality Reduction 관련 방법들이 존재한다. 그 중에서 PCA가 가장 일반적으로 많이 사용되고 있는 방법이다.\n\n## Principal Component Analysis\n\nPrincipal Component Analysis(PCA)는 핵심이 되는 principal component(basis, 기저, 차원 축)를 재정의하여 차원을 줄이는 방법이다. 그렇다면, 어떤 basis가 좋은 basis인지를 알 수 있을까? 아마도 좋은 basis는 이전 basis에서 가지고 있던 정보들을 최대한 보존할 수 있다면 좋다고 할 수 있을 것이다. 그렇다면, 여기서 어떻게 information을 많이 보관할 수 있을지에 대한 통찰이 필요하다.\n\n![ml-pca-1](/images/ml-pca-1.png)\n\n위의 그림을 봤을 때, 왼쪽과 오른쪽 중 어떤 basis가 더 좋은 basis일지를 보자. 차원을 옮긴다는 것은 기존 basis에서의 data를 새로운 basis로 projection하는 것이다. 다시 말해, 해당 축에 직각으로 data를 내려보내는 것이다. 그렇게 했을 때, 왼쪽 그림이 오른쪽 그림보다 더 넓게 data가 퍼지는 것을 알 수 있다. 즉, 차원 이동 시에 충돌로 인해 사라지는 data의 수가 더 적다는 것을 의미한다. 이에 따라 더 많은 정보를 포함하는 것은 data를 최대한 넓게 퍼트릴 수 있는 basis를 가지는 것이라고 할 수 있다. <mark>**따라서, PCA는 기존 basis보다 적은 수의 새로운 basis로 옮기는 과정에서 기존 dimension에서의 정보를 최대한 포함하기 위해서 variance가 최대가 되는 basis를 찾는 것이 목표이다.**</mark> 그럼 이를 수학적으로 표현해볼 것이다. 우선은 이해를 위해서 새로운 basis의 수를 1이라고 가정하고 우리는 sample mean과 variance를 이용해서 이를 추론할 것이다. (해당 basis가 $u_{1}$이다.)\n\n$$\n\\begin{align*}\nVar[u_{1}^{\\top}x] &= E[(u_{1}^{\\top}x - E[u_{1}^{\\top}x])^{2}] \\\\\n&= E[(u_{1}^{\\top}x - u_{1}^{\\top}\\bar{x})^{2}] \\quad (\\bar{x} = E[x] = \\frac{1}{N}\\sum_{n\\in[N]}x_{n}) \\\\\n&=\\frac{1}{N}\\sum_{n\\in[N]}(u_{1}^{\\top}x_{n} - u_{1}^{\\top}\\bar{x})^{2} \\\\\n&=\\frac{1}{N}\\sum_{n\\in[N]}(u_{1}^{\\top}x_{n} - u_{1}^{\\top}\\bar{x})^{\\top}(u_{1}^{\\top}x_{n} - u_{1}^{\\top}\\bar{x}) \\\\\n&=\\frac{1}{N}\\sum_{n\\in[N]}(u_{1}^{\\top}(x_{n}-\\bar{x})(x_{n} -\\bar{x})^{\\top}u_{1}) \\\\\n&=u_{1}^{\\top} \\times \\{\\frac{1}{N}\\sum_{n\\in[N]}(x_{n}-\\bar{x})(x_{n} -\\bar{x})^{\\top}\\} \\times u_{1} \\\\\n&=u_{1}^{\\top} S u_{1} \\quad (S = \\frac{1}{N}\\sum_{n\\in[N]}(x_{n}-\\bar{x})(x_{n} -\\bar{x})^{\\top})\n\\end{align*}\n$$\n\n결국 우리가 얻고자 하는 다른 basis에서의 variance를 구하기 위해서 우리는 기존 차원에서의 모든 data들의 covariance($S_{ij} = Cov[x_{i}, x_{j}]$)를 구해야한다.\n\n자 이제 이를 maximization하는 답을 찾아볼 것이다. 그러기 위해서, 우선 basis의 크기 역시 variance의 영향을 미치기 때문에 이를 unit vector로 제한해야 한다. 이를 종합하면 결론적으로 dimension을 1로 바꾸는 PCA는 다음과 같은 형태로 표현할 수 있다.\n\n$$\n\\begin{align*}\n\\text{maximize }&\\quad u_{1}^{\\top} S u_{1} \\\\\n\\text{subject to }&\\quad u_{1}^{\\top}u_{1} = 1\n\\end{align*}\n$$\n\n위의 maximization problem을 해결해보자. 그러면 다음과 같은 lagrange function을 얻을 수 있다.\n\n$$\n\\mathcal{L} = u_{1}^{\\top} S u_{1} + \\lambda(1-u_{1}^{\\top}u_{1})\n$$\n\n이를 미분하면 다음과 같다.\n\n$$\n\\begin{align*}\n\\frac{\\partial\\mathcal{L}}{\\partial u_{1}} &= 2S u_{1} - 2\\lambda u_{1} = 0 \\\\\nS u_{1} &= \\lambda u_{1}\n\\end{align*}\n$$\n\n즉, 우리가 찾고자 하는 basis는 S matrix의 eigenvector 중 하나의 eigenvector인 것이다. 간단하게 eigenvector와 eigenvalue가 뭔지를 설명하자면, 위처럼 동일한 vector에 대해서, matrix와 vector의 곱이 scalar와 vector과 동일하게 하는 scalar(eigenvalue)와 vector(eigenvector)를 의미한다. (후에 시간이 되면 해당 개념을 다루겠지만, 여기서는 eigenvalue와 eigenvector에 대한 개념은 생략한다.)\n\n그리고 우리가 구한 식을 maximization 식에 한 번 대입하면 다음과 같은 결과를 얻을 수 있다.\n\n$$\n\\begin{align*}\n\\text{maximize }& \\quad u_{1}^{\\top} S u_{1} \\\\\n\\text{maximize }& \\quad u_{1}^{\\top} \\lambda u_{1} \\\\\n\\text{maximize }& \\quad \\lambda u_{1}^{\\top} u_{1} \\\\\n\\text{maximize }& \\quad \\lambda\n\\end{align*}\n$$\n\n따라서, eigenvalue 중 가장 큰 값을 가질 때의 eigenvector가 우리가 구하고자 하는 basis가 된다는 것을 알 수 있다. 또한, 결론적으로 $u_{1}^{\\top} S u_{1} = \\lambda$이기 때문에 $\\lambda$가 variance가 된다는 것도 포인트 중 하나이다.\n\n또한 최종적으로 이를 확장해서 이제 M개의 basis를 사용하는 PCA를 다음과 같이 표현할 수 있다.\n\n$$\n\\begin{align*}\n\\text{maximize }\\quad& \\sum_{i \\in [M]} u_{i}^{\\top} S u_{i} \\\\\n\\text{subject to }\\quad& u_{i}^{\\top}u_{j} = \\delta_{ij} \\quad \\forall i,j \\in [M] \\\\\n&(\\delta_{ij} = \\begin{cases} 1 & i=j \\\\ 0 & i \\neq j \\end{cases})\n\\end{align*}\n$$\n\n따라서, PCA는 data의 covariance matrix에 대한 eigenvalue decomposition을 통해 얻은 eigenvalue 중에 큰 값을 가지는 것을 총 M개 뽑고, 이에 상응하는 eigenvector들을 찾는 것이다. 그리고, 이에 따라서 우리가 가지는 M개의 basis의 eigenvalue($\\lambda$)의 합은 우리가 옮긴 차원에서 갖고 있는 총 variance를 의미한다.\n\n### Other Approaches\n\n위에서 우리는 PCA를 variance를 최대로 하는 basis를 찾는 것으로 정의했다. 하지만, 관점을 바꿔서 문제를 projection error, 기존 data와 projected data 사이의 거리를 최소화할 수 있는 basis를 찾는 것으로 정의할 수도 있다. 이 또한 생각하기에 합리적이라고 생각할 수 있는데 이를 실제로 수학적으로 나타내면 어떻게 되는지 알아보겠다.\n\n먼저, 우리가 총 D개의 unit vector가 있고, 이 중에 임의의 M개의 vector를 basis로 하는 차원으로 reduction을 한다고 해보자. 그렇다면, 우리는 다음과 같이 N개의 data들 중 하나인 $x_{n}$를 표현할 수 있을 것이다.\n\n$$\n\\begin{align*}\n  x_{n} &= \\sum_{i=1}^{D}\\{(x_{n}^{\\top}u_{i})u_{i}\\} \\\\\n  &= \\sum_{i=1}^{M}\\{(x_{n}^{\\top}u_{i})u_{i}\\} + \\sum_{i = M+1}^{D}\\{(x_{n}^{\\top}u_{i})u_{i}\\}\n\\end{align*}\n$$\n\n그리고 우리는 옮겨진 data($\\tilde{x}_{n}$)를 다음과 같이 표현할 수 있다.\n\n$$\n\\begin{align*}\n  \\tilde{x}_{n} &= \\sum_{i=1}^{M}\\{(x_{n}^{\\top}u_{i})u_{i}\\} + \\sum_{i = M+1}^{D}\\{(\\bar{x}^{\\top}u_{i})u_{i}\\}\n\\end{align*}\n$$\n\n여기서 의문이 들 수 있다. $\\sum_{i=M+1}^{D}$ 부분이 와닿지 않을 것이다. 왜냐하면, 우리는 projected data가 실제로는 $\\sum_{i=1}^{M}$ 부분만을 가지기 때문이다. 뒷 부분이 추가된 이유는 해당 M차원 data를 D차원의 공간에 표현할 때, 어느 부분을 중점으로 할지를 정한 것이다. 따라서, 앞 서 보았던 전체 data의 평균만큼을 남은 모든 방향에 더해준 것이다. 이 값은 모든 projected data에 동일하게 더해지는 상수값이라고 봐도 무방하다. 이래도 이해가 조금 어렵다면 아래 그림을 통해 이해할 수 있다.\n\n![ml-pca-3](/images/ml-pca-3.png)\n\n위와 같이 3개의 vector는 1차원에서는 동일한 vector이다. 하지만, projected data와 원래 data간의 적절한 거리를 구하기 위해서는 중앙에 있는 형태로 basis로 옮겨야 한다. 이를 위해서 필요한 것이 뒤의 요소이다. 따라서, 우리는 아래식과 같이 두 projected data와 원래 data간의 거리를 구할 수 있다.\n\n$$\n\\begin{align*}\n  x_{n} - \\tilde{x}_{n} &= (\\sum_{i=1}^{M}\\{(x_{n}^{\\top}u_{i})u_{i}\\} + \\sum_{i = M+1}^{D}\\{(x_{n}^{\\top}u_{i})u_{i}\\}) - (\\sum_{i=1}^{M}\\{(x_{n}^{\\top}u_{i})u_{i}\\} + \\sum_{i = M+1}^{D}\\{(\\bar{x}^{\\top}u_{i})u_{i}\\}) \\\\\n  &= \\sum_{i = M+1}^{D}\\{(x_{n}^{\\top}u_{i})u_{i}\\} - \\sum_{i = M+1}^{D}\\{(\\bar{x}^{\\top}u_{i})u_{i}\\} \\\\\n  &= \\sum_{i = M+1}^{D}\\{(x_{n}^{\\top}u_{i} - \\bar{x}^{\\top}u_{i})u_{i}\\}\n\\end{align*}\n$$\n\n따라서, 우리가 구하고자하는 최종 목적함수를 mean squared error라고 한다면 다음과 같이 정의할 수 있다.\n\n$$\n\\begin{align*}\n\\mathcal{J} &= \\frac{1}{N}\\sum_{n=1}^{N}||x_{n} - \\tilde{x}_{n}||^2 \\\\\n&= \\frac{1}{N}\\sum_{n=1}^{N}(\\sum_{i = M+1}^{D}x_{n}^{\\top}u_{i} - \\bar{x}^{\\top}u_{i})^{\\top}(\\sum_{i = M+1}^{D}x_{n}^{\\top}u_{i} - \\bar{x}^{\\top}u_{i}) \\\\\n&= \\frac{1}{N}\\sum_{n=1}^{N}\\sum_{i = M+1}^{D}(x_{n}^{\\top}u_{i} - \\bar{x}^{\\top}u_{i})^{2}u_{i}^{\\top}u_{i} \\\\\n&= \\sum_{i = M+1}^{D}\\frac{1}{N}\\sum_{n=1}^{N}(x_{n}^{\\top}u_{i} - \\bar{x}^{\\top}u_{i})^{2}\\\\\n&= \\sum_{i=M+1}^{D} u_{i}^{\\top} S u_{i}\\quad (\\because \\text{앞 서 살펴본 첫 번째 관점과 동일})\n\\end{align*}\n$$\n\n따라서, 우리는 다음과 같은 결론에 도달할 수 있다.\n\n$$\n\\begin{align*}\n\\text{minimize }\\quad& \\sum_{i=M+1}^{D} u_{i}^{\\top} S u_{i} \\\\\n\\text{subject to }\\quad& u_{i}^{\\top}u_{j} = \\delta_{ij} \\quad \\forall i,j \\in [M] \\\\\n&(\\delta_{ij} = \\begin{cases} 1 & i=j \\\\ 0 & i \\neq j \\end{cases})\n\\end{align*}\n$$\n\n기존 식과 다른 점이라면, maximization이 minimization으로 바뀌었고, 범위가 $[1, M]$에서 $[M+1, D]$로 바뀌었다는 점이다. 그리고, 우리는 다음과 같은 통찰을 얻을 수 있다. eigenvalue들 중에서 가장 큰 값부터 M번째로 큰 값을 구하는 것과 M+1부터 시작해서 가장 작은 eigenvalue를 찾는 과정은 동일하므로 두 식은 사실상 동일하다.\n\n![ml-pca-4](/images/ml-pca-4.png)\n\n### Very High Dimensional Data\n\n일반적으로 우리가 PCA를 구하기 위해서 eigenvector를 구하는 비용은 O($D^3$)이다. 하지만, 차원이 data의 수보다 큰 경우에 약간의 꼼수를 쓸 수 있다. 간단하게 S를 (M x M) matrix에서 (N x N) matrix로 변환하여 사용하는 것이다. 이를 이용하면, O($N^3$)로 시간 복잡도를 바꾸는 것이 가능하다. 식은 아래를 참고 하자. 아래에서 사용하는 $X$는 각 행이 $(x_{n} - \\bar{x})^{\\top}$인 matrix이다.\n\n$$\n\\begin{align*}\n  Su_{i} &= \\lambda_{i}u_{i} &\\\\\n  \\frac{1}{N}X^{\\top}Xu_{i} &= \\lambda_{i}u_{i} &\\leftarrow X^{\\top}X \\in R^{D\\times D} \\\\\n  X \\times \\frac{1}{N}X^{\\top}Xu_{i} &= X \\times \\lambda_{i}u_{i}& \\\\\n  \\frac{1}{N}XX^{\\top}(Xu_{i}) &= \\lambda_{i}(Xu_{i})& \\\\\n  \\frac{1}{N}XX^{\\top}(v_{i}) &= \\lambda_{i}(v_{i}) &\\leftarrow XX^{\\top} \\in R^{N\\times N}\\\\\n\\end{align*}\n$$\n\n## Probabilistic PCA\n\nPCA를 통해서 data를 다른 차원으로 옮기는 과정을 수행했다. 사실 이것으로 끝나기는 조금 아쉽다. 왜냐하면, 우리는 현재 가지고 있는 data에 대응하는 차원으로의 이동을 수행한 것이다. 즉, 우리가 실제로 inferencing 단계에서 unseen data를 보게 되었을 때 제대로 동작할지는 미지수라고 할 수 있다. 이를 극복하기 위해서, continueous한 형태를 만들어야 한다. 이를 위해서, PCA를 확률적으로 해석하는 것이 필요하다. 하지만, 여기서는 자세히 다루지 않는다. 후에 더 자세히 다루도록 하겠다.\n\n## Kernel PCA\n\n여태까지 앞에서 살펴봤던 PCA는 새로운 basis가 기존 Dimenalality에서 linear하게 만들었다. 하지만, 우리가 다루는 data가 사실은 그렇지 않은 형태일 가능성이 높다. 우리가 관측한 특징들에 의한 좌표 공간에서 선형 형태로 data가 존재하는게 아니라 더 복잡한 곡선 형태를 가질 수 있다. 가장 일반적인 data가 원형으로 이루어진 data 분포이다. 원형으로 반지름이 0.5이하인 data와 반지름이 1인 data를 구분하고 싶다고 하자. 일반적인 x, y 공간에서 linear basis를 이용해서 이를 적절하게 나누려면, dimensionality reduction에서는 정보를 모두 거의 균일하게 잃을 수 밖에 없다.\n\n![ml-kernel-pca-1](/images/ml-kernel-pca-1.png)\n\n하지만, 우리는 일반적으로 중심과 떨어진 정도($x^{2} + y^{2}$)와 같은 기존 feature를 non-linear하게 조합하여 활용하면 더 효과적인 구분이 가능할 것이라는 것을 알 수 있다. (아래 그림은 다른 방식을 사용한 것이지만, 원의 중심과 비슷하다.)\n\n![ml-kernel-pca-2](/images/ml-kernel-pca-2.png)\n\n따라서, 우리는 기존 차원에서 선형으로 basis를 변경하는 것이 아니라 비선형으로 basis를 찾고 싶은 것이다. 기존 차원과 비교했을 때 비선형의 basis를 통해서 만들어지는 차원을 manifold라고 하며, 아래 왼쪽 위와 같은 manifold를 발견만 한다면, Dimensionality reduction을 기존 linear 방식과 비교했을 때 더 효과적으로 수행할 수 있다.\n\n![ml-kernel-pca-3](/images/ml-kernel-pca-3.png)\n\n자 그렇다면 이 또한 어떻게 수학적으로 표현할 수 있을까? 이전에 썼던 Maximum Variance 방식을 이용할 것이다. 우선 우리가 data($x$)를 non-linear 공간으로 차원 이동시킨 값을 $\\phi(x)$라고 정의하고, $\\sum_{i=1}^{N}\\phi(x_{i})=0$이 되는 상황이라고 가정을 해보자.(그렇지 않으면 굉장히 수식이 복잡해지기 때문에 우선 이렇게 가정을 할 것이다.)\n\n$$\n\\begin{align*}\nVar[u_{1}^{\\top}\\phi(x)] &= E[(u_{1}^{\\top}\\phi(x) - E[u_{1}^{\\top}\\phi(x)])^{2}] \\\\\n&= E[(u_{1}^{\\top}\\phi(x) - u_{1}^{\\top}\\bar{\\phi}(x))^{2}]\\quad (\\bar{\\phi}(x) = E[\\phi(x)] = \\frac{1}{N}\\sum_{n \\in [N]}\\phi(x_{n})) \\\\\n&= E[(u_{1}^{\\top}\\phi(x))^2] \\\\\n&= \\frac{1}{N}\\sum_{n \\in [N]}(u_{1}^{\\top}\\phi(x_{n}))^{2} \\\\\n&= u_{1}^{\\top}\\frac{1}{N}\\{\\sum_{n \\in [N]}\\phi(x_{n})\\phi(x_{n})^{\\top}\\}u_{1} \\\\\n&= u_{1}^{\\top}\\bar{S}u_{1} \\quad (\\bar{S} = \\frac{1}{N}\\sum_{n \\in [N]}\\phi(x_{n})\\phi(x_{n})^{\\top})\n\\end{align*}\n$$\n\n따라서, 우리는 결론상 이전과 마찬가지로 다음과 같은 식을 얻을 수 있다.\n\n$$\n\\begin{align*}\n\\text{maximize}\\quad& \\sum_{i \\in [M]}u_{i}^{\\top}\\bar{S}u_{i} \\\\\n\\text{subject to}\\quad& u_{i}^{\\top}u_{j} = \\delta_{ij}\\quad \\forall i,j \\in [M] \\\\\n\\end{align*}\n$$\n\n이를 푸는 과정은 앞에서 살펴봤으니 정리를 하자면, 결국 다음과 같은 eigenvalue, eigenvector를 찾는 것이다.\n\n$$\n\\bar{S}u_{i} = \\lambda_{i}u_{i}\n$$\n\n하지만, 이를 푸는 것은 굉장히 곤혹스럽다. 왜냐하면, 우리는 모든 data에 대해서 차원 변환 함수인 $\\phi$를 적용해주어야 하기 때문에 연산의 복잡도는 급격하게 증가하게 된다. 따라서, 우리는 이를 차원 변환 함수 $\\phi$의 연산 과정을 효과적으로 줄이는 방법을 제시한다. 이것이 kernel 함수이다. 이는 앞 서 살펴봤었던, [🔗 5. Multiclass Classification](/posts/ml-multiclass-classification-in-svm#Kernel-Method)의 Kernel Method와 동일하다. 간단하게 설명하자면, $\\phi(x_{i})^{\\top}\\phi(x_{j})$의 결과와 동일한 $\\kappa(x_{i}, x_{j})$의 연산을 활용해서 총 2번의 차원 변환과 곱셈 연산을 두 개의 변수를 받는 하나의 함수로 대체한다는 idea이다. 이를 통해서, 연산 비용을 획기적으로 줄일 수 있다. 따라서, 우리는 기존 식에서 $\\phi$를 없애고, kernel 만으로 이루어진 형태로 바꿀 것이다.\n\n이를 위해서, 우리는 먼저 $u_{i}$를 다시 표현해보자.\n\n$$\n\\begin{align*}\n\\bar{S}u_{i} &= (\\frac{1}{N}\\sum_{n \\in [N]}\\phi(x_{n})\\phi(x_{n})^{\\top})u_{i} \\\\\n&= \\frac{1}{N}\\sum_{n \\in [N]}\\{\\phi(x_{n})\\times (\\phi(x_{n})^{\\top}u_{i})\\} \\\\\n&= \\frac{1}{N}\\sum_{n \\in [N]} <\\phi(x_{n}), u_{i}>\\phi(x_{n})\\quad(<\\phi(x_{n}), u_{i}> = \\phi(x_{n})^{\\top}u_{i})  \\\\\n\\\\\n\\lambda_{i}u_{i} &= \\bar{S}u_{i} \\\\\n\\lambda_{i}u_{i} &= \\frac{1}{N}\\sum_{n \\in [N]} <\\phi(x_{n}), u_{i}>\\phi(x_{n}) \\\\\nu_{i} &= \\sum_{n \\in [N]} \\frac{<\\phi(x_{n}), u_{i}>}{N\\lambda_{i}}\\phi(x_{n}) \\\\\n\\therefore u_{i} &= \\sum_{n \\in [N]} \\alpha_{in}\\phi(x_{n})\n\\end{align*}\n$$\n\n해당 과정을 통해서, 우리가 얻고자 하는 basis는 임의의 상수 $\\alpha_{in}$에 의해서 정의된다는 것을 알 수 있다. 따라서, 이제부터 문제는 $\\alpha_{in}$을 모든 N과 M에 대해서 찾기만 하면 되는 것이다. 이제 기존 식을 다시 정리해보도록 하자.\n\n$$\n\\begin{align*}\n\\bar{S}u_{i} &= \\lambda_{i}u_{i} \\\\\n(\\frac{1}{N}\\sum_{n \\in [N]}\\phi(x_{n})\\phi(x_{n})^{\\top})(\\sum_{m \\in [N]} \\alpha_{in}\\phi(x_{m})) &= \\lambda_{i}(\\sum_{n \\in [N]} \\alpha_{in}\\phi(x_{n})) \\\\\n\\phi(x_{\\ell})^{\\top}\\times (\\frac{1}{N}\\sum_{n \\in [N]}\\phi(x_{n})\\phi(x_{n})^{\\top})(\\sum_{m \\in [N]} \\alpha_{im}\\phi(x_{m})) &= \\phi(x_{\\ell})^{\\top}\\times \\lambda_{i}(\\sum_{n \\in [N]} \\alpha_{in}\\phi(x_{n})) \\\\\n\\frac{1}{N}\\sum_{n \\in [N]}\\phi(x_{\\ell})^{\\top}\\phi(x_{n})\\phi(x_{n})^{\\top}\\sum_{m \\in [N]} \\alpha_{im}\\phi(x_{m}) &= \\lambda_{i}\\sum_{n \\in [N]} \\alpha_{in}\\phi(x_{\\ell})^{\\top}\\phi(x_{n}) \\\\\n\\frac{1}{N}\\sum_{n \\in [N]}\\phi(x_{\\ell})^{\\top}\\phi(x_{n})\\sum_{m \\in [N]} \\alpha_{im}\\phi(x_{n})^{\\top}\\phi(x_{m}) &= \\lambda_{i}\\sum_{n \\in [N]} \\alpha_{in}\\phi(x_{\\ell})^{\\top}\\phi(x_{n}) \\\\\n\\frac{1}{N}\\sum_{n \\in [N]}\\kappa(x_{\\ell}, x_{n})\\sum_{m \\in [N]} \\alpha_{im} \\kappa(x_{n}, x_{m}) &= \\lambda_{i}\\sum_{n \\in [N]} \\alpha_{in}\\kappa(x_{\\ell}, x_{n}) \\\\\n\\sum_{n \\in [N]}\\kappa(x_{\\ell}, x_{n})\\begin{bmatrix} \\kappa(x_{n}, x_{1}) \\\\ \\kappa(x_{n}, x_{2}) \\\\ \\vdots \\\\ \\kappa(x_{n}, x_{N}) \\end{bmatrix}^{\\top}\\begin{bmatrix}\\alpha_{i1} \\\\ \\alpha_{i2} \\\\ \\vdots \\\\ \\alpha_{iN} \\\\\\end{bmatrix} &= N\\lambda_{i} \\begin{bmatrix} \\kappa(x_{\\ell}, x_{1}) \\\\ \\kappa(x_{\\ell}, x_{2}) \\\\ \\vdots \\\\ \\kappa(x_{\\ell}, x_{N}) \\end{bmatrix}^{\\top}\\begin{bmatrix}\\alpha_{i1} \\\\ \\alpha_{i2} \\\\ \\vdots \\\\ \\alpha_{iN} \\\\\\end{bmatrix} \\\\\n\\begin{bmatrix} \\kappa(x_{\\ell}, x_{1}) \\\\ \\kappa(x_{\\ell}, x_{2}) \\\\ \\vdots \\\\ \\kappa(x_{\\ell}, x_{N}) \\end{bmatrix}^{\\top}\\begin{bmatrix} \\kappa(x_{1}, x_{1}) & \\kappa(x_{1}, x_{2}) & \\cdots & \\kappa(x_{1}, x_{N}) \\\\\\kappa(x_{2}, x_{1}) & \\kappa(x_{2}, x_{2}) & \\cdots & \\kappa(x_{2}, x_{N}) \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\kappa(x_{N}, x_{1}) & \\kappa(x_{N}, x_{2}) & \\cdots & \\kappa(x_{N}, x_{N}) \\end{bmatrix}\\begin{bmatrix}\\alpha_{i1} \\\\ \\alpha_{i2} \\\\ \\vdots \\\\ \\alpha_{iN} \\\\\\end{bmatrix} &= N\\lambda_{i} \\begin{bmatrix} \\kappa(x_{\\ell}, x_{1}) \\\\ \\kappa(x_{\\ell}, x_{2}) \\\\ \\vdots \\\\ \\kappa(x_{\\ell}, x_{N}) \\end{bmatrix}^{\\top}\\begin{bmatrix}\\alpha_{i1} \\\\ \\alpha_{i2} \\\\ \\vdots \\\\ \\alpha_{iN} \\\\\\end{bmatrix} \\\\\n\\begin{bmatrix} \\kappa(x_{1}, x_{1}) & \\kappa(x_{1}, x_{2}) & \\cdots & \\kappa(x_{1}, x_{N}) \\\\\\kappa(x_{2}, x_{1}) & \\kappa(x_{2}, x_{2}) & \\cdots & \\kappa(x_{2}, x_{N}) \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\kappa(x_{N}, x_{1}) & \\kappa(x_{N}, x_{2}) & \\cdots & \\kappa(x_{N}, x_{N}) \\end{bmatrix}\\begin{bmatrix}\\alpha_{i1} \\\\ \\alpha_{i2} \\\\ \\vdots \\\\ \\alpha_{iN} \\\\\\end{bmatrix} &= N\\lambda_{i} \\begin{bmatrix}\\alpha_{i1} \\\\ \\alpha_{i2} \\\\ \\vdots \\\\ \\alpha_{iN} \\\\\\end{bmatrix} \\\\\nK\\alpha_{i} &= N\\lambda_{i} \\alpha_{i} \\\\\n\\end{align*}\n$$\n\n결국 또 다른 eigenvalue problem을 만들 수 있게 된다. 하지만, 여기서 $\\alpha_{i}$의 크기는 1이 아니다. 따라서, $\\alpha_{i}$를 정규화해주어야 한다.\n\n$$\n\\begin{align*}\nu_{i}^{\\top}u_{i} &= \\sum_{n \\in [N]} \\alpha_{in}\\phi(x_{n})\\sum_{m \\in [N]} \\alpha_{im}\\phi(x_{m}) \\\\\n&= \\sum_{n \\in [N]}\\alpha_{in} \\sum_{m \\in [N]}\\alpha_{im}\\phi(x_{n})\\phi(x_{m}) \\\\\n&= \\sum_{n \\in [N]}\\alpha_{in} \\sum_{m \\in [N]}\\alpha_{im}\\kappa(x_{n}, x_{m})\\\\\n&= \\sum_{n \\in [N]}\\alpha_{in} \\begin{bmatrix} \\kappa(x_{n}, x_{1}) \\\\ \\kappa(x_{n}, x_{2}) \\\\ \\vdots \\\\ \\kappa(x_{n}, x_{N}) \\end{bmatrix}^{\\top}\\begin{bmatrix}\\alpha_{i1} \\\\ \\alpha_{i2} \\\\ \\vdots \\\\ \\alpha_{iN} \\\\\\end{bmatrix}\\\\\n&= \\begin{bmatrix}\\alpha_{i1} \\\\ \\alpha_{i2} \\\\ \\vdots \\\\ \\alpha_{iN} \\\\\\end{bmatrix}^{\\top} \\begin{bmatrix} \\kappa(x_{1}, x_{1}) & \\kappa(x_{1}, x_{2}) & \\cdots & \\kappa(x_{1}, x_{N}) \\\\\\kappa(x_{2}, x_{1}) & \\kappa(x_{2}, x_{2}) & \\cdots & \\kappa(x_{2}, x_{N}) \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\kappa(x_{N}, x_{1}) & \\kappa(x_{N}, x_{2}) & \\cdots & \\kappa(x_{N}, x_{N}) \\end{bmatrix}  \\begin{bmatrix}\\alpha_{i1} \\\\ \\alpha_{i2} \\\\ \\vdots \\\\ \\alpha_{iN} \\\\\\end{bmatrix}\\\\\n&= \\alpha_{i}^{\\top}K\\alpha_{i} \\\\\n&= \\alpha_{i}^{\\top}N\\lambda_{i} \\alpha_{i}\\quad(\\because K\\alpha_{i} = N\\lambda_{i} \\alpha_{i}) \\\\\n&= N\\lambda_{i}\\alpha_{i}^{\\top}\\alpha_{i} = 1 \\\\\n\n\\therefore ||\\alpha_{i}||^{2} &= \\frac{1}{N\\lambda_{i}}\n\\end{align*}\n$$\n\n따라서, 결론적으로 우리는 nonlinear PCA를 수행하기 위해서 아래의 조건을 만족하는 $\\lambda_{i}$를 큰값부터 시작하여 M번째까지에서의 $\\alpha_{i}$를 구하는 것이다.\n\n$$\n\\begin{align*}\nK\\alpha_{i} &= N\\lambda_{i} \\alpha_{i} \\\\\n||\\alpha_{i}||^{2} &= \\frac{1}{N\\lambda_{i}}\n\\end{align*}\n$$\n\n그리고, 마지막으로 data를 우리가 구한 basis로 projection한 결과는 다음과 같이 구할 수 있다.\n\n$$\n\\begin{align*}\n<u_{i}, \\phi(x)> &= \\sum_{i\\in[N]}\\alpha_{in}\\phi(x)^{\\top}\\phi(x_{n}) \\\\\n&= \\sum_{i\\in[N]}\\alpha_{in}\\kappa(x, x_{n}) \n\\end{align*}\n$$\n\n즉, 이 또한 이전에 계산했던 kernel을 활용해서 그대로 활용할 수 있다.\n\n자 이제 마지막으로 해줘야 할 것은 우리가 맨 처음 가정했던 $\\sum_{i\\in[N]}\\phi(x_{i}) = 0$ 부분이다. 사실 대게의 일반적인 변환에서는 이렇게 이동하는 것이 더 드물 것이다. 따라서, 우리는 강제로 평균을 0으로 맞춰주는 과정을 수행해야 한다. 평균이 0이 되는 차원 변환 함수를 $\\tilde{\\phi}$라고 하고, 이때의 Kernel Matrix를 $\\tilde{K}$라고 하자. 그렇다면, 우리는 아래와 같이 적용하면, 강제로 평균을 0으로 만들 수 있다.\n\n$$\n\\tilde{\\phi}(x_{n}) = \\phi(x_{n}) - \\frac{1}{N}\\sum_{i\\in[N]}\\phi(x_{i})\n$$\n\n또한, $\\tilde{\\kappa}, \\tilde{K}$는 다음과 같이 구할 수 있다.\n\n$$\n\\begin{align*}\n\\tilde{\\kappa}(x_{n}, x_{m}) &= \\tilde{\\phi}(x_{n})^{\\top}\\tilde{\\phi}(x_{m}) \\\\\n&= (\\phi(x_{n}) - \\frac{1}{N}\\sum_{i\\in[N]}\\phi(x_{i}))^{\\top}(\\phi(x_{m}) - \\frac{1}{N}\\sum_{j\\in[N]}\\phi(x_{j})) \\\\\n&= \\phi(x_{n})^{\\top}\\phi(x_{m}) - \\frac{1}{N}\\sum_{i\\in[N]}\\phi(x_{i})^{\\top}\\phi(x_{m}) - \\frac{1}{N}\\sum_{j\\in[N]}\\phi(x_{n})^{\\top}\\phi(x_{j}) + \\frac{1}{N^{2}}\\sum_{i\\in[N]}\\sum_{j\\in[N]}\\phi(x_{i})^{\\top}\\phi(x_{j}) \\\\\n&= \\kappa(x_{n}, x_{m}) - \\frac{1}{N}\\sum_{i\\in[N]}\\kappa(x_{i}, x_{m}) - \\frac{1}{N}\\sum_{j\\in[N]}\\kappa(x_{j}, x_{n}) + \\frac{1}{N^{2}}\\sum_{i\\in[N]}\\sum_{j\\in[N]}\\kappa(x_{i}, x_{j})\n\\\\\n&\\text{위의 식을 일반화하여 행렬로 표현하면 아래와 같다.}\n\\\\\n\\tilde{K} &= K - 1_{N}K - K1_{N} + 1_{N}K1_{N}\\quad(1_{N} = \\frac{1}{N}\\begin{bmatrix}1 & 1 & \\cdots 1 \\\\ 1 & 1 & \\cdots & 1 \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 1 & 1 & \\cdots & 1\\end{bmatrix})\n\\end{align*}\n$$\n\n## Auto Encoder\n\n우리가 PCA에서 마지막에 살펴본 Kernel PCA의 한계는 data마다 kernel 함수를 어떻게 적용해야할지를 알 수 없다는 것이다. 그래서, 이를 위한 여러 Heuristic 방법들이 존재하지만 항상 완벽할 수는 없다. 그렇다면, 이 $\\phi$를 스스로 학습하는 방법을 알아볼 것이다.\n\n먼저, **Encoding**이란 data의 특징(feature)을 활용하여 이를 변형하는 것을 의미한다. 또한, 이 과정에서 중요한 것은 **Encoding**을 통해 얻은 결과를 이용해서 다시 원본 data를 복구할 수  있어야 한다.(복구하는 과정은 **Decoding**이라고 한다.) 이를 통해서, 우리는 압축을 하기도 하고, 관측 data로부터 숨겨진 feature를 추출하기도 한다. 여기서는 Dimensionality Reduction이 Encoding이라고 보는 것이다.\n\n여기서 **Auto Encoder**는 **Encoding**을 통해서 Dimensionality Reduction을 수행하고, 이를 통해 얻은 결과로 원래 data를 **Decoding**할 수 있을 때가지 반복하는 것이다. 이 모든 과정의 결과로 원래 data와 Decoding된 data 간의 차이가 일정 임계값 이하로 떨어졌다면, 우리는 이제 이 Encoder를 $\\phi$의 대용으로 쓸 수 있다. 그리고 이 $\\phi$를 안다면, 이를 근사하는 kernel function도 찾을 수 있다.\n\n![ml-auto-encoder-1](/images/ml-auto-encoder-1.png)\n\n이러한 방식은 굉장히 많은 분야에서 넓게 사용되고 있다. 이들을 간단하게 살펴보도록 하자.\n\n1. <mark>**CNN**</mark>  \n   결국 CNN은 너무 큰 image data를 처리하기 위해서 어쩔 수 없이 Dimensionality Reduction을 수행해야 한다. 따라서, 이를 감소시키기 위해서 Auto Encoder를 사용하여 true dimension을 찾을 수 있다.\n2. <mark>**Semi-Supervised Learning**</mark>  \n   label이 존재하는 data는 굉장히 희귀하며, 이 labeling 비용이 매우 많이 든다. 따라서, label이 존재하는 data와 존재하지 않는 data를 동시에 활용하는 방법이 필요한 경우가 많다. 이때 auto encoding을 활용하게 되면, 일단 labeled, unlabeled data를 모두 활용하여 먼저 true dimension을 구한 뒤에 여기서 labeled data를 활용하여 classifier를 학습할 수 있다. 이것이 unlabed data를 활용하여 더 높은 적중률을 보여줄 수 있다.  \n   ![ml-auto-encoder-2](/images/ml-auto-encoder-2.png)\n\n그리고, 마지막으로 Auto Encoding의 성능을 올리기 위한 방법으로 Masking과 같은 data augmentation을 활용하는 것이다. 기존 data의 일부분을 masking하고도 실제 원본 data를 복구해낼 수 있도록 하는 것이다.\n   \n\n## Reference\n\n- Tumbnail : Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n- Kernel PCA, <https://sebastianraschka.com/Articles/2014_kernel_pca.html>\n","slug":"ml-dimensionality-reduction","date":"2022-12-04 14:19","title":"[ML] 11. Dimensionality Reduction","category":"AI","tags":["ML","PCA","KernelPCA","AutoEncoder"],"desc":"Clustering과 같은 Unsupervised Learning으로 Feature Selection 또는 Feature Extraction 등 여러가지 이름으로 불리는 Dimensionality Reduction 기법에 대해서 다룰 것이다. 특정 data에서 유의미한 정보를 얻기 위해서 우리는 data 전체를 볼 필요가 없다. 따라서, feature들을 최소한으로 줄이면서 유의미한 정보를 얻을 수만 있다면 굉장히 효율적인 inferencing과 learning을 할 수 있다.","thumbnailSrc":"https://euidong.github.io/images/ml-thumbnail.jpg"},{"content":"\n## Intro\n\nRegression(회귀)이라는 단어는 \"원래의 상태로 돌아간다\"로 돌아간다는 의미를 가진다. 결국 어떤 일련의 Event로 인해서 데이터에 Noise가 발생할 수 있어도 결국은 하나의 \"보편\"으로 시간이 지나면 수렴(회귀)할 것이라는 생각에 기반하는 것이다.  \n따라서, 우리는 이러한 \"보편\"을 찾기 위해서 우리가 알고 있는 독립 데이터 X를 통해서 알고자 하는 값 Y를 보편적으로 추론할 수 있다. 이 과정을 우리는 Regression이라고 부른다. 또한, X에 의해 독립적이지 않고 종속적인 Y의 관계가 Linear하게 표현될 때 이를 우리는 Linear Regression이라고 한다.  \n따라서, 해당 Posting에서는 Linear Regression을 바탕으로 Machine Learning이 어떻게 동작하는지를 이해하는 것이 목표이다.\n\n## Regression\n\n> **정의**\n\n독립 변수 X로 부터 종속 변수 Y에 대응되는 함수 f를 생성하는 과정을 의미한다.\n\n$$\n\\bold{y} = f(\\bold{x}) + \\epsilon\n$$\n\n$$\nf(\\bold{x}) = \\bold{w}^{\\top}\\bold{x},\n(\\bold{w} = \\begin{bmatrix} w_{0} \\\\ w_{1} \\\\ w_{2} \\\\ \\vdots \\\\ w_{N} \\\\ \\end{bmatrix}, \\bold{x} = \\begin{bmatrix} 1 \\\\ x_{1} \\\\ x_{2} \\\\ \\vdots \\\\ x_{N} \\\\ \\end{bmatrix} )\n$$\n\n여기서 각 변수 $x$, $y$, $\\epsilon$, $w$은 다음과 같이 여러 이름으로 불려진다.\n\n- $x$ : input, 독립 변수, predictor, regressor, covariate\n- $y$ : output, 종속 변수, response\n- $\\epsilon$ : noise, 관측되지 않은 요소\n- $w$ : weight, 가중치, parameter\n\n> <mark>**성능 평가(MSE)**</mark>\n\n우리가 만든 Regression이 얼마나 데이터를 잘 반영하는지를 알고 싶을 때, 즉 평가하고자 할 때, 우리는 Mean Squared Error(MSE)를 사용한다. 이는 이전 포스팅인 [Parametric Estimation](/posts/ml-parametric-estimation)에서도 살펴보았었다.\n\n그렇다면, MSE를 최소로 하는 f(x)는 무엇일까? 이를 통해서 또, 하나의 식견을 넓힐 수 있다. 한 번 MSE 식을 정리해보자.\n\n$$\n\\begin{align*}\n\\Epsilon(f) &= E[||\\bold{y}_*-f(\\bold{x})||^2] \\\\\n&= \\int\\int||\\bold{y}_*-f(\\bold{x})||^2p(\\bold{x}, \\bold{y}_*)d\\bold{x}d\\bold{y}_* \\\\\n&= \\int\\int||\\bold{y}_*-f(\\bold{x})||^2p(\\bold{x})p(\\bold{y}_* | \\bold{x})d\\bold{y}_*d\\bold{x} \\\\\n&= \\int p(\\bold{x}) \\red{\\int||\\bold{y}_*-f(\\bold{x})||^2p(\\bold{y}_* | \\bold{x})d\\bold{y}_*}d\\bold{x}\n\\end{align*}\n$$\n\n여기서 중요한 것은 바로 빨간색으로 색칠한 부분이다. 우리가 바꿀 수 있는 값은 f(x)를 구성하는 w밖에 없다 즉, 위 식을 최소화하는 것은 빨간색 부분을 최소화하는 것과 같아진다.  \n따라서, 이 부분을 미분해서 최솟값을 구할 수 있는데 이를 확인해보자.\n\n$$\n\\begin{align*}\n&{\\partial\\over{\\partial{f(\\bold{x})}}}({\\int||\\bold{y}_*-f(\\bold{x})||^2p(\\bold{y}_* | \\bold{x})d\\bold{y}_*}) = 0 \\\\\n&{\\partial\\over{\\partial{f(\\bold{x})}}}({\\int||\\bold{y}_*^2p(\\bold{y}_* | \\bold{x})d\\bold{y}_*} - 2f(\\bold{x}){\\int\\bold{y}_*p(\\bold{y}_* | \\bold{x})d\\bold{y}_*} + f(\\bold{x})^2{\\int p(\\bold{y}_* | \\bold{x})d\\bold{y}_*}) = 0 \\\\\n&-2{\\int\\bold{y}_*p(\\bold{y}_* | \\bold{x})d\\bold{y}_*} + 2f(\\bold{x}) = 0 \\\\\n&f(\\bold{x}) = {\\int\\bold{y}_*p(\\bold{y}_* | \\bold{x})d\\bold{y}_*} = E[\\bold{y}_*|\\bold{x}]\n\\end{align*}\n$$\n\n즉, 우리가 구하고자 하는 Linear Regression 함수는 data x에 따른 실제 y 값의 평균을 의미한다. Regression의 정의를 생각했을 때, 어느정도 합리적이라는 것을 알 수 있다. \"보편\"적이다는 의미에서 \"평균\"을 쓰는 경우가 많이 있기 때문이다.\n\n위에서는 MSE를 이용해서 분석하였지만, MAE(Mean Absolute Error)를 활용하여 구할 수 있는데 이 경우에는 Regression의 형태가 또 달라진다. 즉, MSE를 최소화하는 방식은 우리가 \"보편\"적인 답을 구하는데 있어 \"평균\"을 활용한 것이고, MAE를 사용한다면, 또 다른 방식을 사용한다는 것을 알게 될 것이다.\n\n## MLE of Linear Regression\n\n이제 Linear Regression에서 $\\bold{w}$를 어떻게 찾아 나갈지에 대해서 살펴볼 것이다. 순서는 이전 Posting [Parametric Estimation](/posts/ml-parametric-estimation)에서 살펴봤던 것과 마찬가지로 MLE, MAP 순으로 살펴볼 것이다. 그리고 이것이 왜 MLE고, MAP랑 관련이 있는지도 살펴볼 것이다.\n\n들어가기에 앞 서, 표기법과 용어를 몇 개 정리할 필요가 있다.\n\n- $\\bold{x}, \\bold{y}, \\bold{w}$ 등 굵은 선 처리되어 있는 변수는 vector를 의미한다.\n- $\\bold{X}$ 등 굵고 대문자로 처리되어 있는 변수는 Matrix를 의미한다.\n- $\\bold{w^{\\top}}$, $\\bold{X}^{\\top}$ 에서 T는 Transpose를 의미한다.\n- feature : input 데이터의 각 각 분류 기준들을 의미한다. 수식으로는 $x_1, x_2, x_3$ 이런 식으로 표현된 input들 중에 각 각의 input을 feature라고 하며, 실제 예시로는 데이터 수집 시에 각 데이터의 column(나이, 성별, 등 등)이 될 것이다.\n\n위의 용어 정리에 의해서 다음과 같은 사실을 다시 한 번 확인하자.\n\n먼저, 단일 Linear Regression이다.\n\n$$\n\\hat{y} = f(\\bold{x}) = \\bold{w}^{\\top}\\bold{x} = \\bold{x}^{\\top}\\bold{w}\n$$\n\n이번에는 여러 개의 데이터를 한 번에 추측한 결과값 $\\hat{\\bold{y}}$ 이다.\n\n$$\n\\hat{\\bold{y}} = \\bold{X}\\bold{w}\n$$\n\n각 의미를 곱씹어보면 어떻게 생겼을지 어렵풋이 짐작이 올 것이다.\n\n> **basis function**\n\n여기서 또 하나 짚어볼 것은 바로 $\\bold{x}$를 변형하는 방법이다. 바로, 우리는 데이터로 입력 받은 데이터를 바로 사용할 수도 있지만, 해당 input 값을 제곱해서 사용해도 되고, 서로 더해서 사용해도 되고, 나누어서 사용할 수도 있다. 예를 들어서 우리가 구하고 싶은 값이 대한민국 인구의 평균 나이라고 하자. 이때, 우리가 사용하는 데이터의 값이 가구 단위로 조사되어 부,모,자식1, 자식2, ... 로 분류되어 나이가 적혀있다고 하자. 이때 우리가 필요한 것은 결국 전체 인구의 나이 데이터임으로 모두 하나의 feature로 합쳐버릴 수도 있다.\n\n이러한 과정을 위해서 우리는 basis function($\\phi(\\bold{x})$)이라는 것을 이용한다. 단순히 input data를 합성해서 하나의 input을 생성하는 것이다.\n\n따라서, 우리는 필요에 따라 input data를 가공하여 사용하며 여러 $\\phi$를 적용하여 나타낼 경우 linear regression은 다음과 같은 형태가 된다.\n\n$$\nf(\\bold{x}) = \\bold{w}^{\\top}\\boldsymbol{\\phi}(\\bold{x})\n$$\n\n대표적인 Basis function을 살펴보자.\n\n- Polynomial basis : 하나의 input feature에 대해서 n-제곱형태의 vector로 변환하는 형식이다. 따라서, 다음과 같이 표기 된다.  \n  $\\boldsymbol{\\phi}(\\bold{x}) = \\begin{bmatrix} 1 \\\\ x \\\\ x^{2} \\\\ \\vdots \\\\ x^{n} \\\\ \\end{bmatrix}$, $\\bold{w}^{\\top}\\boldsymbol{\\phi}(\\bold{x}) = w_{0} + w_{1}x + w_{2}x^{2} + ... + w_{n}x^{n}$  \n  대게 이러한 형태로 변형한 Linear Regression을 Polinomial Regression이라고 부르는데, 이를 통한 결과 값이 마치 다항식의 형태를 띄기 때문이다. 하지만, feature의 값이 polynomial이 되었더라도 $\\bold{w}$가 선형임을 잊어서는 안된다.  \n  이를 사용하게 되면, 우리는 1차원의 input 공간에서 선형으로는 나눌 수 없던 분류를 수행할 수 있다.\n- Gaussian basis : 가우시안 분포로 변환하는 것으로 특정 feature를 gaussian으로 변환하게 되면, 데이터의 경향성이 파악된다. 이는 후에 더 자세히 다룰 기회가 온다.  \n- Spline basis: 특정 구간마다 다른 Polynomial 형태의 feature를 적용하도록 하는 방식이다. 대게 구간마다 다른 확률 분포를 적용하고자 할 때 사용한다.\n- Fourier basis, Hyperbolic tangent basis, wavelet basis 등 여러 가지 방식이 존재한다.\n\n> **Design Matrix**\n\n마지막으로, 이렇게 만들어진 $\\phi(\\bold{x})$를 하나의 Matrix로 합친 것을 Design Matrix라고 한다. N개의 데이터를 L개의 서로 다른 basis function으로 변환한 데이터를 행렬로 표현하면, 다음과 같다.\n\n$$\n\\Phi =\n  \\begin{bmatrix}\n    \\phi_1({\\bold{x_1}})  & \\phi_2(\\bold{x_1})  & \\cdots  & \\phi_L(\\bold{x_1})  \\\\\n    \\phi_1({\\bold{x_2}})  & \\phi_2(\\bold{x_2})  & \\cdots  & \\phi_L(\\bold{x_2})  \\\\\n    \\vdots                & \\vdots              & \\ddots  & \\vdots              \\\\\n    \\phi_1({\\bold{x_N}})  & \\phi_2(\\bold{x_N})  & \\cdots  & \\phi_L(\\bold{x_N})  \\\\\n  \\end{bmatrix}\n$$\n\n이를 통해서 표현한 모든 데이터에 대한 Linear Regression은 다음과 같다.\n\n$$\n\\hat{\\bold{y}} = \\Phi\\bold{w}\n$$\n\n자 이제부터 우리는 본론으로 들어와서 우리의 Linear Regression의 Weight(Parameter, $\\bold{w}$)를 어떻게 추정할 수 있을지를 알아보자.\n\n우리는 최종적으로 우리의 Linear Regression이 정답과 매우 유사한 값을 내놓기를 원한다. 따라서, 이때 우리는 Least Square Error를 사용할 수 있다. 이는 모든 데이터에서 얻은 예측값(Linear Regression의 output)과 실제 y의 값의 Square Error의 합을 최소화하는 것이다.\n\n$$\n\\varepsilon_{LS}(\\bold{w}) = {1\\over2}\\sum_{n=1}^{N}(y_n - \\bold{w}^{\\top}\\boldsymbol{\\phi}(\\bold{x_n}))^2 = {1\\over2}||\\bold{y}_* - \\Phi\\bold{w}||^2\n$$\n\n이제 $\\argmin_{\\bold{w}}\\varepsilon_{LS}(\\bold{w})$을 풀기 위해서 미분을 해보자.\n\n$$\n\\begin{align*}\n&{\\partial\\over\\partial\\bold{w}}{1\\over2}||\\bold{y}_* - \\Phi\\bold{w}||^2 = 0 \\\\\n&\\Phi^{\\top}(\\bold{y}_* - \\Phi\\bold{w}) = 0 \\\\\n&\\Phi^{\\top}\\Phi\\bold{w} = \\Phi^{\\top}\\bold{y_*} \\\\\n&\\bold{w} = (\\Phi^{\\top}\\Phi)^{-1}\\Phi^{\\top}\\bold{y_*} \\\\\n&\\bold{w} = \\Phi^{\\dagger}\\bold{y_*}\n\\end{align*}\n$$\n\n이를 통해서, 위와 같은 식을 얻을 수 있다.\n\n---\n\n그럼 이 식이 왜 MLE랑 관련이 있는 것일까? 그것은 다음의 과정을 통해서 증명할 수 있다.\n\n우리는 각 data마다 존재하는 error(noise, $y_* - \\hat{y}$, $\\varepsilon$)가 그 양이 많아짐에 따라 정규 분포를 따른다는 것을 알 수 있다. (Central Limit Theorem)\n\n$$\n\\begin{align*}\n\\varepsilon &= y_* - \\hat{y} = y_*-\\phi(\\bold{x}) \\\\\ny_* &= \\phi(\\bold{x}) + \\varepsilon\n\\end{align*}\n$$\n\n이를 좌표 평면 상에서 나타내면 다음과 같다고 할 수 있다.\n\n![gaussian-error](/images/gaussian-error.jpeg)\n\n또한, $\\varepsilon$의 확률을 정의하면 다음과 같은 확률을 얻을 수 있다.\n\n$$\n\\begin{align*}\np(\\varepsilon) &= {1\\over{\\sqrt{2\\pi}\\sigma}}\\exp{[-{\\varepsilon^2\\over{2\\sigma^2}}]} \\\\\np(\\varepsilon) &= {1\\over{\\sqrt{2\\pi}\\sigma}}\\exp{[-{(y_*-\\phi(\\bold{x}))^2\\over{2\\sigma^2}}]}\n\\end{align*}\n$$\n\n여기서 우리는 $p(\\varepsilon)$을 $p(y_*|\\bold{x}; \\theta)$라고 볼 수 있다. ($\\theta = (\\bold{w}, \\phi, \\sigma)$)\n\n우리는 이를 이용해서 Likelihood를 구할 수 있다.\n\n$$\n\\begin{align*}\n\\mathcal{L} &= \\log{p(\\bold{y}_*|\\bold{X}; \\theta)} = \\sum_{i=1}^{N}{\\log{p(y_{*(i)}|\\bold{x}_{(i)}; \\theta)}} \\\\\n&= N\\log{{1\\over{\\sqrt{2\\pi}\\sigma}}} + \\sum_{i=1}^{N}{-{(y_*-\\phi(\\bold{x}))^2\\over{2\\sigma^2}}} \\\\\n&= N\\log{{1\\over{\\sqrt{2\\pi}\\sigma}}} - {1\\over{\\sigma^2}}\\red{{1\\over{2}}\\sum_{i=1}^{N}{(y_*-\\phi(\\bold{x}))^2}}\n\\end{align*}\n$$\n\n우리가 변경할 수 있는 데이터는 $\\phi(\\bold{x})$ 밖에 없다. 따라서, 빨간색을 제외한 부분은 Likelihood의 최댓값을 구할 때, 고려하지 않아도 되는 상수로 볼 수 있다. 그렇다면, 우리는 Likelihood의 최댓값을 구하기 위해서 빨간색 표시된 부분을 최소화해야 한다는 것을 알 수 있다. 그리고, 이는 우리가 앞에서 살펴봤던, Least Squared Error와 같다.\n\n<mark>즉, $\\bold{w}_{LS}=\\bold{w}_{MLE}$ 라는 것이다.</mark>\n\n## MAP of Linear Regression\n\n이번에는 Linear Regression에서 $\\bold{w}$를 찾아나가는 과정에서 MAP를 활용하는 과정을 알아볼 것이다.\n\n> **overfitting**\n\n우리가 MLE를 통해서 Linear Regression을 찾는 것이 충분하다고 생각할 수 있다. 하지만, 우리는 어쩔 수 없이 **overfitting**이라는 문제에 직면하게 된다.\n\n![over-fitting-example](/images/over-fitting-example.jpg)\n\n**overfitting**이란 데이터를 통해서 구할 수 있는 분포가 학습에 사용된 데이터에 대해서는 에러가 거의 없는 형태로 예측하지만, 그 외에 데이터에 대해서는 에러가 크게 발생하는 경우를 의미한다. 위의 예시에서 처럼 데이터가 전체 Sample space보다 턱없이 적은 경우에 발생하기 쉽다.\n\n이러한 문제는 사실 basis function을 잘 선택하면 해결할 수 있다. 하지만, 우리가 어떻게 매번 적절한 basis function을 찾기 위해서 iteration을 반복하는 것이 올바를까? 그리고 이는 실제 적합한 값을 찾기 위한 수학적 식도 존재하지 않는다.\n\n> **Regularization**\n\n따라서, 우리는 **regularization**을 수행한다. 위의 overfitting된 그래프를 보면 하나의 insight(번뜩이는 idea?)를 얻을 수 있다. 바로, 급격한 기울기의 변화는 overfitting과 유사한 의미로 볼 수 있다는 것이다. 즉, 그래프의 형태가 smooth 해야한다는 것이다.\n\n따라서, 우리는 하나의 error에 대해서 다음과 같이 재정의해서 smoothing(regularization)을 수행할 수 있다.\n\n$$\n\\varepsilon = {1\\over2}||\\bold{y}_* - \\Phi\\bold{w}||^2 + {\\lambda\\over{2}}||\\bold{w}||^2\n$$\n\n$\\bold{w}$의 L2 norm을 error에 추가하여 $\\bold{w}$의 크기가 작아지는 방향으로 예측을 할 수 있도록 하는 것이다. (물론 L1 norm을 사용할 수도 있다. 이 또한, 후에 다룰 것이니 여기서는 넘어가겠다. 추가로 이렇게 L2 norm을 이용하면 **Ridge Regression**, L1 norm을 이용하면 **Lasso Regression**이라고 한다.)\n\n자 이제 위의 식을 미분해서 최소값이 되게 하는 $\\bold{w}$를 찾아보자. 과정은 연산이 그렇게 어렵지 않으므로 넘어가고 결과는 아래와 같다.\n\n$$\n\\bold{w}_{ridge} = (\\lambda I + \\Phi^{\\top}\\Phi)^{-1}\\Phi^{\\top}\\bold{y}_*\n$$\n\n---\n\n그럼 이 역시 MAP를 통해서 해석해보도록 하자.\n\n위에서 살펴본 바와 같이 우리는 w값이 작을 확률이 높을 수록 좋은 성능을 가질 것이라는 Prior를 얻을 수 있다.\n\n즉,$p(\\bold{w})$가 zero-mean gaussian(표준정규분포)형태를 이루기를 바랄 것이다.\n\n$$\np(\\bold{w}) = \\mathcal{N}(\\bold{w}|0, \\Sigma)\n$$\n\n그리고, 이전에 MLE를 구할 때, Likelihood를 다음과 같이 정의했다.\n\n$$\n\\begin{align*}\np(\\bold{y}_*|\\bold{X}; \\theta) &= \\mathcal{N}(\\bold{y}_*-\\Phi\\bold{w}, \\sigma I) \\\\\np(\\bold{y}_*|\\Phi, \\bold{w}) &= \\mathcal{N}(\\bold{y}_*-\\Phi\\bold{w}, \\sigma I)\n\\end{align*}\n$$\n\n따라서, 우리는 이를 이용해서 posterior를 추론할 수 있다.\n\n$$\np(\\bold{w}|\\bold{y}_*, \\Phi) = {{p(\\bold{y}_*| \\Phi, \\bold{w})p(\\bold{w})}\\over{p(\\bold{y}_*|\\Phi)}}\n$$\n\n여기서 MAP를 구할 때에는 Lemma 정리(두 정규분포의 conditional Probability를 구하는 공식)를 이용하면 편하다. 따로 연산은 수행하지 않지만 결과 값은 아래와 같다.\n\n$$\n\\bold{w}_{MAP} = (\\sigma^2\\Sigma^{-1}+\\Phi^{\\top}\\Phi)^{-1}\\Phi^{\\top}\\bold{y}\n$$\n\n여기서 만약 우리가 $\\Sigma = {\\sigma^2\\over{\\lambda}}I$라고 가정하면, 위의 MAP 식은 Ridge Regression과 동일해지는 것을 알 수 있다.\n\n즉, Ridge Regression은 MAP의 한 종류라고 볼 수 있는 것이다.\n\n$$\n\\bold{w}_{ridge} \\in {(\\bold{w}_{MAP}, \\Sigma)}\n$$\n\n## Gradient Descent\n\n여태까지 우리는 Loss를 정의하고, 이 Loss가 최솟값을 갖는 $\\bold{w}$를 찾는 것을 목표로 하였다. 하지만, 우리가 다루는 모든 Loss가 미분이 항상 쉬운 것은 아니다. 뿐만 아니라, Loss의 미분 값이 5차원 이상의 식으로 이루어진다면, 우리는 이를 풀 수 없을 수도 있다. 5차원 이상의 polynomial에서는 선형대수적인 해결법(근의 방정식)이 없다는 것이 증명되어있다.(Abel-Ruffini theorem)\n\n따라서, 우리는 Loss가 0이 되는 지점을 찾기 위해서, w의 값을 점진적으로 업데이트하는 방식을 활용한다. 이때, 우리는 w의 값이 계속해서 Loss를 감소시키기를 원한다. 따라서, 우리는 현재 $\\bold{w}$에서 Gradient를 현재 $\\bold{w}$에 빼준다. 이를 우리는 **Gradient Descent**라고 한다.\n\n$$\n\\bold{w}_{t+1} = \\bold{w}_{t} - \\gamma((\\nabla L)(\\bold{w}_{t}))^{\\top}\n$$\n\n여기서 $\\gamma$는 step size(learning rate)라고 하며, 기울기값을 얼마나 반영할지를 의미한다.\n\n---\n\n이제부터는 Gradient Descent를 더 효과적으로 진행하기 위한 3가지의 기술들을 추가적으로 제시한다.\n\n> **1. optimize stepsize**\n\nstepsize($\\gamma$)가 특정 상수로 제시된 게 아니라 변수로 표현된 이유는 linear regression마다 적절한 $\\gamma$가 다르기 때문이다. 하나의 예시를 들어보자.\n\n![loss-divergence](/images/loss-divergence.jpg)\n\n위는 Loss function이 convex할 때, 최솟값을 찾아나가는 과정이다. 만약, $\\gamma$가 크다면, Loss가 특정값으로 수렴하는 것이 아니라 발산하는 것을 알 수 있다. 이를 막기 위해 $\\gamma$를 굉장히 작은 수로 하는 경우에는 Loss의 최솟값을 찾기도 전에 특정 지점에서 멈춰버릴 수도 있다. 또한, Loss의 graph형태는 data마다 달라지기 때문에 절대적인 $\\gamma$역시 존재하지 않는다.\n\n따라서, 우리는 매 update마다 적절한 $\\gamma$를 찾을려고 노력한다. 여기서는 자세히 다루지 않지만 후에 더 다룰 기회가 있을 것이다. 간단히 프로그래밍적으로(systemical) 생각하면, 업데이트 이후 loss가 만약 그전 Loss보다 커진다면, 이를 취소하고 더 작은 $\\gamma$를 사용하도록 하고, 업데이트 된 후의 Loss와 그전 Loss가 같다면, 진짜 수렴하는지를 확인하기 위해서 $\\gamma$를 키워볼 수도 있다.\n\n> **2. momentum**\n\n우리가 Gradient Descent를 진행하다보면, 다음과 같은 현상을 자주 마주하게 된다.\n\n![momentum-example-1](/images/momentum-example-1.jpg)\n\n우리가 찾고자 하는 Loss를 찾아가는 과정에서 매 업데이트마다 반대방향으로 기울기가 바뀌는 경우이다.(진동한다) 이는 최종으로 찾고자 하는 값을 찾는 과정이 더 오래 걸리게 한다. 따라서, 우리는 이러한 진동을 막기 위해서 Momentum을 사용한다. 즉, 이전 차시에서의 gradient를 저장해두고, 이를 더해서 진동하는 것을 막는 것이다.\n\n$$\n\\bold{w}_{i+1} = \\bold{w}_{i} - \\gamma_{i}((\\nabla L)(\\bold{w}_{i}))^{\\top} + \\alpha \\Delta \\bold{w}_i ,( \\alpha \\in [0, 1] )\n$$\n\n$$\n\\Delta \\bold{w}_i = \\bold{w}_{i} - \\bold{w}_{i-1} = \\alpha \\Delta \\bold{w}_{i-1} - \\gamma_{i-1}((\\nabla L)(\\bold{w}_{i-1}))^{\\top}\n$$\n\n즉, 그림으로 표현하면, 다음과 같다.\n\n![momentum-example-2](/images/momentum-example-2.jpg)\n\n이전 변화량과 현재 변화량을 합하여 이동하기 때문에 위에 새로 추가된 것처럼 진동하지 않고, 진행하는 것을 볼 수 있다.\n\n> **3. Stochastic Gradient Descent**\n\n우리의 Gradient Descent의 가장 큰 문제는 바로 Global Minimum을 찾을 거라는 확신을 줄 수 없다는 것이다. 아래 그림을 보자.\n\n![gradient-descent-example](/images/gradient-descent-example.jpg)\n\n여기서 우리는 초기 w 값을 어떻게 정하냐에 따라서, **local minimum**을 얻게 되거나 **global minimum**을 얻게 된다. 즉, 초기값이 결과에 굉장히 큰 영향을 준다는 것이다.\n\n이를 해결할 수 있으며, 학습 효율도 높일 수 있는 것이 Stochastic Gradient Descent이다. 원리는 Loss를 구하기 위해서 전체 데이터(모집단)를 사용했었는데 그러지말고 일부 데이터를 랜덤하게 추출(sampling)해서(표본 집단) 이들을 통해서 Loss function을 구하기를 반복하자는 것이다.\n\n이 방식을 통해서 구한 Gradient의 평균이 결국은 전체 batch의 평균과 같다는 것은 Central Limit Theorem(중심 극한 정리)에 의해 증명이 된다. 따라서, 우리는 이를 통한 gradient descent도 특정 minimum을 향해 나아가고 있음을 알 수 있다.\n\n그렇지만, 표본 집단을 이용한 평균을 구했을 때에 우리는 noise에 의해서 local minimum으로만 수렴하는 현상을 막을 수 있다. 즉, gradient descent를 반복하다보면, 다른 local minimum으로 튀어나가기도 하며 global minimum을 발견할 확률을 높일 수 있는 것이다.\n\n## Reference\n\n- Tumbnail : Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n- [Probabilistic interpretation of linear regression clearly explained](https://towardsdatascience.com/probabilistic-interpretation-of-linear-regression-clearly-explained-d3b9ba26823b), Lily Chen\n","slug":"ml-linear-regression","date":"2022-10-17 09:46","title":"[ML] 2. Linear Regression","category":"AI","tags":["ML","LinearRegression","BasisFunction","Regularization","GradientDescent","Momentum","StochasticGradientDescent"],"desc":"Regression(회귀)이라는 단어는 \"원래의 상태로 돌아간다\"로 돌아간다는 의미를 가진다. 결국 어떤 일련의 Event로 인해서 데이터에 Noise가 발생할 수 있어도 결국은 하나의 \"보편\"으로 시간이 지나면 수렴(회귀)할 것이라는 생각에 기반하는 것이다.  따라서, 우리는 이러한 \"보편\"을 찾기 위해서 우리가 알고 있는 독립 데이터 X를 통해서 알고자 하는 값 Y를 보편적으로 추론할 수 있다. 이 과정을 우리는 Regression이라고 부른다. 또한, X에 의해 독립적이지 않고 종속적인 Y의 관계가 Linear하게 표현될 때 이를 우리는 Linear Regression이라고 한다.  따라서, 해당 Posting에서는 Linear Regression을 바탕으로 Machine Learning이 어떻게 동작하는지를 이해하는 것이 목표이다.","thumbnailSrc":"https://euidong.github.io/images/ml-thumbnail.jpg"},{"content":"\n## Intro\n\n이전까지 우리는 input data가 들어왔을 때, continuos한 output을 얻는 것을 목표로 했다. 하지만 현실에서는 대게 정확한 수치보다는 특정 분류로 나누는 것이 효과적인 경우가 많다. 예를 들어, spam 필터링, object detection, 등 등. 따라서, 해당 포스팅에서는 classification을 위해서 사용할 수 있는 logistic regression에 대해서 살펴볼 것이다.\n\n## Classification\n\n**Classification**이란 결국 특정 input이 들어왔을 때, 이를 하나의 Class라는 output을 내보내는 것이다. 즉, output은 연속적이지 않고, descret하다. 대게 Classification에서는 Class의 갯수를 K라고 표기하고, $C_k$는 k 번째 Class라는 의미로 사용되어진다.\n\n그렇다면, 어떻게 Class를 나눌 수 있는 것일까? 매우 단순하게도 이는 **Decision Boundary**라는 선을 그어서 해결 할 수 있다.\n\n![decision-boundary](/images/decision-boundary.jpg)\n\n위의 예시처럼 우리는 선을 하나 그어서 $\\red{\\text{x}}$와 $\\blue{\\text{o}}$를 구분할 수 있다. 이를 통해서 우리는 Class 1에 해당할 것이라고 예측하는 구간 $R_1$이 만들어지고, Class 2라고 예측하는 구간 $R_2$를 구성할 수 있다.\n\n즉, classification을 수행하기 위해서 해야할 일은 기존의 Regression 과정과 마찬가지로 선을 찾는 것이다.\n\n결국 찾고자 하는 것이 선이라면, 이것을 Linear Regression으로 해결할 수 있을 것이다. 따라서, 우리는 다음과 같은 식으로 간단히 Linear Regression을 바꿔서 생각할 수 있다.\n\n- 예측값($\\hat{y}$, $h(\\bold{x})$)  \n  $h(\\bold{x}) = \\text{sign}(\\bold{w}^{\\top}\\bold{x}) = \\begin{cases} +1 & \\bold{w}^{\\top}\\bold{x} \\geq 0 \\\\ -1 & \\text{otherwise}\\end{cases}$\n- Least Squared Error(LS, MLE)  \n  실제로 parameter를 구할 때에는 sign을 취하지 않는데, sign을 취하게 되면 모두 LS는 결국 오답의 갯수 정도로 취급된다. 즉, 얼마나 예측이 잘못되었는지를 반영할 수 없다는 것이다. 따라서, 이는 기존 Linear Regression의 LS를 구하는 방법과 동일하게 수행한다.  \n  $\\argmin_{w} {1\\over2}\\sum_{n=1}^{N}{(y_n - (\\bold{w}^{\\top}\\bold{x}))^2}$\n\n이렇게 Linear Regression을 적용하면 문제가 없을 거 같다. 하지만, 실제로는 문제가 있다. 바로, 데이터가 불균형할 때이다. 만약 데이터가 decision boundary를 기준으로 대칭(symmetric)인 형태로 존재한다면, 문제가 없다. 하지만, 비대칭(asymmetric)인 경우 제대로 동작하지 않는다. 왜냐하면, linear regression은 최적에서 데이터의 평균을 반영하는데 불균형한 경우 데이터의 평균이 Decision Boundary가 되는 것은 문제가 있다.\n\n![linear-in-classification](/images/linear-in-classification.jpg)\n\n## Logistic Regression\n\n위에서 제시한 문제를 해결하기 위해서 Classification에서는 Linear Regression이 아닌 Logistic Regression을 활용한다. 이를 이해하기 위해서 기반이 될 요소들을 먼저 살펴보자.\n\n> **Discriminant Function**\n\n판별함수(Discriminant Function, Score Function) 등으로 불리는 해당 함수는 특정 data가 특정 class에 속할 가능성(likelihood, probability, score)을 나타내는 함수이다. 즉, input으로 data를 받고, output으로 class에 속할 확률을 내보낸다.\n\n이를 통해서 우리는 다음과 같은 과정을 할 수 있다.\n\n만약, $f_k(\\bold{x}) \\gt f_j(\\bold{x})$이라면, $\\bold{x}$의 class는 $C_k$이다.\n\n따라서, 우리는 다음과 같은 식으로 여러 개의 Class가 있는 공간에서 data를 분류할 수 있다.\n\n$$\nh(\\bold{x}) = \\argmax_{k}f_{k}(\\bold{x})\n$$\n\n그렇다면, Discriminant Function으로 어떤 값을 쓰면 좋을까? 이에 대한 해결책을 Bayes Decision Rule에서 제시한다.\n\n> **Bayes Decision Rule**\n\n만약 우리가 특정 data가 특정 Class에 속할 확률을 구한다고 하자. 우리는 먼저 Likelihood를 생각할 수 있다. $P(x|C = k), P(x|C = j)$를 구하여 각 Class에 속할 확률을 비교할 수 있을까?  \n물론 비교는 가능하다 하지만, 반쪽짜리 비교라고 할 수 있다. 만약, class k에 속하는 데이터보다 class j에 속하는 데이터가 훨씬 많다고 하자. 그러면, 일반적으로 class j가 발생할 확률 자체가 높다. 하지만, likelihood는 이러한 경향을 반영하지 않는다. 간단한 예시를 들어보자.\n\n```plaintext\n 🤔 어떤 동물의 털에 존재하는 색의 갯수가 주어졌을 때, 고양이일 확률과 호랑이일 확률이라고 하자.\n\n  그리고, input data는 털에 존재하는 색의 수라고 하자. (호랑이는 대게 3가지 색, 백호 = 2가지 색, 고양이는 매우 다양)\n  그렇다면, P(털의 색 = 3|C = 호랑이), P(털의 색 = 3|C = 고양이)를 비교했을 때, 우리는 당연히 전자가 크다고 생각할 것이다.\n  하지만, 여기서 우리가 고려하지 않은 것이 있다. 바로 전체 고양이와 호랑이의 비율이다. \n  상대적으로 고양이가 호랑이보다 압도적으로 많다는 것을 고려했을 때, 고양이의 확률이 더 높을 수도 있다. \n\n  즉, 어떤 동물의 털에 존재하는 색의 갯수가 주어졌을 때, 고양이일 확률은 \n  P(C=고양이|털의 색=3) =  P(털의 색 = 3|C = 고양이)P(C=고양이)이다. (분모는 생략함.)\n```\n\n즉, Bayes Rule에 기반하여 우리가 원하는 output은 Posterior라는 것을 명확히 알 수 있다.\n\n$$\n\\begin{align*}\np(C_{k}|\\bold{x}) &= {{p(\\bold{x}| C_{k}) p(C_{k})}\\over{\\sum_{j=1}^{K}{p(\\bold{x}|C_{j})p(C_{j})}}} \\\\\n&\\propto p(\\bold{x}| C_{k}) p(C_{k})\n\\end{align*}\n$$\n\n위의 경우 Class간의 상대 비교에 사용하는 지표로 이를 사용하기 때문에, 분모(Normalization Factor, 확률의 총합이 1이 되도록 하는 역할)를 제외하여도 상관없기에 대게 복잡한 분모 계산을 제외하고 표현하는 것이 일반적이다.\n\n또한, 앞선 예시에서 얻을 수 있는 insight는 편향된 데이터일수록 MLE를 사용할 수 없다는 것이다. 위에서 Linear Regression이 Classification에 부적함한 경우도 데이터의 편향이 있을 경우이다. 이 역시 Linear Regression이 결국은 MLE에 기반하기 때문인 것이다.\n\n우리는 각 Class 자체의 확률(Prior)과 Likelihood를 이용할 수 있는 Discriminant Function을 구해야 한다는 것이다.\n\n> **Logistic Regression**\n\n자 이제 드디어 Logistric Regression을 시작해보자. 우리는 Discriminant Function을 먼저 지정해야 한다. 여러 가지 방법이 있지만, 가장 대표적으로 사용되는 방법은 **Softmax**를 활용하는 것이다. **Softmax**를 활용하여 식을 나타내면 아래와 같다.\n\n$$\np(y_n = k | \\bold{x}_n, \\bold{w}) = {{\\exp(\\bold{w}_{k}^{\\top}\\bold{x}_n)}\\over{\\sum_{j=1}^{K}{\\exp(\\bold{w}_{j}^{\\top}\\bold{x}_n)}}}\n$$\n\n만약, class가 2개인 Binary Classification인 경우에 **Softmax**는 다음과 같아진다. 특히 이를 **Sigmoid**(**Logit**)라고 정의한다.\n\n$$\np(y_n = k | \\bold{x}_n, \\bold{w}) = {1\\over{1+\\exp(-y_{n}\\bold{w}^{\\top}\\bold{x}_{n})}}\n$$\n\n이를 유도하는 과정은 생략하지만, 여타 다른 블로그를 더 참고하면 좋다.\n\n이를 Linear Regression과 비교해서 살펴보자.\n\n![logistic-vs-linear](/images/logistic-vs-linear.jpg)\n\nLinear Regression은 특정값을 향해 나아가고 있다. 해당 방식을 보면 x가 대상의 특성을 강하게 가지고 있다면, 명확하게 구분할 수 있는데, 이는 **sigmoid**($\\sigma$) 함수가 [0, 1] 범위 내에서 정의되기 때문에 Regression 과정에서 극단 데이터(outlier)가 가지는 영향력이 Linear Regression보다 극단적으로 적다는 것을 알 수 있다.\n\n자 이것이 가지는 의미를 이전에 살펴본 **Bayes Decision Rule**에 기반해서 생각해보자. **sigmoid**($\\sigma$)는 결국 극단적인 데이터이든, 애매한 데이터이든 거의 비슷한 값으로 변환한다. 그렇다는 것은 기존에는 평균을 구하는데에 input(x)의 값이 큰 영향을 미쳤다면, **sigmoid**($\\sigma$)에서는 특정 class에 속하는 x의 갯수가 많은 영향을 주는 것을 알 수 있다. 이를 통해서 **sigmoid**($\\sigma$)가 완벽하지는 않지만, **Bayes Decision Rule**을 반영했다는 것을 알 수 있다.\n\n마지막으로, MLE를 통해서 Logistic Regression의 parameter를 추정해보자. (MAP는 기존에 살펴본 Linear Regression과 동일하게 regularizer를 더해주는 방식이기 때문에 생략한다.)\n\n$$\n\\begin{align*}\n\\argmax_{w}\\log{p(\\mathcal{D}|\\bold{w})} &= \\argmax_{w}\\sum_{n=1}^{N}{\\log p(y_{n}|\\bold{x}_{n}, \\bold{w})} \\\\\n&= \\argmax_{w}\\sum_{n=1}^{N}{\\log ({1\\over{1+\\exp(-y_{n}\\bold{w}^{\\top}\\bold{x}_{n})}}) } \\\\\n&= \\argmax_{w}\\sum_{n=1}^{N}{-\\log (1+\\exp(-y_{n}\\bold{w}^{\\top}\\bold{x}_{n})) } \\\\\n&= \\argmin_{w}\\sum_{n=1}^{N}{\\log (1+\\exp(-y_{n}\\bold{w}^{\\top}\\bold{x}_{n})) } \\\\\n\\end{align*}\n$$\n\n## Gradient Descent/Ascent\n\n위의 복잡한 식을 봤으면 알겠지만, 안타깝게도 일반식으로 $\\bold{w}_{MLE}, \\bold{w}_{MAP}$ 등을 구할 수는 없다. 따라서, 우리가 믿을 것은 Gradient를 이용한 방식이다.\n\n> **Gradient Descent**\n\n먼저, 위에서 봤겠지만, Loss는 다음과 같다.\n\n$$\n\\mathcal{L} = \\sum_{n=1}^{N}{\\log(1+\\exp(-y_{n}\\bold{w}^{\\top}\\bold{x}_{n}))}\n$$\n\n이제 이를 미분해서 Gradient를 구하면 다음과 같다.\n\n$$\n\\nabla_{\\bold{w}}\\mathcal{L}(\\bold{w}) = \\sum_{n=1}^{N}{{{-y_{n}\\exp(-y_{n}\\bold{w}^{\\top}\\bold{x}_{n})}\\over{1+\\exp(-y_{n}\\bold{w}^{\\top}\\bold{x}_{n})}}\\bold{x}_{n}}\n$$\n\n따라서, Gradient Descent 방식은 다음과 같이 진행된다.\n\n$$\n\\bold{w}_{t+1} = \\bold{w}_{t} - \\alpha\\nabla_{\\bold{w}}\\mathcal{L}(\\bold{w}_{t})\n$$\n\n> **Gradient Ascent**\n\n위의 방식이 가장 일반적이지만, 우리가 sigmoid의 class값으로 $y \\in \\{-1, 1\\}$ 대신 $y \\in \\{0, 1\\}$을 사용했을 경우 다른 식으로도 접근이 가능하다.\n\n이 경우에는 Loss라기 보기 어렵지만, 다른 형태의 optimization 형태가 만들어진다. (여기서 $\\sigma$는 sigmoid 함수를 의미한다.)\n\n$$\n\\argmax_{\\bold{w}} \\sum_{n=1}^{N}y_{n}\\log{\\sigma(\\bold{w}^{\\top}\\bold{x}_{n}) + (1-y_{n})\\log{(1-\\sigma(\\bold{w}^{\\top}\\bold{x}_{n}))} }\n$$\n\n이를 똑같이 미분하여 사용하지만, 반대로 이 경우에는 maximization 이기 때문에 Gradient Ascent를 수행해야 한다.\n\n우선 미분 결과 얻는 Gradient는 다음과 같다.\n\n$$\n\\nabla_{\\bold{w}}\\mathcal{L}(\\bold{w}) = \\sum_{n=1}^{N}{[y_{n} - \\sigma(\\bold{w}^{\\top}\\bold{x}_{n})]\\bold{x}_{n}}\n$$\n\n굉장히 간단하게 정리가 되어지는 것을 볼 수 있다.\n\n$$\n\\bold{w}_{t+1} = \\bold{w}_{t} - \\alpha\\nabla_{\\bold{w}}\\mathcal{L}(\\bold{w}_{t})\n$$\n\n따라서, 아래와 같이 Gradient Ascent를 활용하여 계산하는 것도 충분히 가능하다.\n\n> **Newton Method**\n\n이러한 형태로 넘어오게 되면, 굉장히 많은 연산이 각 update마다 필요하다는 것을 알 수 있다. 따라서, 우리는 이 과정을 축약할 방법을 찾게 된다. 그 아이디어는 바로 gradient를 업데이트 할 때, linear 하게 update하는 것이 아니라 Quadratic하게 update하는 것이다. 이를 위한 방법론이 **Newton Method**이다. 이 방식을 Logistic Regression에 적용하였을 때, 이를 IRLS(Iterative Re-weighted Least Squared) Algorithm 이라고 부른다.\n\n![newton-method](/images/newton-method.jpg)\n\n위 그래프에서 f(x)가 Loss 라고 할 때, 우리는 $x_k$에서 직선형의 gradient를 사용하는 것보다 quadratic 형태를 사용하는 것이 더 빠르게 수렴값을 찾을 수 있다는 것을 알 수 있다.\n\n이를 사용하기 위해서는 다음 2가지에 대한 사전 이해가 필요하다.\n\n- Taylor Series  \n  smooth한 형태를 가진 x에 대한 함수를 x에 대한 급수의 형태로 변환한 것이다. 따라서 이를 식으로 나타내면 다음과 같다.  \n  $T_{\\infin}(x) = \\sum_{k=0}^{\\infin}{f^{(k)}(x_{0})\\over{k\\!}}(x-x_{0})^{k} $  \n  즉, sine 함수와 같은 형태의 그래프도 x의 급수 형태로 변환이 가능하다는 것이다. Newton Method에서는 무한대까지는 사용하지 않고, 대게 K=2까지를 쓴다.\n- Hessian Matrix  \n  특정 함수 $f(\\bold{x})$를 각 feature에 대해서 이중 편미분한 결과를 저장한 행렬이다. 식은 다음과 같다.  \n  $\n  H = \\nabla^{2}f(x) =\n  \\left[\n    \\begin{array}{ccc}\n      \\dfrac{\\partial^{2} f(\\mathbf{x})}{\\partial x_{1}^{2}} & \\cdots & \\dfrac{\\partial^{2} f(\\mathbf{x})}{\\partial x_{1} \\partial x_{D}} \\\\\n      \\vdots & \\ddots & \\vdots \\\\\n      \\dfrac{\\partial^{2} f(\\mathbf{x})}{\\partial x_{D} \\partial x_{1}} & \\cdots & \\dfrac{\\partial^{2} f(\\mathbf{x})}{\\partial x_{n}^{2}}\n    \\end{array}\n  \\right]\n  $\n\n이를 이용해서, Newton Method의 결과값을 정리하면 결과는 다음과 같다.\n\n$$\n\\bold{w}^{(k+1)} = \\bold{w}^{(k)} - [\\nabla^{2}\\mathcal{J}(\\bold{w}^{(k)})]^{-1}\\nabla\\mathcal{J}(\\bold{w}^{(k)})\n$$\n\n자 이제 이것을 실제로 Logistic Regression 식에 대입해보자.\n\n$$\n\\begin{align*}\n  \\nabla\\mathcal{J}(w) &= - \\sum_{n=1}^{N}(y_{n}-\\hat{y}_{n})x_{n} \\\\\n  \\nabla^{2}\\mathcal{J}(w) &= \\sum_{n=1}^{N}\\hat{y}_{n}(1-\\hat{y}_{n})\\bold{x}_{n}\\bold{x}_{n}^{\\top}\n\\end{align*}\n$$\n\n여기서, 아래와 같이 변수를 정의하면,\n\n$$\nS =\n  \\begin{bmatrix}\n    \\hat{y}_{1}(1-\\hat{y}_1)  & \\cdots  & 0                         \\\\\n    \\vdots                    & \\ddots  & \\vdots                     \\\\\n    0                         & \\cdots  & \\hat{y}_{N}(1-\\hat{y}_N)  \\\\\n  \\end{bmatrix},\n\n\\bold{b} =\n  \\begin{bmatrix}\n    {{y_{1} - \\hat{y}_{1}}\\over{\\hat{y}_{1}(1-\\hat{y}_{1})}} \\\\\n    \\vdots \\\\\n    {{y_{N} - \\hat{y}_{N}}\\over{\\hat{y}_{N}(1-\\hat{y}_{N})}}\n  \\end{bmatrix}\n$$\n\n결과적으로 다음과 같은 형태를 얻을 수 있다.\n\n$$\n\\begin{align*}\n\\bold{w}_{k+1} &= \\bold{w}_{k} + (XS_{k}X^{\\top})^{-1}XS_{k}\\bold{b}_{k} \\\\\n&= (XS_{k}X^{\\top})^{-1}[(XS_{k}X^{\\top})\\bold{w}_{k} + XS_{k}\\bold{b}_{k}] \\\\\n&= (XS_{k}X^{\\top})^{-1}XS_{k}[X^{\\top}\\bold{w}_{k} + \\bold{b}_{k}]\n\\end{align*}\n$$\n\n이는 결코 계산 과정이 단순하다고는 할 수 없지만, 빠르게 수렴할 수 있기 때문에 가치있는 방법이다.\n\n## Reference\n\n- Tumbnail : Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n","slug":"ml-logistic-regression","date":"2022-10-18 09:58","title":"[ML] 3. Logistic Regression","category":"AI","tags":["ML","LogisticRegression","Classification","SigmoidFunction","SoftmaxFunction","NewtonMethod"],"desc":"이전까지 우리는 input data가 들어왔을 때, continuos한 output을 얻는 것을 목표로 했다. 하지만 현실에서는 대게 정확한 수치보다는 특정 분류로 나누는 것이 효과적인 경우가 많다. 예를 들어, spam 필터링, object detection, 등 등. 따라서, 해당 포스팅에서는 classification을 위해서 사용할 수 있는 logistic regression에 대해서 살펴볼 것이다.","thumbnailSrc":"https://euidong.github.io/images/ml-thumbnail.jpg"},{"content":"\n## Intro\n\n우리는 Classification을 하기 위해서 Logistic Regression을 수행하였다. 그 결과 결국 Classification도 결국은 선을 긋는 것이라는 결론을 내리게 되었다. 하지만, 여기서 그치지 않고 하나 더 고민해 볼 수 있는 것이 있다. 바로 주어진 데이터에 대해서 완벽하게 구분하는 decision boundary가 여러 개 있을 때, 어떤 것이 가장 좋은 것일까? 이것에 대한 아이디어를 제시하는 것이 SVM이다. 해당 Posting에서는 이에 대해서 살펴보도록 하겠다.\n\n## (Hard Margin) SVM\n\nSoft Vector Machine의 약자로, 위에서 제시한 문제를 해결하기 위해서 Margin이라는 것을 도입하였다.\n\n> **Margin**\n\n**Margin**이란 decison boundary와 가장 가까운 각 class의 두 점 사이의 거리를 2로 나눈 값이다.\n\n![svm-1](/images/svm-1.jpg)\n\n위의 그림은 똑같은 데이터 분포에서 대표적인 decision boundary 두 개를 제시한 것이다. 여기서 우리는 굉장히 많은 decision boundary를 그릴 수 있다. 그 중에서도 파란색 실선이 직관적으로 가장 적절한 decision boundary가 될 것이라고 짐작할 수 있다. 그 이유는 필연적으로 data는 noise에 의한 오차가 발생할 수 있는데 실제 데이터의 오차의 허용 범위를 우리는 **margin**(=capability of unexpected noise)만큼 확보할 수 있다는 의미로 이를 해석할 수 있다. 따라서, 이 margin을 크게 하면 할 수록 좋은 성능을 가지는 선을 그을 수 있을 것이라는 결론을 내릴 수 있다.\n\n이것이 SVM의 핵심 아이디어이다.\n\n그렇다면, margin을 수학적으로 정의해보자. 우리가 decision boundary를 $f(\\bold{x}) := \\bold{w}^{\\top}\\bold{x} + b = 0$이라고 한다면, 점($\\bold{x}_{i}$)과 vector 직선 vector 사이의 거리 공식을 통해서 ${{|f(\\bold{x}_{i})|}\\over{||\\bold{w}||^{2}}}$라는 것을 알 수 있다.\n\n따라서 margin은 수학적으로 다음과 같다.\n\n$$\n\\min_{i}{{|f(\\bold{x}_{i})|}\\over{||\\bold{w}||^{2}}}\n$$\n\n```plaintext\n 🤔 Canonical(법칙까지는 아니지만 사실상 표준화된) SVM\n\n SVM에서는 f(x) = 0인 등식 형태를 같는다. 즉 f(x)에 어떤 값을 곱해도 똑같다는 것이다.\n 그런데 margin의 크기를 구할 때에는, w와 b에 어떤 값이 곱해진다면 이 값이 굉장히 달라지게 된다.\n 따라서, 일반적으로 우리는 margin에서의 |f(x)| = 1이 될 수 있도록 설정한다. \n 이렇게 하면 계산이 굉장히 쉬워진다.\n```\n\n![svm-2](/images/svm-2.jpg)\n\n따라서, 우리는 위의 그림과 같은 형태로 $\\bold{x}^{-}$와 $\\bold{x}^{+}$를 찾을 수 있는 것이다.\n\n이제 마지막으로 margin을 정의해보자.\n\n$$\n\\begin{align*}\n\\rho &= {1\\over2}\\{ {{|f(\\bold{x}^{+})|}\\over{||\\bold{w}||^{2}}} - {{|f(\\bold{x}^{-})|}\\over{||\\bold{w}||^{2}}}  \\} \\\\\n&= {1\\over2}{1\\over{||\\bold{w}||^{2}}}\\{\\bold{w}^{\\top}\\bold{x}^{+} - \\bold{w}^{\\top}\\bold{x}^{-}\\} \\\\\n&= {1\\over{||\\bold{w}||^{2}}}\n\\end{align*}\n$$\n\n> **Optimization**\n\n그렇다면, 이제 우리는 문제를 해결할 준비가 된 것이다. 우리가 하고자 하는 것은 margin을 최대화하면서도, 모든 data를 오류없이 분류하는 것이다. 이는 다음과 같은 Constraint Optimization 형태로 변환할 수 있다.\n\n$$\n\\begin{align*}\n  \\text{maximize}   \\quad & {1\\over{||\\bold{w}||^{2}}} &\\\\\n  \\text{subject to} \\quad & y_{i}(\\bold{w}^{\\top}\\bold{x}_{i} + b) \\geq 1, & i = 1, ..., N\n\\end{align*}\n$$\n\nConditional Optimization은 이전 Posting([[ML] 0. Base Knowledge](/posts/ml-base-knowledge))에서 다룬바 있다. 해당 내용에 대해 미숙하다면 한 번 살펴보고 오도록 하자.\n\n위 내용을 숙지하였다면, 위의 폼이 다소 바뀌어야 한다는 것을 알 것이다. 해당 형태를 바꾸면서, minimize 형태를 미분이 간편할 수 있도록 바꾸도록 하겠다.\n\n$$\n\\begin{align*}\n  \\text{minimize}   \\quad & {1\\over2}||\\bold{w}||^{2} &\\\\\n  \\text{subject to} \\quad & 1 - y_{i}(\\bold{w}^{\\top}\\bold{x}_{i} + b) \\leq 0, & i = 1, ..., N\n\\end{align*}\n$$\n\n우선 lagrangian은 다음과 같다.\n\n$$\n\\mathcal{L} = {1\\over2}||\\bold{w}||^{2} + \\sum_{i=1}^{N}\\alpha_{i}(1 - y_{i}(\\bold{w}^{\\top}\\bold{x}_{i} + b))\n$$\n\n이것에 KKT Condition을 적용하여 정리하면 다음과 같은 등식을 얻을 수 있다.\n\n$$\n\\bold{w} = \\sum_{i=1}^{N}\\alpha_{i}y_{i}\\bold{x}_{i}\n$$\n\n$$\n\\sum_{i=1}^{N}\\alpha_{i}y_{i} = 0\n$$\n\n이를 $\\mathcal{L}$에 대입하여 식을 정리하면, 다음과 같다.\n\n$$\n\\mathcal{L} = -{1\\over2}\\sum_{i=1}^{N}\\sum_{j=1}^{N}\\alpha_{i}\\alpha_{j}y_{i}y_{j}\\bold{x}_{i}^{\\top}\\bold{x}_{j} + \\sum_{i=1}^{N}\\alpha_{i}\n$$\n\n이제 이것을 이용해서 Dual Problem을 정의하면 다음과 같다.\n\n$$\n\\begin{align*}\n  \\text{maximize}   \\quad & -{1\\over2}\\sum_{i=1}^{N}\\sum_{j=1}^{N}\\alpha_{i}\\alpha_{j}y_{i}y_{j}\\bold{x}_{i}^{\\top}\\bold{x}_{j} + \\sum_{i=1}^{N}\\alpha_{i} &\\\\\n  \\text{subject to} \\quad & \\sum_{i=1}^{N}\\alpha_{i}y_{i} = 0, & \\\\\n  & \\alpha_{i} \\geq 0, & i = 1, ..., N\n\\end{align*}\n$$\n\n이 식에서 눈여겨 볼점은 바로 constraint 부분이다. 이 과정을 통해서 결론적으로 constraint 부분이 부등식에서 등식이 되었다. 이는 연산 과정을 매우 간단하게 한다. 뿐만 아니라 $\\bold{x}_{i}^{\\top}\\bold{x}_{j}$는 한 번 계산하면, 전체 과정에서 계속해서 재사용할 수 있기 때문에 컴퓨팅 시에는 굉장한 이점을 발휘할 수 있다. 따라서, 실제로 값을 구할 때에는 이것을 이용하여 값을 구하는 것이 가장 일반적이다.\n\n## (Soft Margin) SVM\n\nSVM의 모든 절차를 살펴본 것 같지만, 우리가 간과한 사실이 하나 있다. 바로 그것은 우리는 data가 하나의 선을 통해서 완벽하게 나뉘어진다고 가정했다. 하지만, 실제 데이터는 그렇지 않을 가능성이 크다. 따라서, 우리는 어느 정도의 오차를 허용할 수 있도록 해야 한다. 이를 slack($\\zeta$)이라고 한다.\n\n![svm-2](/images/svm-2.jpg)\n\n이를 적용하면, 우리의 목적함수와 제약 조건을 변경해야 한다. 이를 변경하는 방법은 두 가지가 존재하는데 각 각 slack variable의 L2-norm을 목적함수에 더하는 방식과 L1-norm을 더하는 방식이다.\n\n> **L2-norm Optimization**\n\n먼저 L2-norm을 더하는 방식을 알아보자\n$$\n\\begin{align*}\n  \\text{minimize}   \\quad & {1\\over2}||\\bold{w}||^{2} + C\\sum_{i=1}^{N}\\zeta_{i}^{2} &\\\\\n  \\text{subject to} \\quad & 1 - y_{i}(\\bold{w}^{\\top}\\bold{x}_{i} + b) - \\zeta_{i} \\leq 0, & i = 1, ..., N\n\\end{align*}\n$$\n\n여기서 $C$는 margin 최대화와 slackness 정도의 상대값을 의미한다. 만약, slackness보다 margin의 최대화가 중요하다면, C값은 커지고 반대라면 이 값은 작아진다.\n\n우선 lagrangian을 먼저 구하면 다음과 같다.\n\n$$\n\\mathcal{L} = {1\\over2}||\\bold{w}||^{2} + {C\\over2}\\sum_{i=1}^{N}\\zeta_{i}^{2} + \\sum_{i=1}^{N}\\alpha_{i}(1 - \\zeta_{i} - y_{i}(\\bold{w}^{\\top}\\bold{x}_{i} + b))\n$$\n\nKKT condition을 이용하여 주요 값들을 구하면 다음과 같은 등식을 얻을 수 있다.\n\n$$\n\\bold{w} = \\sum_{i=1}^{N}\\alpha_{i}y_{i}\\bold{x}_{i}\n$$\n\n$$\n\\sum_{i=1}^{N}\\alpha_{i}y_{i} = 0\n$$\n\n$$\n\\boldsymbol{\\zeta} = {\\alpha\\over{C}}\n$$\n\n마지막으로 이를 Dual Problem으로 재정의하면 다음과 같아진다.\n\n$$\n\\begin{align*}\n  \\text{maximize}   \\quad & -{1\\over2}\\sum_{i=1}^{N}\\sum_{j=1}^{N}\\alpha_{i}\\alpha_{j}y_{i}y_{j}(\\bold{x}_{i}^{\\top}\\bold{x}_{j} + {1\\over{C}}\\delta_{ij}) + \\sum_{i=1}^{N}\\alpha_{i} &\\\\\n  \\text{subject to} \\quad & \\sum_{i=1}^{N}\\alpha_{i}y_{i} = 0, & \\\\\n  & \\alpha_{i} \\geq 0, & i = 1, ..., N\n\\end{align*}\n$$\n\n여기서 $\\delta_{ij}$는 단위행렬이다. 기존 hard margin svm과 비교했을 때, ${1\\over{C}}\\delta_{ij}$ 외에는 바뀌지 않는 것을 알 수 있다.\n\n> **L1-norm Optimization**\n\n그 다음은 L1-norm이다.\n$$\n\\begin{align*}\n  \\text{minimize}   \\quad & {1\\over2}||\\bold{w}||^{2} + C\\sum_{i=1}^{N}\\zeta_{i} &\\\\\n  \\text{subject to} \\quad & 1 - y_{i}(\\bold{w}^{\\top}\\bold{x}_{i} + b) - \\zeta_{i} \\leq 0, & \\\\\n  & \\zeta_{i} \\geq 0 & i = 1, ..., N\n\\end{align*}\n$$\n\n여기서는 slack variable이 반드시 0보다 크거나 같다는 것을 주의하자.\n\nlagrangian은 다음과 같다.\n\n$$\n\\mathcal{L} = {1\\over2}||\\bold{w}||^{2} + C\\sum_{i=1}^{N}\\zeta_{i} + \\sum_{i=1}^{N}\\alpha_{i}(1 - \\zeta_{i} - y_{i}(\\bold{w}^{\\top}\\bold{x}_{i} + b)) -  \\sum_{i=1}^{N}\\beta_{i}\\zeta_{i}\n$$\n\nKKT condition을 이용하여 주요 값들을 구하면 다음과 같은 등식을 얻을 수 있다.\n\n$$\n\\bold{w} = \\sum_{i=1}^{N}\\alpha_{i}y_{i}\\bold{x}_{i}\n$$\n\n$$\n\\sum_{i=1}^{N}\\alpha_{i}y_{i} = 0\n$$\n\n$$\n\\sum_{i=1}^{N}\\beta_{i} = C\n$$\n\n마지막으로 이를 Dual Problem으로 재정의하면 다음과 같아진다.\n\n$$\n\\begin{align*}\n  \\text{maximize}   \\quad & -{1\\over2}\\sum_{i=1}^{N}\\sum_{j=1}^{N}\\alpha_{i}\\alpha_{j}y_{i}y_{j}\\bold{x}_{i}^{\\top}\\bold{x}_{j} + \\sum_{i=1}^{N}\\alpha_{i} &\\\\\n  \\text{subject to} \\quad & \\sum_{i=1}^{N}\\alpha_{i}y_{i} = 0, & \\\\\n  & 0 \\leq \\alpha_{i} \\leq C, & i = 1, ..., N\n\\end{align*}\n$$\n\n결국 기존 Hard margin과 비교했을 대는 마지막 constraint에 $\\alpha_{i} \\leq C$가 추가된 것 밖에 없다.\n\n---\n\n마지막으로 여기서 하나의 insight를 더 얻을 수 있다.  \nL1-norm의 optimization으로 돌아가보자.\n\n$$\n\\begin{align*}\n  \\text{minimize}   \\quad & {1\\over2}||\\bold{w}||^{2} + C\\sum_{i=1}^{N}\\zeta_{i} &\\\\\n  \\text{subject to} \\quad & 1 - y_{i}(\\bold{w}^{\\top}\\bold{x}_{i} + b) - \\zeta_{i} \\leq 0, & \\\\\n  & \\zeta_{i} \\geq 0 & i = 1, ..., N\n\\end{align*}\n$$\n\n목적 함수의 slack variable에 constraint의 값을 대입하여, 다음과 같이 변환이 가능하다.\n\n$$\n\\min {C^{\\prime}\\over2}||\\bold{w}||^{2} + \\sum_{i=1}^{N}max\\{ 0, 1 - y_{i}(\\bold{w}^{\\top}\\bold{x}_{i} + b) \\}\n$$\n\n이 형태는 logistric regression에 regularization을 수행한 것과 동일한 형태를 가지게 된다. 즉, 이전 logistic regression에서 regularization을 다루지 않았는데, 결국은 soft margin svm의 L1-norm 목적함수가 logistic regression 중에서도 hinge function이라는 것을 이용했을 때의 regularization이 되는 것이다.\n\n## Generalization\n\n여태까지 살펴본 Regression을 통해서 우리는 General한 Classification 방식을 지정할 수 있다. 우선 아래 식을 살펴보자.\n\n- Linear Regression(Quadratic Loss)  \n  $\\min {C^{\\prime}\\over2}||\\bold{w}||^{2} + \\sum_{i=1}^{N}{1\\over2}(1 - y_{i}(\\bold{w}^{\\top}\\phi(\\bold{x}_{i})) )^{2}$\n- Logit Regresion(Log Loss)  \n  $\\min {C^{\\prime}\\over2}||\\bold{w}||^{2} + \\sum_{i=1}^{N}\\log( 1 + \\exp[-y_{i}(\\bold{w}^{\\top}\\phi(\\bold{x}_{i})]) )$\n- Binary SVM(Hinge Loss)  \n  $\\min {C^{\\prime}\\over2}||\\bold{w}||^{2} + \\sum_{i=1}^{N}max\\{ 0, 1 - y_{i}(\\bold{w}^{\\top}\\phi(\\bold{x}_{i})) \\}$\n\n여태까지 나온 식들을 살펴보면 위와 같다. 우리는 여기서 아래와 같은 일반적인 형태의 Classification을 제시할 수 있다.\n\n- General Classification  \n  $\\min {C^{\\prime}\\over2}||\\bold{w}||^{2} + \\sum_{i=1}^{N}\\varepsilon\\log( 1 + \\exp[-y_{i}(\\bold{w}^{\\top}\\phi(\\bold{x}_{i})]) )$\n\n여기서 $\\varepsilon$이 1이면 바로 logistic regression이 되고, $\\varepsilon$이 0에 수렴할 수록 SVM이 된다. 아래 그림을 보면 이를 알 수 있다.\n\n![compare-regressions](/images/compare-regressions.jpg)\n\n## Reference\n\n- Tumbnail : Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n","slug":"ml-svm","date":"2022-10-18 17:29","title":"[ML] 4. SVM","category":"AI","tags":["ML","SVM","GeneralClassifier"],"desc":"우리는 Classification을 하기 위해서 Logistic Regression을 수행하였다. 그 결과 결국 Classification도 결국은 선을 긋는 것이라는 결론을 내리게 되었다. 하지만, 여기서 그치지 않고 하나 더 고민해 볼 수 있는 것이 있다. 바로 주어진 데이터에 대해서 완벽하게 구분하는 decision boundary가 여러 개 있을 때, 어떤 것이 가장 좋은 것일까? 이것에 대한 아이디어를 제시하는 것이 SVM이다. 해당 Posting에서는 이에 대해서 살펴보도록 하겠다.","thumbnailSrc":"https://euidong.github.io/images/ml-thumbnail.jpg"},{"content":"\n## Intro\n\n이전 Posting에서는 SVM에 대해서 알아보았다. 일반적인 Logistic Regression에서는 softmax function을 통해서 여러 class를 구분할 수 있었지만, SVM의 경우 구분 선이 결국은 hyperplane으로만 표현 가능하다. 이를 해결하기 위한 SVM에서의 여러 해결책을 알아보자.\n\n## Multiclass in SVM\n\n가장 쉽게 생각할 수 있는 것은 SVM을 결합해서 Multiclass를 구분할 수 있다는 idea이다. 아래에서 곧바로 제시할 아이디어들이 이에 대한 내용이다.\n\n> **1. OvR SVM**\n\nOne vs Rest 의 약자로 다양한 별명이 존재한다. (One vs All, OVA, One Against All, OAA)  \n이름에서부터 느껴지다시피 하나의 class와 그 외에 모든 class를 하나로 묶어서 SVM을 총 class 갯수만큼 만들어서 각 decision boundary로 부터 거리가 양의 방향으로 가장 큰 class를 선택하는 방식이다.\n\n$$\n\\argmax_{k \\in [K]}(\\bold{w}_{(k)}^{\\top}\\phi(\\bold{x})+ b_{(k)})\n$$\n\n![svm-ovr](/images/svm-ovr.jpg)\n\n이 방식은 하나의 큰 문제를 갖고 있는데, 그것은 과도한 데이터 불균형을 유발한다는 것이다. 이러한 문제는 class의 수가 많아질 수록 더 심해진다.\n\n> **2. OvO SVM**\n\nOne vs (Another) One의 약자로, 해당 방식은 1대1로 비교하면서 각 SVM에서 선택한 class 중에서 가장 많은 선택을 받은 class를 최종한다. OvR과는 다르게 각 각의 class를 1대1로 비교하기 때문에 데이터의 불균형에 대한 위협은 덜하다. 하지만, 해당 과정을 수행하기 위해서는 총 K(K-1)/2개의 SVM이 필요하다.\n\n![svm-ovo](/images/svm-ovo.jpg)\n\n또한, 그림에서 \"?\"로 표시된 부분을 어떤 class로 선택할지에 대한 기준이 없다. 왜냐하면, 각 영역에서 한 표씩만 받기 때문이다.\n\n> **3. DAG SVM**\n\n앞 서 보았던 OvO와 OvR의 문제를 해결하기 위해서 장단점을 취하기 위해서 둘을 결합한 방식이다. 계층 형태로 SVM을 구성하기 때문에 OvO보다는 적은 SVM을 사용하면서, OvO에서의 과도한 데이터 불균형을 해결한다.\n\n![svm-multiclass-comparing](/images/svm-multiclass-comparing.jpg)\n\n> **4. WW SVM**\n\nmulticlass 구분을 SVM 최적화 과정에 적용하기 위해서 목적 함수의 형태를 변형하여 구현한 방법으로 자세히 다루지 않지만, 궁금하다면 해당 [🔗 link](https://www.csie.ntu.edu.tw/~cjlin/papers/multisvm.pdf)를 통해서 확인할 수 있다.\n\n## Kernel Method\n\n이전까지는 실제로 SVM의 형태를 변형시키거나 SVM을 여러 개 활용하여 multiclass classification을 수행하기 위한 방법을 보았다.\n\n또 다른 방법이 존재한다. 바로 input 공간을 확장하는 것이다. 즉, 더 많은 유의미한 feature를 수집하거나 기존 feature를 가공하여 새로운 feature로 활용하는 것이다. 시스템적으로 해결할 수 있는 방법은 기존 feature를 가공하여 새로운 feature를 활용하는 것이다. 아래의 예시를 보자.\n\n![feature-transposing](/images/feature-transposing.jpg)\n\n왼쪽 공간에서는 SVM은 decision vector를 적절하게 선택하는 것이 어렵다. 하지만, 기존 x 데이터에 절대값을 취하여 나타내어 데이터에 추가하면, 쉽게 decision boundary를 결정하는 것을 볼 수 있다. 그렇다면, 이러한 여러 변환 함수를 적용해보며 여러 feature를 더 추출하는 것이 좋은 해결책을 가져다 줄 것이다.\n\n그렇다면, 우리의 Soft margin SVM의 Dual Problem을 다시 한 번 살펴보자.\n\n$$\n\\begin{align*}\n  \\text{maximize}   \\quad & -{1\\over2}\\sum_{i=1}^{N}\\sum_{j=1}^{N}\\alpha_{i}\\alpha_{j}y_{i}y_{j}\\bold{x}_{i}^{\\top}\\bold{x}_{j} + \\sum_{i=1}^{N}\\alpha_{i} &\\\\\n  \\text{subject to} \\quad & \\sum_{i=1}^{N}\\alpha_{i}y_{i} = 0, & \\\\\n  & 0 \\leq \\alpha_{i} \\leq C, & i = 1, ..., N\n\\end{align*}\n$$\n\n이것을 feature 변환(basis function을 취한다.)을 통해서 다음과 같이 변형한다는 것이다.\n\n$$\n\\begin{align*}\n  \\text{maximize}   \\quad & -{1\\over2}\\sum_{i=1}^{N}\\sum_{j=1}^{N}\\alpha_{i}\\alpha_{j}y_{i}y_{j}\\red{\\boldsymbol{\\phi}^{\\top}(\\bold{x}_{i})\\boldsymbol{\\phi}(\\bold{x}_{j})} + \\sum_{i=1}^{N}\\alpha_{i} &\\\\\n  \\text{subject to} \\quad & \\sum_{i=1}^{N}\\alpha_{i}y_{i} = 0, & \\\\\n  & 0 \\leq \\alpha_{i} \\leq C, & i = 1, ..., N\n\\end{align*}\n$$\n\n하지만, 우리가 새로운 feature를 생성할 수록, 그리고 기존 feature를 복잡하게 사용할 수록 $\\boldsymbol{\\phi}(\\bold{x}_{i})$를 연산하는 비용이 커질 수 밖에 없다.  \n\n따라서, 우리는 일종의 trick을 하나 사용하도록 한다. 바로, 매 bayese update 마다 변하지 않고 재사용되는 값인 $\\boldsymbol{\\phi}^{\\top}(\\bold{x}_{i})\\boldsymbol{\\phi}(\\bold{x}_{j})$를 다른 값으로 대체하면 어떨까? 그렇게 하면 우리는 $\\boldsymbol{\\phi}(\\bold{x}_{i})$를 계산하고 구성하는 수고를 덜 수 있다.\n\n이것이 kernel method(trick)의 핵심 아이디어이다.\n\n가장 대표적인 예시로 아래와 같은 복잡한 $\\phi$ 가 주어졌을 때,\n\n$$\n\\boldsymbol{\\phi}(x) = \\exp[{{-x^{2}}\\over{2\\sigma^{2}}}](1, \\sqrt{1\\over{1!\\sigma^{2}}}x, \\sqrt{1\\over{2!\\sigma^{4}}}x^{2}, \\sqrt{1\\over{3!\\sigma^{6}}}x^{3}, \\cdots)\n$$\n\n아래의 (RBF) kernel로 대체가 가능해진다.\n\n$$\n\\kappa(x,x^{\\prime}) = \\exp(-{{(x - x^{\\prime})}\\over{2\\sigma^{2}}}) = \\boldsymbol{\\phi}^{\\top}(x)\\boldsymbol{\\phi}(x^{\\prime})\n$$\n\n대게 우리가 표현하고자 하는 형태의 $\\boldsymbol{\\phi}$는 이미 특정 kernel 함수로 매핑되고 있으니 직접 $\\boldsymbol{\\phi}$를 계산하기 전에 찾아보는 것이 도움이 될 것이다.[🔗 link](https://dataaspirant.com/svm-kernels/#t-1608054630726)\n\n## Reference\n\n- Tumbnail : Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n- A Comparison of Methods for Multi-class Support Vector Machines, Chih-Wei Hsu and Chih-Jen Lin, <https://www.csie.ntu.edu.tw/~cjlin/papers/multisvm.pdf>\n- SEVEN MOST POPULAR SVM KERNELS, <https://dataaspirant.com/svm-kernels/#t-1608054630726>\n","slug":"ml-multiclass-classification-in-svm","date":"2022-10-18 23:19","title":"[ML] 5. Multiclass Classification in SVM","category":"AI","tags":["ML","SVM","KernelMethod"],"desc":"이전 Posting에서는 SVM에 대해서 알아보았다. 일반적인 Logistic Regression에서는 softmax function을 통해서 여러 class를 구분할 수 있었지만, SVM의 경우 구분 선이 결국은 hyperplane으로만 표현 가능하다. 이를 해결하기 위한 SVM에서의 여러 해결책을 알아보자.","thumbnailSrc":"https://euidong.github.io/images/ml-thumbnail.jpg"},{"content":"\n## Intro\n\n우리는 Linear Regression, Logistic Regression, SVM을 거치며 data로 부터 유의미한 pattern을 발견하는 과정을 알아보았다. 이 과정은 우리에게 명확한 식 하나를 제시하였고, 모든 과정을 우리가 제어할 수 있게 하였다. 하지만, 실제 데이터를 우리가 모두 명확하게 이해할 수 있는 형태로 분류할 수 있는 것인지는 의문이 들 수 있다. 그렇다면, 우리가 이해하지는 못하지만, 알아서 최적의 결과를 가져오게 할 수 있는 방법이 있을까? 이런 마법같은 일에 대한 아이디어를 제시하는 것이 Neural Network이다.\n  게 알지 못하지만 input이 들어왔을 때, 이를 처리해서 output을 전달하는 시스템을 우리의 신체에서 찾게 된다. 바로 우리 몸을 이루는 신경망이다. 예시로 우리는 눈을 통해 빛이라는 input을 받으면, 우리 눈과 뇌에서 무슨 일이 발생하는지는 모르지만 결과적으로 우리는 물체를 볼 수 있다. 이 과정을 추측의 과정에 도입하면 어떻게 될까?\n\n## Perceptron\n\nPerception(인지 능력) + Neuron(신경 세포)의 합성어이다. 중고등학교 생명 수업을 들었다면, 우리의 모든 신경은 뉴런이라는 단위 세포로 이루어진다는 것을 배웠을 것이다. 즉, 우리의 신경 세포를 컴퓨터 공학에서 활용하기 위해서, 수학적으로 변환한 것이다. 형태를 먼저 살펴보자.\n\n$$\ny = sign(\\bold{w}^{\\top}\\bold{x} + b)\n$$\n\n![nn-perceptron-1](/images/nn-perceptron-1.jpg)\n\n대단한 것을 기대했다면 실망하겠지만, simple한 것이 최고라는 연구의 진리에 따라서 위의 식은 꽤나 합리적이다. 우리가 Linear Regression과 Logistic Regression을 배웠으니 알 것이다. 이는 사실 Linear Regression을 이용해서 우리가 Classification을 수행할 때 사용했던 식이다. 즉, perceptron 하나는 input을 선형으로 구분할 수 있도록 하는 decision boundary를 찾는 것과 같다.\n\n> **Optimization**\n\n그렇다면, 해당 perceptron을 통해서 모든 데이터를 구분하기 위해서는 다음을 만족하는 $\\bold{w}$를 찾아야 한다.\n\n$$\ny_{n} =\n\\begin{cases}\n1  &\\text{ if  } \\bold{x}_{n} \\in \\mathcal{C}_{1} \\\\\n-1 &\\text{ if  } \\bold{x}_{n} \\in \\mathcal{C}_{2} \\\\\n\\end{cases}\n$$\n$$\ny_{n}\\bold{w}^{\\top}\\bold{x}_{n} \\gt 0, \\forall n\n$$\n\n결국 Loss 함수는 perceptron의 잘못된 classification 결과를 최소화하는 것이다.\n\n$$\n\\mathcal{J}(\\bold{w}) = - \\sum_{n \\in \\mathcal{M}(\\bold{w})}{y_{n}\\bold{w}^{\\top}\\bold{x}_{n}} \\quad( \\mathcal{M}(\\bold{w}) = \\{ n : y_{n}\\bold{w}^{\\top}\\bold{x}_{n} \\} )\n$$\n$$\n\\nabla_{\\bold{w}}\\mathcal{J}(\\bold{w}) = - \\sum_{n \\in \\mathcal{M}(\\bold{w})}{y_{n}\\bold{x}_{n}}\n$$\n\n따라서, 우리가 사용할 수 있는 Gradient Descent식은 다음과 같다.\n\n$$\n\\bold{w}_{t+1} = \\bold{w}_{t} + \\alpha\\sum_{n \\in \\mathcal{M}(\\bold{w})}{y_{n}\\bold{x}_{n}}\n$$\n\n간단한 예시로 AND, OR Gate를 percentron을 통해 표현해보자.\n\n![nn-and-gate](/images/nn-and-gate.jpg)\n![nn-or-gate](/images/nn-or-gate.jpg)\n\n하지만, 우리가 다루는 데이터는 항상 완벽하게 선으로 나뉘어지지는 않는다. 하나의 perceptron으로는 아래의 XOR조차도 구분해낼 수 없다.\n\n![nn-multi-line-example](/images/nn-multi-line-example.jpg)\n\n## Multilayer Perceptron\n\n위의 문제를 해결하기 위해서 나온 것이 perceptron을 다층으로 쌓아서 해결하는 방법이다. 이제는 하나의 신경세포였던 perceptron을 진짜 신경망처럼 연결해보자는 것이다.\n\n먼저 추상적인 예시를 생각해보자. 우리가 XOR Gate를 만들기 위해서는 어떤 Gate를 결합해야할까?\n\n$$\na \\oplus b = ab + \\bar{a}\\bar{b}\n$$\n\n우리는 AND Gate 2개 연산을 수행하고, 해당 결과값을 이용해서 OR Gate 연산을 수행하면 XOR Gate를 표현할 수 있다는 것을 알고 있다. 그렇다면, 각 Gate는 우리가 perceptron으로 나타낼 수 있었는데 그냥 이것을 gate로 표현하듯이 똑같이 나타내면 풀 수 있지 않을까?\n\n그래서 직접 수행해보면 다음과 같은 값을 구할 수 있다.\n\n![nn-xor-gate](/images/nn-xor-gate.jpg)\n\n```plaintext\n 🤔 Insight\n\n 위의 과정을 보다보면 놀라운 것을 하나 발견할 수 있다. 바로 왼 쪽 그림의 변화이다. \n 첫번째, 두 개의 perceptron을 통해서 만들어진 output이 이루는 결과값의 형태로 feature를 변환하면, \n 하나의 perceptron으로 decision boundary를 그릴 수 있다는 것이다. \n 이는 마치 이전 linear regression에서 배웠던 basis function(ϕ)이 했던 역할이다.\n\n 그렇다면, 이를 더욱 확장해보자. \n 만약 해당 Layer가 더 깊어진다고 해도, 출력 직전의 layer는 단순히 이전 모든 layer는 입력 데이터를 가공해서\nfeature를 변환하는 하나의 basis function(ϕ)를 취한 것으로 이해할 수 있다.\n```\n\n결론적으로 우리는 더 복잡하고, 어려운 문제의 경우에도 더 깊게 신경망을 구성하면 결국은 문제를 풀 수 있다는 것이다.\n\n> **Universal Approximation Theorem**\n\n위와 같은 깊은 신경망 구조를 이용하자는 주장도 있지만, 이와 유사하게 넓은 신경망을 쓰자는 주장도 존재했다.  \n\n![nn-universal-approx-theorem-1](/images/nn-universal-approx-theorem-1.jpg)\n\n만약, 우리가 하나의 Layer와 output에서 최종 output perceptron만 갖고 처리를 한다면, 결국 여러 perceptron의 weighted 합으로 볼 수 있다. 그 경우 우리는 계단 함수의 weighted 합으로 생각할 수 있는데 perceptron이 많아질 수록 촘촘해지며 정답과 유사한 추론이 가능해진다.(마치 적분의 개념과 유사하다. 물론 이는 추상적인 설명이기 때문에 실제로는 계단함수의 합이기 때문에 좀 다르다.)\n\n![nn-universal-approx-theorem-2](/images/nn-universal-approx-theorem-2.jpg)\n\n위의 그림을 보면 이해할 수 있다. 하지만, 이 방식은 결국 모든 함수 형태를 기억하는 것이다.(**memorizer**) 이것은 input data가 많아질 수록 복잡도가 급격하게 증가하기 때문에 학습과 예측과정에 굉장히 많은 시간을 소모한다.\n\n> **Multilayer Optimization(Backpropagation)**\n\n그렇다면, 넓은 신경망이 한계가 있으니 선택지는 input과 output 사이의 layer(**hidden layer**)의 갯수를 늘려서 깊은 신경망을 만드는 것이다. 하지만, 우리가 사용하고 있는 perceptron은 sign함수로 감싸져있기 때문에 미분 시에 기울기가 0이라는 문제를 갖는다. 또한, 그렇다고 정답의 갯수를 이용하기에는 각 perceptron의 영향을 전달하기에 부족하다는 것이 명확하다. 따라서, 우리는 perceptron에 있는 정답을 판별하는 함수 sign을 다른 함수로 대체하기로 한다.\n\n![nn-perceptron-2](/images/nn-perceptron-2.jpg)\n\n여기서 이 함수를 우리는 **activation function**이라고 부르고 대표적으로는 같은 종류가 있다.\n\n- **sigmoid**  \n  우리가 가장 쉽게 생각할 수 있는 함수이다. logistic regression에서 사용해본만큼 기울기값을 효과적으로 가질 수 있다.\n- **tanh**  \n  sigmod와 굉장히 유사한 함수이다. 따라서, 비슷한 용도로 사용될 수 있다.\n- **ReLU**  \n  출력 시점에서는 사용하지 않지만, 각 각의 hidden layer에서 이를 사용하는 경우가 많다. 왜냐하면, sigmoid 함수는 출력값의 형태가 [0, 1], tanh는 [-1, 1]이기 때문에 반복해서 적용하면, gradient가 사라지는 현상이 발생할 수 있다. 따라서, 기울기를 있는 그대로 적용할 수 있는 이러한 형태를 출력 이전에는 많이 사용한다.\n- **Leaky ReLU**  \n  ReLU가 음수값을 완전히 무시하는데 Leaky ReLU는 이러한 데이터가 조금이라도 의미 있는 경우에 사용할 수 있다.\n- **ELU**  \n  Leaky ReLU와 비슷한 이유이다.\n\n  ![activation-functions](/images/activation-functions.png)\n  \n자료가 보이지 않는다면 [🔗 wikipedia](https://en.wikipedia.org/wiki/Activation_function)를 참고하자.\n\n---\n\n자 이제 실제로 어떻게 optimization을 수행할지를 알아보도록 하자.\n\n먼저, Loss는 가장 마지막 layer(output layer)의 output과 실제 값과의 차이가 될 것이다. 따라서, 다음과 같이 정의할 수 있다.\n\n(아래서 $\\bold{h}_{L}$은 L번째 layer의 output을 의미한다.)\n\n$$\n\\begin{align*}\n\\mathcal{L} &= \\sum_{n=1}^{N}{\\ell(y_n, \\bold{h}_L)} \\\\\n&= \\sum_{n=1}^{N}{(y_{n} - \\bold{h}_{L})^2} \\\\\n&= \\sum_{n=1}^{N}{(y_{n} - \\sigma(\\bold{w}_{L}^{\\top}\\bold{h}_{L-1} + b_{L-1}))^2} \\\\\n&= \\sum_{n=1}^{N}{(y_{n} - \\sigma(\\bold{w}_{L}^{\\top}\\sigma(\\bold{w}_{L-1}^{\\top}\\bold{h}_{L-2} + b_{L-2}) + b_{L-1}))^2} \\\\\n&= ...\n\\end{align*}\n$$\n\n여기서 중요한 것은 우리는 전체 $\\bold{W}$를 학습시켜야 한다는 것이다. 우리는 출력층만 학습하는 게 아니라 전체 모든 layer의 $\\bold{w}_{i}$를 업데이트해야 한다는 것이다.\n\n그러기 위해서는 우리는 ${{\\partial\\mathcal{L}}\\over{\\partial \\bold{w}_{i}}}$를 모두 구해야 한다는 것이다. 아마 가장 습관적으로 하는 행위는 숫자가 작은 값부터 편미분하면서 진행하는 것이다. 하지만, 그렇게 하지말고 반대 순서로 미분을 하라는 것이 **backpropagation**의 main idea이다.\n\n$$\n{{\\partial\\mathcal{L}}\\over{\\partial \\bold{w}_{L}}} = \\sum_{n=1}^{N}\\{({\\partial \\bold{h}_L \\over \\partial \\bold{w}_{L}} )\\times\\red{-2(y_{n} - \\sigma(\\bold{w}_{L}^{\\top}\\bold{h}_{L-1} + b_{L-1}))}\\}\n$$\n\n$$\n{{\\partial\\mathcal{L}}\\over{\\partial \\bold{w}_{L-1}}} = \\sum_{n=1}^{N}\\{({\\partial \\bold{h}_{L} \\over \\partial \\bold{w}_{L-1} })\\times\\red{-2(y_{n} - \\sigma(\\bold{w}_{L}^{\\top}\\bold{h}_{L-1} + b_{L-1}))}\\}\n$$\n\n즉, 다음과 같은 chain rule을 이용하는 것이다.\n\n$$\n\\begin{align*}\n{{\\partial\\mathcal{L}}\\over{\\partial \\bold{w}_{L}}} &= \\red{ {{\\partial\\mathcal{L}}\\over{\\partial \\bold{h}_{L}}} } {{\\partial\\bold{h}_{L}}\\over{\\partial \\bold{w}_{L}}} \\\\\n{{\\partial\\mathcal{L}}\\over{\\partial \\bold{w}_{L-1}}} &= \\red{ {{\\partial\\mathcal{L}}\\over{\\partial \\bold{h}_{L}}} } {{\\partial\\bold{h}_{L}}\\over{\\partial \\bold{w}_{L-1}}} \\\\\n&= \\red{ {{\\partial\\mathcal{L}}\\over{\\partial \\bold{h}_{L}}} } {{\\partial\\bold{h}_{L}}\\over{\\partial \\bold{h}_{L-1}}} {{\\partial\\bold{h}_{L-1}}\\over{\\partial \\bold{w}_{L-1}}} \\\\\n&= \\blue{ {{\\partial\\mathcal{L}}\\over{\\partial \\bold{h}_{L-1}}} } {{\\partial\\bold{h}_{L-1}}\\over{\\partial \\bold{w}_{L-1}}} \\\\\n{{\\partial\\mathcal{L}}\\over{\\partial \\bold{w}_{L-2}}} &= \\blue{ {{\\partial\\mathcal{L}}\\over{\\partial \\bold{h}_{L-1}}} } {{\\partial\\bold{h}_{L}}\\over{\\partial \\bold{w}_{L-2}}} \\\\\n\\end{align*}\n$$\n\n우리는 빨간색과 파란색 부분의 연산을 재활용할 수 있다는 것이다. 또한, ${{\\partial\\bold{h}_{l}}\\over{\\partial \\bold{w}_{l}}}$은 굉장히 쉬운 연산이기에 우리가 신경 써서 계산해야 할 값은 매단계를 연결해줄 $ {{\\partial\\bold{h}_{l}}\\over{\\partial \\bold{h}_{l-1}}}$이다.\n\n![ml-backpropagation](/images/ml-backpropagation.jpg)\n\n## Loss Function\n\n우선 KL-Divergence, Entropy, Cross Entropy에 대한 약간의 이해가 필요하니 이전 Posting([🔗 Base Knowledge](posts/ml-base-knowledge))을 살펴보고 오자.\n\n위에서는 자연스럽게 Loss를 계산할 때, Squared Error를 사용하였다. 하지만 경우에 따라서는 다양한 함수를 사용할 수 있다. multiclass classification에서는 **Cross Entropy Loss**를 사용한다.\n\n우선 Cross Entropy Loss는 대게 L2 Loss(Squared Error)와 같이 비교되어진다. 우선 우리가 이전 [🔗 Parametric Estimation](posts/ml-parametric-estimation)에서 MLE를 다룰 때, KL-Divergence를 통해서 MLE가 최적 parameter를 찾을 것이라는 걸 증명한 적이 있다. 그렇다면, 우리가 [🔗 Logistic Regression](/posts/ml-logistic-regression)에서 Squared Error를 통해서 Loss를 구했던 공식을 확인해보자.(Gradient Asecent Part)\n\n여기서 우리는 다음과 공식을 봤었다.\n\n$$\n\\argmax_{\\bold{w}} \\sum_{n=1}^{N}y_{n}\\log{\\sigma(\\bold{w}^{\\top}\\bold{x}_{n}) + (1-y_{n})\\log{(1-\\sigma(\\bold{w}^{\\top}\\bold{x}_{n}))} }\n$$\n\n이 공식을 Cross Entropy를 통해서 설명할 수 있다.\n\n$$\n\\begin{align*}\nH_{q}(p) &= - \\sum_{x \\in \\Omega}q(x)\\log_{2}p(x) \\\\\n&= \\sum_{n=1}^{N}{[-y_{n}\\log\\hat{y}_{n} - (1- y_{n})\\log(1-\\hat{y}_{n})]}\n\\end{align*}\n$$\n\n즉, 여기서 우리가 얻을 수 있는 insight는 Cross Entropy는 sigmoid를 취한 binary classification에서 Squared Error와 같고, 이러한 Cross Entropy를 Squared Error가 할 수 없는 Multiclass에는 적용할 수 있을 것이라는 점이다. 왜냐하면, multiclass classification에 사용되는 Softmax Function을 이용해서 Sigmoid function을 유도하기 때문이다. 잠시 까먹었을까봐 Softmax 함수를 다시 적는다.\n\n$$\n\\hat{y}_{k} = {{\\exp(\\bold{w}_{k}^{\\top}\\bold{x})}\\over{\\sum_{i=1}^{K}{\\exp(\\bold{w}_{i}^{\\top}\\bold{x})}}}\n$$\n\n따라서, Cross Entropy Loss를 대입하여 다음과 같은 Loss를 얻을 수 있다.\n\n$$\n\\mathcal{L} = \\sum_{n=1}^{N}\\sum_{k=1}^{K}[-y_{k,n}\\log\\hat{y}_{k,n}],\\quad y_{k,n} = p(x_{n} \\in C_{k}| x_{n})\n$$\n\n여기서 $y_{k,n}$은 one-hot encoding된 데이터로, 정답인 class만 1이고 나머지는 모두 0으로 되어 있다. 따라서, multiclass classification에서는 위와 같은 Loss를 주로 사용한다.\n\n이 두가지 뿐만 아니라 여러가지 Loss Function이 이미 존재한다. 예전에 잠깐 설명했던 L1 Loss부터 시작해서 NLLLoss, KLDivLoss 등등 존재하며, data의 특성과 output의 형태에 따라서 우리는 스스로 Loss Function을 새로 정의할 수도 있다.\n\n## Reference\n\n- Tumbnail : Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n- activation function, wikipedia, <https://en.wikipedia.org/wiki/Activation_function>\n","slug":"ml-nn","date":"2022-10-20 09:00","title":"[ML] 6. Neural Network","category":"AI","tags":["ML","NeuralNetwork","Perceptron","Backpropagation","CrossEntropyLoss"],"desc":"우리는 Linear Regression, Logistic Regression, SVM을 거치며 data로 부터 유의미한 pattern을 발견하는 과정을 알아보았다. 이 과정은 우리에게 명확한 식 하나를 제시하였고, 모든 과정을 우리가 제어할 수 있게 하였다. 하지만, 실제 데이터를 우리가 모두 명확하게 이해할 수 있는 형태로 분류할 수 있는 것인지는 의문이 들 수 있다. 그렇다면, 우리가 이해하지는 못하지만, 알아서 최적의 결과를 가져오게 할 수 있는 방법이 있을까? 이런 마법같은 일에 대한 아이디어를 제시하는 것이 Neural Network이다.  게 알지 못하지만 input이 들어왔을 때, 이를 처리해서 output을 전달하는 시스템을 우리의 신체에서 찾게 된다. 바로 우리 몸을 이루는 신경망이다. 예시로 우리는 눈을 통해 빛이라는 input을 받으면, 우리 눈과 뇌에서 무슨 일이 발생하는지는 모르지만 결과적으로 우리는 물체를 볼 수 있다. 이 과정을 추측의 과정에 도입하면 어떻게 될까?","thumbnailSrc":"https://euidong.github.io/images/ml-thumbnail.jpg"},{"content":"\n## Intro\n\n여태까지 ML을 수행할 수 있는 여러 가지 방법론을 살펴보았다. 그렇다면, 어떤 Model을 선택하고, 학습과 추정을 해야할지 결정해야 한다. 따라서, 여기서는 어떤 것이 좋은 Model이고, 각 Model 간에 어떻게 비교를 수행할 것인지 그리고 더 나아가 Model을 혼합하는 방법에 대해서 알아볼 것이다.\n\n## What is Good Model?\n\n우리가 사람 image를 입력받아서 긴 머리를 가진 사람인지 여부를 판단하는 classifier를 만든다고 하자. 이때 어떤 Model이 좋은 Model이 될 수 있을까?\n\n가장 쉽게 생각할 수 있는 Model은 Fully Connected Neural Network(FCNN)를 구성하는 것이다. 이를 위해서 Image의 각 pixel을 일렬로 줄 세워 입력할 수 밖에 없다. 하지만, 이는 pixel들 간의 인접 관계를 사용할 수 없게 한다는 단점 때문에 높은 성능을 내기가 어려웠다. 따라서, 이를 극복하기 위헤서 제시된 방법이 Convolutional Neural Network(CNN)를 사용하는 것이다. 이는 FCNN을 적용하기 이전에 Image에 Filter를 적용하여 특정 구간을 대표하는 값을 뽑아내서 더 효율적인 학습을 하는 것을 목표로 한다.(물론 더 자세히 다루면 Pooling Layer 등 더 자세한 설명이 필요하지만, 여기서는 자세히 다루지 않는다. 해당 글을 참고하도록 하자. [🔗 CNN(Convolutional Neural Networks) 쉽게 이해하기](https://halfundecided.medium.com/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-cnn-convolutional-neural-networks-%EC%89%BD%EA%B2%8C-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-836869f88375))\n\n우리의 뇌에서도 Image를 인식하고 처리하기 위해서, color와 motion 그리고 윤곽 등을 따로 따로 처리한다고 한다. 즉, CNN은 이러한 Domain Knowledge를 활용한 훌륭한 예시 중 하나라고 할 수 있다. 즉, 여기서 말하고자 하는 바는 결국 모든 환경에서 최고의 성능을 보여줄 수 있는 Model은 없다는 것이며, Good Model은 우리가 하고자 하는 일에 따라서 Domain Knowledge를 충실하게 활용하여 최고의 성능을 낼 수 있는 Model이라고 할 수 있다.\n\n```plaintext\n 🤔 Data Augmentation\n \n Domain Knowledge를 활용하여 Model의 성능을 높일 수 있는 방법은 \n 단순히 Model 자체를 바꾸는 것 뿐만 아니라 Domain Knowledge를 바탕으로 \n Data를 추가적으로 더 만들어내는 방법이 있다. 이러한 방법을 \n Data Augmentation이라고 한다.\n\n Image data 같은 경우에는 원본 Image를 약간 회전시키거나 확대하거나 \n Noise를 주는 등의 작업을 하여 전체 데이터의 크기를 늘릴 수 있다.\n\nText 같은 경우에는 동의어를 활용하여 문장 데이터의 크기를 효과적으로\n늘리는 것도 가능하다.\n```\n\n![ml-data-augmentation](/images/ml-data-augmentation.png)\n\n## Comparison between Models\n\n여기서 만약 우리가 얻을 수 있는 Model의 종류가 다양하다면 이들을 어떻게 비교하여 하나의 Model을 선택할 수 있을까? 이 역시 중요한 문제이다.\n\n사실 우리가 학습했던 data를 그대로 평가할 때 사용하는 것은 굉장히 불공평하다고 할 수 있다. 우리가 만들고자 하는 Model은 일반적으로 어느 상황에 두어도 그리고 안본 data일지라도 올바르게 분류하기를 원한다. 즉, 우리의 Model이 **Generalization**을 수행할 수 있기를 바란다.\n\n이러한 Model의 **Generalization** 성능을 측정하기 위해서 자주 사용되는 것이 Dataset을 Train과 Test set으로 나누는 것이다. 하지만, 이것도 부족할 때가 있다. 특정 Model이 특정 Train set에서만 성능이 높을 수도 있기 때문이다. 따라서, 우리는 **Cross Validation**이라는 방식을 도입한다. 이는 우리가 가진 dataset을 골고루 test와 train set으로 활용하는 방법이다. 즉, 여러 번의 training을 수행하며, test를 수행하기를 반복하는 것이다. 그리고, 이를 평균을 내서 전체적인 Model 성능을 평가하는 방법이다.\n\n![ml-k-fold-cross-validation](/images/ml-k-fold-cross-validation.png)\n\n위와 같이 공평하게 k개로 나누는 방식을 k fold cross validation이라고 하며, 해당 예시는 $k=4$인 경우이다. 즉, 위와 같이 Validation을 하기 위해서는 Model의 수가 $N$개라고 할 때, 총 $N \\times k$번의 Training과 Evaluation이 필요하다.\n\n하지만, 여기서 또 간과한 사실은 hyperparameter가 각 model마다 큰 영향을 미친다는 사실이다. 즉, Hyper Parameter를 정하는 과정 역시 필요한데, 이는 각 각의 Model 내부에서 어떤 Hyper Parameter를 사용할지에 대한 합의가 필요한 것이다. 이를 확인하기 위해서 어쩔 수 없이 우리는 Training과 Evaluation을 수행해야 하며, 이를 위한 data를 별도로 분리해야 한다. 따라서, 우리가 가지는 dataset을 다음과 같이 세개로 나누어야 한다는 것이다.\n\n![ml-dataset](/images/ml-dataset.png)\n\n여기서 더 정당하게 하고 싶다면, 아래와 같은 과정을 반복해야 한다.\n\n![ml-nested-cross-validation](/images/ml-nested-cross-validation.png)\n\n하지만, 이는 굉장히 비용이 커질 수 있다. validation set을 고를 때, $k^{\\prime}$개가 필요하다고 한다면, 우리는 $N \\times k^{\\prime} \\times k$번의 Training과 Evaluation이 필요한 것이다. 굉장히 비용이 커지기 때문에 대게 validation set까지 cross validation하는 nested cross validation은 상황에 따라 사용되기도 하고, 사용되지 않기도 한다.\n\n## Combining Simple Models\n\n좋은 Model을 만들 수 있는 방법 중에서 가장 쉽게 생각할 수 있는 것 중에 하나가 여러 개의 Model을 활용하는 방법이다. 쉽게 집단 지성을 활용한다고 볼 수 있다. 이러한 방식을 **Ensemble**(앙상블)이라고 부르고, 이를 활용할 수 있는 방법은 여러 가지가 있다.\n\n1. 서로 다른 여러 개의 Model, 또는 Hyperparameter만을 변경하거나 또는 feature를 다르게 변형하여 Model을 여러 개 생성하고 평균 또는 최댓값을 취하는 방법 (**Voting**)\n2. 여러 개의 Model을 혼합하지만, 각 단계에 따라서 Model을 선택하는 방법 (**Stacking**)\n3. dataset을 여러 번 sampling하여 각 각의 Model을 만들고, 각 Model의 결과를 평균 또는 최댓값을 취하는 방법 (**Bagging**, **Pasting**)\n4. 이전과는 달리 앞 서 진행한 Model의 결과를 반영하여 다음 Model에 적용하기를 반복하며, 여러 Model을 제작하고 취합하는 방법 (**Boosting**)\n\n크게는 이렇게 3가지로 나눌 수 있다. 여기서 각각을 자세히 다루지는 않고, **Boosting** 방식 중에서도 많이 사용되는 방법 중에 하나인 **AdaBoost**에 대해서 좀 더 자세히 다뤄보도록 하겠다.\n\n### AdaBoost\n\nAdaptive Boosting의 약자인 AdaBoost는 이름에서 볼 수 있듯이 반복적인 작업을 통해서 최종 Model의 성능을 높이는 것을 목표로 한다. 우선 Boosting 방법 자체가 동시에 Model을 학습시키는 것이 아니고, 순차적으로 학습시키면서 성능을 높이는 방법이다. 그렇다면, 우리가 이전 Model들의 학습 과정에서 다음 Model에게 넘겨줄 수 있는 특별한 정보는 무엇일까? 이는 바로 자신들이 잘못 분류한 데이터에 대한 정보이다. 자신들이 잘못 분류한 data들에게 더 높은 가중치를 부여하도록 하여 다음 Model에서는 이를 중심적으로 분류할 수 있도록 하는 방식으로 최종 Model의 성능을 높여보자는 것이 Idea이다.\n\n그렇다면, 이것이 어떻게 가능할까? 매우 간단한 이진 분류기를 기반으로 이를 설명하도록 하겠다. 우리가 만약 특정 임계값($\\theta_{t}$)보다 작으면 -1, 그렇지 않으면 1이라고 분류하는 아주 간단한 분류기(weak classifier, decision stump)를 가지고 있다고 하자.\n\n$$\nf_{t}(x) = \\begin{cases} -1 & \\text{if } x < \\theta_{t} \\\\ 1 & \\text{otherwise} \\end{cases}\n$$\n\n이제 우리는 이 간단한 분류기 T개를 합쳐서 복잡한 분류 문제를 해결할 분류기를 제작할 것이다. 이 때, 각 분류기는 다음과 같은 가중치($\\alpha_{t}$)를 가지게 된다.\n\n$$\n\\begin{align*}\n\\text{output} = \\text{sign}(F_{T}(x)) \\\\\nF_{T}(x) = \\sum_{t=1}^{T} \\alpha_{t} f_{t}(x)\n\\end{align*}\n$$\n\n그렇다면, 우리는 위 식에서 어떻게 하면, 현명하게 $\\theta_{t}, \\alpha_{t}$를 결정할 수 있을까? 이에 대한 해답으로 **AdaBoost**는 이전 $F_{t-1}$에 의해 발생한 **error**에 집중한다.\n\n우선 $F_{t}$의 Error($E(F_{t})$)를 아래와 같다고 하자.\n\n$$\nE(F_{t}) = \\sum_{i=1}^{N} \\exp(-y^{(i)}F_{t}(x^{(i)}))\n$$\n\n즉, 예측이 맞다면 error는 $1 \\over e$, 틀리다면 $e$만큼 error가 증가한다.  \n여기서 우리는 현재 학습할 Model 이전까지의 Model의 하나의 데이터에 대한 Error를 $\\gamma_{t}^{(i)}$라고 정의해보자.\n\n$$\n\\gamma_{t}^{(i)} = \\exp(-y^{(i)}F_{t-1}(x^{(i)})),\\quad \\gamma_{1}^{(i)} = 1\n$$\n\n다시 한 번 $\\gamma_{t}^{(i)}$의 의미를 정의하면, 간단하게 이전까지의 Model의 합으로 만든 Model이 잘 분류했다면, $e$ 그렇지 않다면, $1 \\over e$가 된다.\n\n그렇다면, 계속해서 Error 식을 정리해보자.\n\n$$\n\\begin{align*}\nE(F_{t}) &= \\sum_{i=1}^{N}\\{\\exp(-y^{(i)}F_{t-1}(x^{(i)})) \\times \\exp(-y^{(i)}\\alpha_{t}f_{t}(x^{(i)}))\\} \\\\\n&= \\sum_{i=1}^{N} \\gamma_{t}^{(i)} \\exp(-y^{(i)}\\alpha_{t}f_{t}(x^{(i)})) \\\\\n&= \\sum_{i:y^{(i)}=f_{t}(x^{(i)})}\\gamma_{t}^{(i)}\\exp(-\\alpha_{t}) + \\sum_{i:y^{(i)}\\neq f_{t}(x^{(i)})}\\gamma_{t}^{(i)}\\exp(\\alpha_{t}) \\\\\n&= \\sum_{i=1}^{N}\\gamma_{t}^{(i)}\\exp(-\\alpha_{t}) + \\sum_{i:y^{(i)}\\neq f_{t}(x^{(i)})}\\gamma_{t}^{(i)}(\\exp(\\alpha_{t})-\\exp(-\\alpha_{t})) \\\\\n&= \\exp(-\\alpha_{t})\\sum_{i=1}^{N}\\gamma_{t}^{(i)} + (\\exp(\\alpha_{t})-\\exp(-\\alpha_{t}))\\sum_{i:y^{(i)}\\neq f_{t}(x^{(i)})}\\gamma_{t}^{(i)}\n\\end{align*}\n$$\n\n여기서 Error를 가장 작게 할 수 있는 $\\theta_{t}, \\alpha_{t}$를 찾기 위한 방법은 각 각 다음과 같다.\n\n1. 식에서 $\\theta_{t}$가 바꿀 수 있는 것은 $f_{t}$밖에 없다. 즉 $\\sum_{i:y^{(i)}\\neq f_{t}(x^{(i)})}\\gamma_{t}^{(i)}$를 조정하는 것이다.  \n   즉, $\\gamma_{t}^{(i)}$는 이전 분류기($F_{t-1}$)가 잘 분류했다면 $e$, 그렇지 않다면 $1 \\over e$가 되는데, 이들의 합이 최소가 되도록 하는 임계값 $\\theta_{t}$를 찾는 것이다.  \n   즉, 기존 분류기가 잘못 분류한 data에 대해서 더 중점적으로 분류할 수 있도록 가중치를 부여하여 다시 분류한다는 것이다.\n2. Error를 $\\alpha_{t}$에 대한 미분을 하여, 0이 되도록 하는 $\\alpha_{t}$를 찾으면 된다. 이 과정은 다음과 같다.\n\n$$\n\\alpha_{t} = \\frac{1}{2}\\ln\\frac{1-\\varepsilon_{t}}{\\varepsilon_{t}},\\quad \\varepsilon_{t} = \\frac{\\sum_{i:y^{(i)}\\neq f_{t}(x^{(i)})}\\gamma_{t}^{(i)}}{\\sum_{i}^{N}\\gamma_{t}^{(i)}}\n$$\n\n여기서 $\\varepsilon_{t}$를 자세히 보면, 분모는 decision stump의 최대 Error이고 분자는 현재 decision stump의 Error를 의미한다. 이것이 직접적으로 $\\alpha_{t}$에 영향을 미치는 것이다.\n\n따라서 이르 조금 더 정리하자면 다음과 같다.\n\n1. $\\varepsilon_{t} \\gt \\frac{1}{2} \\rArr \\alpha_{t} \\lt 0$  \n   $\\varepsilon_{t} \\gt \\frac{1}{2}$라는 것은 사실 $f_{t}$의 성능이 선택지 두 개지 하나를 Random하게 고르는 경우의 확률 $\\frac{1}{2}$보다 못하다는 것이다. 이 경우에 $\\alpha_{t}$를 음수로 설정하여 적용하는 것이 반대로 확률을 적용하는 것이고, 이것이 전체 성능을 높일 수 있기에 타당하다.\n2. $\\varepsilon_{t} = \\frac{1}{2} \\rArr \\alpha_{t} = 0$  \n   만약, 성능이 딱 $\\frac{1}{2}$라면, 더 이상 개선의 여지가 없어진다. 즉, $\\alpha_{t}$를 0으로 설정하여 적용하게 되면, $F_{t}=F_{t-1}$이 된다. 즉, 더 이상의 Model 중첩은 무의미하다는 것을 의미하므로 해당 단계에 도달하면 학습을 중단한다.\n3. $0 \\lt \\varepsilon_{t} \\lt \\frac{1}{2} \\rArr \\alpha_{t} \\gt 0$  \n   일반적인 경우로, 새롭게 만든 분류기가 기존 분류기($F_{t-1}$)를 보완할 만큼 잘 예측을 하고 있기에 $\\alpha_{t}$를 양수로 설정하여 적용한다.\n4. $\\varepsilon_{t} \\rarr 0 \\rArr \\alpha \\rarr \\infin$  \n   $\\varepsilon_{t}$가 0에 가까워지면, 즉, $f_{t}$가 모든 data를 정확하게 분류한다면, 사실상 기존 분류기들은 더 이상 의미가 없다. 하나의 $decision stump$로 완벽하게 분류되는 문제였기 때문이다. 즉, $F_{t} = f_{t}$가 된다.\n\n### Decision Tree\n\n앞 선 **AdaBoost**에서는 Decision Stump를 다루었지만, 더 다양한 분류기를 이용해서 Decision Tree를 구성하는 것도 가능하다. 실제 Stacking 또는 Bagging 등의 작업을 할 때에는 단순한 Decision Stump의 합 같은 형태가 아니라 Tree형태로 구성되는 경우가 많다(Decision을 할 때마다 가지치기를 하며 나뉘는 형태). 그리고 실제로도 이 형태가 인간의 사고 과정도 매우 유사하다. 따라서, 대게의 경우 성능도 좋은 뿐만 아니라 직관적이기 때문에 이러한 방식을 사용해서 여러 Model을 혼합하는 경우도 있다. 이 안에서 Decision을 수행할 때 복잡한 Deep Learning을 수행할 수도 있고, 단순하게 Decision Stump를 사용할 수도 있는 것이다.\n\n![ml-decision-tree](/images/ml-decision-tree.png)\n\n그렇다면, 이러한 Decision Tree를 어떻게 학습하는 게 좋을지를 조금만 살펴보도록 하겠다. 가정을 하나 해보자. 우리가 분류하고자 하는 Category가 10개이고, feature가 100개이다. 이때, 어떤 Feature를 이용한 어떤 Model을 사용한 것을 우선으로 적용해야할까? 이것이 사실 가장 중요한 문제이다. 이를 해결하기 위해서 여러 알고리즘(ID3, CART, 등)이 제시되었다. 하지만, 결국 핵심은 각 각의 단계에서 데이터를 가장 적절하게 나누는 것이 중요한 것이다. 따라서, Model(f)에 대해서 <mark>**얻을 수 있는 정보의 양**(**IG**, Information Gain)</mark>이 많을 수록 좋은 Model이라고 칭하는 것이다. 이를 식으로 표현하면 다음과 같다.\n\n$$\nIG(\\mathcal{D}, f) = I(\\mathcal{D}) - \\sum_{j=1}^{J} \\frac{D_{j}}{D}I(\\mathcal{D}_{j})\n$$\n\n여기서, 또 그렇다면, I는 무엇인지 궁금할 수 있다. 이는 Impurity(정보의 혼탁도)를 의미하며, 이를 표현하는 지표는 아래와 같은 것들이 있다.\n\n1. Gini Impurity\n2. Entropy\n3. Classification Error\n\n위 중에서 우리가 [🔗 ML Base Knowledge(Information Theory)](/posts/ml-base-knowledge#Information-Theory)에서 다루었던 **Entropy**에 기반한 방법이 가장 즐겨서 사용되어진다.\n\n즉, Entropy에 기반한 설명을 하자면, 우리는 IG(정보 획득량)를 최대화하기 위한 선택을 하게 되면, 해당 결정의 Child들은 적은 Entropy를 가지게 되고 이 과정을 반복해 나가면서 최적화를 수행하는 것이다.\n\n즉, Decision Tree를 생성할 때에는 여러 가지 feature와 Model을 적용하며 각 Model이 가지는 IG를 기반으로 하여 Tree의 Root에서부터 Model을 선택하며 내려오는 것이다.\n\n## Cutting down a Compex Model\n\n또한, 좋은 Model을 만들기 위해서 아이러니하게도 일부 정보를 삭제하는 것이 도움이 될 때가 있다. 대게 Deep Learning 환경에서 많이 발생하는 경우인데, **over fitting**으로 인한 문제를 해결하기 위해서 일부 edge를 제거하는 **dropout**을 수행한다. 이러한 방법은 **over fitting**을 방지할 뿐만 아니라 학습의 속도 역시 개선할 수 있기 때문에 자주 사용되어진다. 실제로 model의 성능이 증가할 수 있는지에 대해 다룬 논문이 별도로 있으니 참고할 수 있다면 해보도록 하자. 만약 시간이 된다면 이에 대해서도 다룰 수 있도록 하겠다.\n\n- Frankle, Jonathan, and Michael Carbin. \"The lottery ticket hypothesis: Finding sparse, trainable neural networks.\" ICRL 2019\n\n## Reference\n\n- Tumbnail : Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n- [🔗 CNN(Convolutional Neural Networks) 쉽게 이해하기](https://halfundecided.medium.com/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-cnn-convolutional-neural-networks-%EC%89%BD%EA%B2%8C-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-836869f88375)\n","slug":"ml-model-selection","date":"2022-11-08 16:07","title":"[ML] 7. Model Selection","category":"AI","tags":["ML","ModelSelection","CrossValidation","Boosting","AdaBoost","DecisionTree","NetworkPruning"],"desc":"여태까지 ML을 수행할 수 있는 여러 가지 방법론을 살펴보았다. 그렇다면, 어떤 Model을 선택하고, 학습과 추정을 해야할지 결정해야 한다. 따라서, 여기서는 어떤 것이 좋은 Model이고, 각 Model 간에 어떻게 비교를 수행할 것인지 그리고 더 나아가 Model을 혼합하는 방법에 대해서 알아볼 것이다.","thumbnailSrc":"https://euidong.github.io/images/ml-thumbnail.jpg"},{"content":"\n## Intro\n\nMachine Learning은 주어진 data를 가장 잘 설명할 수 있는 pattern(Model)을 찾는 것이 목표라고 하였다. 그렇다면, \"data가 가지는 여러가지 정보(feature)들 중에서 어떤 feature를 중점적으로 보고 이용할 수 있을까?\" 그리고, \"만약 여러 feature들이 서로 연관이 있다면 이를 연산의 최적화를 위해 이용할 수 있지 않을까?\" 라는 접근이 가능하다. 여기서 Graphical Model은 이러한 관계를 시각적으로 표현할 수 있으며, 이를 통해서 연산 최적화에 대한 insight를 얻을 수 있다.\n\n## Relation\n\n각 feature들 즉, Random Variable들 간의 관계는 크게 세 가지 종류가 있다.\n\n1. **Correlation(상관관계)**  \n   쉽게 생각하면 두 Random Variable이 있을 때, 서로가 값 추정에 영향을 준다는 것이다. 즉, 특정 Random Variable의 값이 관측되었을 때, Random Variable이 가지는 값의 범위가 제한되고, 확률이 변화한다.  \n   즉, $X$와$Y$가 서로 Correlation이 존재한다면, $P(X) \\neq P(X|Y)$  \n   그렇기에 두 Random Variable이 서로 독립(independence)이라면, Correlation이 존재하지 않는 것이다.  \n2. **Causality(인과관계)**  \n   쉽게 Correlation과 헷갈릴 수 있지만, Causality는 원인과 결과가 나타나는 관계를 의미한다. 쉬운 예시로 X라는 사건과 Y라는 사건이 빈번하게 같이 발생한다고, 쉽게 X라는 사건이 Y의 원인이라고 말할 수는 없는 것과 같은 원리이다. 또한, 중요한 특징 중에 하나는 방향이 분명하다는 것이다. 원인과 결과는 대게 분리되기 때문에 원인이 되는 사건과 결과가 되는 사건이 분명이 구분된다. 결론적으로, Causality를 가지는 두 사건은 서로 Correlation이 있는 것은 자명하지만, Correlation이 존재한다고 Causality를 단정할 수 있는 것은 아니다. 즉, Correlation이 Causality를 포함하는 개념이다. 그렇기에 서로 독립이라면, Causality도 존재하지 않는 것이다.\n3. **Independence(독립)**  \n   위에 제시된 두 가지는 dependence 관계를 나타낸다. 이는 두 Random Variable의 값이 서로의 값에 영향을 전혀 주지 않음을 의미한다.  \n   즉, $X$와 $Y$가 서로 독립하다면, $P(X) = P(X|Y), P(Y) = P(Y|X)$이다.  \n   (결과적으로 Independence가 아니라면 최소한의 Correlation이 존재한다.)\n\n이러한 관계를 어떻게 활용할 수 있을지를 고민해보자. 우리가 집중적으로 살펴볼 것은 **Independence**이다. 만약, 우리가 구하고자 하는 결과값($Y$)가 존재할 때, 특정 feature($X_{1}$)가 서로 독립한다고 하자. $P(Y|X_{1})=P(Y)$에 의해서 $X_{1}$는 전혀 쓸모가 없는 정보임을 알 수가 있다. 이렇게 명확한 independence를 안다면 해당 feature를 Learning 및 Estimation에서 제거하는 것은 쉬울 것이다. 하지만, 우리는 이러한 관계를 명확하게 밝히기 어려울 때가 많다. 그렇다면 결국 우리가 Machine Learning을 통해서 구하고자 하는 식인 아래 식을 어떻게 하면 좀 더 최적화할 수 있을까?\n\n$$\nP(Y|X_{1}, X_{2}, \\cdots, X_{N}) = \\frac{P(Y, X_{1}, X_{2}, \\cdots, X_{N})}{P(X_{1}, X_{2}, \\cdots, X_{N})}\n$$\n\n여기서의 핵심은 바로 **Joint Probability**에 있다. 우리는 결국 좋든 싫든 **Joint Probability**를 구해야 한다.\n\n$$\n\\begin{align*}\nP(X_{1}, X_{2}, \\cdots, X_{N}) &= P(X_{1} | X_{2}, X_{3}, \\cdots, X_{N}) \\times P(X_{2}, X_{3}, \\cdots, X_{N})\\\\\n&= P(X_{1} | X_{2}, X_{3}, \\cdots, X_{N}) \\times P(X_{2} |, X_{3}, X_{4}, \\cdots, X_{N}) \\times P(X_{3}, X_{4}, \\cdots, X_{N}) \\\\\n&= \\prod_{i=1}^{N} P(X_{i} | X_{i+1}, X_{i+2}, \\cdots, X_{N})\n\\end{align*}\n$$\n\n위에 제시한 **Probability Chain Rule**에 의해서 우리는 Joint Probability는 각각의 Random Variable 의 Conditional Probability라고 할 수 있다. 그렇다면, 우리는 Random Variable이 N개 있고, 각 Random Variable의 dimension이 L이라고 할 때, 다음과 같아짐을 알 수 있다.\n\n$$\nL^{N} \\times L^{N-1} \\times \\cdots \\times L^{1} = O(L^{N})\n$$\n\n이러한 연산을 어떻게 하면 좀 더 최적화할 수 있을까? Hint는 Conditional Probability 각 각의 변수의 양을 줄이는 것이다. 우리가 어떤 관계가 있을 때, 이 Random Variable의 갯수를 줄일 수 있을까? 바로 변수 간 Conditional Independence가 이에 대한 해답을 제시한다.\n\n### Conditional Independence\n\nConditional Independence는 Conditional Probability처럼 특정 정보(다른 Random Variable의 값)가 주어졌을 때, 두 Random Variable이 서로 독립이라는 것이다.\n\n쉽게 예를 들어 설명한다면, \"과음\"과 \"빨간 얼굴\" 사이의 관계라고 할 수 있다. 일반적으로 우리는 \"빨간 얼굴\"인 사람이 \"과음\"을 했을 것이라고 판단할 것이다. 즉, \"빨간 얼굴\"과 \"과음\" 사이에는 관계가 존재한다(dependency). 하지만, \"혈중 알코올 농도\"라는 정보가 주어진다면 어떨까? \"혈중 알코올 농도\"가 주어진다면, 사실 \"빨간 얼굴\"은 더 이상 \"과음\" 여부를 판단하는 기준에 영향을 1도 주지 않을 것이다. 이때에는 \"과음\"과 \"빨간 얼굴\"은 independence하다. 우리는 이런 경우를 다음과 같이 표현할 수 있다.\n\n$$\n\\text{과음} \\not\\!\\perp\\!\\!\\!\\perp \\text{빨간 얼굴}\n$$\n$$\n\\text{과음} \\perp\\!\\!\\!\\!\\perp \\text{빨간 얼굴} |\\ \\text{혈중 알코올 농도}\n$$\n\n즉, 확률에 적용하면 다음과 같다.\n\n$$\nP(\\text{과음} | \\text{빨간 얼굴, 혈중 알코올 농도}) = P(\\text{과음} | \\text{혈중 알코올 농도})\n$$\n\n여기서 우리가 하고 싶었던 것이 나왔다. 바로 \"빨간 얼굴\"이라는 Random Variable이 없어졌다. 즉, \"과음\"과 \"빨간 얼굴\" 사이의 관계 같은 것을 찾을 수 있다면, 우리는 계산 과정을 단순화할 수 있다.\n\n즉, 이것이 우리가 **Graph**를 통해서 찾고자 하는 것이다.\n\n## Graphical Model\n\n**Graphical Model**은 **Graph**를 이용해서 Random Variable들의 관계를 표현하고, 이를 통해서 **Joint Probability**를 계산하는 방법이다. **Graph**를 그리는 방법은 기본적으로 Random Variable 하나 하나가 Graph의 Node가 되고, 각 Node간의 관계가 Edge가 된다. 그런데, 이 관계가 Correlation이냐, Causality냐에 따라서 두 가지 종류로 나뉘게 된다. <mark>**Correlation**은 일반적으로 관계의 방향이 없기에 **Undirected Graph**</mark>로 표현하고, <mark>**Causality**는 관계의 방향이 있기에 **Directed Graph**</mark>로 표현한다. 이는 아래에서 더 자세히 다루도록 하겠다.\n\n### Markov Random Field(Undirected Graphical Model, Correlation)\n\n**Markov Random Field**(MRF)라고 불리며, **Correlation**를 표현한 Graph이다. 각 Node는 Random Variable을 의미하며, Edge는 Correlation를 의미한다. 즉, 두 Node가 Edge로 연결되어 있다면, 두 Random Variable은 Independence하지 않다는 것이다.\n\n![ml-undirected-graph-1](/images/ml-undirected-graph-1.jpg)\n\n여기서 중요한 것은 Random Variable을 대표하는 Node와 Correlation을 대표하는 Edge이기 때문에, Graph $G=(V, E)$에서 Random Variable의 집합 $X = \\{X_{1}, X_{2}, \\cdots, X_{|V|}\\}$이고, $\\{1,2, \\cdots, |V|\\}$가 주어질 때 반드시 아래에 제시된 **Markov Property들**을 만족해야 한다.\n\n1. <mark>**Pairwise Markov Property**</mark>  \n   인접하지 않은 Node 두 개는 다른 모든 Node가 주어질 때 conditionally independent하다.  \n   (아래에서 \\는 포함하지 않는다는 의미이다.)\n   $$\n   X_{i} \\perp\\!\\!\\!\\!\\perp X_{j} | X_{S\\backslash\\{i, j\\}}\n   $$\n2. <mark>**Local Markov Property**</mark>  \n   한 Node에 인접한 모든 Node(Neighbors)가 주어질 때, 해당 Node는 다른 모든 Node와 conditionally independent하다.  \n   (아래에서 $\\mathcal{N}_{i}$는 Node i와 인접한 모든 Node를 의미한다.)\n   $$\n   X_{i} \\perp\\!\\!\\!\\!\\perp X_{S\\backslash \\mathcal{N}_{i}} | X_{\\mathcal{N}_{i}}\n   $$\n3. <mark>**Global Markov Property**</mark>  \n   만약, Node들의 Subset으로 이루어진 $A, B$가 특정 subset $C$가 주어질 때, 서로 conditionally independent하다면, $A, B$에 속하는 어떤 subset이라도 서로 independent하다.  \n   (subset간의 conditionally independent를 확인하기 위해서는 특정 Subset들간에 이어지는 모든 경로를 차단할 수 있는 subset이 있는지를 확인한다.)  \n   $$\n   \\begin{align*}\n   X_{A} &\\perp\\!\\!\\!\\!\\perp X_{B} | X_{C} \\\\\n   X_{\\text{subset of }A} &\\perp\\!\\!\\!\\!\\perp X_{\\text{subset of }B} | X_{C} \\\\\n   \\end{align*}\n   $$  \n   ![ml-global-markov-property](/images/ml-global-markov-property.jpg)\n\n따라서, 우리는 이전 그림에서 Conditional Independence를 활용할 수 있다. $X_{1}, X_{4}$의 경우 다른 모든 Random Variable과 correlation이 존재하지만, $X_{2}, X_{3}$의 경우 $X_{1}, X_{4}$만 알면 된다. 즉, $X_{2} \\perp\\!\\!\\!\\!\\perp X_{3} | X_{1}, X_{4}$이다. 따라서, 우리는 이 관계를 확률 식에서 녹여낼 수 있다.\n\n$$\n\\begin{align*}\nP(X_{1}, X_{2}, X_{3}, X_{4}) &= P(X_{2}|X_{1},\\cancel{X_{3}},X_{4})P(X_{1}, X_{3}, X_{4}) (\\because X_{2} \\perp\\!\\!\\!\\!\\perp X_{3} | X_{1}, X_{4}) \\\\\n&= P(X_{2}|X_{1},X_{4})P(X_{1}, X_{3}, X_{4})\n\\end{align*}\n$$\n\n또한, 우리는 Graph를 통해서 Joint Probability를 다음과 같이 정의할 수 있다.\n\n$$\nP(\\cap_{i=1}^{N}X_{i}) = \\frac{1}{Z} \\prod_{C \\in \\mathcal{C}} \\psi_{C}(\\cap_{X_{j}\\in C}X_{j})\n$$\n\n식이 다소 난해하다. 하나 하나 해석을 해보도록 하자. 먼저, $P(\\cap_{i=1}^{N}X_{i})$이다. 이는 Joint Probability를 표현하는 방법 중의 하나로 단순히 이를 정리하면, $P(\\cap_{i=1}^{N}X_{i})=P(X_{1} \\cap X_{2} \\cap \\cdots \\cap X_{N})=P(X_{1}, X_{2}, \\cdots, X_{N})$이다. 다음은 $C$와 $\\mathcal{C}$이다. 둘 다 아마 집합일 것이라는 것은 $\\in$ 기호 덕분에 알 수 있을 것이다. 그렇다면, 어떤 데이터를 담고 있는 집합일까? 이는 Random Variable들로 이루어진 부분 집합이다. 이를 <mark>**Clique($C$)**</mark>라고 한다. Clique는 Graph에서 Node들의 부분 집합으로, Graph에서 **Fully Connected Node**의 집합을 의미한다. 이것이 가지는 의미는 사실상 하나의 Node로 합칠 수 있다는 것이다.(이를 Graph 상에서의 인수분해(**factorization**)라고도 한다.) Clique에 속하는 Node끼리는 서로 완벽하게 연결되어 있기 때문에 이 중에 하나의 Node라도 다른 Node와 연결을 가진다면, 이에 속하는 모든 Node가 이 관계로 연결된다는 것이다. 추가적으로 Clique들 중에서 다른 Clique에 속하지 않는 Clique들을 <mark>**Maximal Clique($\\mathcal{C}$)**</mark>라고 한다. 아래 그림에서는 Maximal Clique를 빨간색으로 표기한 것이다.\n\n![ml-max-clique](/images/ml-max-clique.jpg)\n\n마지막으로 $\\psi$이다. 이는 <mark>**Clique Potential Function**</mark>로, 각 Clique의 Node(Random Variable)를 parameter로 사용하는 함수로 확률과 비슷한 성질을 가지지만 확률처럼 합이 1이 아닐 수도 있고, 값 자체가 음수일 수도 있다. 즉, 이를 구할 때에는 각 Random Variable의 경우의 수와 해당 경우의 상대적 확률로 이루어진 table을 작성하고, 이를 표현할 수 있는 함수를 찾아낸 것이 $\\psi$이다. 대게의 경우 $\\psi$는 해당 Parameter로 이루어진 Condition Probability 또는 Joint Probability가 되는 경우가 많다. 하지만, 그렇지 않은 경우에도 $\\psi$로 표현이 가능하다.(이에 대한 엄밀한 증명은 여기서 다루지 않을 뿐만 아니라 중요하지 않다.) 여기서 <mark>$Z$</mark>의 의미를 마지막으로 짚어보자면, 단순한 normalization이다. $\\psi$가 운좋게도 Joint Probability, Conditional Probability로 쉽게 구해진다면 $Z=1$이다. 하지만, 그렇지 않을 경우에는 이들의 합이 1이 아니기 때문에 Normalization이 필요한 것이다.\n\n$$\n\\begin{align*}\nZ &= \\sum_{X_{1}}\\sum_{X_{2}} \\cdots \\sum_{X_{N}}{\\prod_{C \\in \\mathcal{C}} \\psi_{C}(\\cap_{X_{j}\\in C}X_{j})} \\\\\n&= \\sum_{X_{1}, X_{2}, \\cdots, X_{N}}{\\prod_{C \\in \\mathcal{C}} \\psi_{C}(\\cap_{X_{j}\\in C}X_{j})}\n\\end{align*}\n$$\n\n결론적으로 의미를 따지자면, 위에서 구한 **Maximal Clique**에 특정 함수를 취한 $\\psi$가 인수분해(**factorization**)에서 하나의 인자(**factor**)가 되는 것이다. 따라서, 이를 **factor function**이라고도 부른다.\n\n자, 마지막으로 우리가 4개의 Random Variable 4개($A, B, C, D$)가 있을 때, Graph로 그릴 수 있는 형태를 네 개 정도 가정하여 예시들을 살펴볼 것이다.\n\n![ml-undirected-graph-2](/images/ml-undirected-graph-2.jpg)\n\n1. $A, B, C, D$가 선형으로 이루어진다.  \n   여기서는 **Maximal Clique**가 3개이다($\\{\\{A, B\\}, \\{ B, C\\}, \\{ C, D\\}\\}$). 따라서, 이를 통해서 Joint Probability를 추정하면 다음과 같다.  \n   $$\n   P(A, B, C, D) = \\frac{1}{Z} \\times \\psi_{1}(A, B) \\times \\psi_{2}(B, C) \\times \\psi_{3}(C, D)\n   $$  \n   여기서 직접적으로 한 번 $P(A, B, C, D)$를 추정해보자.  \n   $$\n   \\begin{align*}\n   P(A, B, C, D) &= P(A| B, C, D) \\times P(B | C, D) \\times P(C, D) \\\\\n   &= P(A|B) \\times P(B|C) \\times P(C, D)\n   \\end{align*}\n   $$  \n   즉, 이렇게 일렬로 된 Graph에서는 마지막 $\\psi$를 제외하고는 모두 Conditional Probability이고, 마지막 $\\psi$는 Joint Probability이다. 그리고, $Z$는 1이라는 것을 알 수 있다.\n2. $A, B, C, D$가 모두 완벽하게 연결되어 있다.  \n   이 경우에는  **Maximal Clique**가 1개이다($\\{\\{A, B, C, D\\}\\}$). 따라서, Joint Probability를 다음과 같이 추정할 수 있다.  \n   $$\n   P(A, B, C, D) = \\frac{1}{Z} \\times \\psi(A, B, C, D)\n   $$  \n   결론적으로 Clique가 하나기 때문에 줄일 수 있는 변수가 없다. 즉, $\\psi$가 Joint Probability이고, $Z$는 1이다.\n3. **Maximal Clique**가 2개이다($\\{\\{A, B, D\\}\\, \\{A, C, D\\}\\}$). 따라서, 다음과 같이 정리된다.  \n   $$\n   \\begin{align*}\n   P(A, B, C, D) &= P(B|A, C, D) \\times P(A, C, D) \\\\\n   &= P(B|A,D) \\times P(A, C, D) \\\\\n   &= \\frac{1}{Z} \\times \\psi_{1}(A, B, D) \\times \\psi_{2}(A, C, D) \\\\\n   \\end{align*}\n   $$\n4. **Maximal Clique**가 4개이다($\\{\\{A, B\\}, \\{ A, C\\}, \\{ B, D\\}, \\{ C, D\\}\\ \\}$).  \n   $$\n   \\begin{align*}\n   P(A, B, C, D) &= P(A|B, C, D) \\times P(B|C, D) \\times P(C, D) \\\\\n   &= P(A|B, C) \\times P(B|D) \\times P(C, D) \\\\\n   &= \\frac{P(A, B, C)}{P(B, C)} \\times P(B|D) \\times P(C, D) \\\\\n   &= \\frac{P(B, C| A)}{P(A)P(B, C)} \\times P(B|D) \\times P(C, D) \\\\\n   &= \\frac{P(B|A)P(C|A)}{P(A)P(B, C)} \\times P(B|D) \\times P(C, D) \\\\\n   &= \\frac{1}{P(B,C)} \\times P(A, B) \\times P(C|A) \\times P(B|D) \\times P(C, D) \\\\\n   &\\neq \\frac{1}{Z} \\times \\psi_{1}(A, B) \\times \\psi_{2}(A, C) \\times \\psi_{3}(B, D) \\times \\psi_{4}(C, D) \\\\\n   \\end{align*}\n   $$  \n   이것이 바로 $\\psi$를 확률 함수라고 부르지 않는 이유이다.  \n   우리가 $\\psi$를 확률 함수 형태로 표현하기 위해서는 **Chordal graph**(4개 이상의 Node로 이루어진 Cycle에서는 중간에 반드시 Cycle을 이루는 Edge가 아닌 Edge가 존재하는 Graph) 형태를 가져야 한다는 것이다. $\\psi$가 확률 함수로 표현되지 않는다고 우리가 하고자 하는 일에 영향을 주지는 않으니 그런가보다 하고 넘어가도 무방하다.\n\n여기서 우리는 **factorization**이라는 개념을 익혔고, 이것이 가능하기 위해서는 Chordal graph가 주어진 상황에서 Markov Property를 만족해야 함을 확인했다. 그리고, 우리는 이러한 **factorization** 형태를 좀 더 명확하게 나타내기 위해서 다음과 같은 형태로 표현하고, 이를 <mark>**factor graph**</mark>라고 정의한다. 따라서, 각 **factor**(인수)는 **Maximal Clique** 단위로 생성된다.\n\n![ml-factor-graph-1](/images/ml-factor-graph-1.jpg)\n\n### Bayesian Network(Directed Graphical Model, Causality)\n\n**Bayesian Network**라고 불리며, **Causality**를 표현한 Graph이다. 각 Node는 Random Variable을 의미하며, Edge는 Causality(원인($C$) -> 결과($R$))를 의미한다. 그렇기에 굉장히 명확하게 표현이 될 수 있다. 왜냐하면, $P(R, C) = P(C|R)P(R)$임을 명백하게 드러낸다. 그렇기에 우리는 해당 Graph가 주어지는 순간 Joint Probability를 다음과 같이 유추할 수 있는 것이다.\n\n![ml-bayesian-network](/images/ml-bayesian-network.jpg)\n\n즉, 이것을 식으로 나타내면 다음과 같다.\n\n$$\nP(\\cap_{i=1}^{N}X_{i}) = \\prod_{i \\in \\{1, 2, \\cdots, N\\}} P(X_{i}| \\cap_{j \\in \\text{Parents}(X_{i})} X_{j})\n$$\n\n이러한 점 때문에 Bayesian Network에서는 Cycle이 존재할 수 없다. 왜냐하면, Cycle이 존재한다는 것은 각 Random Varaible이 서로 원인과 결과가 되는 것이 때문에 사실상 하나의 사건이라는 의미를 내포하는 것이다. 그렇기에 이는 사실상 존재할 수 없다.\n\n여기서도 마찬가지로 Conditional Independence를 찾을 수 있다. 뿐만 아니라 Marginal Independence에 대한 힌트도 얻을 수 있다. 이때 우리는 <mark>**D-Seperation**</mark>이라는 방법을 활용한다. 이를 위해서는 자신과 주변 2개의 Node가 이룰 수 있는 관계 3가지를 정의해야 한다.\n\n![ml-bayesian-network-2](/images/ml-bayesian-network-2.jpg)\n\n1. **head-to-tail**  \n   이 경우에는 $X \\rightarrow Y \\rightarrow Z$의 관계를 의미한다. 따라서, $X$와 $Z$는 $Y$가 주어질 때, 서로 Independent하다.  \n   $$\n   \\begin{align*}\n   P(X, Z | Y) &= \\frac{P(X,Y,Z)}{P(Y)}\\\\\n   &= \\frac{P(X)P(Y|X)P(Z|Y)}{P(Y)}\\\\\n   &= \\frac{P(X, Y)}{P(Y)} \\times P(Z|Y) \\\\\n   &= P(X | Y)P(Z | Y)\n   \\end{align*}\n   $$\n2. **tail-to-tail**  \n   이 경우에는 $X \\leftarrow Y \\rightarrow Z$의 관계를 의미한다. 따라서, $X$와 $Z$는 $Y$가 주어질 때, 서로 Independent하다.  \n   $$\n   \\begin{align*}\n   P(X, Z | Y) &= \\frac{P(X, Y, Z)}{P(Y)} \\\\\n   &= \\frac{P(X|Y)P(Y)P(Z|Y)}{P(Y)} \\\\\n   &= P(X | Y)P(Z | Y)\n   \\end{align*}\n   $$\n3. **head-to-head**  \n   이 경우에는 $X \\rightarrow Y \\leftarrow Z$의 관계를 의미한다. 따라서, $X$와 $Z$는 서로 Independent하다.  \n   즉, Conditional Independence가 아니라 Marginal Independence이다.  \n   $$\n   \\begin{align*}\n   P(X, Z) &= \\sum_{Y} P(X, Y, Z) \\\\\n   &= \\sum_{Y} P(X)P(Y|X,Z)P(Z) \\\\\n   &= P(X)P(Z)\\sum_{Y} P(Y|X,Z) \\\\\n   &= P(X)P(Z)\n   \\end{align*}\n   $$\n\n이 관계에서 중요한 것은 $X,Z$간 edge가 존재해서는 안된다는 점이다. 위의 관계를 활용하면, 인접한 관계에서의 Conditional Independence는 판별이 가능하다.하지만, <mark>**D-Seperation**</mark>을 통해서 이를 더 넓은 범위로 확장할 수 있다. 세 Node의 집합 $A, B, C$가 주어질 때, $A \\perp\\!\\!\\!\\!\\perp B | C$이기 위해서는 다음 조건을 만족해야 한다.\n\n1. A에서 B로 가는 경로가 하나 이상 존재한다.(여기서 경로는 방향을 신경쓰지 않고 연결 여부에 따라 결정한다.)\n2. 모든 경로에 대해서, C에 속하는 Node가 적어도 하나 head-to-tail 또는 tail-to-tail 관계를 중계할 수 있어야 한다.\n3. 모든 경로에 대해서, C에 속하는 Node는 head-to-head 관계를 중계하면 안되며, head-to-head 관계를 중계하는 Node의 자손이여도 안된다.\n\n즉, $A, B, C$가 이러한 조건을 모두 만족할 때, 우리는 $C$가 $A, B$를 Block했다고 하며, $A \\perp\\!\\!\\!\\!\\perp B | C$이다.\n\n예를 들어 아래와 같은 두 경우를 예를 들어볼 수 있다.\n\n![ml-d-seperation](/images/ml-d-seperation.jpg)\n\n왼쪽의 경우 C의 parent가 A에서 B로 가는 경로에서 head-to-head를 중계하고 있다. 따라서, A와 B는 Conditionally Independence를 만족하지 않는다. 반면, 오른쪽의 경우 C가 A에서 B로 가는 경로에서 head-to-tail 관계를 중계하고 있으므로, A와 B는 Conditionally Independence를 만족한다. 여기서 재밌는 점은 A와 B는 두 경우 모두 Marginal Independence를 만족한다는 점이다. 왜냐하면, A에서 B로 가는 경로가 순방향만으로는 이루어지지 않기 때문이다.\n\n마지막으로, Bayesian Network도 **factorization**이 가능하다 A, B의 **Causality**가 $P(A|B)P(B)$를 의미한다는 점을 활용해서 우리는 다음과 같은 형태로 정의하는 것이 가능하다.\n즉, 초기 시작 점은 자신만을 가지는 factor를 가지고, head-to-head 관계는 하나로 통일하며, 나머지 관계(head-to-head, 등)는 별도로 factor를 분리한다. 즉, 다음과 같은 형태를 가진다.\n\n![ml-factor-graph-2](/images/ml-factor-graph-2.jpg)\n\n```plaintext\n 🤔 Markov Blankets\n\n Markov Blanket은 특정 Node에 대한 정보(관계)가 있는 모든 Node를 의미한다. \n 즉, 특정 Random Variable의 확률이 궁금하다면, 이 Markov Blanket만 가지면 된다. \n 그 중에서도 가장 작은 크기로 모든 필요한 정보를 담은 subset을 Markov Boundary라고 한다. \n Markov Boundary는 Markov Random Field에서는 Neighbor이고,\n Bayesian Network에서는 Parent, Child, Co-Parent이다.\n```\n\n![ml-markov-boundary](/images/ml-markov-boundary.jpg)\n\n### Factor Graph\n\n앞 서 본 두 가지 Graph 표현 방법은 각 각 장단점을 가지고 있다.\n\n1. Markov Random Field는 Joint Probability를 Potential이라는 임의의 변수를 통해서 추정하는 것이 가능하다. 따라서, 명확성이 떨이지지만, Conditional Independence를 파악하는 것은 더 분명하고 쉽다.\n2. Bayesian Network는 Joint Probability를 명확하게 판별할 수 있다. 하지만, Conditional Independence를 판별하는 것이 더 어렵고 복잡하다.\n\n이러한 장단점을 모두 살릴 수 있는 방법으로 제시된 것이 Factor Graph이다. 위에서 각 각 Factor Graph를 표현하는 방법에 대해서는 제시하였으므로 여기서는 다루지 않는다. Factor Graph는 근본적으로 Graph의 요소들을 인수분해(Factorization)하여 인수(Factor)로 분리해낸 것이다. 그렇기에 더 명확한 구분이 가능하다. 각 Node는 Factor와 기존 Node에 해당하는 값이 두 개 다 존재하고, Factor는 꽉 찬 네모, 기존 Node(Variable)는 비어있는 동그라미로 표현하는 것이 일반적이다.\n\n그리고, 여기서는 Joint Probability를 다음과 같이 정의한다.\n\nVariable Node는 $\\{X_{1},X_{2}, \\cdots, X_{N}\\}$이고, Factor Node가 $\\{f_{1},f_{2}, \\cdots, f_{M}\\}$일 때, $f_{j}$와 이웃한 Variable Node의 집합을 $\\mathcal{N}_{j}$라고 하자.\n\n$$\nP(X_{1}, X_{2}, \\cdots, X_{N}) = \\prod_{j=1}^{M}{f_{j}(\\cap_{X \\in \\mathcal{N}_{j}} X)}\n$$\n\n이렇게 표현하는 것은 확실히 Markov Random Field에서는 명확하다. 하지만, Bayesian Network에서는 표현할 수 있는 정보를 어느정도 잃었다고 볼 수도 있다. 어차피 Conditional Probability인데, 다르게 표현한 것이기 때문이다. 하지만, 이를 이용하게 되면 기존에 문제였던 Conditional Independence를 쉽게 파악할 수 있다. 왜냐하면 Factor Graph에서는 Conditional Independence를 확인하기 위해서 해당 집합으로 이어지는 모든 경로에서 중간에 하나라도 Variable Node가 껴있는지만 확인해도 충분하다.\n\n![ml-factor-graph-3](/images/ml-factor-graph-3.jpg)\n\n따라서, 앞으로의 과정에서는 Factor Graph를 Main으로 하여 설명을 진행하도록 하겠다.\n\n## Message Passing\n\n우리는 앞의 Graph 표현을 통해서 Feature를 Factor로 압축하는 과정을 익혔다. 이 역시 엄청난 계산 효율을 가져온다. 하지만, 이를 더 효과적으로 활용할 수 있는 방법이 있다. 그것은 Message Passing 방법이다. 우선 우리가 해결하고자하는 문제를 정의해보자. 우리는 Joint Probability($P(X_{1}, X_{2}, \\cdots, X_{N})$)가 주어졌을 때, 다음 값을 구하고 싶을 수 있다.\n\n1. <mark>**Marginalization**</mark>  \n   Marginal Probability는 Joint Probability에서 구하고자 하는 Random Variable을 제외한 모든 경우의 수를 더한 것이다.\n   $$\n   \\begin{align*}\n   P(X_{i}) &= \\sum_{X_{j}}P(X_{i}, X_{j}) \\\\\n   &= \\sum_{X_{j}, X_{k}}P(X_{i}, X_{j}, X_{k}) \\\\\n   &= \\cdots \\\\\n   &= \\sum_{X_{-i}}P(X_{1}, X_{2}, \\cdots, X_{N})\n   \\end{align*}\n   $$  \n   즉, 이를 일반적인 방법으로 풀고자하면 Random Variable($X_{i}$)이 각 각 $\\mathbb{R}^{L}$로 정의된다고 할 때, $L^{N-1}$번의 합연산이 필요하다.\n2. <mark>**Maximization**</mark>  \n   Joint Probability의 최댓값을 갖게 하는 경우의 수($\\hat{X}$)를 구하고자 한다면 다음을 구해야 한다.  \n   $$\n   \\hat{X} = \\argmax_{X_{1}, X_{2}, \\cdots, X_{N}} P(X_{1}, X_{2}, \\cdots, X_{N})\n   $$  \n   이 또한 무식하게 풀고자하면, $L^{N-1}$번의 max 연산이 필요하다.\n\n그렇다면, 이를 한 번 가장 간단한 형태인 일자형 Factor Graph로 표현해보자.\n\n![ml-bp-1](/images/ml-bp-1.jpg)\n\n여기서 $P(X_{2})$를 알고 싶다고 해보자. 그 경우 다음과 같이 식이 정리되는 것을 볼 수 있다.\n\n$$\n\\begin{align*}\nP(X_{2}) &= \\sum_{X_{1}}P(X_{1},X_{2}) \\\\\n&= \\sum_{X_{1}, X_{3}, X_{4}, X_{5}}P(X_{1}, X_{2}, X_{3}, X_{4}, X_{5}) \\\\\n&= \\sum_{X_{1}}\\sum_{X_{3}}\\sum_{X_{4}}\\sum_{X_{5}}P(X_{1}, X_{2}, X_{3}, X_{4}, X_{5}) \\\\\n&= \\sum_{X_{1}}\\sum_{X_{3}}\\sum_{X_{4}}\\sum_{X_{5}}f_{a}(X_{1}, X_{2})f_{b}(X_{2}, X_{3})f_{c}(X_{3}, X_{4})f_{d}(X_{4}, X_{5}) \\\\\n&= (\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))(\\sum_{X_{3}}\\sum_{X_{4}}\\sum_{X_{5}}f_{b}(X_{2}, X_{3})f_{c}(X_{3}, X_{4})f_{d}(X_{4}, X_{5})) \\\\\n&= (\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))(\\sum_{X_{3}}\\sum_{X_{4}}f_{b}(X_{2}, X_{3})f_{c}(X_{3}, X_{4})\\sum_{X_{5}}f_{d}(X_{4}, X_{5})) \\\\\n&= (\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))(\\sum_{X_{3}}f_{b}(X_{2}, X_{3})\\sum_{X_{4}}f_{c}(X_{3}, X_{4})\\sum_{X_{5}}f_{d}(X_{4}, X_{5}))\n\\end{align*}\n$$\n\n이것이 의미하는 바는 무엇일까? 이는 단순하게 순서를 바꾸어 재조합하는 것만으로 Computing을 줄일 수 있음을 보여줬다. 먼저, 앞의 $\\sum$연산만 단독으로 할 때, $L$번의 연산이 필요하고, 뒤에 연속해서 나오는 3번의 $\\sum$을 구하기 위해서는 결국 $L^{3}$의 연산이 필요하다. 즉, $L + L^{3}$의 합연산으로 marginalization 결과를 구할 수 있다는 것이다. 그렇기에 더 효율적인 연산이 가능한 것이다. 이는 특히 Graph의 중앙에 있는 값을 구할 때 더 도드라지게 나타난다. 전체 marginalization 결과를 나타내면 다음과 같다.\n\n$$\n\\begin{align*}\nP(X_{1}) &= \\sum_{X_{2}}f_{a}(X_{1}, X_{2})\\sum_{X_{3}}f_{b}(X_{2}, X_{3})\\sum_{X_{4}}f_{c}(X_{3}, X_{4})\\sum_{X_{5}}f_{d}(X_{4}, X_{5}) \\rightarrow L^{4} \\\\\nP(X_{2}) &= (\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))(\\sum_{X_{3}}f_{b}(X_{2}, X_{3})\\sum_{X_{4}}f_{c}(X_{3}, X_{4})\\sum_{X_{5}}f_{d}(X_{4}, X_{5})) \\rightarrow L^{3} + L \\\\\nP(X_{3}) &= (\\sum_{X_{2}}f_{b}(X_{2}, X_{3})\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))(\\sum_{X_{4}}f_{c}(X_{3}, X_{4})\\sum_{X_{5}}f_{d}(X_{4}, X_{5})) \\rightarrow 2L^{2} \\\\\nP(X_{4}) &= (\\sum_{X_{3}}f_{c}(X_{3}, X_{4})\\sum_{X_{2}}f_{b}(X_{2}, X_{3})\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))(\\sum_{X_{5}}f_{d}(X_{4}, X_{5})) \\rightarrow L^{3} + L \\\\\nP(X_{5}) &= \\sum_{X_{4}}f_{d}(X_{4}, X_{5})\\sum_{X_{3}}f_{c}(X_{3}, X_{4})\\sum_{X_{2}}f_{b}(X_{2}, X_{3})\\sum_{X_{1}}f_{a}(X_{1}, X_{2}) \\rightarrow L^{4}\n\\end{align*}\n$$\n\n이것이 끝이 아니다. 우리는 중복된 연산을 별도로 저장해두어서 더 빠른 연산을 수행하는 것도 가능하다. 예를 들어 다음과 같은 과정이라고 할 수 있다.\n\n$$\n\\begin{align*}\nP(X_{2}) &= \\underbrace{(\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))}_{\\red{\\mu_{a\\rightarrow2}(X_{2})}}(\\sum_{X_{3}}f_{b}(X_{2}, X_{3})\\sum_{X_{4}}f_{c}(X_{3}, X_{4})\\sum_{X_{5}}f_{d}(X_{4}, X_{5})) \\\\\nP(X_{3}) &= \\underbrace{(\\sum_{X_{2}}f_{b}(X_{2}, X_{3})\\red{\\mu_{a\\rightarrow2}(X_{2})})}_{\\red{\\mu_{b\\rightarrow3}(X_{3})}}(\\sum_{X_{4}}f_{c}(X_{3}, X_{4})\\sum_{X_{5}}f_{d}(X_{4}, X_{5})) \\\\\nP(X_{4}) &= \\underbrace{(\\sum_{X_{3}}f_{c}(X_{3}, X_{4})\\red{\\mu_{b\\rightarrow3}(X_{3})})}_{\\red{\\mu_{c\\rightarrow4}(X_{4})}}(\\sum_{X_{5}}f_{d}(X_{4}, X_{5})) \\\\\nP(X_{5}) &= \\underbrace{\\sum_{X_{4}}f_{d}(X_{4}, X_{5})\\red{\\mu_{c\\rightarrow4}(X_{4})}}_{\\red{\\mu_{d\\rightarrow5}(X_{5})}}\n\\end{align*}\n$$\n\n![ml-bp-2](/images/ml-bp-2.jpg)\n\n즉, 이전 Marginalization에서 계산했던 $\\mu_{\\text{factor}\\rightarrow\\text{variable}}(X_{\\text{variable}})$를 저장해서, 다음 Marginalization 연산 시에 사용할 수 있기 때문에 전체 Marginalization을 구하는데에도 더 빠른 연산이 가능하다. 이 방식은 역으로 진행하는 것도 가능한데 다음과 같다.\n\n$$\n\\begin{align*}\nP(X_{4}) &= (\\sum_{X_{3}}f_{c}(X_{3}, X_{4})\\sum_{X_{2}}f_{b}(X_{2}, X_{3})\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))\\underbrace{(\\sum_{X_{5}}f_{d}(X_{4}, X_{5}))}_{\\blue{\\mu_{d\\rightarrow4}(X_{4})}} \\\\\nP(X_{3}) &= (\\sum_{X_{2}}f_{b}(X_{2}, X_{3})\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))\\underbrace{(\\sum_{X_{4}}f_{c}(X_{3}, X_{4})\\blue{\\mu_{d\\rightarrow4}(X_{4})})}_{\\blue{\\mu_{c\\rightarrow3}(X_{3})}} \\\\\nP(X_{2}) &= (\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))\\underbrace{(\\sum_{X_{3}}f_{b}(X_{2}, X_{3})\\blue{\\mu_{c\\rightarrow3}(X_{3})})}_{\\blue{\\mu_{b\\rightarrow2}(X_{2})}} \\\\\nP(X_{1}) &= \\underbrace{\\sum_{X_{2}}f_{a}(X_{1}, X_{2})\\blue{\\mu_{b\\rightarrow2}(X_{2})}}_{\\blue{\\mu_{a\\rightarrow1}(X_{1})}}\n\\end{align*}\n$$\n\n![ml-bp-3](/images/ml-bp-3.jpg)\n\n이를 합쳐서 표현하면 다음과 같은 형태를 가지는 것을 알 수 있다.\n\n$$\n\\begin{align*}\nP(X_{1}) &= \\blue{\\mu_{a\\rightarrow1}(X_{1})} &= \\red{\\mu^{-}(X_{1})}\\blue{\\mu^{+}(X_{1})} \\\\\nP(X_{2}) &= \\red{\\mu_{a\\rightarrow2}(X_{2})}\\blue{\\mu_{b\\rightarrow2}(X_{2})}&= \\red{\\mu^{-}(X_{2})}\\blue{\\mu^{+}(X_{2})} \\\\\nP(X_{3}) &= \\red{\\mu_{b\\rightarrow3}(X_{3})}\\blue{\\mu_{c\\rightarrow3}(X_{3})}&= \\red{\\mu^{-}(X_{3})}\\blue{\\mu^{+}(X_{3})} \\\\\nP(X_{4}) &= \\red{\\mu_{c\\rightarrow4}(X_{4})}\\blue{\\mu_{d\\rightarrow4}(X_{4})}&= \\red{\\mu^{-}(X_{4})}\\blue{\\mu^{+}(X_{4})} \\\\\nP(X_{5}) &= \\red{\\mu_{d\\rightarrow5}(X_{5})}&= \\red{\\mu^{-}(X_{5})}\\blue{\\mu^{+}(X_{5})} \\\\\n&\\therefore P(X_{i}) = \\red{\\mu^{-}(X_{i})}\\blue{\\mu^{+}(X_{i})} \\\\\n\\end{align*}\n$$\n\n![ml-bp-4](/images/ml-bp-4.jpg)\n\n$\\mu^{+}$와 $\\mu^{-}$의 방향이 헷갈릴 수 있는데, 이는 자신($X_{i}$)을 기준으로 큰 쪽에서 왔는지 작은 쪽에서 왔는지를 표시한다고 생각하면 쉽다. 따라서, $\\mu$는 다음과 같이 정의되어질 수 있다.\n\n$$\n\\begin{align*}\n\\mu^{-}(X_{1}) &= 1,\\, \\mu^{+}(X_{N}) = 1 \\text{이고,}\\\\\n\\mu^{-}(X_{i}) &= \\sum_{X_{i-1}}f_{i}(i-1, i)\\mu^{-}(X_{i-1}) \\\\\n\\mu^{+}(X_{i}) &= \\sum_{X_{i+1}}f_{i}(i, i+1)\\mu^{+}(X_{i+1}) \\\\\n\\end{align*}\n$$\n\n여기서 $\\mu$가 바로 <mark>**Message**</mark>를 의미한다. 즉, 우리가 마치 운동장에서 사람 수를 세기 위해서 앞 사람이 말한 수 + 1을 반복하면서 진행하는 것처럼 Message를 전달하며 전체 확률을 구해나가는 것이다. 이러한 방법을 **Message Passing**이라고 하며, 이 방법을 통해서 우리는 Marginal Probability를 더 효과적으로 구할 수 있다. 왜냐하면, $\\mu^{-}(X_{i})$를 구하기 위한 연산량이 $(i-1) \\times L$이라는 것과, $mu^{+}(X_{i})$를 구하기 위한 연산량이 $(N-i) \\times L$이라는 것을 알고 있다. 따라서, 각 각의 Marginalization을 구하기 위한 연산량이 $L^{N-1}$에서 $(N-1)L$로 줄어들었다.\n\n여기까지 우리는 Line으로 되어있는 가장 간단한 Factor Graph에서의 <mark>**Sum-Product Belief Propagation**</mark>을 알아본 것이다. 이제부터 우리는 더 복잡한 상황에서의 Belief Propagation(BP)을 살펴볼 것이다. Belief Propagation과 Message Passing은 대게 비슷한 의미로 사용되어 진다(일부는 Message Passing 후에 데이터를 가공하는 작업을 분리하고 이를 통합하여 Belief Propagation이라고 하기도 한다.)\n\n### Sum-Product Belief Propagation\n\n합의 곱을 통해서 Marginal Probability를 구하는 방법으로, 앞 서 보았던 Linear Factor Graph 뿐만 아니라 Tree형태의 Factor Graph에서도 사용할 수 있다. 물론 Cycle이 존재하는 Factor Graph가 존재할 수도 있지만, 이 경우에 대해서는 특별한 알고리즘을 별도로 적용하는 것이 일반적이다. 따라서, 여기서는 Tree형태의 Factor Graph에서 일반적으로 적용할 수 있는 방법을 제시한다.\n\n우선 아래 그림을 통해서 대략적인 이해를 해보도록 하자.\n\n![ml-sum-product-bp-1](/images/ml-sum-product-bp-1.jpg)\n\n우리는 위에서 Line Factor Graph에서 어떻게 Marginal Probability를 어떻게 구하는지를 보았다. Tree 구조에서도 동일하게 결국 Marginal Probability를 자신과 이웃한 Factor Node들로 부터 전달된 Message의 곱이라고 할 수 있다. 단지 다른 점은 이웃한 factor가 복수 개라는 것이다.  \n(factor 또는 variable에 해당하는 Node 중에서 index가 i인 Node와 인접한 Node(Node i가 factor라면 variable, variable이라면 factor이다.)들의 index 집합을 $\\mathcal{N}_{i}$ 라고하고, 값은 종류의 Node의 index를 모아둔 집합 I가 있을 때 $X_{I} = \\{X_{i}\\}_{i \\in I}$라고 하자.)\n\n$$\nP(X_{i}) = \\prod_{p \\in \\mathcal{N}_{i}}\\mu_{p \\rightarrow i}(X_{i})\n$$\n\n그렇다면, 여기서 $\\mu_{p \\rightarrow i}(X_{i})$를 각 각 어떻게 구할 수 있을까? 그러기 위해서 빨간색 부분을 자세히 봐보자.\n\n![ml-sum-product-bp-2](/images/ml-sum-product-bp-2.jpg)\n\n여기서도 기존 Linear Factor Graph와 다른 점은 Factor Node역시 여러 개의 Variable Node와 연결된다는 점이다. 이 부분만 떼어서 자세히 보면 다음과 같다.\n\n![ml-sum-product-bp-3](/images/ml-sum-product-bp-3.jpg)\n\n그렇기에 이전 Variable Node로 부터 오는 Message들과 factor 값을 함께 곱하는 과정이 필요하다. 여기서, Varaible Node에서 factor Node로 오는 Message를 $\\nu$라고 정의한다면, 다음과 같이 표현할 수 있다. 여기서 주의할 점은 Factor Node와 이웃한 Variable Node 중에서 Message를 전달할 Variable Node는 연산에서 제외해야 한다는 점이다.\n\n$$\n\\mu_{u \\rightarrow i}(X_{i}) = \\sum_{X_{\\mathcal{N}_{u}\\backslash\\{i\\}}}f_{u}(X_{\\mathcal{N}})\\prod_{j \\in \\mathcal{N}\\backslash\\{i\\}}{\\nu_{j \\rightarrow u}(x_{j})}\n$$\n\n그리고 마지막으로 $\\nu$를 구하는 과정은 다음과 같다.\n\n![ml-sum-product-bp-4](/images/ml-sum-product-bp-4.jpg)\n\n$$\n\\nu_{j \\rightarrow u}(X_{j}) = \\prod_{v \\in \\mathcal{N}_{j}\\backslash\\{u\\}}\\mu_{v \\rightarrow j}(X_{j})\n$$\n\n따라서, Marginal Probability($P(X_{i})$)를 구하고자 할 때 우리는 Leaf Node에서 부터 시작해서 차례차례 값을 구하면서, $\\mu_{\\mathcal{N}_{i} \\rightarrow i}$를 모두 구할 때까지 연산을 수행해야 한다.\n\n```plaintext\n 🤔 Loopy Sum-Product BP\n\n 우리는 Sum-Product BP를 Tree에서만 쓸 수 있다고 제한하였지만, \n 사실 Cycle이 존재하는 Factor Graph에서도 동일한 BP를 사용할 수 있다.\n 하지만, 이 경우에는 비례 관계를 통해서 나타낼 수 밖에 없기 때문에\n 결과값에 대해서 100% 확신할 수는 없다.\n```\n\n### Max Product Belief Propagation\n\nBelief Propagation은 앞 서 살펴보았던 Marginal Probability를 구할 때에도 사용할 수 있지만, Maximization 문제를 풀 때에도 사용할 수 있다. 마찬가지로 가장 간단한 예시인 Linear Factor Graph를 가정해보자.\n\n![ml-bp-1](/images/ml-bp-1.jpg)\n\n$$\nP(X_{1}, X_{2}, X_{3}, X_{4}, X_{5}) = f_{a}(X_{1}, X_{2})f_{b}(X_{2}, X_{3})f_{c}(X_{3}, X_{4})f_{d}(X_{4}, X_{5})\n$$\n\n이 경우에 $P(X_{1}, X_{2}, X_{3}, X_{4}, X_{5})$를 최대로 만드는 $\\hat{x_{1}}, \\hat{x_{2}}, \\hat{x_{3}}, \\hat{x_{4}}, \\hat{x_{5}}$를 찾아보자.  \n\n$$\n\\begin{align*}\n&\\max_{X_{1}, X_{2}, X_{3}, X_{4}, X_{5}} f_{a}(X_{1}, X_{2})f_{b}(X_{2}, X_{3})f_{c}(X_{3}, X_{4})f_{d}(X_{4}, X_{5})\\\\\n&= \\max_{X_{1}}\\{f_{a}(X_{1}, X_{2})\\max_{X_{2}}\\{\\max_{X_{3}}\\{f_{b}(X_{2}, X_{3}) \\max_{X_{4}}\\{f_{c}(X_{3}, X_{4})\\max_{X_{5}}\\{f_{d}(X_{4}, X_{5})\\}\\}\\}\\}\\}\\\\\n&= \\max_{X_{2}}\\{\\max_{X_{1}}\\{f_{a}(X_{1}, X_{2})\\} \\max_{X_{3}}\\{f_{b}(X_{2}, X_{3}) \\max_{X_{4}}\\{f_{c}(X_{3}, X_{4})\\max_{X_{5}}\\{f_{d}(X_{4}, X_{5})\\}\\}\\}\\}\\\\\n&= \\max_{X_{3}}\\{\\max_{X_{2}}\\{f_{b}(X_{2}, X_{3})\\max_{X_{1}}\\{f_{a}(X_{1}, X_{2})\\}\\} \\max_{X_{4}}\\{f_{c}(X_{3}, X_{4})\\max_{X_{5}}\\{f_{d}(X_{4}, X_{5})\\}\\}\\}\\\\\n&= \\max_{X_{4}}\\{\\max_{X_{3}}\\{f_{c}(X_{3}, X_{4})\\max_{X_{2}}\\{f_{b}(X_{2}, X_{3})\\max_{X_{1}}\\{f_{a}(X_{1}, X_{2})\\}\\}\\}\\max_{X_{5}}\\{f_{d}(X_{4}, X_{5})\\}\\}\\\\\n&= \\max_{X_{5}}\\{f_{d}(X_{4}, X_{5})\\max_{X_{4}}\\{\\max_{X_{3}}\\{f_{c}(X_{3}, X_{4})\\max_{X_{2}}\\{f_{b}(X_{2}, X_{3})\\max_{X_{1}}\\{f_{a}(X_{1}, X_{2})\\}\\}\\}\\}\\}\\\\\n\\end{align*}\n$$\n\nMarginalization과 굉장히 유사하다고 하다. 이를 이전에 사용한 Tree 구조에 반영해도 동일하다.\n\n![ml-sum-product-bp-1](/images/ml-sum-product-bp-1.jpg)\n\n단, 여기서 Message와 최종 결과를 다음과 같이 재정의하면 끝난다.\n\n$$\n\\begin{align*}\n\\max P(X_{1}, X_{2}, \\cdots, X_{N}) &= \\max_{X_{i}}\\{\\prod_{p\\in\\mathcal{N}_{i}}\\mu_{p \\rightarrow i}(X_{i})\\} \\\\\n\\mu_{u \\rightarrow i}(X_{i}) &= \\max_{\\mathcal{N}_{u}\\backslash\\{i\\}}\\{f_{u}(\\mathcal{N}_{i})\\prod_{j \\in \\mathcal{N}_{u}\\backslash\\{i\\}}\\nu_{j \\rightarrow u}(X_{j})\\} \\\\\n\\nu_{j \\rightarrow u}(X_{j}) &= \\prod_{v\\in\\mathcal{N}_{j}\\backslash\\{u\\}}\\mu_{v \\rightarrow j}(X_{j})\n\\end{align*}\n$$\n\n추가적으로 Max Sum Belief Propagation을 소개하겠다. 이는 Maximization 문제를 풀 때, $\\log$를 취한 결과도 동일하다는 점을 활용하여 문제를 푸는 것이다. 따라서, 다음과 같이 식이 조금 변화한다. 이 방식을 쓰면, 너무 작은 probability로 인한 문제를 피할 수 있다.\n\n$$\n\\begin{align*}\n\\max \\red{\\log} P(X_{1}, X_{2}, \\cdots, X_{N}) &= \\max_{X_{i}}\\{\\red{\\sum_{p\\in\\mathcal{N}_{i}}}\\mu_{p \\rightarrow i}(X_{i})\\} \\\\\n\\mu_{u \\rightarrow i}(X_{i}) &= \\max_{\\mathcal{N}_{u}\\backslash\\{i\\}}\\{\\red{\\log} f_{u}(\\mathcal{N}_{i}) + \\red{\\sum_{j \\in \\mathcal{N}_{u}\\backslash\\{i\\}}}\\nu_{j \\rightarrow u}(X_{j})\\} \\\\\n\\nu_{j \\rightarrow u}(X_{j}) &= \\red{\\sum_{v\\in\\mathcal{N}_{j}\\backslash\\{u\\}}}\\mu_{v \\rightarrow j}(X_{j})\n\\end{align*}\n$$\n\n## Construction from Data\n\n앞에서는 Graph를 통해서 연산 과정을 Optimization하는 방법을 알아보았다면, 여기서는 실제 관측 data를 이용해서 어떻게 Graph를 구조화할 수 있는지에 대해서 알아볼 것이다. 이를 수행하기 위해 많은 Algorithm이 존재하지만 가장 기본이 될 수 있는 Algorithm인 **Chow-Liu Algorithm**만 살펴보도록 하겠다.\n\n### Chow-Liu Algorithm\n\n제일 먼저 구해야할 것은 **Joint Probability**이다. 이는 Empirical distribution을 이용하여 구할 수 있다. 아래는 feature가 N개인 총 K개의 data가 있을 때, 다음과 같이 **Joint Probability**를 구한 것이다.\n\n$$\np(X_{1}=x_{1}, X_{2}=x_{2}, \\cdots, X_{N}=x_{n}) = \\frac{1}{K} \\sum_{k=1}^{K} \\mathbb{1}[x^{(k)}=(x_{1}, x_{2}, \\cdots, x_{n})]\n$$\n\n위와 같이 **Joint Probability**가 주어졌을 때, **Chow-Liu Algorithm**에서는 **Second Order Conditional Probability**(총 두개의 Random Variable로 구성된 Conditional Probability. 즉, Condtion도 하나이고, 확률을 구하고자 하는 변수도 하나이다.)와 **Marginal Probability**로 Graph를 가정하고 **Bayesian Network**를 구성한다. 이 경우에는 형태가 Tree 형태로 만들어지기 때문에 결론적으로 head-to-head 관계가 만들어지지 않는다.(각 각의 node는 하나의 parent만 갖기 때문이다.)\n\n![ml-chow-liu-1](/images/ml-chow-liu-1.jpg)\n\n따라서, 위와 같은 Graph로 추정했다면, 확률은 다음과 같아진다.\n\n$$\np(x_{1}, x_{2}, \\cdots, x_{n}) = p(x_{6}|x_{5})p(x_{5}|x_{2})p(x_{4}|x_{2})p(x_{3}|x_{2})p(x_{2}|x_{1})p(x_{1})\n$$\n\n여기서 이제 우리는 다음과 같은 문제만 풀면 끝이다. Empirical distribution으로 구한 Joint Probability($p$)와 우리가 추정한 Graph에서의 Joint Probability($p_{\\intercal}$)사이의 차이가 최소가 되도록 하면 된다. 이를 위해서 사용하는 것이 **KL Divergence**이다. 따라서, 우리가 구하고 싶은 **Bayesian Network**는 다음과 같이 구할 수 있다.\n\n$$\n\\argmin_{\\intercal\\text{:tree}} KL(p||p_{\\intercal})) = \\argmin_{\\intercal\\text{:tree}} \\sum_{x^{(k)} \\in \\mathcal{D}}p(x^{(k)})\\log \\frac{p(x^{(k)})}{p_{\\intercal}(x^{(k)})}\n$$\n\n그렇다면, 좀 더 면밀하게 $p_{\\intercal}$을 정의해보자.\n\n$$\n\\begin{align*}\np_{\\intercal}(x_{1}, x_{2}, \\cdots, x_{N}) &= \\prod_{i=1}^{N}p(x_{i}|x_{\\text{parent}(i)})\\, (\\because \\text{Bayesian Network Definition})\\\\\n&= p(x_{root})\\prod_{(i,j) \\in E}p(x_{j}|x_{i})\n\\end{align*}\n$$\n\n여기서 V는 node의 집합을 의미하고, E는 edge를 저장하며 각 tuple(i,j)는 (parent, child)를 의미한다. 그리고, Tree에서는 단 하나의 Node만 Root이고 parent가 없기 때문에 해당 Root만 marginal Probability를 가지는 것을 알 수 있다.\n\n$$\n\\begin{align*}\np_{\\intercal}(x_{1}, x_{2}, \\cdots, x_{N}) &= p(x_{root})\\prod_{(i,j) \\in E}p(x_{j}|x_{i})\\\\\n&= p(x_{root})\\prod_{(i,j) \\in E} \\frac{p(x_{j},x_{i})}{p(x_{i})}\\\\\n&= \\red{p(x_{root})}\\prod_{(i,j) \\in E} \\frac{p(x_{j},x_{i})\\red{p(x_{j})}}{p(x_{i})p(x_{j})}\\\\\n&= \\prod_{i\\in V}p(x_{i}) \\prod_{(i,j) \\in E} \\frac{p(x_{j},x_{i})}{p(x_{i})p(x_{j})}\\\\\n\\end{align*}\n$$\n\n마지막이 좀 애매할 수 있는 tree이기 때문에 가능한 것이다. 특정 node로 가는 path는 단 하나이기 때문에 $j$로 끝나는 edge도 하나일 수 밖에 없다. 따라서, $p(x_{root})\\prod_{(i,j) \\in E} p(x_{j}) = \\prod_{i=V}p(x_{i})$일 수 있는 것이다.\n\n이것이 정의되면, 우리는 이제 최적의 Tree인 $\\intercal_{*}$를 찾을 수 있다.\n\n$$\n\\begin{align*}\n\\intercal_{*} &= \\argmin_{\\intercal\\text{:tree}} KL(p||p_{\\intercal})\\\\\n&= \\argmin_{\\intercal\\text{:tree}} \\sum_{x^{(k)} \\in \\mathcal{D}}p(x^{(k)})\\log \\frac{p(x^{(k)})}{p_{\\intercal}(x^{(k)})}\\\\\n&= \\argmin_{\\intercal\\text{:tree}} \\sum_{x^{(k)} \\in \\mathcal{D}}\\cancel{p(x^{(k)})\\log{p(x^{(k)})}} -p(x^{(k)})\\log{p_{\\intercal}(x^{(k)})}\\\\\n&= \\argmax_{\\intercal\\text{:tree}} \\sum_{x^{(k)} \\in \\mathcal{D}}p(x^{(k)})\\log{p_{\\intercal}(x^{(k)})}\\\\\n&= \\argmax_{\\intercal\\text{:tree}} \\sum_{x^{(k)} \\in \\mathcal{D}}p(x^{(k)})\\log({\\prod_{i\\in V}p(x_{i}^{(k)}) \\prod_{(i,j) \\in E} \\frac{p(x_{j}^{(k)},x_{i}^{(k)})}{p(x_{i}^{(k)})p(x_{j}^{(k)})}})\\\\\n&= \\argmax_{\\intercal\\text{:tree}} \\sum_{x^{(k)} \\in \\mathcal{D}}\\sum_{i\\in V}p(x^{(k)})\\log(p(x_{i}^{(k)})) + \\sum_{x^{(k)} \\in \\mathcal{D}}\\sum_{(i,j) \\in E} p(x^{(k)})\\log({\\frac{p(x_{j}^{(k)},x_{i}^{(k)})}{p(x_{i}^{(k)})p(x_{j}^{(k)})}})\\\\\n&= \\argmax_{\\intercal\\text{:tree}} \\sum_{i\\in V}\\sum_{x^{(k)} \\in \\mathcal{D}}p(x^{(k)})\\log(p(x_{i}^{(k)})) + \\sum_{(i,j) \\in E}\\sum_{x^{(k)}_{i}, x^{(k)}_{j}} p(x^{(k)}_{i}, x^{(k)}_{j})\\log({\\frac{p(x_{j}^{(k)},x_{i}^{(k)})}{p(x_{i}^{(k)})p(x_{j}^{(k)})}})\\, (\\because \\text{marginalization})\\\\\n&= \\argmax_{\\intercal\\text{:tree}} \\cancel{\\sum_{i\\in V}-H(X_{i})} + \\sum_{(i,j) \\in E}I(X_{i}, X_{j})\\, (\\because H(X_{i})\\text{는 constant이다.})\\\\\n&= \\argmax_{\\intercal\\text{:tree}}\\sum_{(i,j) \\in E}I(X_{i}, X_{j})\\\\\n\\end{align*}\n$$\n\n마지막 marginalization은 헷갈린다면, 해당 Posting의 Sum-Product BP 부분을 다시 보고오도록 하자.\n\n자, 이제 우리가 얻은 결론은 다음과 같다. 결국, 최적의 Tree는 $I(X_{i}, X_{j})$가 최대가 되는 Tree이다. I(Mutual Information)이 헷갈린다면, [Information Theory](/posts/ml-base-knowledge#Information-Theory) 정리해놓은 Posting을 다시 보고 오자. 결국, $X_{i}, X_{j}$간의 모든 Mutual Information을 구해서 weighted graph를 구축한다음에 Kruskal Algorithm을 통해서 최적 Tree를 찾으면 되는 것이다.\n\n따라서, 과정은 다음과 같다.\n\n1. 가능한 모든 (i,j) 쌍에 대하여 $I(X_{i}, X_{j})$를 구하여, Weighted Graph를 구성한다.\n2. Kruskal Algorithm을 수행한다.\n   1. weight의 내림차순으로 Edge를 정렬한다.\n   2. 하나씩 Edge를 뽑으면서, Cycle이 생기는지 확인하여 생기면 버리고, Cycle이 생기지 않으면 Tree에 추가한다.(Cycle 여부는 동일한 Node가 두 개 다 존재하는지 확인)\n   3. 모든 Node를 뽑았다면 종료하고, 그렇지 않다면 2번을 반복 시행한다.\n\n이렇게 Graph를 만들게 되면, 우리는 Joint Probability를 이전에 배운 Optimization 방법을 통해서 쉽게 구할 수 있다. 그리고, 이를 Model에 직접 적용할 수 있다. 예를 들면, 우리가 Classification을 수행할 때이다.\n\n$$\n\\argmax_{\\mathcal{l} \\in \\{0,1,2,\\cdots, 9\\}} p_{\\mathcal{l}} \\times p(x^{\\text{new}}|\\mathcal{l}^{\\text{new}}=\\mathcal{l}) \\propto \\argmax_{\\mathcal{l} \\in \\{0,1,2,\\cdots, 9\\}} p_{\\mathcal{l}} \\times p_{\\intercal}(x^{\\text{new}})\n$$\n\n위와 같이 추정하여 계산을 획기적으로 줄일 수 있다.\n\n## Reference\n\n- Tumbnail : Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n- Medium[Chullin], Graphical Model이란 무엇인가요?, <https://medium.com/@chullino/graphical-model%EC%9D%B4%EB%9E%80-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80%EC%9A%94-2d34980e6d1f>\n- Wiki, Markov Random Field, <https://en.wikipedia.org/wiki/Markov_random_field>\n- Adaptive Computation and Machine Learning, Thomas G. Dietterich\n- <https://cedar.buffalo.edu/~srihari/CSE574/Chap8/Ch8-PGM-Inference/Ch8.3.2-FactorGraphs.pdf>\n","slug":"ml-graphical-model","date":"2022-11-14 13:08","title":"[ML] 8. Graphical Model","category":"AI","tags":["ML","GraphicalModel","ConditionalIndependence","MarkovRandomField","BayesianNetwork","FactorGraph","D-Seperation","Factorization","MarkovProperty","MessagePassing","BeliefPropagation","Chow-LiuAlgorithm"],"desc":"Machine Learning은 주어진 data를 가장 잘 설명할 수 있는 pattern(Model)을 찾는 것이 목표라고 하였다. 그렇다면, \"data가 가지는 여러가지 정보(feature)들 중에서 어떤 feature를 중점적으로 보고 이용할 수 있을까?\" 그리고, \"만약 여러 feature들이 서로 연관이 있다면 이를 연산의 최적화를 위해 이용할 수 있지 않을까?\" 라는 접근이 가능하다. 여기서 Graphical Model은 이러한 관계를 시각적으로 표현할 수 있으며, 이를 통해서 연산 최적화에 대한 insight를 얻을 수 있다.","thumbnailSrc":"https://euidong.github.io/images/ml-thumbnail.jpg"},{"content":"\n## Intro\n\n이전까지의 Posting에서는 Supervised Learning 즉, 이미 Labeling이 완료된 데이터에 의한 Learning을 중점적으로 다루었다. 지금부터는 Unsupervised Learning에 대해서 조금 더 살펴보도록 하겠다. 대표적인 Unsupervised Learning은 Clustering, Feature Selection(or Dimensionality Reduction), Generative Model 등이 존재한다. 이들에 대해서 차근차근 살펴보도록 하고, 해당 Posting에서는 가장 대표적이라고 할 수 있는 Clustering을 먼저 살펴보면서 Unsupervised Learning에 대한 계략적인 이해를 해보도록 하겠다.\n\n## Clustering\n\nClustering은 unlabeled data를 data간 유사성 또는 거리 지표 등을 활용하여 미리 지정한 수 만큼의 partitioning하는 작업을 의미한다. 즉, 우리가 학습을 진행함에 있어 data는 label이 존재하지 않기 때문에 우리는 data간의 관계에서 정보를 추출해서 이를 분류해내는 것이 목표인 것이다.\n\n이를 수행하기 위한 방법은 크게 두 가지로 나눌 수 있다.\n\n1. **Non-Parametric Approach**  \n   이름 그대로 확률적 분포를 가정한 후, Parameter를 찾아가는 방식이 아닌 직관적인 방법(Huristic Approach)을 활용하는 방법이다. 그렇기에 확률적인 해석이 뒷받침되기 보다는 Algorithm을 통해서 이를 설명한다. 대표적인 방법이 K-Means Clustering이다.\n2. **Parametric Approach**  \n   확률적 분포를 가정한 후, Parameter를 찾아가는 방식으로, 대표적인 방법이 Gaussian 분포를 가정하고 찾아나가는 Gaussian Mixture Model(GMM, or MoG, Mixture of Gaussian)이 있다.\n\n따라서, Clustering을 대표하는 K-means Clustering과 GMM을 각 각 살펴보도록 하겠다.\n\n### K-Means Clustering\n\nK-Means Clustering은 K개의 평균값을 통한 Clustering으로 해석하면 의미 파악이 쉽다. 즉, K개의 Partition을 만들기 위해서 K개의 평균값을 찾아 이를 기반으로 더 가까운 평균값에 속하는 Partition에 data를 분배하는 방식이다.\n\n그렇다면, 우리가 구해야할 값은 각 data가 어느 Partition에 속하는지에 대한 정보($\\bold{r}\\leftarrow\\text{one hot vector}$)와 각 Partition의 평균값($\\mu$)이다. 즉, K-means Clustering에서는 기존 data들을 통해서 K개의 평균값(K-means)을 찾아서(**Learning**) 이후에 추가로 들어올 data에 대해서도 똑값은 K-means를 통해서 Partition을 찾을 수 있다(**Inference**).또는 모든 data를 저장해두었다가 K-means를 다시 계산하는 방법도 있다(Online K-means).\n\n그렇다면, $\\boldsymbol{\\mu}(=\\{\\mu_{1}, \\mu_{2}, \\cdots, \\mu_{K}\\})$와 $\\bold{R}$(모든 data의 $\\bold{r}$로 이루어진 Matrix)을 어떻게 구할 수 있을까? 이에 대한 해답은 다음과 같은 Cost Function을 제시하는 것으로 해결할 수 있다.\n\n$$\n\\mathcal{L} = \\min_{\\boldsymbol{\\mu}}\\min_{\\bold{R}} \\sum_{i \\in \\{1,2, \\cdots, N\\}}\\sum_{k \\in \\{1, 2, \\cdots, K\\}}\\bold{R}_{ik}||x_{i} - \\mu_{k}||^{2}\n$$\n\n현재 data의 point로 부터 가장 가까운 평균을 선택하는 경우를 최대화해야 해당 값이 가장 작아질 수 있다는 것을 알 수 있다. <mark>즉, 여기서는 평균과의 거리를 유사성의 지표로 사용한 것이다.</mark> 여기서는 Euclidean distance(L2-norm)를 사용했지만, Manhatan distance(L1-norm)을 활용할 수도 있고 아예 다른 지표를 활용할 수도 있다. 중요한 것은 Cost Function이 아래와 같은 form을 가진다는 것이다.\n\n$$\n\\mathcal{L} = \\min_{\\boldsymbol{\\mu}}\\min_{\\bold{R}} \\sum_{i \\in \\{1,2, \\cdots, N\\}}\\sum_{k \\in \\{1, 2, \\cdots, K\\}}\\bold{R}_{ik}\\times(\\text{Similarity measure})\n$$\n\n그렇다면, 실제로 위에서 제시한 Cost Function을 활용하여 어떻게 $\\boldsymbol{\\mu}$와 $\\bold{R}$을 구할 수 있을까? minimize하고자하는 요소가 두 개이기 때문에 미분을 하기도 다소 난해하다. 따라서, 여기서는 EM Algorithm이라는 방식을 제시한다. 이에 대해서는 다음 Posting에 대해서 자세히 다루겠지만, 간단히 설명하자면 하나의 Variable을 Random하게 지정하고, 다른 Variable의 최적값을 구한 후 이를 다시 대입하고 반대 Variable을 최적값으로 구하기를 반복하면서 더 이상 Variable이 유의미하게 변경되지 않을 때까지 반복해서 구한 값이 최적값과 근사한다는 점을 활용한 Algorithm이다. 지금은 다소 엉뚱할 수 있지만, 지금은 해당 방법을 사용하도록 하겠다. 증명이 궁금하다면, 해당 Posting([🔗 [ML] 10. EM Algorithm](/posts/ml-em-algorithm))을 참고하자.\n\n따라서, 우리가 수행할 과정은 다음과 같다.\n\n1. $\\boldsymbol{\\mu}$를 랜덤하게 초기화한다.\n2. Assignment step: $\\boldsymbol{\\mu}$가 주어졌을 때, $\\bold{R}$을 구한다.  \n   $$\n   R_{ik} = \\begin{cases}\n    1 & \\text{if}\\quad k = \\argmin_{k}||x_{i} - \\mu_{k}||^{2} \\\\\n    0 & \\text{otherwise}\n   \\end{cases}\n   $$\n3. Update step: $\\bold{R}$이 주어졌을 때, $\\boldsymbol{\\mu}$를 구한다.  \n   우리가 분류한 $R$을 활용하여 각 k에 속하는 data의 평균을 통해서 $\\boldsymbol{\\mu}$를 구한다.\n   $$\n   \\mu_{k} = \\frac{\\sum_{i=1}^{N}R_{ik}x_{i}}{\\sum_{i=1}^{N}R_{ik}}\n   $$\n4. 특정값으로 $\\boldsymbol{\\mu}$가 수렴할 때까지 2번, 3번 과정을 반복한다.\n\n아래는 이 과정을 그림을 통해서 표현한 것이다.\n\n![ml-clustering-1](/images/ml-clustering-1.jpg)\n\nK-means 방식은 위와 같은 Iteration 절차를 많이 수행하지 않아도 몇번의 수행만으로 수렴한다는 것을 관측할 수 있다. 또한, Assignment 시에는 $O(KND)$의 시간이 소모되고, Update 시에는 $O(N)$ 만큼의 시간이 소모되기 때문에 무겁지 않고, 굉장히 간단하다는 장점을 갖고 있다. 하지만, 이 방법은 Global Optimal을 찾을 것이라는 확신을 줄 수 없다. 그렇기에 초기값을 어떻게 잡느냐에 따라서 결과가 크게 변할 수도 있다. 뿐만 아니라, outlier data에 대해서도 굉장히 민감하게 반응한다는 단점이 있다. 예를 들어, 아래 사진에서 왼쪽보다 오른쪽이 더 성공적인 Clustering이라고 말할 수 있을 것이다.\n\n![ml-clustering-2](/images/ml-clustering-2.jpg)\n\n이를 해결하기 위한 방법으로 다음과 같은 방법들이 제시되었다.\n\n1. **K-means++**: 초기값을 잘 설정하기 위한 방법으로, 초기값을 잘 설정하면 수렴하는 속도가 빨라지고, Global Optimal에 수렴할 가능성이 높아진다.\n2. **K-mendoids**: K-means에서는 중심점을 data의 평균으로 설정했지만, K-mendoids에서는 중심점을 data의 중간값으로 설정한다. 이렇게 하면 outlier에 민감하지 않게 된다.\n\n> <mark>**Soft K-means**</mark>\n\n마지막으로 K-means Clustering에서 확률적인 접근을 시도한 방법 또한 소개하겠다. 앞 서 본 (Hard)K-means에서는 $\\bold{R}_{ik}$를 0 또는 1로 보았다. 하지만, 이를 확률적으로 표현하는 것에 대해서 생각해 볼 수 있다. 즉, 다음과 같이 soft-max function을 활용한다면 표현이 가능할 것이다.\n\n$$\n\\bold{R}_{ik} = \\frac{\\exp(-\\beta||x_{i}-\\mu_{k}||^{2})}{\\sum_{l \\in {1, 2, \\cdots, K}} \\exp(-\\beta||x_{i}-\\mu_{l}||^{2})}\n$$\n\n이렇게 확률적으로 표현하게 되면, 우리는 추가적인 정보를 활용할 수 있다. 대표적으로 특정 Cluster로 해당 확률이 편향되어 있을 수록 더 좋은 분류일 것이라는 사전 지식(Prior)을 활용할 수 있다. 따라서, 우리는 다음과 같이 Cost Function을 변경할 수 있다.\n\n$$\n\\mathcal{L} = \\min_{\\boldsymbol{\\mu}}\\min_{\\bold{R}} \\sum_{i \\in \\{1,2, \\cdots, N\\}}\\sum_{k \\in \\{1, 2, \\cdots, K\\}}\\bold{R}_{ik}||x_{i} - \\mu_{k}||^{2} - \\frac{1}{\\beta}\\sum_{i \\in \\{1,2, \\cdots, N\\}}\\sum_{k \\in \\{1, 2, \\cdots, K\\}}\\bold{R}_{ik}\\log\\bold{R}_{ik}\n$$\n\n뒷 부분에 새로 추가된 $-\\frac{1}{\\beta}\\sum_{i \\in \\{1,2, \\cdots, N\\}}\\sum_{k \\in \\{1, 2, \\cdots, K\\}}\\bold{R}_{ik}\\log\\bold{R}_{ik}$는 $R_{ik}$가 확률이 되었기 때문에 사실상 Entropy를 의미한다. Entropy는 균형잡힌 분포일 수록 커지고, skew된 경우에는 작아지기 때문에 적절한 지표라고 할 수 있다. $\\beta$는 이러한 prior를 얼마나 사용할지에 대한 hyperparameter이다. $\\beta$가 클 수록 사실상 Hard K-means와 동일한 결과를 얻게 되고, $\\beta$가 작을 수록 Entropy를 더 중요시하는 결과를 얻게 된다.\n\n### Gaussian Mixture Model\n\nGaussian Mixture Model, 일명 GMM은 Finite Mixture Model의 일종이다. Finite Mixture Model은 우리가 추정하고자 하는 확률 분포가 다양한 확률 분포 몇 개의 조합으로 이루어진 분포라고 가정하고, 해당 확률 분포의 Parameter를 학습(Learning) 단계에서 찾아내고, 이를 이용해서 새로운 data에 대해서 추정(Inference)하는 방식이다.\n\n$$\np(x) = \\sum_{k \\in \\{1, 2, \\cdots, K\\}}p(x, z=k) = \\sum_{k \\in \\{1, 2, \\cdots, K\\}}p(x|z=k)p(z=k) = \\sum_{k \\in \\{1, 2, \\cdots, K\\}}p_{k}(x)p(z=k)\n$$\n\n여기서 $z$는 관측할 수 없는 latent(hidden) variable로 data가 몇 번째 확률 분포에 속할 것인지를 의미한다. 따라서, $p(z=k)$ k번째 분포에 속할 확률이라고 볼 수 있다. 대게 이것이 어느정도로 확률 분포를 섞는지를 의미하기 때문에 mixing parameter라고도 부른다.\n\n이에 따라 GMM은 각 $p_{k}(x)$가 Gaussian Distribution이라고 가정하는 Finite Mixture Model인 것이다.\n\n![ml-gmm-graphical-form](/images/ml-gmm-graphical-form.jpg)\n\n그렇다면, 우리는 다음과 같이 Graphical Model 형태로 Finite Mixture Model을 생성할 수 있다. 여기서 $\\pi,\\, \\mu,\\, \\Sigma$는 Parameter를 의미한다.\n\n- $\\pi_{k} = p(z = k)$\n- $\\mu_{k} = E[x|z=k]$ 즉, Gaussian의 기댓값을 의미한다.\n- $\\Sigma_{k} = Cov[x|z=k]$ 즉, Gaussian의 분산을 의미한다.\n\n이를 통해서 우리는 위에서 제시한 확률을 다음과 같이 재정의할 수 있다. (Joint Probability를 Bayesian Network로 푼 식이다. 모르겠다면, [🔗 [ML] 8. Graphical Model](/posts/ml-graphical-model#Graphical-Model)에서 Bayesian Network를 다시 살펴보고 오자.)\n\n$$\n\\begin{align*}\np(x) &= \\sum_{k \\in \\{1, 2, \\cdots, K\\}}p(x, z=k) \\\\\n&= \\sum_{k \\in \\{1, 2, \\cdots, K\\}}p(z=k| \\pi_{k})p(x|z=k, \\mu_{k}, \\Sigma_{k}) \\\\\n&= \\sum_{k \\in \\{1, 2, \\cdots, K\\}}\\pi_{k}\\mathcal{N}(x|\\mu_{k}, \\Sigma_{k})\n\\end{align*}\n$$\n\n여기서 우리가 실제로 추측(Inference)을 할 때에는 $p(z|x)$가 필요하다. 이는 우리가 posterior를 활용해서 구할 수 있다.\n\n$$\n\\begin{align*}\n\\hat{k} &=\\argmax_{k}p(z=k|x) \\\\\n&= \\argmax_{k}\\frac{p(x|z=k)p(z=k)}{p(x)} \\\\\n&= \\argmax_{k}p(x|z=k)p(z=k)\\\\\n&= \\argmax_{k}\\pi_{k}\\mathcal{N}(x|\\mu_{k}, \\Sigma_{k})\n\\end{align*}\n$$\n\n학습(Learning)을 할 때에는 결국 $\\pi,\\, \\mu,\\, \\Sigma$ 이 세 개의 parameter 값을 찾는 것이 중요하다. 이것은 우리가 Parametric Estimation에서 줄기차게 했던 MLE를 이용하면 된다. 이를 위한 Likelihood는 다음과 같다.\n\n$$\n\\begin{align*}\n\\mathcal{L}(\\pi,\\, \\mu,\\, \\Sigma) &= \\log{p(\\mathcal{D} | \\pi,\\, \\mu,\\, \\Sigma)} \\\\\n&= \\log{\\prod_{i=1}^{N}{p(x_{i} | \\pi,\\, \\mu,\\, \\Sigma)}} \\\\\n&= \\sum_{i=1}^{N}{\\log{p(x_{i}| \\pi,\\, \\mu,\\, \\Sigma)}} \\\\\n&= \\sum_{i=1}^{N}{\\log{\\sum_{k=1}^{K}{\\pi_{k}\\mathcal{N}(x_{i}|\\mu_{k}, \\Sigma_{k})}}}\n\\end{align*}\n$$\n\n하지만, 이것을 단순한 Optimization Technique으로는 풀 수 없다. 왜냐하면, 단순한 미분으로 각 parameter를 구할 수 없기 때문이다. 따라서, EM Algorithm을 이용해서 풀어야 한다. (이것은 [🔗 [ML] 10. EM Algorithm](/posts/ml-em-algorithm)에서 다룬다.)\n\n따라서, 아래 그림과 같이 임의의 $\\pi,\\, \\mu,\\, \\Sigma$를 가정한 상태에서 data에 알맞는 최적의 Cluster set을 구하고, data에 cluster가 label된 상태에서 최적의 $\\pi,\\, \\mu,\\, \\Sigma$를 구하는 과정을 반복하는 것이다.\n\n![ml-gmm-1](/images/ml-gmm-1.jpg)\n\n그렇다면, 이를 실제로 어떻게 하는지를 알아보도록 하겠다. 하지만, 그냥 모든 Gaussian 형태를 위한 방법을 사용하면 다소 식이 복잡해지기 때문에 isotropic Gaussian(모든 방향에서 분산이 동일한 Gaussian)을 가정으로 하겠다.\n\n또한, 다음과 같은 요소를 추가로 정의하자.\n\n1. $z_{i} \\in \\{1, 2, \\cdots, K\\}$ : $i$번째 data가 속하는 cluster의 index  \n   $z_{ik} = \\begin{cases} 1 & \\text{if } z_{i} = k \\\\ 0 & \\text{otherwise} \\end{cases}$\n2. $\\theta_{k} = (\\pi_{k},\\, \\mu_{k},\\, \\Sigma_{k})$ : $k$번째 cluster를 위한 parameter의 집합  \n   $\\theta = (\\pi,\\, \\mu,\\, \\Sigma)$ : parameter의 집합  \n\n앞 서 말한 바와 같이 이제 우리는 $\\theta$를 구하는 과정에서 $z_{i}$에 해당하는 정보도 알고 있다. 따라서, Likelihood 식도 변형되어야 한다.\n\n$$\n\\begin{align*}\n\\mathcal{L}(\\theta) &= \\log{p(\\mathcal{D} | \\theta)} \\\\\n&\\geq \\log{p(X, Z | \\theta)} \\\\\n&= \\sum_{i=1}^{N}{\\log{p(x_{i}, z_{i}| \\theta)}} \\\\\n&= \\sum_{i=1}^{N}{\\log{p(z_{i} | \\theta) \\times p(x_{i}| z_{i}, \\theta)}} \\\\\n&= \\sum_{i=1}^{N}{\\log{(\\prod_{k=1}^{K}{\\pi_{k}^{z_{ik}}} \\times \\prod_{k=1}^{K}{\\mathcal{N}(x_{i}|\\mu_{k}, \\Sigma I)^{z_{ik}}})}} \\\\\n&= \\sum_{i=1}^{N}{\\sum_{k=1}^{K}\\log{({\\pi_{k}}{\\mathcal{N}(x_{i}|\\mu_{k}, \\Sigma I)})^{z_{ik}}}} \\\\\n&= \\sum_{i=1}^{N}{\\sum_{k=1}^{K}z_{ik}\\log{({\\pi_{k}}{\\mathcal{N}(x_{i}|\\mu_{k}, \\Sigma I)})}} \\\\\n\\end{align*}\n$$\n\n이에 따라서 우리는 EM Algorithm의 $\\mathcal{Q}$를 다음과 같이 구할 수 있다.\n\n$$\n\\begin{align*}\n\\mathcal{Q}(\\theta; \\theta^{\\prime}) &= \\sum_{i=1}^{N}E_{z_{i}|x_{i}, \\theta^{\\prime}}[\\log p(x_{i}, z_{i} | \\theta)] \\\\\n&= \\sum_{i=1}^{N}E_{z_{i}|x_{i}, \\theta^{\\prime}}[\\sum_{k=1}^{K}z_{ik}\\log{({\\pi_{k}}{\\mathcal{N}(x_{i}|\\mu_{k}, \\Sigma I)})}] (\\because \\text{위의 식에서 3번째 줄을 참고})\\\\\n&= \\sum_{i=1}^{N}\\sum_{k=1}^{K}E_{z_{i}|x_{i}, \\theta^{\\prime}}[z_{ik}\\log{({\\pi_{k}}{\\mathcal{N}(x_{i}|\\mu_{k}, \\Sigma I)})}] \\\\\n&= \\sum_{i=1}^{N}\\sum_{k=1}^{K}E_{z_{i}|x_{i}, \\theta^{\\prime}}[z_{ik}\\log{({\\pi_{k}}{\\mathcal{N}(x_{i}|\\mu_{k}, \\Sigma I)})}] \\\\\n&= \\sum_{i=1}^{N}\\sum_{k=1}^{K}E_{z_{i}|x_{i}, \\theta^{\\prime}}[z_{ik}]\\log{({\\pi_{k}}{\\mathcal{N}(x_{i}|\\mu_{k}, \\Sigma I)})} \\\\\n\\end{align*}\n$$\n\n따라서, 우리는 각 step을 다음과 같이 정의할 수 있다.\n\n- **E-step**  \n  $\\mathcal{Q}$에서 parameter($\\pi,\\, \\mu,\\, \\Sigma$)를 제외하고, 아직 미지수로 남아있는 값은 $E_{z_{i}|x_{i}, \\theta^{\\prime}}[z_{ik}]$이다. 즉, 이 값만 구하면 $\\mathcal{Q}$를 구했다고 할 수 있다.  \n  $$\n  \\begin{align*}\n  E_{z_{i}|x_{i}, \\theta^{\\prime}}[z_{ik}] &= \\sum_{k=1}^{K}{z_{ik}p(z_{i} = k | x_{i}, \\theta^{\\prime})} \\\\\n  &= p(z_{i} = k^{*} | x_{i}, \\theta^{\\prime}) = r_{ik^{*}}\n  \\end{align*}\n  $$  \n  결국 우리가 해당 단계에서 구할 것은 관측 가능한 data와 이전 parameter가 주어졌을 때, 속하게 되는 cluster에서의 확률을 구하는 것이다. 이것을 모든 data에 대해서 구하면, $\\mathcal{Q}$에서 parameter를 제외한 모든 부분을 구할 수 있다. 따라서, 식을 좀 더 정리하면 다음과 같은 결론을 얻을 수 있다.\n  $$\n  \\begin{align*}\n  E_{z_{i}|x_{i}, \\theta^{\\prime}}[z_{ik}] = r_{ik^{*}} &= \\frac{p(x_{i}, z_{i}=k^{*} | \\theta^{\\prime})}{p(x_{i}|\\theta^{\\prime})} \\\\\n  &= \\frac{\\pi_{k^{*}}^{\\prime}{\\mathcal{N}(x_{i}|\\mu_{k^{*}}^{\\prime}, \\Sigma_{k^{*}}^{\\prime} I)}}{\\sum_{l=1}^{K}{\\pi_{l}{\\mathcal{N}(x_{i}|z_{i} = l, \\mu_{l}, \\Sigma_{l} I)}}}\n  \\end{align*}\n  $$  \n  \n- **M-step**  \n  결론적으로 우리는 다음과 같은 $\\mathcal{Q}$와 constraint를 얻었다.  \n  $$\n  \\begin{align*}\n  \\text{maximize}&\\quad \\mathcal{Q}(\\theta; \\theta^{\\prime}) = \\sum_{i=1}^{N}\\sum_{k=1}^{K}r_{ik}\\log{({\\pi_{k}}{\\mathcal{N}(x_{i}|\\mu_{k}, \\Sigma I)})} \\\\\n  \\text{subject to}&\\quad \\sum_{k=1}^{K}{\\pi_{k}} = 1\n  \\end{align*}\n  $$  \n  이제 우리는 이를 Optimization 방식을 활용하여 풀기만 하면 끝이다. ([🔗 참고(Base Knowledge)](/posts/ml-base-knowledge))  \n  $$\n  \\begin{align*}\n  \\mu_{k} &= \\frac{\\sum_{i=1}^{N}{r_{ik}x_{i}}}{\\sum_{i=1}^{N}{r_{ik}}} \\\\\n  \\Sigma_{k} &= \\frac{\\sum_{i=1}^{N}{r_{ik}||x_{i} - \\mu_{k}||^{2}}}{\\sum_{i=1}^{N}{r_{ik}}} \\\\\n  \\pi_{k} &= \\frac{1}{N}\\sum_{i=1}^{N}{r_{ik}}\n  \\end{align*}\n  $$\n\n---\n\n마지막으로 짚고 넘어갈 것은, 바로 K-means Clustering은 사실 GMM의 하나의 special case라는 것이다. 만약, 우리가 $\\pi_{k},\\, \\Sigma_{k}$를 모두 같은 값으로 설정하면, $\\pi_{k} = \\frac{1}{K}$이고 $\\Sigma_{k} = \\Sigma$가 된다고 하자. 이때 EM algorithm을 살펴보면 다음과 같다.\n\n- **E-step**  \n  $$\n  r_{ik} = \\begin{cases} 1 & k = \\argmax_{l\\in \\{1, 2, \\cdots, K\\}} p(x_{i}|z_{i} = l, \\mu_{l}, \\Sigma) \\\\ 0 & \\text{otherwise} \\end{cases}\n  $$  \n  이는 사실상 K-means Clustering에서 중심과의 거리를 통해서 구했던 것과 매우 유사한 식이다.\n- **M-step**  \n  $$\n  \\begin{align*}\n  \\mu_{k} &= \\frac{\\sum_{i=1}^{N}{r_{ik}x_{i}}}{\\sum_{i=1}^{N}{r_{ik}}} \\\\\n  \\pi_{k} &= \\frac{1}{N}\\sum_{i=1}^{N}{r_{ik}}\n  \\end{align*}\n  $$  \n  $\\pi_{k}$가 추가되기는 했지만, $\\mu_{k}$를 구하는 식은 완전 동일하다.\n\n## Reference\n\n- Tumbnail : Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n","slug":"ml-clustering","date":"2022-11-23 09:19","title":"[ML] 9. Clustering","category":"AI","tags":["ML","UnsupervisedLearning","Clustering","K-means","GMM"],"desc":"이전까지의 Posting에서는 Supervised Learning 즉, 이미 Labeling이 완료된 데이터에 의한 Learning을 중점적으로 다루었다. 지금부터는 Unsupervised Learning에 대해서 조금 더 살펴보도록 하겠다. 대표적인 Unsupervised Learning은 Clustering, Feature Selection(or Dimensionality Reduction), Generative Model 등이 존재한다. 이들에 대해서 차근차근 살펴보도록 하고, 해당 Posting에서는 가장 대표적이라고 할 수 있는 Clustering을 먼저 살펴보면서 Unsupervised Learning에 대한 계략적인 이해를 해보도록 하겠다.","thumbnailSrc":"https://euidong.github.io/images/ml-thumbnail.jpg"},{"content":"\n## Intro\n\nNatural Language(자연어, 사람이 사용하는 통상 언어)를 input으로 활용하고자 하는 노력은 컴퓨터의 등장부터 시작하여 여러 번 시도되어 왔다. 지금까지도 완벽하게 이를 처리하는 것은 힘들다. 왜 Natural Language를 다루는 것은 어렵고, 이를 해결하기 위해서 NLP에서는 어떤 방식을 활용할지에 대한 개략적인 overview를 제시한다. 또한, Natural Language의 특성과 분석 단계를 이해하기 위해서 Linguistics(언어학)을 간략하게 정리한다.\n\n## NLP\n\nNatural Language Processing의 약자로 사람이 사용하는 언어를 input으로 하여 원하는 값을 추출해내는 것이 목표이다. 이를 위해서 우리는 사람의 언어를 이해하거나 다룰 수 있는 능력을 컴퓨터에게 부여해야 한다.\n\n먼저, 이러한 필요가 있는 대표적인 usecase를 살펴보면 다음과 같다.\n\n### Usecase\n\n- **Spam Detection**  \n  가장 간단한 예시로 mail에서 spam 여부를 확인하는 기능이다.\n- **POS tagging / NER**  \n  특정 단어 단위의 처리를 수행하게 되는데 단어의 품사와 대략적인 의미를 가진 category로 분류로 tagging하는 과정이다. 이를 기반으로 하여 다른 usecase에서 활용하는 경우가 많다. 품사와 category는 단어의 뜻을 추론하는데 큰 도움을 주며, 이것이 문장의 이해 등에 도움을 주기 때문이다.\n- **Sentiment Analysis**  \n  감정/여론 분석 등의 영역을 의미하며, 텍스트 또는 대화에서의 긍정/부정 여부를 판단하거나 평점 등을 추출하는 기능이다.\n- **Conference Resolution**  \n  \"he\", \"she\" 등 대명사, 생략 단어 등을 원래의 단어로 대체하거나 채우는 과정을 수행한다. 이 역시도 여러 영역에서 이를 기반으로 추가적인 작업을 할 수 있다.  \n- **Word Sense Disambiguation(WSD)**  \n  특정 단어가 주어졌을 때, 동의어, 동음이의어 등에서 가르키는 진짜 의미를 헷갈리지 않게 명확하게 다시 한 번 처리한다. 이 역시도 다른 NLP usecase에서 두루 사용된다.\n- **Parsing**  \n  문장에서 단어들을 의미를 가지는 단위(구, 절, 문장)로 다시 grouping한다. 이 과정을 잘 수행하기 위해서는 이전 단계에서 WSD와 Conference Resolution, POS tagging, NER이 이루어지면 좋다. 이 과정을 통해서 문장의 개략적인 의미를 파악할 수 있다.\n- **Machine Translation(MT)**  \n  특정 언어를 또 다른 Natural Language로 변경하는 기능이다.\n- **Information Extraction(IE)**  \n  특정 문장에서 사용자에게 의미있을만한 데이터를 추출하는 것이다.\n- **Q&A**  \n  특정 사용자가 질문을 하였을 때, 이 뜻을 이해하고, 이에 적절한 대답을 수행하는 방식이다.\n- **Paraphrase**  \n  문장의 뜻을 이해하고, 더 쉬운 형태의 표현으로 변환하는 기능이다.\n- **Summarization**  \n  여러 문장으로 이루어진 글의 의미를 이해하고, 적절한 내용으로 요약하는 기능이다.\n- **Dialog**  \n  Natural Language를 사용하는 사람과 1:1로 담화를 주고 받는 것이다. 의미를 이해할 뿐만 아니라 자신이 내보낼 output에 대해서도 적절하게 생성할 수 있는 능력이 필요하다.\n\n위와 같이 많은 usecase가 있는데 이를 구현하는 것은 지금까지도 굉장히 challenge한 부분이다. 그것은 Natural Language가 가지는 몇몇 특징 때문이다.\n\n### Why is NLP difficult?\n\n여기서는 Natural Language 중에서 영어를 기반으로 한 설명이지만, 한국어도 매우 유사하다.\n\n- **non-standard** : Natural Language를 사용하는 사람들이 표준을 항상 따르지는 않는다는 것이다. 우리는 약어를 사용하거나 문법에 맞지 않는 비문을 사용하여 의사소통을 하기 때문에 이것을  시스템이 이해하게 하는 것은 어렵다.\n- **segmentation** issues : 의미를 가지는 단어 단위로 묶는 것이 어렵다는 것이다. 우리는 문장의 띄어쓰기를 어디로 받아들이냐에 따라서 의미가 달라지는 것을 본 경우가 있을 것이다.\n- **idioms** : 관용구의 사용은 NLP에서 예외처리로 해주어야 하는 것이다. 단어 그대로의 의미와 다른 의미를 가지기 때문이다.\n- **neologisms** : 신조어는 계속해서 생겨나기 때문에 이를 계속해서 업데이트 해주는 것도 부담이 된다.\n- **world knowledge** : 사전 지식을 알고 있어야 이해할 수 있는 단어, 문장이 존재한다. 즉, 어떤 지식을 가지고 있느냐에 따라서 해석이 달라진다는 것이다.\n- **tricky entity names** : 고유 명사 중에서 특히 contents(노래, 그림, 소설) 등의 제목이 해석 시에 헷갈리게 한다. 예를 들면, \"Let it be\"라는 비틀즈의 노래는 문장 중간에 들어가면, 하나의 문장으로 받아들여지게 되는데 이를 잘 해결할 수 있도록 해야 한다.\n\n위의 내용을 요약하자면, 다양한 단어가 다양한 현상과 다양한 법칙(Grammer)의 영향을 받기에 어려우며, 단어가 가지는 모호성이 문제를 야기한다는 것이다.\n\n### Solutions\n\n이러한 문제를 해결하기 위해서 크게 두 가지 방식을 사용할 수 있다.\n\n- Rule based approach  \n  Gammer와 같은 법칙을 모두 적용해서 prgoramming을 하는 것이다. 하지만, 이 방식은 비문과 같은 문장을 제대로 처리할 수 없을 뿐만 아니라 정확한 형태의 문장이라도 여러 의미로 해석되는 문장에서 경향성과 문맥을 전혀 파악할 수 없다.\n- Statistic based approach  \n  그래서 최근에는 경향성과 문맥을 파악할 수 있도록 AI 기술, ML, Deep Learning을 이용하여 NLP를 수행하는 것이 하나의 trend로 자리 잡았다. 그렇다면, 어떻게 통계적인 접근법이 경향성과 문맥을 포함할 수 있을까? 이는 통계가 가지는 경향성이라는 특징과 conditional probability를 사용할 때의 문맥을 포함한 경향성을 파악할 수 있다는 점을 활용해서 가능하다.\n\n## Linguistics\n\n결국 앞으로 통계적인 방식을 활용하더라도 우리는 최소한의 언어학적인 기본이 필요하다. 왜냐하면, 통계에 사용할 데이터를 처리하기 위해서이다. 우리가 사용할 데이터는 text 또는 음성이다. 이를 적절하게 처리하여 통계에 사용할 유의미한 데이터로 변환하는 과정이 필요하다. 이를 위해서 언어학에 대한 이해가 필요한 것이다.\n\n일반적으로 언어를 분석할 때, 사용할 수 있는 도구는 **Grammar**이다. 이는 특정 language에서 허용되는 규칙의 집합을 정리한 것이다. 이것의 종류는 크게 두 가지로 나뉜다.\n\n- **Classic Grammar**  \n  사람이 실제로 언어를 사용함에 있어 발생하는 이상한 습관과 같은 언어 표현이다. 이러한 법칙들은 대게 예제들을 통해서 정의되는데 이런 것을 명확하게 구분할 수 있는 명백한 도구가 존재하지는 않는다. 예를 들면, 감탄사와 같은 것들이 여기에 포함되겠다. 이는 이러한 변칙적인 형태 때문에 programming적으로 표현하는 것이 불가능하다.\n- **Explicit Grammar**  \n  명백하게 정의되어 있는 언어 규칙을 의미한다. 이는 Programm으로 구현할 수 있으며, 여러 Grammar 정리 내용이 이미 정리되어 있다. (CFG, LFG, GPSG, HPSG, ....)  \n  이를 문법적으로 분석하기 위해서 우리는 6단계의 순차적인 처리가 필요하다.\n\n### 6 Layers in Language\n\n각 단계는 input과 output을 가진다. 단계적으로 진행되기 때문에 이전 단계의 output이 다음 단계의 input이 되며, 때때로 몇 단계는 생략될 수 있기에 유연하게 생각하도록 하자.\n\n각 단계에서 실제로 특정 문장이 처리되는 과정을 이해하기 위해서 \"Astronomers saw stars with telescope\"라는 문장이 음성 또는 text로 들어왔을 때를 가정하여 각 단계에는 무엇을 하고 이를 통해서 어떻게 이 문장을 바꿀 수 있는지를 확인해보겠다.\n\n> **1. Phonetics/Orthography(음성학/맞춤법)**\n\n먼저 Orthography는 맞춤법 검사를 의미하며, character sequence로 input이 들어오면, 이를 맞춤법에 맞는지를 확인하여 이것이 수정된 sequence로 반환한다.  \n예시 문장에 있는 \"telescope\"는 문법에 맞지 않으므로 \"telescopes\"로 바뀌어야 한다.\n\n| input                                 | output                                 |\n| :------------------------------------ | :------------------------------------- |\n| Astronomers saw stars with telescope. | Astronomers saw stars with telescopes. |\n\nPhonetics는 음성학을 의미하며, 혀와 음성의 영향을 주는 다양한 근육의 위치 형태, 모양, 빈도를 활용하여 자음과 모음을 분류하는 작업을 수행한다. Orthoography와는 달리 억양이라는 것을 추가적으로 활용할 수 있다.\n\n| input                                                       | output                                 |\n| :---------------------------------------------------------- | :------------------------------------- |\n| Astronomers saw stars with telescopes.를 의미하는 음성 신호 | əsˈtrɒnəməz sɔː stɑːz wɪð ˈtɛlɪskəʊps. |\n\n*<https://tophonetics.com/> 을 통해서 변환하여 얻을 수 있다.\n\n> **2. Phonology/Lexicalization(음운론/어휘화)**\n\nPhonology은 음운론으로 소리와 phonemes(음소)사이의 관계를 이용하여, 음소를 특정 word로 변환하고, Lexicalization에서는 해당 단어를 사전에서의 형태로 변환하는 과정을 수행한다.\n\n| input                                  | output                                 |\n| :------------------------------------- | :------------------------------------- |\n| əsˈtrɒnəməz sɔː stɑːz wɪð ˈtɛlɪskəʊps. | Astronomers saw stars with telescopes. |\n\n> **3. Morphology(어형론)**\n\nMorphology는 어형론으로 음소의 구성을 기본형(lemma)의 형태로 변환하며, 각 단어들을 형태학적인 의미를 갖는 카테고리(category, tag)로 분류한다.\n여기서 사용되는 lemma와 category가 무엇인지 좀 더 자세히 살펴보자.\n\n- **lemma**  \n  - 사전에 표기되는 단어의 기본형으로, 사전에서 word를 찾는 pointer가 된다.  \n  - 동음이의어의 경우 특정 뜻을 지칭하고 싶은 경우에는 numbering을 수행하기도 한다.\n  - 더 나아가서는 형태소(morpeheme)까지 구분하기도 한다. 이는 혼자서 쓰일 수 있는 자립 형태소(root)와 의존 형태소(stem)으로 나눌 수 있다.  \n    - 예를 들면, quotations -> quote[root] + -ation[stem] + -s[stem]\n    - 위와 같은 형태로 세분화할 수도 있지만, 대게는 lemma 단위에서 그친다.\n- **categorizing**  \n  - category는 정하기 나름이며, 이미 정해져있는 tagset들도(Brown, Penn, Multext) 많이 존재하고, 억양이나 실제 분류 등을 수행하는 것도 가능하다.\n  - **POS tagging**은 category를 분류하는 방법 중에서 가장 유명한데, 이는 여러 언어에서 거의 호환되기 때문에 이 방식을 활용하여 분석하는 것이 가장 안정적인 방법이라고 할 수 있다. 이는 별도의 Posting에서 더 자세히 다루도록 하겠다.\n\n또한, 단어의 형태는 언어마다 다양하기 때문에 어느정도 언어마다 다른 작업을 해주어야 한다. 크게 구분되는 형태로 언어를 3개의 종류로 나눌 수 있다.\n\n1. **Analytical Language(고립어)**  \n   하나의 단어가 대게 하나의 morpheme을 가진다. 따라서, 하나 이상의 category로 구분되어질 수 있다.  \n   ex. English, Chinese, Italian\n2. **Inflective Fusional Language(굴절어)**  \n   prefix/suffix/infix가 모두 morpheme에 영향을 미치며, morpheme의 정의 자체가 애매해지는 언어 형태  \n   ex. Czech, Russian, Polish, ...\n3. **Agglutinative Language(교착어)**  \n   하나의 단어에는 morpheme이 명확하게 구분되고, prefix/suffix/infix 또한 명확하게 구분 가능하다. 따라서, 각 morpheme에 명확한 category를 mapping하는 것이 가능하다.  \n   ex. Korean, ...\n\n| input                                  | output(based on Brown tagset)                                         |\n| :------------------------------------- | :-------------------------------------------------------------------- |\n| Astronomers saw stars with telescopes. | (astronomer/NNS) (see/VBD) (star/NNS) (with/IN) (telescope/NNS) (./.) |\n\n> **4. Syntax(통사론)**\n\nlemma나 morpheme을 구문의 요소인 S(Subject, 주어), V(Verb, 동사), O(Object, 목적어)와 같은 요소로 분류한다. 이 분류를 수행할 때에는 문장의 구성요소를 알아야 한다. 이를 bottom-up으로 살펴보자.\n\n- **Word(단어)**  \n  사전에 명시된 하나의 단위라고 볼 수 있다. 이는 관용어(dark horse)를 포함한다.\n- **Phrase(구)**  \n  둘 이상의 단어 또는 구의 결합으로 만들어진다. 대게 하나의 문법적인 의미로 변환되어진다.  \n  - 대표적인 예시\n    - Noun : a new book\n    - Adjective : brand new\n    - Adverbial : so much\n    - Prepositional : in a class\n    - Verb : catch a ball\n  - **Elipse(생략)**  \n    대게 단어 또는 구가 생략되는 경우가 많다. 특히 담화의 경우 더욱 그렇다.  \n    이를 추론을 통해서 추가할 수도 있다.\n- **Clause(절)**  \n  절은 주어와 서술어를 갖춘 하나의 문장과 유사하지만, 문장 요소로서 더 상위 문장에 속하는 경우이다.  \n  또한, 영어에서는 특히 접속사로 연결된 절이 아닌 경우에는 해당 절이 지칭하는 대상이 절 내부에서 생략된다. 이를 gap이라고 한다.\n- **Sentense**  \n  하나 이상의 절로 이루어지고, 영어에서는 시작 시에 대문자로 표기하며 종료 시에는 구분자로 .?!로 끝난다.\n\n결국 우리는 이러한 요소를 적절하게 표시해야 하는데, 이를 위해서 tree 구조를 사용하는 것이 일반적이다. 대표적으로 두 가지의 구조가 있다.\n\n1. **phrase structure(derivation tree)**\n   문장을 기점으로 절, 구, 단어로 top-down으로 내려가는 구조를 가진다.  \n   각 단위를 묶을 때에는 ()를 이용하고, 그 뒤애 해당하는 내용이 무슨 구, 절인지를 표기한다.\n2. **dependency structure**  \n   단어 간의 관계에 더 집중하여 나타낸다. 따라서, 사람이 보기에는 불명확해 보일 수 있지만 특정 usecase에서는 유용하다.\n\n| input                                                                 | output (phrase structure)                                                              |\n| :-------------------------------------------------------------------- | :------------------------------------------------------------------------------------- |\n| (astronomer/NNS) (see/VBD) (star/NNS) (with/IN) (telescope/NNS) (./.) | ((astronomer/NNS)NP ((see/VBD)V ((star/NNS)NP ((with/IN)P (telescope/NNS)NP)PP)NP)VP)S |\n\n![nlp-phase-structure](/images/nlp-phase-structure.jpg)\n\n> **5. Semantics(Meaning, 의미론)**\n\n간단하게는 주어, 목적어와 같은 tag나 \"Agent\"나 \"Effect\"와 같은 tag를 적용하며, 전체적인 의미를 유추해낸다.\n\n| input                                                                                  | output                                                                                                |\n| :------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------- |\n| ((astronomer/NNS)NP ((see/VBD)V ((star/NNS)NP ((with/IN)P (telescope/NNS)NP)PP)NP)VP)S | ((astronomer/NNS)NP/agent ((see/VBD)V ((star/NNS)NP/affected ((with/IN)P (telescope/NNS)NP)PP)NP)VP)S |\n\n> **6. Discourse/Pragmatics(담화/화용론)**\n\n실제 대화 등과 같은 목표를 해결하기 위해서 앞서 보았던 문장 구조를 이용한다.\n\n만약, 해당 데이터를 통해서 하고자 하는 것이 이 이야기를 한 사람이 식당 내부에 있는지를 판단하고자 한다고 가정해보자.\n\n| input                                                                                                 | output |\n| :---------------------------------------------------------------------------------------------------- | :----- |\n| ((astronomer/NNS)NP/agent ((see/VBD)V ((star/NNS)NP/affected ((with/IN)P (telescope/NNS)NP)PP)NP)VP)S | False  |\n\n## Reference\n\n- Tumbnail : Photo by [David Ballew](https://unsplash.com/@daveballew?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@daveballew?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n- text to phonetic converter, <https://tophonetics.com>\n","slug":"nlp-linguistics","date":"2022-10-19 09:03","title":"[NLP] 1. Linguistics","category":"AI","tags":["NLP","Languagistics"],"desc":"Natural Language(자연어, 사람이 사용하는 통상 언어)를 input으로 활용하고자 하는 노력은 컴퓨터의 등장부터 시작하여 여러 번 시도되어 왔다. 지금까지도 완벽하게 이를 처리하는 것은 힘들다. 왜 Natural Language를 다루는 것은 어렵고, 이를 해결하기 위해서 NLP에서는 어떤 방식을 활용할지에 대한 개략적인 overview를 제시한다. 또한, Natural Language의 특성과 분석 단계를 이해하기 위해서 Linguistics(언어학)을 간략하게 정리한다.","thumbnailSrc":"https://euidong.github.io/images/nlp-thumbnail.jpg"},{"content":"\n## Intro\n\nNLP를 수행할 때, 우리는 sequence of character를 처리하는 방식을 제대로 알아야 제대로 된 전처리와 후처리 등이 가능하다. 따라서 해당 chapter에서는 어떻게 원본 문자/단어/문장을 처리하는 방식을 다룰 것이다.\n\n## Regular Express\n\n아주 기본적인 문자열 처리 방법이다. 이를 알고 있어야 실질적인 처리가 가능하다. 해당 내용은 별도의 Posting으로 분리하여 다루었다. ([🔗 Regex](/posts/regex))를 살펴보도록 하자.\n\n## Text Normalization\n\n우리가 사용할 NL은 정제되어 있지 않아서 여러 전처리를 수행해야 한다. 그 중에서 대중적으로 좋다고 알려진 방법들을 살펴볼 것이다. 기본적으로는 아래 단계를 처리하는 것이 일반적이다.\n\n1. Word Tokenization  \n   말 그대로 NL 데이터가 입력되었을 때, 이를 단어 단위로 쪼개는 것이다.\n2. Word Reformating  \n   단어를 나누었다면, 각 단어의 형태를 처리하기 쉬운 형태로 Normalizing하는 것이다.  \n3. Sentence Segmentation  \n   문장 단위로 구분해는 과정이다.\n\n이제 각 단계를 세부적으로 다뤄보겠다.\n\n### 1. Word Tokenization\n\n우선 쉽게 생각할 수 있는 것은 단순히 띄어쓰기를 기준으로 구분하는 것이다. 그렇게 하면, 우리는 입력으로 주어진 Corpus에서 token을 추출할 수 있다.\n\n하지만, \"San Francisco\"와 같은 단어가 두 개의 token으로 나누는 것이 아니라 하나의 token으로 처리되기를 원할 수 있다. 뿐만 아니라 일부 언어들(특히 중국어와 일본어)의 경우 띄어쓰기 없이 작성하는 언어들의 경우 문제는 더 커질 수 있다. 이 경우에는 **Word Segmenting**이라는 알고리즘을 활용할 수도 있는데, 원리는 매우 간단하다. 언어의 모든 단어를 포함하는 사전을 기반으로 문장에서 사전에 일치하는 가장 긴 문자열을 찾을 수 있을 때까지 token을 연장해서 만드는 방식이다.\n\n그러나 이 방식도 결국은 특정 언어(중국어, 등)에서는 잘 작동하지만, 일부 언어(영어 등)에서는 잘 작동하지 않는 경우가 많다. 따라서, 최근에는 확률에 기반하여 같이 등장하는 횟수가 많을 경우 하나의 token으로 묶는 형태의 tokenization을 더 선호한다.\n\n이 과정에서 우리가 추가적으로 수행하는 것이 바로 word의 갯수를 추출하는 것이다. 대게 우리가 관심 있어하는 수는 총 3가지이다.\n\n1. **number of tokens**  \n   즉, 띄어쓰기로 나뉘어지는 token들의 총 갯수를 의미한다.\n2. **number of types(Vocabulary)**  \n   띄어쓰기로 나뉘어진 token들의 중복을 제거한 종류들의 갯수를 의미한다. 대게 이러한 type들의 모음을 Vocabulary라고 한다.\n3. **number of each type's tokens**  \n   각 종류의 token이 얼마나 많이 등장했는지를 의미한다.\n\n여기서 이러한 token이나 type이 서로 같나는 것을 어떻게 구분할 수 있을까? 이를 위해서 Word Reformating을 수행하여 좀 더 일반적인 형태로 변형하여 위의 수들을 파악하기도 한다.\n\n### 2. Word Normalization and Stemming(Word Reformating)\n\n대게의 언어는 word의 형태가 여러 개로 존재한다. 이 과정에서 우리가 고려해야 할 것이 정말 많다. 그 중에서 가장 기본적으로 수행되어야 할 내용은 다음과 같다. 해당 내용은 영어에 중심을 둔 설명이다.\n\n1. **Uppercase**  \n   영어에서 첫 글자는 대문자로 시작한다는 규칙이 있다. 또는 강조하고 싶은 단어를 대문자로 표현하기도 한다. 그 결과 token의 종류를 추출하는 과정에서 문제를 일으키기도 한다. 따라서, 이를 모두 lowercase로 바꿔버리는 것이다. 하지만, 모든 경우에 이를 적용할 수 잇는 것은 아니다. 가장 대표적인 예시로 US와 us의 의미가 다르다는 것이다. 또, 고유 명사인 General Motors와 같은 경우도 다르게 처리하는 것이 좋다. 따라서, 이를 고려해서 먼저 처리한 이후에 전체 데이터를 lowercase로 변환하는 방식을 수행한다.  \n2. **Lemmatization**  \n   Lemma(기본형, 사전형)로 단어를 변환하는 것이다. 가장 기본적인 것은 am, are, is와 같은 be동사를 모두 be로 변환하거나 car, cars, car's를 모두 기본형태인 car로 바꾸는 것이다. 대게의 경우에는 이 과정에서 의미를 일부 잃어버리기 때문에 lemma + tag로 기존 token을 복구할 수 있도록 하는 tag를 포함하는 것이 좋다.\n3. **Stemming**  \n   morpheme(형태소)은 중심 의미를 가지는 stem과 핵심 의미는 아니지만 stem에 추가 의미를 더해주는 affixes로 나누어 word를 나눌 수 있다. 따라서, 각 token을 가장 core의 의미를 가지는 stem으로 나타내는 방식이다. 대표적인 예시가 automate, automatic, automation을 automat으로 변환하는 것이다. 이는 lemmatization보다 넓은 범위의 word를 하나로 묶기 때문에 세부의미가 더 손실될 수 있다. 따라서, 기존 의미로 복구할 수 있는 tag를 포함하는 것이 좋다.\n\n### 3. Sentence Segmentation\n\n문장을 구분할 수 있는 도구로 우리는 \"?\", \"!\", \".\"을 활용한다. \"?\"와 \"!\" 같은 경우는 문장의 끝을 의미하는것이 대게 자명하다. 하지만, \".\"은 꽤나 애매할 수 있다. 소수점, Abbreviation(Mr., Dr., Inc.)와 같은 경우에 빈번하게 사용되기 때문이다. 따라서, 이를 판단하기 위해서 Decision Tree를 만들어서 이를 수행한다. 아래와 같이 사람이 직접 규칙을 정할 수도 있지만 현재는 대게 통계 기반으로 수행한다.\n\n![nlp-sentence-segmentation](/images/nlp-sentence-segmentation.jpg)\n\n## Collocation(연어) processing\n\nText Normalization을 통해서 우리는 sentence를 구분하고, word를 추출할 수 있었다. 하지만, 단순히 하나의 word를 기반으로 처리하는 것이 아니라 주변 단어를 활용하여 처리해야만 얻을 수 있는 정보들이 있다. 우리는 이를 Collocation(연어)를 활용하여 수행한다. 이는 특정 단어쌍이 높은 빈도로 같이 붙어 사용되는 현상을 말한다. **\"모든 단어는 이를 동반하는 주변 단어에 의해 특성 지어진다.\"** 따라서, 우리는 이 collocation을 co-ocurrence로 생각할 수 있다. 이를 통해서 우리는 다음과 같은 것들을 할 수 있다.\n\n1. **lexicography(사전 편찬)** : 같가니 유사한 뜻을 가지는 단어는 빈번하게 붙어서 사용되는데 이를 이용해서 하나의 단어의 뜻을 안다면, 이를 통해서 다른 단어의 뜻을 추론하며 확장해나갈 수 있다.\n2. **language modeling** : NL를 통해서 원하는 결과를 얻기 위해서 특정 parameter를 추정해내는 것을 language modeling이라고 하는데 이 과정에서 collocation을 활용하는 것이 단일 단어를 활용하는 것보다 context를 활용할 수 있다는 점에서 장점을 발휘할 수 있다.\n3. **NL generation** : 우리는 문맥상 매끄러운 문장을 원한다. 즉, \"감을 잡다\"를 \"감을 붙잡다\"라고 했을 때, 뜻을 이해할 수는 있지만 어색하다고 느낀다. 따라서, 이 관계를 활용해서 NL을 생성해야 하기 때문에 collocation을 고려해야 한다.\n\n그렇다면, 이러한 Collocation을 어떻게 찾을 수 있을까?\n\n1. **Frequency**  \n   가장 간단하게 단순히 동시 발생 빈도를 확인하는 것이다. 정확한 파악을 위해서는 빈번하게 등장하는 의미 없는 단어를 먼저 filtering할 필요가 있다. 대표적인 예시로 a, the, and 등이 있다.\n2. **Hypothesis Testing**  \n   가설 검증으로 우리가 가정한 collocation을 지정하고, 이 사건이 일어날 가능성을 굉장히 낮게 하는 가설을 반대로 가정한 후에 이것이 불가능하다는 것을 증명하는 Null Hypothesis를 이용한 증명으로 타당성을 확보하는 것이다. 따라서, 우리가 보이고자 하는 것은 word1, word2가 있을 때, 두 단어가 서로 의존적이라는 것을 증명하고 싶은 것이다. 따라서, Null Hypothesis로 두 단어는 독립이다라고 지정하면, 우리는 다음 식을 얻을 수 있다.  \n   $p(w_{1}, w_{2}) = p(w_{1})p(w_{2})$  \n   이를 바탕으로 t-검증을 다음과 같이 수행할 수 있다.  \n   $t = {{p(w_{1}, w_{2}) - p(w_{1})p(w_{2})} \\over \\sqrt{p(w_{1}, w_{2})\\over{N}}} $  \n   t값이 이제 커질 수록 우리는 해당 가설이 틀렸음을 증명하여 collocation임을 주장할 수 있다.\n\n## Minimum Edit Distance\n\n단어 또는 문장 간 유사도를 측정할 때, 사전을 기반으로 수행할 수도 있지만 참고할 corpus가 마땅하지 않거나 더 추가적인 수치가 필요하다면, Minimum Edit Distance로 유사도를 측정하기도 한다. 즉, 두 문자열이 같아지기 위해서 어느정도의 수정이 필요한지를 수치화한 것이다. 여기서 연산은 새로운 문자 추가, 삭제, 대체만 가능하다.\n\n```plaintext\nS - N O W Y  | - S N O W - Y\nS U N N - Y  | S U N - - N Y\ndistance : 3 | distance : 5\n```\n\n다음과 같이 표현이 가능하다.\n\n1. 문자열 x, y가 있을 때, $E(i, j)$는 x의 0\\~i까지를 포함하는 문자열과 y의 0~j까지를 포함하는 문자열의 distance라고 하자.\n2. 이렇게 되면, $E(i,j)$에서 우리는 끝문자의 규칙을 볼 수 있다.\n\n    오른쪽 끝 문자가 가질 수 있는 조합은 3가지 밖에 없다.\n\n    ```plaintext\n    x[i]        | -           | x[i]\n    -           | y[j]        | y[j]\n    distance: 1 | distance: 1 | distance: 0 or 1\n    ```\n\n3. 그렇다면 우리는 하나의 사실을 알게 된다.\n\n    $E(i,j)$는 다음 경우의 수 중 하나여야만 한다.\n\n    - $E(i-1, j) + 1$\n    - $E(i, j-1) + 1$\n    - $E(i-1, j-1) + ((x[i] == y[j])\\text{ ? 0 : 1} )$\n4. 따라서, 다음과 같은 식을 유도할 수 있다.\n\n    $E(i, j) =\\min( \\\\\n      \\quad E(i-1, j) + 1, \\\\\n      \\quad E(i, j-1) + 1,  \\\\\n      \\quad E(i - 1, j-1) + ((x[i] == y[j])\\text{ ? 0 : 1} )\\\\\n    )$\n\n만약, 각 연산의 비용이 다를 경우라면, 1 대신에 그 값을 넣어주면 충분히 풀 수 있으며, 추가적으로 최적의 이동형태를 알고 싶다면, back pointer 하나를 추가하는 것으로 충분하다.\n\n## Reference\n\n- Tumbnail : Photo by [David Ballew](https://unsplash.com/@daveballew?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@daveballew?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n","slug":"nlp-text-processing","date":"2022-10-19 21:59","title":"[NLP] 2. Text Processing","category":"AI","tags":["NLP","Regex","Tokenization","Collocation","MinimumEditDistance"],"desc":"NLP를 수행할 때, 우리는 sequence of character를 처리하는 방식을 제대로 알아야 제대로 된 전처리와 후처리 등이 가능하다. 따라서 해당 chapter에서는 어떻게 원본 문자/단어/문장을 처리하는 방식을 다룰 것이다.","thumbnailSrc":"https://euidong.github.io/images/nlp-thumbnail.jpg"},{"content":"\n## Intro\n\n이제 통계적인 관점에서 NL을 input으로 하는 문제를 해결할 방법을 찾을 것이다. 이를 Language Modeling이라고 하며, 이를 위해서 또는 이를 더 효과적으로 하기 위한 방법들을 소개할 것이다.\n\n## Noisy Channel\n\n일반적으로 우리는 원하는 결과가 있다. 그 결과를 얻기 위해서 우리는 말을 하거나 행동을 하거나 글을 쓴다. 그 과정은 우리가 갖고 싶은 A라는 것을 얻기 위해서 B라는 행동을 대신하는 것과 같다. 즉, 우리는 이를 A에 noise가 껴서 B라는 것이 생성되었다고 생각하는 것이다. 그리고 우리가 관측할 수 있는 것은 B밖에 없는 것이다.\n\n이는 우리가 사용하는 NL에서도 동일하다. 우리가 원하는 결과값 A를 얻기 위해서 우리는 B라는 문장, 음성을 제시한다. 그 결과가 원하는 결과로 될 수 있는 확률을 얻어서 최종 결과를 예측하는 것이 우리의 목표인 것이다.\n\n이 과정을 수식으로 표현하면 다음과 같아진다.\n\n$$\nP(A|B) = {P(B|A)P(A)\\over{P(B)}}\\quad(\\text{Bayes Rule})\n$$\n\n우리가 얻고 싶은 $P(A|B)$ 를 얻기 위해서, $P(A)$와 $P(B|A)$ 를 통해서 구할 수 있는 것이다. 이에 대한 더 자세한 내용은 ML을 이해하는 것이 좋을 것이다. 추천하는 Posting은 [🔗 [ML] Parametric Estimation](/posts/ml-parametric-estimation)이다.\n\n## Language Modeling\n\n결국 우리가 얻고 싶은 것은 특정 문장의 할당된 확률인 것이다. 따라서, Language Model은 input으로 word sequence과 들어왔을 때, 확률을 계산하는 것이다.\n그리고, 이 계산을 수행하기 위해서 필요한 parameter를 찾는 과정을 Language Modeling이라고 한다.\n\n## Input(N-gram)\n\n대게 이러한 모델은 문장 또는 word의 배열이 다음과 같이 주어질 때, $W = w_{1}\\ w_{2}\\ w_{3}\\ ...\\ w_{n}$ 아래와 같은 형태로 표현하는 것이 일반적이다.\n\n- **Single word probability**  \n  하나의 단어의 확률을 나타낼 때 단순하게 아래와 같이 표현한다.  \n  $P(w_{i})\\quad(w_{i} \\in W)$\n- **Sequence of Words probability**  \n  일반적으로 sentence의 확률을 나타낼 때, 여러 문장을 한꺼번에 가지는 확률이므로 아래와 같이 표현하는 것이 일반적이다.  \n  $P(W) = P(w_{1}, w_{2}, w_{3}, ..., w_{n})$\n- **single word probability with context**  \n  일반적으로 우리는 이전에 사용한 단어가 문맥이라고 이해할 수 있다. 따라서, 구체적인 단어들 이후에 특정 단어가 나오는 것은 문맥을 반영한 확률이라고 생각할 수 있다.  \n  $P(W) = P(w_{5}| w_{1}, w_{2}, w_{3}, w_{4})$\n\n위의 식을 보게 되면, 우리는 다시 한번 sentence의 확률을 다시 정리할 수 있다.\n\n$$\nP(W) = P(w_{1}) \\times P(w_{2}|w_{1}) \\times P(w_{3}|w_{1},w_{2}) \\times ... \\times P(w_{n}| w_{1},w_{2},..., w_{n-1})\n$$\n\n위의 식을 보게되면, W가 짧다고 하더라도 굉장히 많은 처리가 필요하고, 저장을 위해 많은 공간이 필요하다는 것을 알 수 있다. 따라서, 우리는 현재 단어를 기준으로 너무 오래된 단어에 대해서는 무시를 하도록 하는 방법을 취하는 것이다.(**Markov Chain**) 이를 \"n 번째까지 허락\"했을 때, 이를 n-gram 이라고 부른다.\n\n$$\np(W) = \\prod_{i=1}^{n}{p(w_{i}|w_{i-n+1},w_{i-n+2},...,w_{i-1})}\n$$\n\n그렇다면, n-gram에서 적절한 n이란 무엇일까? 일반적으로는 n이 크다는 것은 context를 많이 받아들일 수 있다는 의미로 받아들여질 수 있다. 따라서, n이 클수록 성능의 최적화 가능성이 더 높다. 하지만, Vocabulary의 사이즈가 커지는 경우를 예를 들어보자. 여기서는 $|V| = 60$k 라고 해보자.\n\n| n-gram          | p(w_{i})                         | # of parameters   |\n| :-------------- | :------------------------------- | :---------------- |\n| 0-gram(uniform) | ${1\\over\\vert V\\vert}$           | 1                 |\n| 1-gram(unigram) | $p(w_{i})$                       | $6\\times10^4$     |\n| 2-gram(bigram)  | $p(w_{i}\\vert w_{i-1})$          | $3.6\\times10^9$   |\n| 3-gram(trigram) | $p(w_{i}\\vert w_{i-2}, w_{i-1})$ | $2.16\\times10^14$ |\n\nn이 커질 수록 가능한 조합의 수는 굉장히 커지기 때문에 우리가 보지 못하는 경우의 수도 굉장히 증가하게 되어 data자체의 빈도가 적어지는 현상(sparse)이 발생한다. 따라서, 대게의 경우 최대 n의 크기는 3정도로 하는 것이 일반적이다.\n\n```plaintext\n 🤔 주의\n\n 실제 데이터를 가공할 때에는 bigram부터는 문장의 시작과 끝을 표시해주어야 한다. \n 그렇지 않으면, 첫번째 문자의 확률을 구할 때, 이전 단어의 영향을 받을 수 없다.\n 정해진 규칙은 없지만, 대게 <s></s>를 이용한다.\n ex.  bigram : <s> w1 w2 w3 w4 </s>\n     trigram : <s> <s> w1 w2 w3 w4 </s> </s>\n```\n\n```plaintext\n 🤔 Google N-gram\n\n 구글에서 2006년에 N-gram을 직접 구성한 것이 있다. \n 총 1,024,908,257,229개의 단어가 존재하고, 40회 이상 등장하는 5-gram이 1,176,470,663개 존재한다. \n 총 Vocabulary의 size는 200번 이하로 등장하는 것은 제외하면, 13,588,391개이다. \n```\n\n## Estimation\n\nML에서는 Estimation을 수행할 때, continuous하게 추정하였다. 즉, 보지 못한 데이터에 대한 처리를 수행하기 위해서 continuous한 분포의 parameter만 추정하면 되었다. 하지만, NLP에서는 다르다. NL를 continuous하게 표현할 마땅한 방법이 없다. 따라서, 우리는 결국 모든 확률을 discrete하게 구해야 한다. 따라서, 우리는 특정 단어의 확률을 구하는 방법은 단 하나가 된다.\n\n$$\n|T| = \\text{count of observed tokens}\n$$\n$$\nc(w_{i}) = \\text{count of observed } w_{i}\n$$\n$$\n\\begin{align*}\n&P(w_{i}) = {{c(w_{i})}\\over{|T|}} \\\\\n&P(w_{i}| w_{i-1}) = {{c(w_{i-1}, w_{i})}\\over{c(w_{i-1})}} \\\\\n&P(w_{i}| w_{i-2}, w_{i-1}) = {{c(w_{i-2}, w_{i-1}, w_{i})}\\over{c(w_{i-2}, w_{i-1})}} \\\\\n\\end{align*}\n$$\n\n이때, 반드시 sequence의 순서를 유의하도록 하자. 순서가 바뀌면 다른 종류이다.\n\n> **Small Example**\n\n데이터가 다음과 같이 주어진다고 하자.\n\n```plaintext\n He can buy the can of soda.\n```\n\n이때 각 n-gram을 이용한 model의 확률들을 살펴보자.\n\n| model    | probability                                                                                                                                                     |\n| :------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| uni-gram | $p(He)=p(buy)=p(the)=p(of)=p(soda)=p(.) = 0.125$<br /> $p(can)=0.25$                                                                                            |\n| bi-gram  | $p(He\\vert <s>)=p(can\\vert He)=p(the\\vert buy)=p(can\\vert the)=p(soda\\vert of)=p(.\\vert sode) =p(</s> \\vert .) = 1$<br /> $p(buy\\vert can)=p(of\\vert can)= 0.5$ |\n| tri-gram | $p(He\\vert <s>, <s>)=p(can\\vert <s>, He)=p(the\\vert He, buy)=...=p(</s>\\vert ., </s>) =1$                                                                       |\n\n## Evaluation\n\n평가할 때는 ML과 결국은 동일하다. 우리가 확률분포를 구할 때, 사용한 데이터 외에 데이터를 이용해서 잘 적용이 되었는지를 확인할 수 있다. 하지만, word의 갯수와 데이터의 수가 굉장히 많은 NL의 특성상 이 Evaluation 단계에만 굉장히 많은 시간을 소모할 수 있다. 따라서, 즉각적인 평가를 위해서 사용하는 척도가 있다.\n\n> **Perplexity**\n\ntrain set을 통해 학습을 하고, test set을 통해서 평가를 수행할 때, train set을 통해 구한 확률이 실제 test set에서 어느정도의 Entropy를 발생시키는지를 확인하는 것이다. 원래의 식은\n$PP = 2^{H}$이지만, 이를 변형하여 다음과 같이 나타낼 수 있다.\n\n$$\n\\begin{align*}\nPP(W) &= \\sqrt[N]{1 \\over P(w_1, w_2, ..., w_N)} \\\\\n&= \\sqrt[N]{\\prod_{i=1}^{N}{P(w_i|w_{i-n+1}, w_{i-n+2}, ..., w_{i-1})}}\n\\end{align*}\n$$\n\n이를 통해서, 실제로 해당 문제가 너무 어렵지는 않은지, 선택한 model이 잘못되지는 않았는지를 판단한다.\n\n| model    | probability                                                                                                                                                     | entropy |\n| :------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------ |\n| uni-gram | $p(He)=p(buy)=p(the)=p(of)=p(soda)=p(.) = 0.125$<br /> $p(can)=0.25$                                                                                            | 2.75    |\n| bi-gram  | $p(He\\vert <s>)=p(can\\vert He)=p(the\\vert buy)=p(can\\vert the)=p(soda\\vert of)=p(.\\vert sode) =p(</s> \\vert .) = 1$<br /> $p(buy\\vert can)=p(of\\vert can)= 0.5$ | 0.25    |\n| tri-gram | $p(He\\vert <s>, <s>)=p(can\\vert <s>, He)=p(the\\vert He, buy)=...=p(</s>\\vert ., </s>) =1$                                                                       | 0       |\n\n위의 예시를 가져와서 봐보자. 물론 동일한 dataset에서 perplexity를 측정하기는 했지만, n이 커질 수록 점점 entropy가 작아지는 것을 볼 수 있다. 그렇다면, 이런 data가 좋은 걸까? 이는 좋은 게 아니다. 왜냐하면, 해당 dataset에서만 잘 작동하도록 되어있기 때문이다. 일명 **overfitting**이다.\n\n## Smooting\n\n위에서 말한 overfitting을 어느정도 해소할 뿐만 아니라 정말 큰 문제가 될 수 있는 probability가 0이 되는 문제(우리가 trainset을 통해 학습한 확률 분포에서 testset에 들어오는 데이터에 해당하는 확률값이 없을 때, 즉 해당 확률이 0일때)를 해결하기 위해서는 smoothing이 필수적이다. probability가 0이 된다는 것은 후에 위에서 구한 확률로 Prediction을 할 때 모든 예측을 망치는 요인이 된다. 왜냐하면, 추정확률의 최적 Entropy를 의미하는 Cross Entropy를 $\\infin$로 만들기 때문이다. (최적 Entropy가 무한대라는 것은 추정이 불가능하다는 것이다.)\n\n따라서, 우리는 probability가 0이 되지 않게 하는 방법으로 기존의 확률의 일부를 나누어주도록 하는 방법을 제시한다. 이것이 smoothing이다.\n\n이때 반드시 유의할 점은 smoothing을 하건 안하건 각 확률의 총합은 1이 되도록 보장해야 한다는 것이다.\n\n$$\n\\sum_{w \\in \\Omega}p(w) = 1\n$$\n\n대략 6가지의 대표적인 smoothing 방식들을 소개하겠다.\n\n> <mark>**1. Add-1(Laplace)**</mark>\n\n가장 간단한 방법의 smoothing 방법이지만, 실용적인면은 다소 떨어지는 방법이다. 아이디어는 간단하다. prediction을 수행할 때, 현재 들어온 input까지 포함하여 만든 $|V|$를 분모에 더하고, 분자에 1을 더해주는 방법이다. 이 방법을 사용하면, 설사 count가 0이 더라도 확률이 0이 되지는 않는다.\n\n$$\np(w) = {X \\over Y} \\rArr p^{\\prime}(w) = {X + 1 \\over Y + |V|}\n$$\n\n여기서, $|V|$ 값이 정말 헷갈렸는데, 아무도 잘 설명을 안하는 것 같아서 짚고 넘어가면, 우리가 확률값을 얻기 위해서 사용했던 dataset과 현재 prediction을 하기 위해서 들어온 input 둘에서 발생한 모든 unique한 단어의 수를 의미한다. (# of vocabulary)\n\n그렇게 해야만 $\\sum_{w \\in \\Omega}p(w) = 1$을 만족하는 값이 나온다.\n\n따라서, 이를 각 각의 n-gram에 대입하면 다음과 같다.\n\n| n    | $p(w_{i})$                                                 | $p^{\\prime}(w_{i})$                                                            |\n| :--- | :--------------------------------------------------------- | :----------------------------------------------------------------------------- |\n| $1$  | $c(w_{i}) \\over \\vert T \\vert$                             | $c(w_{i}) + 1 \\over \\vert T \\vert + \\vert V \\vert$                             |\n| $2$  | ${{c(w_{i-1}, w_{i})}\\over{c(w_{i-1})}}$                   | ${{c(w_{i-1}, w_{i}) + 1}\\over{c(w_{i-1})} + \\vert V \\vert} $                  |\n| $3$  | ${{c(w_{i-2}, w_{i-1}, w_{i})}\\over{c(w_{i-2}, w_{i-1})}}$ | ${{c(w_{i-2}, w_{i-1}, w_{i}) + 1}\\over{c(w_{i-2}, w_{i-1})} + \\vert V \\vert}$ |\n\n> <mark>**2. Add-k**</mark>\n\n1이라는 숫자가 경우에 따라서는 굉장히 큰 영향을 줄 때가 있다. 특히 기존 데이터의 수가 적은 경우에 더욱 그렇다. 따라서, 이를 해결하기 위해서 1보다 작은 임의의 값(k)을 쓰는 방법이다.\n\n$$\np(w) = {X \\over Y} \\rArr p^{\\prime}(w) = {X + 1 \\over Y + k|V|}\n$$\n\n하지만, 위와 같은 방식은 결국 어떤 확률 값이든지 분자에 1을 더하기 때문에 불평등하게 값을 나눠준다고 할 수 있다. 왜냐하면, 애초에 count(분자)가 큰 데이터에게 1은 별로 영향을 안주겠지만, 분자가 처음부터 작았던 경우에는 이로 인해서 받는 영향이 굉장히 크기 때문이다. 따라서, 이러한 한계점을 극복할 수 있는 방법들이 아래와 같은 방법들이다.\n\n> <mark>**3.Good Turing**</mark>\n\n이를 이해하기 위해서는 우리는 새로운 feature의 데이터를 가져와야 한다. 바로 word의 frequency의 frequency이다.\n\n$$\nN_{k} = \\sum_{i=1}^{n}1[c(w_{i}) = k]\n$$\n\n아마 예시를 봐야 이해가 빠를테니 하나의 예시를 보자.\n\n```plaintext\n sam I am I am sam I do not eat\n```\n\n이 경우 우리는 다음과 같이 count를 구할 수 있다.\n\n$$\n\\begin{align*}\n  &c(I) &=\\ 3 \\\\\n  &c(sam) &=\\ 2\\\\\n  &c(am) &=\\ 2\\\\\n  &c(do) &=\\ 1\\\\\n  &c(not) &=\\ 1\\\\\n  &c(eat) &=\\ 1\\\\\n\\end{align*}\n\\quad\\rArr\\quad\n\\begin{align*}\n  & N_{1} = 3 \\\\\n  & N_{2} = 2 \\\\\n  & N_{3} = 1\n\\end{align*}\n$$\n\n여기서 Good Turing은 한 번도 안본 데이터에게는 한 번만 보는 경우의 수를 전체 경우의 수로 나눈값만큼의 확률을 나누어주고, 기존 데이터들에게는 laplace처럼 1을 더해주는 것이 아니라 비례하는 만큼을 곱해주어 적절한 확률을 가져갈 수 있게하였다.\n\n따라서, 식은 다음과 같다.\n$$\np(w_{i}) = {(c(w_{i})+1)N_{c(w_{i})+1}\\over{N_{c(w_{i})}}} \\times {1\\over |T|},\\quad (N_{0} = 1)\n$$\n\n대게 ${(c(w_{i})+1)N_{c(w_{i})+1}\\over{N_{c(w_{i})}}}$이 부분을 $c^{*}$라고도 부른다.\n\n> <mark>**4. Kneser-Ney**</mark>\n\n가장 널리 쓰이는 Smoothing 방식으로 기억해두는 것이 좋다. 이를 이해하기 위해서는 먼저, Absolute Discounting을 먼저 이해해야 한다.  \nGood-turing 방식을 사용했을 때 $c$와 $c^{*}$사이에 차이가 경험적으로 특정 상수만큼씩 차이가 난다는 것을 발견하여,\n\n$$\nc^{*} = c - d\n$$\n\nChurch과 Gale은 이를 Absolute Discounting 확률이라며 다음 식을 제시한다.\n\n$$\nP(w_{i}|w_{i-1}) = {c(w_{i-1}, w_{i}) -d \\over c(w_{i-1})} + \\lambda(w_{i-1})P(w)\n$$\n\n여기서 뒷에 부분 $\\lambda(w_{i-1})P(w)$은 discounting으로 발생한 오차를 매꾸기 위한 값이다.\n\n여기서 Kneser-Ney problem은 더 넓은 범위로 확장시킬 수 있는 범위로 확장시킨 것이다. 기존에는 bigram으로 제한되어 있던 Absolute Discounting의 식은 다음과 같이 변형된다.\n\n$$\nP_{KN}(w_{i}|w_{i-n+1}^{i-1}) = {\\max(c(w_{i-1}, w_{i}) -d, 0) \\over c(w_{i-n+1}^{i-1})} + \\lambda(w_{i-n+1}^{i-1})P_{KN}(w_{i}|w_{i-n+2}^{i-1})\n$$\n\n(위의 식에 대해서 정확하게 이해를 하지 않았지만, 그렇구나 하고 넘어가도 충분할 것 같다.)\n\n> <mark>**5. Backoff & Interpolation**</mark>\n\n상황에 따라서 unigram, bigram, trigram을 가중치만큼 더해서 사용하는 방식이다. 결국 n-gram에서 n이 작아질 수록 detail을 신경쓸 수 없지만, 신뢰도 자체는 늘어날 수 있다. 따라서, 이를 적절히 섞어쓰면 좋은 결과가 나온다는 이론이다. 하지만, 어떤 것을 더 중점으로 직접 정해주어야 한다.\n\n$$\np^{\\prime}(w_{i}|w_{i-2}, w_{i-1}) = \\lambda_{3}p(w_{i}|w_{i-2}, w_{i-1}) + \\lambda_{2}p(w_{i}|w_{i-1}) + \\lambda_{1}p(w_{i}) + {\\lambda_{0}\\over|V|}\n$$\n\n이를 정할 때는 대게 held-out data를 활용해서 구한다.(validation set이라고 부른다.) 즉, 전체 corpus를 (train, validation, test)로 적절히 나누어 쓰라는 것이다. 그래서 성능을 측정할 때는 testset을 쓰고, $\\lambda$를 추정할 때에는 validation(heldout)set을 사용하라는 것이다.\n\n## Word Class\n\nSmoothing 방식을 이용해서 unseen data를 처리해주었는데 좀 더 효과적으로 이를 처리하는 방법을 고려한 것이다. class단위로 word를 grouping하는 것이다. 그래서 존재하지 않는 단어였다고 하더라도 특정 group에 속한다면, 이를 활용해서 어느정도 확률을 부여할 수 있다는 것이다. 이 방식을 활용하면, 실제로 보지 않은 데이터에 대해서도 현실적인 추정이 가능하지만 detail에 대한 성능은 감소할 수 있다.\n\n$$\np(w_{i}|w_{i-1}) \\rArr p(w_{i}|c_{i-1}) ={ c(c_{i}, w_{i}) \\over c(c_{i-1}) }\n$$\n\n위의 식을 보면, 이전 단어의 context를 보는 것이 아니라 이제는 class를 보고 다음 단어를 probability를 계산하도록 바뀐 것이다. 그리고 이 확률은 class내부에서 해당 단어의 빈도를 이전 class의 빈도로 나누었다고 보면 되겠다.\n\n$$\np(w_{i}|c_{i-1}) = p(w_{i}|c_{i}) \\times p(c_{i}|h_{i})\n$$\n\n즉, class 단위로 단어를 묶고 class에서 단어의 발생 확률에 class에서의 n-gram을 곱한 값이 되는 것이다. 일반적인 Bayes Decison Rule에 기반하여 선택한다고 보면 되겠다.\n\n## Example. Spelling Correction\n\n여태까지 배운 내용을 활용하여 Spelling 오류를 정정해주는 application을 제작한다고 해보자. 먼저, Spelling Error의 종류부터 알아보도록 하자.\n\n- **Non word Error**  \n  잘못된 spelling에 의해서 전혀 뜻이 없는 단어가 만들어진 경우이다.  \n  해결을 위해서는 사전에서 유사한 단어를 찾아서 가장 가능성이 높은 것 또는 이전에 배웠던 shortest edit distance를 찾는 것이다.\n- **Real word Error**  \n  잘못된 spelling 또는 유사한 발음 때문에 뜻이 있는 단어가 만들어졌지만, 오류가 의심되는 경우이다.  \n  해결책은 비슷한 발음 또는 spelling의 모든 단어를 찾아서 해당 단어와 함께 language model에 넣어서 가장 높은 가능성을 가지는 값을 찾는 것이다.\n\n먼저, **Non Word Error** 같은 경우는 오타 데이터에 원래 쓰려고 했던 값을 labeling해서 모아두고 다음 값을 학습시키는 것이다.\n(*x=오타데이터, w=사전에있는단어)\n\n- $P(x|w)$ = x가 w일 가능성\n- $p(w)$ = w의 확률\n\n그리고 나서, 다음을 실행시켜서 가장 적절한 $\\hat{w}$를 찾으면 된다.\n$$\n\\begin{align*}\n\\hat{w} &= \\argmax_{w \\in V}P(w|x) \\\\\n&= \\argmax_{w \\in V}{P(x|w)P(w)}\n\\end{align*}\n$$\n\n**Real Word Error**의 경우에는 결국 이전 단어 sequence를 활용해야 한다. 전체 corpus를 학습해서 tri-gram을 추출해놓고, 번갈아가면서 후보 단어들을 집어넣어서 가장 높은 확률이 나오는 단어를 사용하는 것이다. 예를 들어, 후보 단어가 다음과 같이 정해졌다고 하자. ($\\bold{w}_{3} = {w_3^{(1)}, w_3^{(2)}, w_3^{(3)}, ...}$) 이때 우리가 원하는 w는 다음과 같이 구할 수 있다.\n\n$$\n\\hat{w}_{3} = \\argmax_{w_{3}^{(i)} \\in \\bold{w}_{3}} P(w_{3}^{(i)}| w_{1}, w_{2})\n$$\n\n## Reference\n\n- Tumbnail : Photo by [David Ballew](https://unsplash.com/@daveballew?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@daveballew?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n","slug":"nlp-language-modeling","date":"2022-10-21 12:15","title":"[NLP] 3. Language Modeling","category":"AI","tags":["NLP","NoisyChannel","Ngram","LanguageModeling","Smoothing","WordClass"],"desc":"이제 통계적인 관점에서 NL을 input으로 하는 문제를 해결할 방법을 찾을 것이다. 이를 Language Modeling이라고 하며, 이를 위해서 또는 이를 더 효과적으로 하기 위한 방법들을 소개할 것이다.","thumbnailSrc":"https://euidong.github.io/images/nlp-thumbnail.jpg"},{"content":"\n## Intro\n\n이전 Posting에서는 sentence의 적절성을 확인한다든지 다음 단어를 유추한다든지 오타를 정정하는 등에 필요한 기본적인 Language Modeling 방식을 살펴보았다. 이번에는 실제로 가장 많이 사용되는 예제인 Classification을 Language Model을 이용하여 어떻게 구현하는지를 다룬다.\n\n## Classification\n\nClassification은 input이 들어왔을 때, 이를 알맞은 분류로 나누는 것이 목표이다. 단순히 Rule에 기반하여 이를 수행할 수도 있지만, Statistic한 Language Modeling을 이용하면, 더 정확도가 높은 분류를 수행할 수 있다. 결국 Statistic Prediction을 수행하기 위해서 우리는 3개(Estimation, Modeling, Evaluation)를 중점적으로 봐야 하는 것은 Classification도 동일하다. 따라서, 이에 대해서 살펴볼 것이고, 그 전에 먼저 Classification Model 의 종류를 살펴보도록 하겠다.\n\n## Generative Model vs Discriminative Model\n\nClassification에서 이용되는 Model을 크게 두가지로 나눌 수 있는데 이에 대해서 먼저 알아보도록 하자.\n\n1. **Generative Model(생성 Model)**\n   1. Naive Bayes\n   2. Hidden Markov Model(HMM)\n2. **Discriminative Model(판별 Model)**\n   1. Logistic Regression\n   2. K Nearest Neighbors\n   3. Support Vector Machine\n   4. Maximum Entropy Model(MaxEnt)\n   5. Neural Network(Deep Learning)\n\n두 Model의 가장 큰 차이점은 추론의 과정이다. 우리가 원하는 데이터 $P(\\text{class}=c | \\text{input} = \\text{data})$(특정 data가 주어졌을 때, 각 class의 속할 확률)를 얻는 과정이 서로 다르다.\n\n**첫 번째**로, $P(\\text{class}=c, \\text{input} = \\text{data})$일 확률을 구하여 **간접적**으로 구하는 방법이다.\n\n$$\n\\begin{align*}\nP(\\text{class}=c | \\text{input} = \\text{data}) &= {{P(\\text{class}=c, \\text{input} = \\text{data})}\\over{P(\\text{input} = \\text{data})}} \\\\\n&\\propto {P(\\text{class}=c, \\text{input} = \\text{data})}\n\\end{align*}\n$$\n\n이런 식으로 생성하여 추론하는 방식을 <mark>Generative Model</mark>이라고 한다. 이 방식은 결국 Conditional Probability를 추론하기 위해서 Joint Probability를 이용하는 방식이기 때문에 어느정도 한계가 존재한다는 점을 유의하자.\n\n**두 번째**로는, $P(\\text{class}=c | \\text{input} = \\text{data})$를 **직접적**으로 구하는 방법이 있다. 이를 위해서, 마친 Conditional Probability를 구한 것과 유사한 효과를 내는 **Discriminant Function(판별 함수)**이라는 특별한 함수를 input에 적용하는 방법이다. 이 함수 중에서 가장 대표적인 것이 Softmax function이다. 우리가 만약 input을 softmax function에 입력하게 되면, 이 값은 [0, 1] 사이의 값으로 표현된다. 이를 통해서 우리는 해당 input이 class인 경우 1에 가깝게, 그렇지 않은 경우 0에 가깝게 표현하여 여러 데이터에 적용하면, class의 inpuut에 따른 분포 양상을 확인할 수 있다. 그리고, 이 분포 양상을 확률로 즉각적으로 표현할 수 있기 때문에 softmax function을 취한 결과가 $P(\\text{class}=c | \\text{input} = \\text{data})$과 비례한다는 결론을 낼 수 있다. 자세한 설명이 필요하다면, [🔗 Logistic Regression](/posts/ml-logistic-regression#Logistic-Regression)을 참고하도록 하자. 이러한 방식을 우리는 <mark>Discriminative Model</mark>이라고 한다.\n\n위에서 제시한 방법들 중 대표적인 방법들은 별도의 Posting을 통해서 정리하였다. 해당 링크를 참조하여 확인해보도록 하자.\n\n- **Generative Model(생성 Model)**\n  - [🔗 Naive Bayes](/posts/nlp-naive-bayes)\n  - [🔗 Hidden Markov Model(HMM)](/posts/nlp-hmm)\n- **Discriminative Model(판별 Model)**\n  - [🔗 Maximum Entropy Model(MaxEnt)](/posts/nlp-maxent)\n  - [🔗 Logistic Regression](/posts/ml-logistic-regression)\n\n## Estimation\n\n어떤 Model을 선택했다고 하더라도 결국 우리가 Class를 결정하는 과정을 동일하다. 위의 과정을 통해서 어찌되었든 다음 값을 찾으면 된다.\n\n$$\n\\begin{align*}\nc^{\\prime} &= \\argmax_{c \\in C}{P(\\text{class}=c | \\text{input} = \\text{data})}\n\\end{align*}\n$$\n\n## Modeling\n\nModel을 만드는 과정, 즉 학습하는 과정은 결국 Model의 구현마다 천차 만별이다. Naive Bayes는 단순하게 data의 word와 count를 활용하고, HMM은 EM algorithm을 활용하며, Linear Regression은 Gradient Descent를 활용한다. 따라서, 여기서는 자세히 다루지 않고 위에서 제시한 링크를 따라가서 각 Model마다의 학습법을 확인해보도록 하자.\n\n## Evaluation\n\nClassification의 성능을 평가하는 것 역시 중요한 일이다. 가장 쉬운 Binary Classification부터 알아보자.\n\nbinary classificaiton의 결과는 아래와 같이 4개 중 하나로 결정된다.\n\n| prediction\\answer | True           | False          |\n| :---------------- | :------------- | :------------- |\n| Positive          | true positive  | false positive |\n| Negative          | false negative | true negative  |\n\n이를 쉽게 이해할려면, 병(코로나)의 양성/음성 판정이 row에 해당하고, 실제 병의 여부를 column으로 생각하면 쉽다. 또한, 각 cell의 값이 헷갈릴 수 있는데, 우리가 원하는 것이 예측의 정확도를 확인하는 것이기 때문에 예측 결과는 그대로 보여주면서, 이것이 틀렸는지 맞았는지를 앞에 true/false로 표현했다고 생각하면 쉽다.\n\nclassification의 성능을 측정하는 지표는 대표적으로 4 가지가 있다.\n\n1. **Accuracy(정확도)**  \n   가장 쉽게 그리고 일반적으로 생각하는 지표다. 위의 표에서는 전체 경우의 수를 더하여 옳게 예측한 것(true postive, true negative)의 합을 나누는 것이다.\n   $tp + fn \\over tp + fp + fn + tn$  \n   하지만, 이 방식은 한계가 있다. 바로, 데이터가 한쪽으로 치우쳐져있을 때이다. 예를 들어, 우리가 진짜를 진짜라고 맞출확률은 높지만, 가짜를 가짜라고 맞출 확률이 낮다고 할 때, 이를 제대로 반영하기가 어렵다. 그런데 데이터에서 진짜가 가짜보다 압도적으로 많을 경우 정확도는 좋은 지표로 쓰기 어렵다는 것이다.\n2. **Precision(정밀도, 정답률)**  \n   쉽게 정답 자체를 맞힐 확률입니다.  \n   $tp \\over tp + fn$\n3. **Recall(재현율)**  \n   예측이 맞을 확률을 의미합니다.  \n   $tp \\over tp + fp$\n4. **F1 Score**  \n   좀 더 세분화된 평가지표이다. 조화 평균에 기반하여 모델의 성능을 정확하게 평가할 때 사용한다.  \n   ${2\\over{{1\\over\\text{Precision}} + {1\\over\\text{Recall}}}} = 2 \\times {\\text{Precision} \\times \\text{Recall} \\over \\text{Precision} + \\text{Recall}}$\n\n여기까지 봤으면, 슬슬 multi class의 경우에는 어떻게 해야할지 궁금할 것이다. 대게 두 가지 방법을 통해서 수행할 수 있다.\n\n> **1. Micro Average**\n\n전체 class를 하나의 binary table로 합치는 것이다. 즉, 클래스가 A, B, C 3개가 있다면, 각 클래스 별로 예측 성공도를 binary로 표시하고, 이를 하나의 테이블로 합치는 것이다. 그 후에는 binary에서 계산하는 식을 그대로사용할 수 있다.  \n\n> **2. Macro Average**\n\nmulti class의 경우에도 별로 다를 것은 없다. 단지 Precision과 Recall 그리고 Accuracy가 어떻게 바뀌는지만 알면 쉽게 이해할 수 있을 것이다.  \n\n| prediction\\answer | c1            | c2            | c3            | c4            |\n| :---------------- | :------------ | :------------ | :------------ | :------------ |\n| c1                | true positive | x             | x             | x             |\n| c2                | x             | true positive | x             | x             |\n| c3                | x             | x             | true positive | x             |\n| c4                | x             | x             | x             | true positive |\n\n- Precision: $c_{ii} \\over \\sum_{j}c_{ij}$\n- Recall: $c_{ii} \\over \\sum_{j}c_{ji}$\n- Accuracy: $c_{ii} \\over \\sum_{i}\\sum_{j}c_{ij}$\n\n## Reference\n\n- Tumbnail : Photo by [David Ballew](https://unsplash.com/@daveballew?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@daveballew?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n","slug":"nlp-classification","date":"2022-10-21 13:37","title":"[NLP] 4. Classification","category":"AI","tags":["NLP","Classification","Generative","Discriminative","ModelEvaluation"],"desc":"이전 Posting에서는 sentence의 적절성을 확인한다든지 다음 단어를 유추한다든지 오타를 정정하는 등에 필요한 기본적인 Language Modeling 방식을 살펴보았다. 이번에는 실제로 가장 많이 사용되는 예제인 Classification을 Language Model을 이용하여 어떻게 구현하는지를 다룬다.","thumbnailSrc":"https://euidong.github.io/images/nlp-thumbnail.jpg"},{"content":"\n## Intro\n\nNaive Bayes Model은 가장 쉽게 Classification을 수행할 수 있는 Model이지만, 성능이 다른 Model에 비해 뛰어나지는 않다. 그럼에도 Naive Bayes는 가장 기본이 되는 Model이기에 비교 대상으로 많이 사용되고, Classification의 insight를 키우는데 많은 도움을 줄 수 있다. 여기서는, 전반적인 개념과 이를 직접 Spam Filtering에서 어떻게 사용하는지 살펴본다.\n\n## Naive Bayes Model\n\n특정 class에서 해당 데이터가 얼마나 자주 발생되는지와 실제로 해당 class의 빈도를 활용하여, classification을 수행하는 것이다. 우선 이를 수식적으로 표현하기 위해서 다음 변수들을 먼저 정의해보자.\n\n- **documents($D$)**: 여러 개의 Document를 의미하며, 하나의 Document는 대게 여러 개의 words를 포함한다. 각 document는 $d_{i} \\in D$의 형태로 표현한다.\n- **classes($C$)**: class는 두 개 이상을 가진다. 각 클래스는 $c_{i} \\in C$의 형태로 표현된다.\n- **labeled dataset**: 이는 (document($d_{i}$), class($c_{i}$))가 하나씩 mapping된 형태로 존재한다. 우리가 가지는 dataset으로 학습, 평가 시에 사용한다. 대게 평가에 사용되는 데이터는 학습 시에 사용하는 것을 금지하기 때문에 별도로 분리하여 사용한다.\n- **word($w$)**: 하나의 word를 의미하며 NLP 학습 시에 사용하는 가장 작은 단위이다. 대게 document 하나에 있는 단어의 수는 N으로 표기하고, unique한 단어의 수는 V(size of vocabulary)로 표시한다.\n\n따라서, 우리가 찾고자 하는 가장 높은 확률을 가진 class는 다음을 통해서 구할 수 있다.\n\n$$\n\\begin{align*}\nc_{MAP} &= \\argmax_{c \\in C}{P(c|d)} \\\\\n&= \\argmax_{c \\in C}{p(d|c)p(c)\\over p(d)} \\\\\n&= \\argmax_{c \\in C}{p(d|c)p(c)} \\\\\n&= \\argmax_{c \\in C}{p(w_{1}, w_{2}, ... , w_{N} | c)p(c)} \\\\\n&= \\argmax_{c \\in C}{\\prod_{i=1}^{N}p(w_{i}|c)p(c)} \\\\\n&= \\argmax_{c \\in C}{\\log(\\prod_{i=1}^{N}p(w_{i}|c)p(c))} \\\\\n&= \\argmax_{c \\in C}{\\sum_{i=1}^{N}\\log p(w_{i}|c) + \\log{p(c)}} \\\\\n\\end{align*}\n$$\n\n여기서 우리가 language model을 무엇으로 정했는지가 중요하다. 위에서는 uni-gram이라고 가정해서 풀이했지만, bi-gram인 경우 document의 형태가 $d={(w_{1}, w_{2}), (w_{2}, w_{3}), ... , (w_{N-1}, w_{N})}$이다. 따라서, 전체적인 크기와 vocabulary자체도 바뀌게 된다.\n\n즉, 우리는 train set을 통해서 vocabulary를 완성한다. 그리고, 각 word의 count 및 필요에 따라 필요한 word sequence의 count를 수집하여 $p(w_i)$를 구한 후 위에 방법을 통해서 특정 class를 추측할 수 있는 것이다.\n\n이제 구체적인 Naive Bayes의 동작 절차는 Spam Filtering이라는 Case Study를 통해서 자세히 살펴보도록 하자.\n\n## Case Study. Spam Filtering\n\n초기 NLP가 가장 많이 사용되었던 예시 중에 하나이다. 여러 개의 메일에 spam인지 ham인지를 labeling한 데이터를 갖고 후에 input으로 mail 데이터가 들어왔을 때, 이를 filtering하는 것이다. 위에서 살펴보았던 확률을 그대로 적용하면 된다. 예측에 필요한 확률을 습득하고, 예측하는 방법과 이를 평가하는 방법의 순으로 설명하겠다.\n\n### 0. Preprocessing\n\n사실 mail data의 형태가 이상할 수도 있다. Subject부터 시작하여 날짜 데이터 그리고 특수 문자 등이 존재할 수 있는데, 이를 먼저 처리해서 후에 있을 Modeling 단계에서 잘 사용할 수 있도록 형태를 변형해주어야 한다.\n\n[🔗 이전 Posting(Text Processing)](/posts/nlp-text-processing)에서 배웠던 기술들을 활용하여 이를 해결할 수 있다.\n\n대표적으로 해줄 수 있는 작업들은 다음과 같다.\n\n1. 대소문자 통일\n2. alphabet이 하나라도 들어있지 않은 데이터는 삭제\n3. date, 참조 등을 의미하는 데이터 삭제\n\n### 1. Modeling\n\nParameter Estimation / Learning / Modeling 등으로 불리는 단계이다. 일단 우리는 train set으로부터 우리가 원하는 확률을 추출해야 한다. 그 전에 우리가 어떤 language model을 이용할지 선택해야 한다. 먼저 uni-gram인 경우에는 다음과 같은 방법으로 train set이 정의된다.\n$$\n\\text{TrainSet} = {(d_{1}, c_{1}),  (d_{2}, c_{2}), ..., (d_{N}, c_{N})}\n$$\n$$\nd_{i} = \\begin{cases}\n  {w_{1}, w_{2}, ... , w_{M_{i}}} \\quad&\\text{unigram} \\\\\n  {(<s>, w_{1}), (w_{1}, w_{2}), ... , (w_{M_{i}}, </s>)} \\qquad&\\text{bigram}\n\\end{cases}\n$$\n\n이제 우리가 원하는 parameter, 즉 확률은 다음과 같은 데이터이다.\n\n> **unigram**\n\n$$\n\\begin{align*}\np(w_{i}|c_{j}) &= {\\text{count}(w_{i}, c_{j}) \\over \\sum_{w \\in V} \\text{count}(w, c_{j})} \\\\\np(c_{j}) &= {\\sum_{i = 1}^{N}{1[c_{i} = c_{j}]} \\over N}\n\\end{align*}\n$$\n\n> **bigram**\n\n$$\n\\begin{align*}\np(w_{i}|w_{i-1},c_{j}) &= {\\text{count}((w_{i-1}, w_{i}), c_{j}) \\over \\sum_{(w^{(1)}, w^{(2)}) \\in V} \\text{count}((w^{(1)}, w^{(2)}), c_{j})} \\\\\np(c_{j}) &= {\\sum_{i = 1}^{N}{1[c_{i} = c_{j}]} \\over N}\n\\end{align*}\n$$\n\n여기서 우리는 반드시 Smoothing을 해주어야 한다. 왜냐하면, spam mail에서 안 본 단어가 나올 가능성이 너무나 높기 때문이다. 따라서, 실제 $p(w_{i}|c_{j})$는 아래와 같이 변경된다. (간단한 예시를 들기 위해서 Add-1 방식을 사용했다. - 해당 내용이 기억이 나지 않는다면, [🔗 이전 포스팅](/posts/nlp-language-modeling)을 다시 보고 오자.)\n\n$$\np(w_{i}|c_{j}) = {\\text{count}(w_{i}, c_{j}) + 1 \\over \\sum_{w \\in V} \\text{count}(w, c_{j}) + |V|}\n$$\n\n주의할 점은 다시 한 번 강조하지만, $V$는 후에 Estimation에서 input으로 사용하는 단일 document까지 포함한 Vocabulary이다.\n\n### 2. Estimation\n\n이제 우리가 얻은 parameter를 이용해서 실제 input data에 대한 estimation을 수행할 수 있다.\n\n이 경우 다음과 같은 과정을 수행할 수 있다.\n\n$$\n\\hat{c} = \\argmax_{c \\in C} p(c)\\prod_{w \\in d_{\\text{input}}}p(w|c)\n$$\n\n물론 어떤 n-gram을 쓰냐에 따라 $d_{\\text{input}}$도 형태가 달라질 것이다.\n\n### 3. Evaluation\n\n이제 평가를 수행할 것이다. 평가는 우리가 알아봤던 Accuracy와 F1 Score를 추출할 수 있다. Binary Classification이기 때문에 쉽게 구할 수 있을 것이다.\n\n| prediction\\answer | True                                                                       | False                                                                     |\n| :---------------- | :------------------------------------------------------------------------- | :------------------------------------------------------------------------ |\n| Positive          | $\\sum_{(d, c) \\in D_{\\text{test}}} 1[\\hat{c}_{d} = c, c = \\text{spam}]$    | $\\sum_{(d, c) \\in D_{\\text{test}}} 1[\\hat{c}_{d} \\neq c, c = \\text{ham}]$ |\n| Negative          | $\\sum_{(d, c) \\in D_{\\text{test}}} 1[\\hat{c}_{d} \\neq c, c = \\text{spam}]$ | $\\sum_{(d, c) \\in D_{\\text{test}}} 1[\\hat{c}_{d} = c, c = \\text{ham}]$    |\n\n## Reference\n\n- Tumbnail : Photo by [David Ballew](https://unsplash.com/@daveballew?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@daveballew?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n","slug":"nlp-naive-bayes","date":"2022-10-21 15:37","title":"[NLP] 5. Naive Bayes","category":"AI","tags":["NLP"],"desc":"Naive Bayes Model은 가장 쉽게 Classification을 수행할 수 있는 Model이지만, 성능이 다른 Model에 비해 뛰어나지는 않다. 그럼에도 Naive Bayes는 가장 기본이 되는 Model이기에 비교 대상으로 많이 사용되고, Classification의 insight를 키우는데 많은 도움을 줄 수 있다. 여기서는, 전반적인 개념과 이를 직접 Spam Filtering에서 어떻게 사용하는지 살펴본다.","thumbnailSrc":"https://euidong.github.io/images/nlp-thumbnail.jpg"},{"content":"\n## Intro\n\n이전까지 특정 word를 기반으로 하여 modeling을 수행하는 방법을 알아보았다. 하지만, 우리가 특정 word의 sequence를 통해서 각 word에 대한 classification을 한 번에 하고 싶은 경우는 어떻게 할까?(예를 들어, 각 단어의 품사를 지정하는 일) 일반적으로 각 단어가 특정 해당 class일 확률로 구하는 방법이 일반적일 것이다. 하지만, 문맥을 고려하여 확률을 구할 방법은 없을까? 그 방법은 바로 bigram을 이용하면 될 것이다. 그렇다면, 사실 우리가 사용하는 문맥이 단어 자체보다는 이전 class가 더 영향이 크다면, 이는 어떻게 해야할까? 이를 위한 해결책이 HMM이다. NLP 뿐만 아니라 여러 분야에서 넓게 사용되고 있지만, 여기서는 NLP 분야에서 어떻게 이를 사용하는지를 알아볼 것이다.\n\n## Markov Model\n\nHMM을 알아보기전에 Markov Model을 알아야 한다. 이는 특정 sequence의 확률을 추정하는 방법이다. 즉 우리에게 state sequence ($S= {s_{0}, s_{1}, ..., s_{N}}$)가 주어질 때, 각 state에서 다음 state로 전이(이동)할 확률을 이용해서 state sequence의 확률을 구하는 방법이다.\n\n![nlp-markov-model-1](/images/nlp-markov-model-1.jpg)\n\n위의 그림이 state 각 각에서 다음 state로 전이할 확률을 나타낸 것이라면, 우리는 아래 그림과 같은 그림으로 sequence의 확률을 추론할 수 있는 것이다.\n\n![nlp-markov-model-2](/images/nlp-markov-model-2.jpg)\n\n따라서, 위의 그림에서 우리가 만약 $(s_{0}, s_{1}, s_{0}, s_{2})$으로 이루어진 sequence의 확률을 얻기를 바란다면, 그 확률은 아래와 같아진다.\n$$\n\\begin{align*}\np(s_{0}, s_{1}, s_{0}, s_{2}) &= p(s_{0}| \\text{start}) \\times p(s_{1}|s_{0}) \\times p(s_{0}|s_{1}) \\times p(s_{2}|s_{1}) \\times p(end|s_{2}) \\\\\n&= \\pi_{0} \\times p_{01} \\times p_{10} \\times p_{12} \\times 1\n\\end{align*}\n$$\n\n이를 잘 살펴보니 bigram에서의 Likelihood를 구하는 공식과 똑같다. 즉, state 각 각을 word라고 본다면, Markov Model을 통해서 구할 수 있는 확률은 bigram의 Likelihood인 것이다.\n\n그리고 이를 일반화하면 다음과 같다.\n\n$$\np(seq) = \\prod_{i=1}^{N}p(seq_{i}|seq_{i-1})\n$$\n\n그런데, 여기서 n이 3 이상인 ngram을 적용하고 싶다면, 각 state를 n-1 gram으로 설정하면 된다.\n\n$$\n\\begin{align*}\nX_{i} &= (Q_{i-1}, Q_{i}) \\text{라면, }\\\\\nP(X_{i} | X_{i-1}) &= P(Q_{i-1}, Q_{i} | Q_{i-2}, Q_{i-1}) \\\\\n&= P(Q_{i} | Q_{i-2}, Q_{i-1})\n\\end{align*}\n$$\n\n따라서, trigram을 적용해보면 아래와 같다.\n\n$$\n\\begin{align*}\np((start, w_{0}), (w_{0}, w_{1}), (w_{1}, w_{0}), (w_{0}, w_{2})) &= p(w_{0}| \\text{start}, \\text{start}) \\times p(w_{1}|\\text{start}, w_{0}) \\times p(w_{0}|w_{0}, w_{1}) \\times p(w_{2}|w_{1}, w_{0}) \\times p(end|w_{0}, w_{2}) \\\\\n&= \\pi_{0} \\times p_{01} \\times p_{10} \\times p_{12} \\times 1\n\\end{align*}\n$$\n\n## Hidden Markov Model\n\nHidden Markov Model은 state를 하나 더 만든다는 것이 핵심이다. 그래서, 우리가 직접 관측하는 state(**observed state**)와 직접적으로 관측하지 않지만, 관측한 state들에 의존하는 state(**hidden state**) 총 두 개의 state를 사용한다. 일반적인 예시가 text가 입력되었을 때 우리는 각 단어를 observed state라고 한다면, 각 단어의 품사를 hidden state라고 정의할 수 있다.\n\n![nlp-markov-model-3](/images/nlp-markov-model-3.jpg)\n\n위의 예시는 우리가 관측하는 데이터($O$)가 3개의 state를 가지고, 이 사건에 의존적인 또 다른 사건($H$)이 3개의 state를 가지는 경우이다. 이를 이용해서 기존 Markov Model보다 복잡한 작업을 수행하는 것이 가능하다.\n\n### Estimation\n\n우리가 할 수 있는 작업은 크게 두 가지이다. 일반적인 Markov Model에서 할 수 있던 방식이 **Trellis** 방식이고, 또 다른 방식이 **Viterbi** 방식이다.\n\n1. $(o_{0}, o_{1}, o_{0}, o_{2})$의 확률이 궁금할 때(**Trellis**)\n2. $(o_{0}, o_{1}, o_{0}, o_{2})$가 주어질 때, 이것의 hidden state의 sequence 중 가장 유력한 sequence를 찾고자할 때(**Viterbi**)\n\n위의 경우를 각각 풀어보도록 하자.\n\n> <mark>**1. Trellis**</mark>\n\n우리가 직접 관측한 데이터의 sequence 자체의 확률이 궁금할 때이다. 따라서, 이에 대한 분석은 $(o_{0}, o_{1}, o_{0}, o_{2})$의 확률을 분석해보면서 설명하겠다.\n\n$$\n\\begin{align*}\np(o_{0}, o_{1}, o_{0}, o_{2}) &= p(o_{0}, o_{1}, o_{0}) \\times p(o_{2} | o_{0}, o_{1}, o_{0}) \\\\\n&= p(o_{0}, o_{1}, o_{0}) \\times \\{p(o_{2} | h_{0})p(h_{0} | o_{0}, o_{1}, o_{0}) + p(o_{2} | h_{1})p(h_{1} | o_{0}, o_{1}, o_{0}) + p(o_{2} | h_{2})p(h_{2} | o_{0}, o_{1}, o_{0})\\} \\\\\n&= p(o_{0}, o_{1}, o_{0}) \\times \\sum_{i=0}^{2}{p(o_{2} | h_{i})p(h_{i} | o_{0}, o_{1}, o_{0}) } \\\\\n&= p(o_{0}, o_{1}) \\times \\sum_{i=0}^{2}{p(o_{0} | h_{i})p(h_{i} | o_{0}, o_{1}) } \\times \\sum_{i=0}^{2}{p(o_{2} | h_{i})p(h_{i} | o_{0}, o_{1}, o_{0}) } \\\\\n&= p(o_{0}) \\times \\sum_{i=0}^{2}{p(o_{1} | h_{i})p(h_{i} | o_{0}) } \\times \\sum_{i=0}^{2}{p(o_{0} | h_{i})p(h_{i} | o_{0}, o_{1}) } \\times \\sum_{i=0}^{2}{p(o_{2} | h_{i})p(h_{i} | o_{0}, o_{1}, o_{0}) } \\\\\n&= \\sum_{i=0}^{2}p(o_{0}|h_{i})p(h_{i}|start) \\times \\sum_{i=0}^{2}{p(o_{1} | h_{i})p(h_{i} | o_{0}) } \\times \\sum_{i=0}^{2}{p(o_{0} | h_{i})p(h_{i} | o_{0}, o_{1}) } \\times \\sum_{i=0}^{2}{p(o_{2} | h_{i})p(h_{i} | o_{0}, o_{1}, o_{0}) }\n\\end{align*}\n$$\n\n이를 그림으로 표현하면 다음과 같다.\n\n![nlp-hidden-markov-model-1](/images/nlp-hidden-markov-model-1.jpg)\n\n또한, 이 식을 다음과 같이 축소가 가능하다.\n\n$$\n\\begin{align*}\n  &\\sum_{i=0}^{2}p(o_{0}|h_{i})p(h_{i}|start) \\times \\sum_{i=0}^{2}{p(o_{1} | h_{i})p(h_{i} | o_{0}) } \\times \\sum_{i=0}^{2}{p(o_{0} | h_{i})p(h_{i} | o_{0}, o_{1}) } \\times \\sum_{i=0}^{2}{p(o_{2} | h_{i})p(h_{i} | o_{0}, o_{1}, o_{0}) } \\\\\n  =& \\sum_{i=0}^{2}\\alpha_{0 i} \\times \\sum_{i=0}^{2}{p(o_{1} | h_{i})p(h_{i} | o_{0}) } \\times \\sum_{i=0}^{2}{p(o_{0} | h_{i})p(h_{i} | o_{0}, o_{1}) } \\times \\sum_{i=0}^{2}{p(o_{2} | h_{i})p(h_{i} | o_{0}, o_{1}, o_{0}) } \\\\\n  =& \\sum_{i=0}^{2}{\\alpha_{1 i} } \\times \\sum_{i=0}^{2}{p(o_{0} | h_{i})p(h_{i} | o_{0}, o_{1}) } \\times \\sum_{i=0}^{2}{p(o_{2} | h_{i})p(h_{i} | o_{0}, o_{1}, o_{0}) } \\\\\n  =& \\sum_{i=0}^{2}{\\alpha_{2 i} } \\times \\sum_{i=0}^{2}{p(o_{2} | h_{i})p(h_{i} | o_{0}, o_{1}, o_{0}) } \\\\\n  =& \\sum_{i=0}^{2}{\\alpha_{3 i} }\n\\end{align*}\n$$\n\n우리는 이를 통해서, Markov Model의 특징을 하나 배울 수 있다. 그것은 바로 복잡한 sequence 전체의 확률에서 벗어나서 바로 직전의 확률값만 으로 다음 확률을 추론할 수 있다는 것이다. 이것이 Markov Chain이라는 이론이고, 이를 이용했기 때문에 Markov Model라고 부르는 것이기도 하다.\n\n따라서, $\\alpha$는 다음과 같이 정의할 수 있다.\n\n$$\n\\alpha(t, i) = \\sum_{k=1}^{N}{\\alpha(t-1, k)p(h_{i}|h_{k})p(o = s_{t}|h_{i})} \\quad (s_{t} = \\text{input으로 들어온 sequence의 t번째 값})\n$$\n\n또, 이를 반대로 할 경우에는 다음과 같은 식을 얻을 수 있다.\n\n![nlp-hidden-markov-model-2](/images/nlp-hidden-markov-model-2.jpg)\n\n$$\n\\begin{align*}\n  &\\sum_{i=0}^{2}p(o_{0}|h_{i})p(h_{i}|start) \\times \\sum_{i=0}^{2}{p(o_{1} | h_{i})p(h_{i} | o_{0}) } \\times \\sum_{i=0}^{2}{p(o_{0} | h_{i})p(h_{i} | o_{0}, o_{1}) } \\times \\sum_{i=0}^{2}{p(o_{2} | h_{i})p(h_{i} | o_{0}, o_{1}, o_{0}) } \\\\\n  =& \\sum_{i=0}^{2}p(o_{0}|h_{i})p(h_{i}|start) \\times \\sum_{i=0}^{2}{p(o_{1} | h_{i})p(h_{i} | o_{0}) } \\times \\sum_{i=0}^{2}{p(o_{0} | h_{i})p(h_{i} | o_{0}, o_{1}) } \\times \\sum_{i=0}^{2}{\\beta_{3i}} \\\\\n  =& \\sum_{i=0}^{2}p(o_{0}|h_{i})p(h_{i}|start) \\times \\sum_{i=0}^{2}{p(o_{1} | h_{i})p(h_{i} | o_{0}) } \\times \\sum_{i=0}^{2}{\\beta_{2i}} \\\\\n  =& \\sum_{i=0}^{2}p(o_{0}|h_{i})p(h_{i}|start) \\times \\sum_{i=0}^{2}{\\beta_{1i}} \\\\\n  =& \\sum_{i=0}^{2}{\\beta_{0i}} \\\\\n\\end{align*}\n$$\n\n$$\n\\beta(t, i) = \\sum_{k=1}^{N}{\\beta(t+1, k)p(h_{k}|h_{i})p(o = s_{t}|h_{i})} \\quad (s_{t} = \\text{input으로 들어온 sequence의 t번째 값})\n$$\n\n위의 처럼 앞에서부터 풀이를 해나가면서, $\\alpha$의 합으로 끝이 나도록 푸는 방법을 forwarding 방식이라하고, 반대로 뒤에서부터 풀이하면서 $\\beta$의 합으로 푸는 방법을 backwarding 방식이라고 한다. 사실 이 경우는 HMM이 굳이 아니더라도, MM으로 구할 수 있으니 굳이 필요는 없다. 하지만, 이것은 후에 modeling 단계에서 사용하기 때문에 알아두어야 한다.\n\n> <mark>**2. Viterbi**</mark>\n\n이는 observed state의 sequence에 의해서 파생되는 가장 적절한 hidden sequence를 구하는 것이 목표이다. 이를 통해서 할 수 있는 대표적인 것이 sequence classification이다.\n\n그렇다면 가장 유력한 hidden state의 sequence를 $\\hat{s}^{(H)}$라고 하자. 이는 다음과 같다.\n\n$$\n\\begin{align*}\n\\hat{s}^{(H)} &= \\argmax_{s^{(H)} \\in S^{(H)}}P(s^{(H)}|s^{(O)}) \\\\\n&= \\argmax_{s^{(H)} \\in S^{(H)}}P(s^{(O)}|s^{(H)})P(s^{(H)}) \\\\\n&= \\argmax_{{h_{1}, h_{2}, ..., h_{N}} \\in S^{(H)}}\\underbrace{P(o_{1}, o_{2}, ... , o_{N}|h_{1}, h_{2}, ... , h_{N})}_{\\text{Markov Model}}\\underbrace{P(h_{1}, h_{2}, ... , h_{N})}_{\\text{Markov Model}} \\\\\n&= \\argmax_{{h_{1}, h_{2}, ..., h_{N}} \\in S^{(H)}}\\prod_{i=1}^{N}p(o_{i}|h_{i})p(h_{i}|h_{i-1})\n\\end{align*}\n$$\n\n![nlp-hidden-markov-model-3](/images/nlp-hidden-markov-model-3.jpg)\n\n즉, 각 layer에서 단 하나의 가장 큰 output만 살아남을 수 있게 되는 것이다. 이 과정이 사실상 HMM의 본질적인 목표이다. sequence를 입력해서 sequence 형태의 classification 결과를 얻는 것이다.\n\n### Modeling\n\n여태까지 HMM을 활용하여 sequential class를 어떻게 estimation 하는지 알아보았다. 그렇다면, 이제는 이를 위해서 사용되는 확률값을 구해야한다. 필요한 확률값은 다음과 같다.\n\n- $p(h_{i}|h_{i-1})$ : Hidden State에서 Hidden State로 넘어가기 위한 확률이다.\n- $p(o_{i}|h_{i})$ : 방출 확률로 특정 Hidden State에서 다음 State의 Observed State로 넘어가는 방법이다.\n- $\\pi_{i}$\n\nTrelli 방식에서 만들었던, $\\alpha$와 $\\beta$의 의미를 이해해야 한다. 각 각은 해당 과정까지 오면서 누적해온 확률이라고 할 수 있다. 그리고, 우리가 원하는 것은 입력으로 주어진 데이터를 잘 반영할 수 있는 확률 값을 찾는 것이다. 그렇다면, 우리가 생각할 수 있는 방법은 평균을 활용하는 것이다. 이를 구하는 과정을 먼저 살펴보자.\n\n$$\n\\begin{align*}\n  c(i, j, k) &= h_{i}\\text{에서 } h_{j}\\text{로 넘어가고, } o_{k}\\text{가 관측될 확률의 합} \\\\\n  &= \\sum_{t=2}^{T} \\alpha(t-1, i)p(h_{j}|h_{i})p(o_{k}|h_{j}) \\beta(t, j) \\\\\n  \\\\\n  c(i,j) &= h_{i}\\text{에서 } h_{j}\\text{로 넘어갈 확률의 합} \\\\\n  &= \\sum_{k=1}^{K}\\sum_{t=2}^{T}{\\alpha(t-1, i)p(h_{j}|h_{i})p(o_{k}|h_{j}) \\beta(t, j)} \\\\\n  \\\\\n  c(i) &= h_{i}\\text{에서 상태를 변경하는 확률의 합} \\\\\n  &= \\sum_{j=1}^{N}\\sum_{k=1}^{K}\\sum_{t=2}^{T}{\\alpha(t-1, i)p(h_{j}|h_{i})p(o_{k}|h_{j}) \\beta(t, j)} \\\\\n\\end{align*}\n$$\n\n위의 값을 통해서 우리는 우리가 가지고 있던 확률을 업데이트할 수 있다.\n\n$$\n\\begin{align*}\np(h_{j}|h_{i}) &= {c(i,j)\\over c(i)} \\\\\np(o_{k}|h_{i}) &= {c(i,j,k)\\over c(i,j)}\n\\end{align*}\n$$\n\n즉, 우리는 다음 과정을 수행하여 Modeling을 수행할 수 있는 것이다.\n\n1. 초기값 ($p(h_{i}|h_{i-1})$, $p(o_{i}|h_{i})$, $\\pi_{i}$)을 초기화 한다.  \n2. Trelli를 통해서 $\\alpha$, $\\beta$를 계산한다.\n3. $p(h_{i}|h_{i-1})$, $p(o_{i}|h_{i})$를 업데이트 한다.  \n   ($pi_{i}$같은 경우는 발생 빈도로 업데이트 한다.)\n4. 임계치에 도달할 때까지 2,3번을 반복한다.\n\n이 과정을 대게 10번 정도만 하면 수렴하게 되고, 이를 확률로 사용하는 것이다.\n\n## Reference\n\n- Tumbnail : Photo by [David Ballew](https://unsplash.com/@daveballew?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@daveballew?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n","slug":"nlp-hmm","date":"2022-10-21 21:55","title":"[NLP] 6. Hidden Markov Model","category":"AI","tags":["NLP","MarkovModel","HMM","HiddenMarkovModel"],"desc":"이전까지 특정 word를 기반으로 하여 modeling을 수행하는 방법을 알아보았다. 하지만, 우리가 특정 word의 sequence를 통해서 각 word에 대한 classification을 한 번에 하고 싶은 경우는 어떻게 할까?(예를 들어, 각 단어의 품사를 지정하는 일) 일반적으로 각 단어가 특정 해당 class일 확률로 구하는 방법이 일반적일 것이다. 하지만, 문맥을 고려하여 확률을 구할 방법은 없을까? 그 방법은 바로 bigram을 이용하면 될 것이다. 그렇다면, 사실 우리가 사용하는 문맥이 단어 자체보다는 이전 class가 더 영향이 크다면, 이는 어떻게 해야할까? 이를 위한 해결책이 HMM이다. NLP 뿐만 아니라 여러 분야에서 넓게 사용되고 있지만, 여기서는 NLP 분야에서 어떻게 이를 사용하는지를 알아볼 것이다.","thumbnailSrc":"https://euidong.github.io/images/nlp-thumbnail.jpg"},{"content":"\n## Intro\n\n해당 Posting에서는 Maximum Entropy를 이용하여 최적의 parameter를 찾아나가는 Machine Learning 접근법에 기반한 NLP 방식을 제안한다. 이를 위해서 NL를 수학적인 형태로 변형하기 위한 기술 중 하나인 word2vec에 대한 설명도 같이 진행한다.\n\n## MaxEnt Model\n\nMaximum Entropy Model(MEM)의 약자로, 이것의 의미는 주어진 dataset을 표현할 수 있는 가장 적절한 분포는 Prior Knowledge를 만족하는 분포들 중에서 가장 높은 Entropy를 가지는 분포라는 것이다.  \n\n이는 다음과 같은 관측에 의해서 정의된 것이다.\n\n1. 다양한 물리현상들은 시간이 지남에 따라 Entropy를 최대화하려는 방향으로 이동하려는 경향이 있다.\n2. 더 적은 수의 논리로 설명이 가능한 경우, 많은 수의 논리를 세우지 말라 (오컴의 면도날)\n\n다소 억지같아 보이는 논리일지라도 후에 가서 살펴보면, Machine Learning의 Logistic Regression에 연결되는 것을 볼 수 있다. 우선은 이 정도 논리로 사용하겠다는 정도로 이해해보자.\n\n따라서, 우리가 풀어야할 식은 다음과 같다.\n\n$$\n\\begin{align*}\n  \\text{maximize}   \\quad & H(p) = - \\sum_{i=1}^{N}p_i\\log p_i &\\\\\n  \\text{subject to} \\quad & p_i \\geq 0, & i = 1, ..., N \\\\\n                          & \\sum_{i=1}^{N}p_i = 1 &\\\\\n                          & \\text{Other Prior Knowledge}\n\\end{align*}\n$$\n\n이를 이용해서 문제를 세 개 정도 풀어보면 감이 잡을 수 있는데 한 번 따라와보도록 하자.\n\n### Example\n\n> <mark>**1. 주사위 던지기**</mark>\n\n1부터 6까지의 눈이 있는 주사위가 있다고 할 때, 주사위의 각 눈이 나올 확률을 알고 싶다고 하자. 이때 우리는 간단하게 $1\\over6$이라고 말할 것이다. 이것도 Maximum Entropy에 기반한 추론 방법 중에 하나라고 할 수 있다. 다음 식을 보자.\n\n$$\n\\begin{align*}\n  \\text{maximize}   \\quad & H(p) = - \\sum_{i=1}^{N}p_i\\log p_i &\\\\\n  \\text{subject to} \\quad & p_i \\geq 0, & i = 1, ..., N \\\\\n                          & \\sum_{i=1}^{N}p_i = 1 &\n\\end{align*}\n$$\n\n정말 아무런 정보가 없을 때에는 위의 식을 Lagrangian을 쓰지 않고도 uniform distribution이라는 것을 알 수 있다. 이는 [🔗 [ML] Base Information Theory](/posts/ml-base-knowledge#Information-Theory)에서 살펴보았었다.\n\n그렇다면, 좀 더 복잡한 경우를 고려해보자. 아래는 Duke University ECE587 수업 PPT의 예제이다.\n\n> <mark>**2. 평균이 주어졌을 때의 추론**</mark>\n\n우리가 만약 평균 데이터를 알고 있다면, 이를 Maximum Entropy로 어떻게 추정할 수 있는지를 살펴볼 것이다. 아래는 어느 fastfood점의 메뉴라고 하자.\n\n| Item    | Price | Calories |\n| :------ | :---- | :------- |\n| Burger  | $1    | 1000     |\n| Chicken | $2    | 600      |\n| Fish    | $3    | 400      |\n| Tofu    | $8    | 200      |\n\n그리고 특정 학생이 이 가게에서 하루에 하나씩 먹는다고 할 때, 평균 소비 가격이 $2.5라고 하자. 그렇다면, 이 학생이 가장 많이 먹는 메뉴는 무엇일지를 추론해보는 것이다.  \n즉, 이를 식으로 정리하면 다음과 같다.\n\n$$\n\\begin{align*}\n  \\text{maximize}   \\quad & H(p) = - \\sum_{i=1}^{N}p_i\\log p_i &\\\\\n  \\text{subject to} \\quad & p_i \\geq 0, & i = 1, ..., N \\\\\n                          & \\sum_{i=1}^{N}p_i = 1 &\\\\\n                          & E[\\text{price}] = 2.5 &\n\\end{align*}\n$$\n\n이를 Lagrangian 방식을 이용해서 표현하면 다음과 같이 나타낼 수 있다.\n\n$$\n\\mathcal{L} = - \\sum_{i}^{N}p_{i}\\log{p_{i}} + \\lambda_{0}(\\sum_{i=1}^{N}p_{i} - 1) + \\lambda_{1}(\\sum_{i=1}^{N}\\text{price}_{i}\\times{p_{i}} -2.5)\n$$\n\n위 식을 각 각의 $p_{i}$에 대해서 미분하면 다음과 같다.\n\n$$\n{\\partial \\mathcal{L}\\over\\partial p_{i}} = -\\log{p_{i}} -1 + \\lambda_{0} + \\lambda_{1}\\times\\text{price}_{i}\n$$\n\n따라서, $p_{i}$는 다음과 같다.\n\n$$\n\\begin{align*}\n0 &= -\\log{p_{i}} -1 + \\lambda_{0} + \\lambda_{1}\\times\\text{price}_{i} \\\\\n\\log{p_{i}} &= \\lambda_{0} + \\lambda_{1}\\times\\text{price}_{i} - 1 \\\\\np_{i} &= e^{\\lambda_{0} + \\lambda_{1}\\times\\text{price}_{i} - 1}\n\\end{align*}\n$$\n\n여기서 나오는 모든 식과 제한 조건을 정리하면 다음과 같다.\n\n- $p(Burger) = e^{\\lambda_{0} + \\lambda_{1} - 1}$, $p(Chicken) = e^{\\lambda_{0} + 2\\lambda_{1} - 1}$, $p(Fish) = e^{\\lambda_{0} + 3\\lambda_{1} - 1}$, $p(Tofu) = e^{\\lambda_{0} + 8\\lambda_{1} - 1}$\n- $p(Burger) + p(Chicken) + p(Fish) + p(Tofu) = 1$\n- $p(Burger) + 2p(Chicken) + 3p(Fish) + 8p(Tofu) = 2.5$\n\n위의 식을 연립해서 풀면, $\\lambda_{0} = 1.2371$, $\\lambda_{1}=0.2586$이고, 전체 확률은 다음과 같다.\n\n| Item    | p      |\n| :------ | :----- |\n| Burger  | 0.3546 |\n| Chicken | 0.2964 |\n| Fish    | 0.2478 |\n| Tofu    | 0.1011 |\n\n> <mark>**3. 주사위의 눈의 합**</mark>\n\n1번에서 보았던 주사위를 n개 던져서 나온 눈의 합을 알 때, 주사위의 비율을 추정한다고 해보자.\n\n이때 우리는 다음과 같은 변수를 정의할 수 있다.\n\n- 주사위의 갯수 : $n$\n- i개의 눈을 가진 주사위의 갯수 : $n_{i}$\n- 전체 눈의 수의 합 : $n\\alpha$\n- 추가되는 Prior Knowledge : $\\sum_{i=1}^{6}{i n_{i}} = n\\alpha$\n\n이를 Maximum Entropy를 이용해서 풀게 되면 다음과 같은 결론을 얻을 수 있다.\n\n$$\np_{i} = {e^{\\lambda_{i}}\\over{\\sum_{i=1}^{6}{e^{\\lambda_{i}}}}}\n$$\n\n## Generalization\n\nMaximum Entropy를 위의 식을 통해서 구하는 것도 문제는 없지만 우리는 좀 더 일반화된 식을 원한다. 따라서, 이를 표현하기 위해서 다음과 같은 상황을 고려해보는 것이다. 우리가 마지막 보았던 예시가 사실은 우리가 하고자 하는 과정을 대표하는 하나의 예시이다. 우리가 가진 사전 지식은 이전에 관측한 데이터와 이것의 class이다. 따라서, 우리는 관측 결과의 가짓수(class)가 $K$개이고, 데이터의 input과 결과를 $(X, Y)$ 쌍이 라고 할 때, 특정 input data($X_{i}$)가 class k일 확률은 다음과 같이 표현할 수 있다.\n\n$$\np(Y_{i} = k) = {e^{w^{\\top}_{k}X_{i}}\\over{\\sum_{k^{\\prime}=1}^{K}{e^{w_{k^{\\prime}}^{\\top}X_{i}}}}}\n$$\n\n여기서 가장 중요한 Point가 발견된다. 바로 이 식이 **softmax** 함수라는 것이다. <mark>즉, Maximum Entropy를 통한 classification의 의미는 사실상 multinomial logistic regression의 다른 이름일 뿐이다.</mark> (logistic regression에 대한 내용은 [🔗 [ML] 3. Logistic Regression](/posts/ml-logistic-regression)에서 다루었다.)\n\n따라서, 여기서는 별도로 Modeling, Estimation, Smoothing 절차를 다루지 않는다. machine learning의 방법과 동일하기 때문이다.\n\n## Features\n\nNL의 가장 큰 특징은 data가 sparse하다는 것이다. domain마다 사용되는 언어와 빈도가 너무나 천차만별이기 때문에 sparse 현상이 필연적으로 발생한다. 이를 극복하기 위해서 대게의 data는 domain 별로 따로따로 수집하는 것이 일반적이다. 또한, data에서 올바른 feature를 추출하는 것이 굉장히 중요하다.  \n이를 위해 NL에서 전통적으로 쓰던 방식은 대소문자 여부, 억양 표기, 품사, 문장구조, 뜻 등을 단어에 미리 적용하기도 하여 이를 이용하는 방법도 있다. 그런데 이러한 품사, 뜻 등을 찾아내는 과정도 Statistical Inference가 필요하다. 따라서, 앞으로 chapter에서는 품사와 문장구조 뜻을 정의하기 위한 기술들과 이를 어떻게 찾을 수 있는지를 알아볼 것이다.\n\n또한, Word자체를 Vector로 치환하여 사용하는 Word2Vec방식에 대해서도 살펴보도록 하겠다.\n\n## Reference\n\n- Tumbnail : Photo by [David Ballew](https://unsplash.com/@daveballew?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@daveballew?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n- Maximum Entropy 자료 참고, <https://www2.isye.gatech.edu/~yxie77/ece587/Lecture11.pdf>\n","slug":"nlp-maxent","date":"2022-11-07 10:02","title":"[NLP] 7. MaxEnt","category":"AI","tags":["NLP","MaximumEntropyModel","softmax"],"desc":"해당 Posting에서는 Maximum Entropy를 이용하여 최적의 parameter를 찾아나가는 Machine Learning 접근법에 기반한 NLP 방식을 제안한다. 이를 위해서 NL를 수학적인 형태로 변형하기 위한 기술 중 하나인 word2vec에 대한 설명도 같이 진행한다.","thumbnailSrc":"https://euidong.github.io/images/nlp-thumbnail.jpg"},{"content":"\n## Intro\n\n우리가 NL을 제대로 분석하기 위해서 각 단어가 가진 의미를 알아야하며, 이를 넘어서 문장이 가지는 의미를 파악해야 한다. 결론적으로 이 과정이 고도화된 NLP를 위한 핵심 단계이다. 이를 위해서는 Raw한 형태로 주어진 text를 처리해서 더 나은 형태의 구조를 만들 필요가 있다. 따지고 보면 하나의 전처리 과정이라고 볼 수 있다. 그치만 이전 text processing chapter과 다른 점은 문장 구분과 같은 간단한 과정이 아닌 Linguistic 단계에 따른 처리 과정을 수행한다고 볼 수 있다. 또한, 각 단계 역시 NLP 중에 하나라고 할 수 있으므로 이 또한 ML과 DL을 통해서 고도화하는 것도 가능하다. Morphology 단계부터 시작하여 Syntax, Semantic까지 어떻게 다루게 되는지를 살펴보도록 하겠다.\n\n## POS tagging\n\nMorphology 단계에서 가장 기본이되는 요소이기 때문에 이를 먼저 살펴보도록 하겠다. Part of Speech라는 단어의 뜻 자체가 \"품사\"이다. 이는 단어의 문법적인 기능이나 형태 등을 표현하기 위해서 제시되었다. 이를 구분하려는 시도는 디오니소스 이전부터 있었지만 근본적인 형태를 제시한 것은 디오니소스가 첫 번째이다. 그는 기원전 100년에 지금과 굉장히 유사한 형태의 8개의 품사를 제시하였다. 지금도 8개지만, 감탄사와 형용사 등이 추가되고 몇몇 요소가 빠졌다. 이를 NLP 과정에서 input으로 활용하게 되면 언어의 모호성을 해결하는데 도움을 줄 수 있다. 품사를 통해서 단어가 가지는 뜻의 범위가 더 줄어들 수 있기 때문이다. 따라서, 이를 각 단어마다 표시하는 절차를 preprocessing으로 진행하는 경우도 많다.\n\n우선 POS의 일반적인 종류는 다음과 같다.\n\n- Noun(명사)\n- Verb(동사)\n- Adjective(형용사)\n- Adverb(부사)\n- Preposition(전치사)\n- Conjunction(접속사)\n- Pronoun(대명사)\n- Interjection(감탄사)\n\n하지만, Computer Science에서는 이를 좀 더 명확하게 표현하기 위해서 더 많은 분류(tag)를 사용하는 것이 일반적이다. 대표적인 예시가 [🔗 Penn Treebank](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html)이다. 여기서는 36개의 종류를 활용하여 표기한다. 이외에도 Brown Corpus 등 다양한 tagging 방법이 있다. 또한, 언어에 따라서는 별도의 품사를 정의하는 경우도 많기 때문에 언어마다 적절한 방식을 사용해주는 것이 좋다.\n\ntag를 정할 때 일반적인 규칙은 우리가 중/고등학교 시간에 배웠을 문법 요소를 적용한 것이 많다는 점을 기억하면 된다. NNS 같은 경우는 복수명사 뒤에 붙은 s를 포함하는 tag를 의미하고, VBD는 동사 과거형을 의미한다. 이와 같은 형태로 품사를 좀 더 세분화한 것 외에는 차이가 없다.\n\n### How can I get?\n\n그렇다면, 어떻게 하면 POS tagging된 데이터를 얻을 수 있을지가 궁금할 것이다. 신기하게도 가장 쉬운 추론을 하더라도 90%의 정확도를 가질 수 있다. 다음과 같은 방법이다.\n\n1. 단어가 가지는 품사 중 가장 빈도가 높은 것을 표기한다.\n2. 못 본 단어인 경우 Noun(명사)로 표기한다.\n\n이것이 가능한 이유는 사실상 대부분의 word는 모호하지 않다는 점이다. 대부분의 word는 품사 앞에서는 그렇게 변화무쌍하지 않다. **하지만,** 특정 word는 사람 조차도 헷갈리는 경우가 있다. 대게 통계적으로 11%정도는 사람 조차도 헷갈릴 수 있는 형태의 품사가 주어진다고 한다. 그래서, 이를 해결하기 위해서 Statistic Inference를 활용하는 경우가 있고, 우리가 앞 서 배웠던 HMM을 활용하면 97%, MaxEnt를 활용하면 99% 정확도를 가지는 tagger를 만들 수 있다. 물론 더 복잡한 Deep Learning을 활용한다면 더 높은 성능도 가능은 할 것이다.\n\n## Morphology\n\nMorphology 단계에서 POS tagging이 중요하긴 하지만 더 나아갈 필요가 있다. 결국 우리가 원하는 것은 단어의 의미를 더 완벽하게 찾는 것이다. 따라서, 대게의 경우 POS tagging을 포함하는 Morphology tagging을 수행한다. 특정 단어를 사전형 기본형(lemma) 또는 더 나아가 가장 뿌리가 되는 요소 root와 stem으로 나누고 여기에 품사를 덧붙이는 형태이다. 우리가 얻은 품사(tag)와 lemma만 갖고도 우리는 원래 단어를 만드는 것이 가능하고, 뜻의 범위를 더 한정할 수 있다. 더 나아가 root와 stem으로 나누게 되면 보지 못한 데이터에 대해서도 더 면밀한 의미 파악이 가능해진다. 이를 구현할 때에는 대게 4가지 방법 중에 하나를 수행하는 것이 일반적이다.\n\n1. Word form list  \n   간단하게 생각하면, word list에서 단어를 조회하는 방식이다. 대게 key, value보다는 Trie 형태로 담는 것을 선호한다. Trie는 각 node가 sequence 데이터의 요소 하나하나가 되는 tree를 의미하며, sequence 데이터의 조회를 위해 사용된다.\n2. Direct coding  \n   root와 stem을 찾는 과정은 사실 영어에서는 간단하다. 앞 뒤에서 부터 진행하면서 대표적인 stem을 제거해 나가면, root만 남기 때문이다. 하지만, 일부 일본어와 같은 경우에는 이것이 불가능한 경우도 있다. 이 경우에는 다른 방식을 적용해야 한다.\n3. Finite state machinery  \n   각 단어의 형태를 FSM으로 정의하여 변할 수 있는 형태와 이에 따른 품사 등을 미리 표현하여 정의하는 방법이다.\n4. CFG, DATR, Unification  \n   언어학에 기반한 분석법이다.\n\n사실 이러한 방법을 직접 구현하는 것은 한계가 있을 수 있다. 따라서, 이미 구현되어 있는 POS tagger를 사용하는 것이 현명할 수 있다. 일반적으로 가장 많이 사용되는 POS tagger는 다음과 같은 것들이 있다.\n\n| Library | Language | ProgrammingLanguage |\n| :------ | :------- | :------------------ |\n| NLTK    | English  | Python              |\n| spaCy   | English  | Python              |\n| KoNLPy  | 한글     | Python              |\n\n## Syntactic Analysis\n\nMorphology 단계에서는 각 word의 뜻을 다루었다면, 이 단계는 word의 결합으로 이루어지는 문장 구조를 분석하는 단계이다. 문장 구조를 분석(구문 분석)하는 방법은 크게 두 가지로 나뉘어진다.\n\n1. <mark>**Phrase Structure**</mark>  \n   문장을 Phrase(구) 단위로 나누어 구조화 시키는 방법이다. 단어 각 각의 품사에서 부터 시작하여 이들을 묶어서 하나의 문장 요소(대게 phrase)를 만들어 하나의 문장을 만드는 구조를 가진다.\n2. <mark>**Dependency Structure**</mark>  \n   문장에서 각 단어가 가지는 의존 관계를 나타낸 구조이다.\n\n각 구조는 둘다 Tree 형태로 이루어지며, 분석하는 방법도 서로 매우 다르다. 각 방법은 밑에서부터 자세히 다루도록 하겠다.\n\n### Phrase Structure\n\n문장을 이루는 요소들과 요소들의 구조화 규칙을 정의해야 우리는 이를 분석할 수 있을 것이다. 따라서, 이를 정의한 것을 Grammar라고 한다. 그리고 이를 위해서 대표적으로 사용되는 것이 **CFG**이다. **CFG**는 Context Free Grammar의 약자로, 모든 잘 구조화된 문장들을 정의할 수 있는 규칙들을 의미한다. 각 각의 Rule은 왼쪽에는 문법적 type이 주어지고, 오른쪽에는 이를 이루는 요소들이 정의되어진다. 각 요소는 하위 문법적 type 또는 이전에 제시한 POS가 될 수 있다.\n\n가장 기본적으로 사용되어지는 문법적 type들은 다음과 같다. 이외에도 기술하지 않은 POS도 사용이 가능하다.\n\n| Symbol  | Mean               | Korean   |\n| :------ | :----------------- | :------- |\n| NP      | Noun Phrase        | 명사 구  |\n| VP      | Verb Phrase        | 동사 구  |\n| S       | Sentence           | 문장     |\n| DET(DT) | Determiner         | 관사     |\n| N       | NOUN               | 명사     |\n| V       | Verb               | 동사     |\n| PREP    | Preposition        | 전치사   |\n| PP      | Preposition Phrase | 전치사구 |\n\n이에 따라 대표적인 Rule은 다음과 같다.\n\n- S -> NP VP\n- NP -> (DT) N\n- NP -> N\n- VP -> V (NP)\n\n위에 제시된 Rule은 가장 기본적인 규칙으로 여기서 더 확장된 규칙을 만들어서 Parsing을 수행할 수 있다. 하지만, 이렇게 규칙을 만들어서 수행을 하게 되면 문제가 발생할 수 있다. 바로 여러 개의 Parsing Result가 만들어졌을 때 이 중에서 어떤 것이 가장 적절한지를 알 수 없다는 것이다. 즉, 너무 구체적인 Rule을 만들기에는 Parsing이 하나도 되지 않는 문장이 만들어질 가능성이 높고, 그렇다고 너무 적은 Rule을 적용하게 되면 Parsing이 너무 많이 만들어지게 된다.\n\n따라서, 결론적으로 말하자면 위와 같은 형태의 CFG로는 phrase structure를 구조화하는데 한계가 있다는 결론을 내리게 된다. 결국 아래와 같은 두 개의 문제점에 직면하게 되고 이를 해결하기 위한 방법이 각 각 제시된다.\n\n1. Repeated work  \n   문장 구조가 동일한 경우 결국 동일한 작업을 반복하게 된다. 이를 해결하기 위해서 Treebank라는 구조를 도입하고, 이것의 일부를 Dynamic Programming의 Memoization처럼 저장해두었다가 쓰는 방식을 적용한다. 즉, 기존에는 Rule만을 저장하고, 때에 따라 이를 적용하였다면, 이제는 모든 단어의 품사와 구조를 기록해두는 것이다. 이를 통해서 이미 나왔던 작업의 경우 빠른 처리가 가능해진다.\n2. Choosing the correct parse  \n   위에서 말했던 것처럼 우리는 결국 <mark>가장 적절할 거 같은 parsing result를 선택해야 한다.</mark> Rule에 기반한 방식으로는 한계가 있지만 우리가 Statistic한 방식을 활용한다면 이를 극복할 수 있다. 따라서, 우리는 CFG에서 나아가 PCFG(Probabilistic CFG)를 적용하여 이를 처리할 수 있다. 이러한 Statistical한 결과를 얻기 위해서도 Treebank 구조가 필요하다.\n\n![nlp-cfg-treebank](/images/nlp-cfg-treebank.jpg)\n\n이제부터는 실제로 PCFG를 어떻게 수행할 수 있는지를 자세히 다뤄보도록 하겠다.\n\n#### PCFG\n\n앞 서 얘기한 것처럼 Probabilistic CFG로, 각 Rule마다 Probability를 적용하는 것이다. 여기서 유의할 것은 다음 내용이다.\n\n1. 기존 정의한 문법적 type을 만드는 Rule에 각 각의 확률을 정의한다.\n2. 이때 각 문법적 type을 만들 수 있는 Rule의 확률의 합은 반드시 1이다.\n3. 또한, 각 단어가 특정 POS일 확률도 같이 구해야 한다.  \n   ex. N -> fish (0.5), V -> fish (0.1)  \n   (실제로 이렇게 크게 나오지 않는다. N 또는 V 일 때, Fish일 확률이므로 굉장히 작은 값이 나오는 것이 일반적이다.)\n\n따라서, 어떤 treebank가 더 적절한 지는 각 각의 treebank의 모든 Rule의 확률의 곱을 구해서 비교하면 된다. 굉장히 쉽게 이 과정이 가능한 것이다. 아래는 간단한 예시이다.\n\n![nlp-pcfg](/images/nlp-pcfg.jpg)\n\n이렇게 주어졌을 때, $p(t_1)$과 $p(t_2)$는 아래와 같이 구할 수 있다.\n\n$$\n\\begin{align*}\np(t_{1}) &= 1.0 \\\\\n&\\times 0.3 \\times 0.6 \\\\\n&\\times 0.4 \\\\\n&\\times 0.5 \\times 0.1 \\times 0.4 \\times 1.0 \\times 0.4  \\\\\n&= 0.000576 \\\\\n\\\\\np(t_{2}) &= 1.0 \\\\\n&\\times 0.3 \\times 0.4 \\\\\n&\\times 1.0 \\\\\n&\\times 0.4 \\\\\n&\\times 0.5 \\times 0.6 \\times 1.0 \\times 1.0 \\times 0.4 \\\\\n&= 0.00576 \\\\\n\\\\\n\\therefore p(t_{1}) &\\lt p(t_{2})\n\\end{align*}\n$$\n\n따라서, $t_{2}$ 형태가 더 적절하다고 판별할 수 있는 것이다.\n\n```plaintext\n 🤔 Chomsky Normal Form\n\n 기존 CFG의 형태의 모호함을 제거하고, 좀 더 명확한 형태로 정의하는 것을 의미한다.\n 대표적으로 모호한 내용이 Sentence안에 Sentence를 포함하는 경우(n-ary)라든지,\n 명령문과 같은 문장을 위한 주어 삭제(unary/empty) 등이 존재한다.\n 이를 해결하기 위한 recursive 형태나 empty 형태 등을 제거하는 것을 의미한다.\n\n 결론상 PCFG에서는 확률 표기시에 모호한 표기를 제거할 수 있다는 장점이 있다.\n```\n\n#### CKY Parsing\n\n앞 서 우리가 treebank 중에서 더 큰 확률곱 값을 가지는 것이 최적값이라는 것을 알 수 있었다. 하지만, 사실 이 과정이 그렇게 쉽지는 않다. 왜냐하면, 우리가 가지는 Parsing Result는 굉장히 많을 수도 있기 때문이다. 그렇다면, 이를 연산하는 비용이 굉장히 비싸진다. 이를 효과적으로 연산하기 위한 알고리즘으로 제시된 것이 CKY Parsing이다.\n\nPseudo code는 다음과 같다.\n\n```javascript\nfunction CKY(words, grammar) returns [scores, backpointers]\n  // score[i][j] = \n  // 모든 Symbol(문법적 type, ex. S, NP, VP)에 대하여 \n  // i부터 j까지 word를 사용했을 때의 최댓값을 저장\n  score = new double[#(words) + 1][#(words)+1][#(Symbol)]\n  // back[i][j] = \n  // 모든 Symbol(문법적 type, ex. S, NP, VP)에 대하여 \n  // i부터 j까지 word를 사용했을 때의 최댓값을 만드는 요소의 위치를 저장\n  // (=back pointer)\n  back = new Pair[#(words)+1][#(words)+1][#(Symbol)]\n  for (i=0; i < #(words); i++)\n    // 초기화 단계로 각 단어가 Symbol일 확률을 입력\n    for (A in Symbol)\n      if A -> words[i] in grammar\n        score[i][i+1][A] = P(A -> words[i])\n    // unary 즉 생략되어서 표현되는 경우를 위해서 확률 재계산\n    // ex. Stop!! (S->VP,VP->V)\n    boolean added = true\n    while (added)\n      added = false\n      for A, B in Symbol\n        if score[i][i+1][B] > 0 && A -> B in grammar\n          prob = p(A -> B) * score[i][i+1][B]\n          if prob > score[i][i+1][A]\n            score[i][i+1][A] = prob\n            back[i][i+1][A] = B\n            added = true\n  for (span = 2 to #(words))\n    for (begin = 0 to #(words) - span)\n      // 일반적인 두 항의 합으로 이루어지는 경우를 계산\n      end = begin + span\n      for (split = begin + 1 to end-1)\n        for (A, B, C in Symbol)\n          prob = score[begin][split][B] * score[split][end][C]*P(A -> B C)\n          if prob > score[begin][end][A]\n            score[begin][end][A] = prob\n            back[begin][end][A] = new Triple(split, B, C)\n      // unary인 경우를 고려해서 재계산\n      boolean added = true\n      while (added)\n        added = false\n        for (A, B in Symbol)\n          prob = P(A -> B) * score[begin][end][B]\n          if prob > score[begin][end][A]\n            score[begin][end][A] = prob\n            back[begin][end][A] = B\n            added = true\n  return score, back\n```\n\n전체적인 동작과정은 그림을 통해서 이해할 수 있다. 먼저초기 score 할당부터 첫 단계에 데이터를 저장하기까지는 아래 그림으로 이해할 수 있다.\n각 그림을 다음을 의미한다.\n\n1. score를 위한 공간 할당\n2. score에 가장 기본이 되는 Symbol -> word 확률 입력\n3. unari case를 확인해서 확률 입력\n\n![nlp-cky-1](/images/nlp-cky-1.png)\n\n그 다음 단계로는 단계적으로 관계를 적립한다.\n\n1. 같은 형광펜으로 칠해진 데이터간 관계가 최댓값을 가진다.\n2. unari case도 확인한 결과 S->VP가 초기화 된다.\n\n![nlp-cky-2](/images/nlp-cky-2.png)\n\n마지막에서 다시 관계를 정리할 때, 유의할 점이 있다. 바로 score\\[0\\]\\[3\\]와 score\\[1\\]\\[4\\]도 중요하지만 score\\[0\\]\\[2\\]와 score\\[2\\]\\[4\\]에 의한 관계도 반드시 유의해서 보아야 한다.\n\n![nlp-cky-3](/images/nlp-cky-3.png)\n\n#### modeling\n\n원래라면, modeling 단계도 다루어야하지만, 해당 단계에서는 넘어가도록 한다. 이를 수행하기 위해서는 간단하게는 단순히 빈도를 확인하는 것부터 EM algorithm을 활용하여 업데이트 하는 방식이 있다. 하지만 여기서는 자세히 다루지 않겠다.\n\n### Dependency Structure\n\n문장에서 각 단어의 의존 관계를 나타내는 Dependency Structure는 중심 의미를 가지는 word로 부터 이에 의존하는 word들의 관계로 확장되며 표기된다. 따라서, 문장에서는 대게 동사가 중심이 되고, 그리고 그 다음으로는 전치사, 명사 등이 뒤를 잇게 된다. 이를 파악하게 되면, 단어가 연관성과 전체적인 구조의 안정성 등을 파악하는데 도움을 줄 수 있다.\n\n이 형태를 얻기 위해서 할 수 있는 대표적인 방법은 다음과 같은 방법이 있다.\n\n1. Dynamic Programming  \n   아주 쉽게 생각할 수 있는 방법으로 **PCFG를 활용**하는 것이다. 일반적으로 PCFG를 활용하여 tree 형태를 구축하면 이를 이용하여 Dependency Structure를 쉽게 구할 수 있다. 단순히 tree의 아래서 부터 의존 관계를 가진 단어를 고르면서 root까지 올라오면 이것으로 충분하다. 하지만, 이 과정은 시간적 비용이 많이 든다는 단점이 있다.\n2. Graph Algorithm  \n   **가장 정확도가 높은 방식**으로 Sentence에 대한 Minimum Spanning Tree를 구성하고, 이를 활용하여 ML classifier를 제작하여 구현할 수 있다. 가장 높은 정확도를 원한다면 해당 방식을 활용하는 경우가 많다.\n3. Constraint Satisfaction  \n   모든 경우의 수를 만들고 거기서 제한사항을 만족하지 않는 구조를 제거하는 방식이다. 이 또한 많이 사용되지는 않는다.\n4. Deterministic Parsing  \n   Greedy algorithm에 기반하여 구현된 방식으로 매우 높지는 않지만 적절한 정확도에 **빠른 속도**를 가지기 때문에 많이 사용되어진다.\n\n#### Malt Parser\n\n여기서는 Deterministic Parsing 중에서 가장 쉬운 방법 중에 하나인 Malt Parser를 좀 더 다뤄보도록 하겠다.\n\n이는 3개의 자료 구조와 4개의 action을 통해서 정의되는 알고리즘이다.  \n먼저 자료구조는 다음과 같다.\n\n1. stack($\\sigma$)  \n   dependency tree의 상위 요소를 저장해두는 공간으로, 처음에는 ROOT라는 요소를 갖고 시작한다.\n2. buffer($\\beta$)  \n   input sequence를 저장하는 공간으로, 처음에는 input sequence를 전체를 저장하고 있다.\n3. arcs($A$)  \n   최종으로 만들고자 하는 dependency tree를 의미한다. 처음에는 비어 있는 상태로 시작한다.\n\naction은 다음과 같다.\n\n1. Reduce  \n   stack($\\sigma$)에서 word를 pop한다.\n2. Shift  \n   buffer($\\beta$)에서 stack($\\sigma$)으로 word를 push한다. 이때 문장의 앞의 단어부터 차례대로 전달한다.\n3. Left-Arc  \n   stack($\\sigma$)의 현재 word가 buffer($\\beta$)의 다음 word에 의존하는 경우, 이 관계를 연결하여 arcs($A$)에 저장한다.  \n   결론상 stack($\\sigma$)에서는 pop이 되고, buffer($\\beta$)는 그대로 유지되며, arcs($A$)에는 depdendency가 하나 추가된다.\n4. Right-Arc  \n   buffer($\\beta$)에서 다음 word를 stack($\\sigma$)에 push하고, 기존 stack($\\sigma$)의 이전 word에 의존하는 관계를 arcs($A$)에 추가한다.\n5. Finish  \n   buffer($\\beta$)에 더 이상 word가 없다면, 모든 연산을 마무리할 수 있다.\n\n이 또한 예시를 통해서 알아보는 것이 명확하다.\n\n우리가 `Happy children like to play with their friends.`를 분석하고 싶다고 하자. 그렇다면, 절차는 다음과 같이 진행된다.\n\n| Index | Action    | Stack($\\sigma$)                   | Buffer($\\beta$)        | Arcs($A$)                                      |\n| :---- | :-------- | :-------------------------------- | :--------------------- | :--------------------------------------------- |\n| 0     |           | [ROOT]                            | [Happy, children, ...] | $\\empty$                                       |\n| 1     | Shift     | [ROOT, Happy]                     | [children, like, ...]  | $\\empty$                                       |\n| 2     | LA(amod)  | [ROOT]                            | [children, like, ...]  | {amod(children, happy) = $A_{1}$}              |\n| 3     | Shift     | [ROOT, children]                  | [like, to, ...]        | $A_{1}$                                        |\n| 4     | LA(nsubj) | [ROOT]                            | [like, to, ...]        | $A_{1} \\cup ${nsubj(like, children)} = $A_{2}$ |\n| 5     | RA(root)  | [ROOT, like]                      | [to, play, ...]        | $A_{2} \\cup ${root(ROOT, like)} = $A_{3}$      |\n| 6     | Shift     | [ROOT, like, to]                  | [play, with, ...]      | $A_{3}$                                        |\n| 7     | LA(aux)   | [ROOT, like]                      | [play, with, ...]      | $A_{3} \\cup ${aux(play, to)} = $A_{4}$         |\n| 8     | RA(xcomp) | [ROOT, like, play]                | [with, their,...]      | $A_{4} \\cup ${xcomp(like, play)} = $A_{5}$     |\n| 9     | RA(prep)  | [ROOT, like, play, with]          | [their, friends, .]    | $A_{5} \\cup ${prep(play, with)} = $A_{6}$      |\n| 10    | Shift     | [ROOT, like, play, with, their]   | [friends, .]           | $A_{6}$                                        |\n| 11    | LA(poss)  | [ROOT, like, play, with]          | [friends, .]           | $A_{6} \\cup ${poss(friends, their)} = $A_{7}$  |\n| 12    | RA(pobj)  | [ROOT, like, play, with, friends] | [.]                    | $A_{7} \\cup ${pobj(with, friends)} = $A_{8}$   |\n| 13    | Reduce    | [ROOT, like, play, with]          | [.]                    | $A_{8}$                                        |\n| 14    | Reduce    | [ROOT, like, play]                | [.]                    | $A_{8}$                                        |\n| 15    | Reduce    | [ROOT, like]                      | [.]                    | $A_{8}$                                        |\n| 16    | RA(punc)  | [ROOT, like, .]                   | []                     | $A_{8} \\cup${punc(like, .)} = $A_{9}$          |\n| 17    | Finish    | [ROOT, like, .]                   | []                     | $A_{9}$                                        |\n\n자 이런 예시를 보았다면, 당연히 궁금해할 것은 어떻게 Action을 고를 것인가이다. 이는 Discriminative classifier 즉, Maxent나 여타 Machine Learning 방법을 동원하여 결정한다. PCFG를 활용하는 방식보다는 성능이 약간 낮을지라도 이를 활용하면 매우 빠르게 parsing이 가능하다는 장점이 있다.\n\n```plaintext\n 🤔 Projectivity\n \n 사실 여태까지 우리는 연속되어 있는 word간의 의존성을 파악하는 과정을 살펴보았다.(특히 PCFG)\n 하지만, 그렇지 않은 경우도 분명히 존재한다. 대표적인 예시가 아래이다.\n Who did Bill buy the coffee from yesterday?\n 여기서 from은 Who와 관계가 있지만, 우리가 여태까지 살펴본 PCFG와 Malt Parser로 \n 이 관계를 밝히는데에는 한계가 있다.\n 따라서, 이를 해결하기 위해서 후처리나 추가적인 action을 Malt Parser에 더하거나 \n 아니면 아예 다른 방식을 앙상블하여 해결하기도 한다.\n```\n\n## Semantics\n\n자세히 여기서 다루지 않지만, 구문 분석을 통해 얻은 Tree를 통해서 어떻게 의미를 추출할 수 있는지를 알아보겠다. 먼저, 우리는 전체 요소를 다시 한 번 두 가지로 나눈다.\n\n1. Entities  \n   특정 의미를 가지는 하나의 주체이다. 주로 NP가 모두 여기에 속한다.\n2. Functions  \n   Entity 또는 다른 Function에게 동작, 특성, 등을 적용한다. 형용사, 동사 등이 여기에 속한다.\n\n따라서, 우리가 `Every nation wants George to love Laura.`라는 문장을 갖고 있다면, 우리는 아래와 같이 Tree를 그릴 수 있고, 이를 이용해서 의미 분석이 가능하다.\n\n![nlp-semantic](/images/nlp-semantic.jpg)\n\n위 Tree를 아래에서부터 연결해서 나가면 다음과 같이 구조화되는 것을 알 수 있다.\n\n| Index | Expression                                                |\n| :---- | :-------------------------------------------------------- |\n| 1     | love(x, Laura)                                            |\n| 2     | love(x, Laura)                                            |\n| 3     | love(George, Laura)                                       |\n| 4     | want(x, love(George, Laura))                              |\n| 5     | present(want(x, love(George, Laura)))                     |\n| 6     | Every(nation)                                             |\n| 7     | present(want(Every(nation), love(George, Laura)))         |\n| 8     | assert(present(want(Every(nation), love(George, Laura)))) |\n\n## Reference\n\n- Tumbnail : Photo by [David Ballew](https://unsplash.com/@daveballew?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@daveballew?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n- Penn Treebank POS tagging, <https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html>\n- spaCy, <https://spacy.io/>\n- NLTK, <https://www.nltk.org/>\n- KoNLPy, <https://konlpy.org/ko/latest/index.html>\n- NLP CFG, <https://tildesites.bowdoin.edu/~allen/nlp/nlp1.html>\n","slug":"nlp-language-parsing","date":"2022-11-07 15:05","title":"[NLP] 8. Language Parsing","category":"AI","tags":["NLP","POS","PCFG","Morphology","Syntax","Semantics"],"desc":"우리가 NL을 제대로 분석하기 위해서 각 단어가 가진 의미를 알아야하며, 이를 넘어서 문장이 가지는 의미를 파악해야 한다. 결론적으로 이 과정이 고도화된 NLP를 위한 핵심 단계이다. 이를 위해서는 Raw한 형태로 주어진 text를 처리해서 더 나은 형태의 구조를 만들 필요가 있다. 따지고 보면 하나의 전처리 과정이라고 볼 수 있다. 그치만 이전 text processing chapter과 다른 점은 문장 구분과 같은 간단한 과정이 아닌 Linguistic 단계에 따른 처리 과정을 수행한다고 볼 수 있다. 또한, 각 단계 역시 NLP 중에 하나라고 할 수 있으므로 이 또한 ML과 DL을 통해서 고도화하는 것도 가능하다. Morphology 단계부터 시작하여 Syntax, Semantic까지 어떻게 다루게 되는지를 살펴보도록 하겠다.","thumbnailSrc":"https://euidong.github.io/images/nlp-thumbnail.jpg"}],"Memoir":[{"content":"\n## Intro\n\nSDN Lullaby는 SDN/NFV 환경에서 효율적인 VNF 배치에 관하여 작성한 논문이다. 이 논문에서는 VNF 배치 문제를 DRL을 이용하여 해결하였다. 이를 위해서, 해당 논문에서는 상용 Cloud Data Center에서 주로 사용되던 VM Consolidation 방식을 활용하였고, 이 과정에서 추가적인 구현을 더해서 VNF 배치 문제를 해결하였다. 해당 Posting에서는 이를 구현 및 작성하는 과정에서 겪은 문제를 기반으로 한 회고록이다.\n\n## Description\n\n우선 해당 프로젝트를 통해서 해결하고자 했던 문제부터 정의하자면, 간단하게 SDN/NFV 환경에서 수 많은 VNF가 Virtual Machine(VM)의 형태로 존재하게 되는데 이를 Network Performance와 Energy Efficiency를 모두 고려하여 효율적으로 배치하는 것이 굉장히 어렵고, Rule based 방식으로는 한계가 있는 NP-Hard 문제라는 것이다. 이를 해결하기 위해서 해당 논문에서는 DRL 방식 중에서 PPO를 활용한 해결책을 제시하였고, 성능은 Rule based 방식보다 System Load가 낮은 경우에는 더 성능이 좋았지만, 높은 경우는 오히려 성능이 떨어졌다.\n\n자세한 설명은 `CNSM 2023` 에 오늘(2023/07/11) 제출하였기 때문에 결과가 나오면 추가로 업데이트하도록 하겠다. 일단은 구현에 대한 모든 내용은 Github [SDN Lullaby](https://github.com/euidong/sdn-lullaby)에서 볼 수 있다.\n\n## Process\n\n해당 프로젝트의 시작은 연구실에서 진행 중인 프로젝트 중 외국인 학생에게 할당되어있던 파트가 통채로 나에게 넘어오면서 시작된다. 프로젝트를 이어 받아서 유지, 보수하는 것으로 얘기가 되고 있었는데 사실상 구현이 거의 되어있지 않다는 것을 알게 되었다. 결국 그 학생은 이미 떠나갔고, 결국 나는 이를 처음부터 구현해야하는 상황에 놓여졌다. 이것이 4월 20일 나에게 주어진 미션이였다.\n\n우선 큰 흐름에서는 기존 외국인 학생이 제시한 방향인 강화학습을 활용한 VM Consolidation으로 가닥을 잡았다. 하지만, 실제 요구사항에 대한 정의가 애매했기에 이 부분은 랩미팅과 기존 자료들을 통해서 얻을 수 있었다.\n\n초기에는 여러 다른 논문을 찾아보면서, 어떤 구현이 가장 타당한지에 대한 조사를 진행하였다. 이 과정에서 VM Consolidation은 **Server Selection**, **VM Selection**, **VM Placement** 3단계로 나누어진다는 것을 알게 되었다. 즉, 어떤 서버에서 VM을 옮길지를 먼저 선택한 후에 해당 Server에서 어떤 VM을 선택할지를 결정한 후, 마지막으로 해당 VM을 어느 Server로 옮길지를 결정하는 것이다. 하지만, 해당 논문들을 읽으면서 든 생각은 왜 첫 번째 단계인 **Server Selection**이 왜 필요한가였다. 사실 결론적으로 원하는 것은 VM을 선택하고자 하는 것다. 즉, Server Selection은 선택하고자 하는 VM을 제한하는 역할을 수행한다. 이는 잘못된 추론을 하는 경우에 명백하게 편향적인 선택이 될 수 밖에 없다. 따라서, 해당 프로젝트에서는 과감하게 해당 단계를 생략하고 두 단계로 진행하는 것을 목표로 하였다. (**VM Selection**, **VM Placement**)\n또한, 알고리즘을 선택하는 과정에서는 처음에는 강화학습 중에서도 기본적인 SARSA, Q-Learning을 적용하여 해당 문제를 푸는 것을 목표로 하였다. 하지만, Server의 상태(State)를 강화학습의 Input으로 주는 과정에서 문제가 발생했다. Input으로 전달해야할 정보는 Server의 상태, VM의 상태, 전체 Server를 포함하는 Edge의 상태 등이 있었는데 이를 모두 하나의 State로 정의하는데에는 한계가 있었기 때문이다. 이는 VM의 수와 Server의 수가 늘어남에 따라 제곱으로 State와 Action의 갯수가 늘어나기 때문에 이를 모두 하나의 Table로 표현하는 단순한 SARSA, Q-Learning으로는 한계가 있다는 것을 깨달았다. 따라서, 이를 해결하기 위해서 두 가지 선택지 중에서 하나를 골라야했다.\n\n1. State를 압축할 수 있는 방법을 찾는다.\n2. Deep Learning을 적용하여, Table을 Network로 추정하자.\n\n랩미팅 과정에서 교수님은 1번을 강조하셨다. State를 압축할 수 있는 방법을 찾는다. 굉장히 간단한 알고리즘만으로도 해결이 가능할 것이라고 얘기하셨다. 하지만, 초기에는 이에 대한 감을 잡지 못했기 때문에 결론적으로는 2번을 선택했다. 사실 State가 많아진다면, 간단한 DQN(Deep Q Network)만 활요하더라도 어느정도 성능을 챙길 수 있을 것이라고 생각했고, State를 압축할 방법이 당시로서는 생각하기 어려웠다.\n\n따라서, DQN을 활용하여 문제를 해결하는 것을 바로 시도하였다. 여기서도 결국 문제에 부딪히게 된다. 바로 State를 모두 활용하는 것까지는 좋은데 Output의 크기가 계속 변화하면 어떻게 할 것인지에 대한 문제를 해결할 수 없었다. 즉, 우리가 원하는 VM Consolidation은 결국 어떤 VM을 어떤 Server로 옮길지를 결정해야 한다. 그렇다면, 매 사건마다 Server와 VM의 갯수가 달라질 수가 있다는 것이다. 일반적으로는 Server의 갯수가 변화하는 일은 흔치 않지만, VM은 매번 바뀔 것이다. 따라서, 우리가 고를 VM의 갯수를 해당 System에서는 Input State가 주어지기 전까지는 알 수 없기 때문에 Deep Learning Model의 Output의 크기를 알 수가 없다는 것이다. 즉, Input과 Output의 크기를 정해놓고 시작하는 일반적인 Deep Learning Model로는 한계가 있다는 것이다. 이를 해결하기 위해서 결국 RNN을 활용하기로 결정한다. 즉, RNN에 Input으로 주어지는 데이터가 (Batch size, Sequence length, Input size)의 형태로 주어졌을 때, output의 형태는 (Batch size, Sequence length, Output size)와 같다. 여기서 Sequence length는 변화하지 않는데, 내가 하고자 하는 작업이 사실은 VM/Server의 정보가 주어졌을 때, 하나의 VM/Server를 선택하는 일이기 때문에 VM/Server의 수만큼 Sequence를 만들고, 여기서 나오는 Output size를 1로 고정한다면, 결국 어떤 크기의 VM/Server 수가 들어오더라도 그만큼의 Output을 보장받을 수 있었다. 따라서, 이를 활용해서 초기에는 LSTM에 기반한 DQN 모델을 구현하였다. 여기서 RNN(LSTM을 포함한)은 사실 Sequence를 거치면서 값을 누적하기 때문에, 우리의 원래 의도랑은 다르게 어느 위치에 Input 데이터를 넣느냐가 영향을 미칠 것이라는 것을 생각해서 이를 완화시키기 위해서 Bi-Direction으로 LSTM을 구성하였다. 이렇게 구성한 모델은 아래와 같다.\n\n![sdn-lullaby-arch-1](/images/sdn-lullaby-arch-1.png)\n\n이를 실험하기 위해서, Emulation 환경도 구현을 해서 실험을 한 결과 서버 4개 정도에서 정상적으로 Consolidation이 진행되는 것을 확인했다. 하지만, 실제로 서버 갯수가 8개를 넘기자 전체적으로 성능이 떨어지는 것을 관측했다. 또한, 학습 과정에서 VM의 갯수가 Episode마다 유동적으로 변화하기 때문에 Batch 단위의 학습을 하기 위해서, Memory에 저장하는 과정에서 Episode Length마다 별도의 공간에 따로 저장하였다. 그리고, 학습을 진행할 때에는 Random하게 Length를 하나 선택해서 Episode를 추출했는데, 어떤 Length를 선택하냐에 따라서도 값의 변화가 크기 때문에 이 구조가 variance를 더 크게 할 것이라는 결론에 도달했다. 따라서, 이 문제를 해결하기 위해서 다음과 같은 해결책을 생각했다.\n\n1. Self Attention 구조 적용(LSTM -> Self Attention)\n2. Zero Padding 추가\n\n앞 서 제시했던 Bi Direction을 활요한 LSTM은 설계 자체가 Hidden Value를 순서대로 추출해나가면서 이득을 취하는 것인데 해당 구조에서는 각 요소의 특징을 입력으로 받아서 어떤 요소를 선택할지에 관한 문제이기 때문에 Self Attention 구조가 더 적절하다는 판단을 했다. 또한, zero padding을 추가하여 모든 데이터를 한 번에 저장하였다. 또한, 추가적으로 불가능한 Action의 선택을 방지하기 위해서 추가적인 preprocessing을 추가하였다. 즉, 옮길 수 있는 서버가 없는 VM인 경우, 선택한 VM을 옮길 수 없는 경우는 미리 filtering을 수행하여 해당 데이터를 zero 로 marking하였다. 이를 통해서, 불가능한 Action을 선택하는 것을 방지하였다. 따라서, 이를 반영하여 변경된 구조는 다음과 같다.\n\n![sdn-lullaby-arch-2](/images/sdn-lullaby-arch-2.png)\n\n하지만, 전체적인 성능 개선이 이루어지지 않았고, 따라서 이를 해결하기 위해서 `AlphaStar`라는 논문을 참고하였다. 해당 구조에서는 아래와 같은 구조를 보여준다.\n\n![alphastar](/images/alphastar.jpeg)\n\n여기서는 Encoding Layer를 두고, 이후에 LSTM을 통해서 Sequence 정보를 입력받고, 후에 이를 기반으로 Action을 선택하는 구조를 갖고 있다. 또한, 여기서 특정 Unit을 선택하기 위해서 Self Attention과 Attention을 혼합하여 사용하는 것을 보고 내가 위에서 VM/Server Selection에 Attention Mechanism을 사용하는 것이 일반적인 해결책이라는 것을 알게 되었다. 어쨌든, 이름 참고하여 다음과 같은 구조를 구현했다. 여기서는 DQN이 아닌 PPO를 적용하였다.\n\n![sdn-lullaby-arch-3](/images/sdn-lullaby-arch-3.png)\n\n해당 구조를 통한 실험 역시 실행하였지만, 전체적인 성능 역시 변화하지 않았다. 그래서 결론적으로 최종적으로 두 가지 구조를 변형하여 구현을 마무리하였다. 먼저, 기존 DQN 구조에서 input layer를 추가하여 PPO 구조로 변경하는 것, 그리고 불가능한 Action에 대한 filtering을 preprocessing이 아닌 postprocessing으로 수행하는 것이다. Preprocessing을 수행하는 경우에는 결론적으로 정보의 손실이 발생하게 되는데 이로 인한 손해를 보지말고 차라리 최종 선택 단계에서 불가능한 Action을 선택할 확률을 0이 되도록 postprocessing하는 방식으로 변경하였다. 따라서, 최종 구조는 다음과 같다.\n\n![sdn-lullaby-arch-4](/images/sdn-lullaby-arch-4.png)\n\n해당 최종 구조를 통해서 결론적으로 에너지 효율성과 네트워크 처리 능력까지 향상하는 결과를 얻을 수 있었다. (이는 논문과 Github에 업로드된 자료를 확인하도록 하자.)\n\n## Opinion\n\n결론적으로 나의 첫 번째 Full Paper 논문이 였기에 아쉬움도 많이 남지만, 애착도 그만큼이나 남을 것으로 생각하고 있다. 먼저 총평을 하자면, 나름 만족할만한 프로젝트였다고 생각한다. 우선 랩 미팅마다 매주 progress를 발표하고, 논의하는 과정 자체가 굉장히 유의미했다고 생각한다. 그 때 작성한 자료들이 지금 작성하고 있는 글 그리고 얼마 전에 제출한 논문을 작성하는데 많은 도움을 주었다. 따라서, progress를 주 단위나 작업 단위로 정리하는 것은 굉장히 중요하다는 것을 다시 한 번 느꼈다. 그리고, 실제로 Deep Learning과 Reinforcement Learning을 활용하여 Project를 직접 구현한 것은 이번이 처음이기 때문에 굉장히 많은 걱정을 하였는데 많은 사람들의 도움을 받고 여러 책곽 논문의 도움을 받아서 결국 성공적으로 마무리했다는 것이 중요한 경험으로 남을 거 같다. 또한, 문제를 정의하는 것이 가장 중요하고, 여러 논문을 찾는 사전 준비 단계가 반 이상이라는 것을 깨달았다. 이 과정이 탄탄해야 막힘없이 진행이 가능한데 이를 초기에는 간과한 거 같아서 앞으로는 초반 준비 단계에서 자료 찾고 읽는 것에 굉장히 집중해야겠다는 생각이 들었다. 그리고, 구현하는 과정에서도 관련 자료가 있으면 계속해서 읽어보는 것이 전체적인 구현의 질을 높일 수 있다는 것을 다시 한 번 상기할 수 있는 기회였다.\n\n해당 프로젝트를 하면서, 만족했던 점은 다음과 같다.\n\n1. 이때까지 프로젝트를 진행하면서, 내가 항상 가지는 마인드는 \"어떠한 판단을 하였다면, 이에 대한 근거를 항상 제시할 수 있어야 한다.\" 였는데 이는 해당 프로젝트에서는 꽤나 잘 지켜진 거 같아서 만족한다.\n2. 정리를 굉장히 잘 해두었다. 발표 자료 및 자료 조사 내용 정리를 굉장히 잘 해두었고, 이를 통해서 논문 작성에도 큰 도움을 받았다.\n\n아쉬웠던 점은 다음과 같다.\n\n1. DRL은 처음 적용하다보니 여러 알고리즘을 실험해보고 싶었는데 결과적으로는 DQN, PPO 밖에 적용하지 못했다.\n2. 실험 결과를 내는 과정에서 시간이 굉장히 오래 걸렸다. 이는 실험을 진행하면서, 여러가지 문제가 발생했기 때문인데 이를 미리 예측하고 대비하지 못한 것이 아쉽다.\n3. 최종 구현의 Performance에 미련이 남는다. 결론적으로는 Baseline 시스템과 비교했을 때, 조금 좋은 부분이 있고, 어떤 부분에서는 매우 뒤떨어지기도 하는데 이에 대해서 General한 성능 향상이 있었다면 더 좋았겠다는 생각이 든다.\n\n## Reference\n\n- For Thumbnail: <a href=\"https://www.flaticon.com/free-icons/lullaby\" title=\"lullaby icons\">Lullaby icons created by Freepik Flaticon</a>\n- For Thumbnail: <a href=\"https://www.flaticon.com/free-icons/data-server\" title=\"data server icons\">Data server icons created by The Chohans Brand - Flaticon</a>\n- Arulkumaran, Kai, Antoine Cully, and Julian Togelius. \"Alphastar: An evolutionary computation perspective.\" Proceedings of the genetic and evolutionary computation conference companion. 2019.\n","slug":"sdn-lullaby","date":"2023-07-11 15:51","title":"SDN Lullaby","category":"Memoir","tags":["SDN","NFV","VNF","SFC","VM Consolidation","DRL"],"desc":"SDN Lullaby는 SDN/NFV 환경에서 효율적인 VNF 배치에 관하여 작성한 논문이다. 이 논문에서는 VNF 배치 문제를 DRL을 이용하여 해결하였다. 이를 위해서, 해당 논문에서는 상용 Cloud Data Center에서 주로 사용되던 VM Consolidation 방식을 활용하였고, 이 과정에서 추가적인 구현을 더해서 VNF 배치 문제를 해결하였다. 해당 Posting에서는 이를 구현 및 작성하는 과정에서 겪은 문제를 기반으로 한 회고록이다.","thumbnailSrc":"https://euidong.github.io/images/sdn-lullaby.png"}]}},"__N_SSG":true}