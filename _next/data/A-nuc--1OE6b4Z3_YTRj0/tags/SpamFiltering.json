{"pageProps":{"posts":[{"content":"\n## Intro\n\nì´ì „ Postingì—ì„œëŠ” sentenceì˜ ì ì ˆì„±ì„ í™•ì¸í•œë‹¤ë“ ì§€ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ìœ ì¶”í•œë‹¤ë“ ì§€ ì˜¤íƒ€ë¥¼ ì •ì •í•˜ëŠ” ë“±ì— í•„ìš”í•œ ê¸°ë³¸ì ì¸ Language Modeling ë°©ì‹ì„ ì‚´í´ë³´ì•˜ë‹¤. ì´ë²ˆì—ëŠ” ì‹¤ì œë¡œ ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ëŠ” ì˜ˆì œì¸ Classificationì„ Language Modelì„ ì´ìš©í•˜ì—¬ í•  ìˆ˜ ìˆëŠ”ì§€ë¥¼ ë°°ìš°ë©°, ì´ë¥¼ ì§ì ‘ Spam Filteringì—ì„œ ì–´ë–»ê²Œ ì‚¬ìš©í•˜ëŠ”ì§€ ì‚´í´ë³¸ë‹¤. ì£¼ì˜í• ì ì€ í•´ë‹¹ Postingì€ Naive Bayes ë°©ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ ì§„í–‰í•˜ëŠ” Classificationì´ë‹¤. ë” ë‹¤ì–‘í•œ ë°©ë²•ë¡ ì„ ì›í•œë‹¤ë©´ í•´ë‹¹ í¬ìŠ¤íŒ…ì€ ë„ì›€ì„ ì£¼ê¸° ì–´ë µë‹¤. ë§Œì•½ ì§€ê¸ˆ ë§ì´ ì´í•´ê°€ ì•ˆëœë‹¤ë©´, ê·¸ëƒ¥ ê³„ì† ì½ìœ¼ì‹œë©´ ë˜ê² ë‹¤.\n\n## Classification\n\nê¸°ë³¸ì ìœ¼ë¡œ inputì´ ë“¤ì–´ì™”ì„ ë•Œ, ì´ë¥¼ ì•Œë§ì€ ë¶„ë¥˜ë¡œ ë‚˜ëˆ„ëŠ” ê¸°ëŠ¥ì„ í•˜ëŠ” ê²ƒì´ë‹¤. ë‹¨ìˆœíˆ ì‚¬ì „ ì§€ì‹ì— ê¸°ë°˜í•´ì„œ ì´ë¥¼ ìˆ˜í–‰í•  ìˆ˜ë„ ìˆì§€ë§Œ, Language Modelingì„ ì´ìš©í•˜ë©´, ë” ì •í™•ë„ ë†’ì€ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.\n\nì¼ë°˜ì ìœ¼ë¡œ ë§ì´ ì‚¬ìš©í•˜ëŠ” Classification ë„êµ¬ëŠ” ì•„ë˜ì™€ ê°™ë‹¤.\n\n1. Naive Bayes\n2. Hidden Markov Model(HMM)\n3. Maximum Entropy Model(MaxEnt)\n   1. Logistic Regression\n   2. Support Vector Machine\n   3. Neural Network(Deep Learning)\n4. K Nearest Neighbors\n\ní•´ë‹¹ Postingì—ì„œëŠ” **Naive Bayes Classifier**ë¥¼ ì´ìš©í•œ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•  ê²ƒì´ë‹¤. 3ë²ˆ ë°©ë²•ì€ ê¸°ë³¸ì ìœ¼ë¡œ ê° ë‹¨ì–´ë¥¼ Random Variableë¡œ ì¹˜í™˜í•´ì„œ ì²˜ë¦¬í•˜ëŠ” ê³¼ì •ì´ í•„ìš”í•œë° ì´ëŠ” í›„ì— ë” ìì„¸íˆ ë‹¤ë£° ê²ƒì´ê¸° ë•Œë¬¸ì— ì—¬ê¸°ì„œëŠ” ê¸°ë³¸ì ì¸ Classifierë¥¼ í™œìš©í•˜ëŠ” ë°©ë²•ì„ ë°°ìš°ê³  í›„ì— ê°€ì„œ wordë¥¼ vectorë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì„ ê±°ì¹œ í›„ì— ë” í›Œë¥­í•œ ê¸°ìˆ ë“¤ì„ í™œìš©í•´ë³´ê² ë‹¤.  \në”°ë¼ì„œ, ì•ìœ¼ë¡œ 3ê°œì˜ Posting ë™ì•ˆì€ Naive Bayes, HMM, MaxEnt ë°©ì‹ì— ëŒ€í•´ì„œ ì•Œì•„ë³¼ ê²ƒì´ê³ , ê·¸ í›„ì—ëŠ” wordë¥¼ vector ë°ì´í„°ë¡œ ì¹˜í™˜í•˜ì—¬ ì²˜ë¦¬ë¥¼ í•˜ëŠ” ë°©ì‹ì„ ë°°ì›Œë³¼ ê²ƒì´ë‹¤.\n\nê¸°ë³¸ì ìœ¼ë¡œ Classificationì€ ë°ì´í„°ê°€ ì£¼ì–´ì¡Œì„ ë•Œ, í•´ë‹¹ ë°ì´í„°ê°€ íŠ¹ì • classì— ì†í•  í™•ë¥ ì„ ì œì‹œí•˜ëŠ” ê²ƒì´ë‹¤. ë”°ë¼ì„œ, íŠ¹ì • classì—ì„œ í•´ë‹¹ ë°ì´í„°ê°€ ì–¼ë§ˆë‚˜ ìì£¼ ë°œìƒë˜ëŠ”ì§€ì™€ ì‹¤ì œë¡œ í•´ë‹¹ classì˜ ë¹ˆë„ê°€ ê°€ì¥ ì¤‘ìš”í•˜ë‹¤.\n\nì´ë¥¼ ìˆ˜ì‹ì ìœ¼ë¡œ í‘œí˜„í•˜ê¸° ìœ„í•´ì„œ ë‹¤ìŒ ë³€ìˆ˜ë“¤ì„ ë¨¼ì € ì‚´í´ë³´ì.\n\n- **documents($D$)**: ì—¬ëŸ¬ ê°œì˜ Documentë¥¼ ì˜ë¯¸í•˜ë©°, í•˜ë‚˜ì˜ DocumentëŠ” ëŒ€ê²Œ ì—¬ëŸ¬ ê°œì˜ wordsë¥¼ í¬í•¨í•œë‹¤. ê° documentëŠ” $d_{i} \\in D$ì˜ í˜•íƒœë¡œ í‘œí˜„í•œë‹¤.\n- **classes($C$)**: classëŠ” ë‘ ê°œ ì´ìƒì„ ê°€ì§„ë‹¤. ê° í´ë˜ìŠ¤ëŠ” $c_{i} \\in C$ì˜ í˜•íƒœë¡œ í‘œí˜„ëœë‹¤.\n- **labeled dataset**: ì´ëŠ” (document($d_{i}$), class($c_{i}$))ê°€ í•˜ë‚˜ì”© mappingëœ í˜•íƒœë¡œ ì¡´ì¬í•œë‹¤. ìš°ë¦¬ê°€ ê°€ì§€ëŠ” datasetìœ¼ë¡œ í•™ìŠµ, í‰ê°€ ì‹œì— ì‚¬ìš©í•œë‹¤. ëŒ€ê²Œ í‰ê°€ì— ì‚¬ìš©ë˜ëŠ” ë°ì´í„°ëŠ” í•™ìŠµ ì‹œì— ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ê¸ˆì§€í•˜ê¸° ë•Œë¬¸ì— ë³„ë„ë¡œ ë¶„ë¦¬í•˜ì—¬ ì‚¬ìš©í•œë‹¤.\n- **word($w$)**: í•˜ë‚˜ì˜ wordë¥¼ ì˜ë¯¸í•˜ë©° NLP í•™ìŠµ ì‹œì— ì‚¬ìš©í•˜ëŠ” ê°€ì¥ ì‘ì€ ë‹¨ìœ„ì´ë‹¤. ëŒ€ê²Œ document í•˜ë‚˜ì— ìˆëŠ” ë‹¨ì–´ì˜ ìˆ˜ëŠ” Nìœ¼ë¡œ í‘œê¸°í•˜ê³ , uniqueí•œ ë‹¨ì–´ì˜ ìˆ˜ëŠ” V(size of vocabulary)ë¡œ í‘œì‹œí•œë‹¤.\n\në”°ë¼ì„œ, ìš°ë¦¬ê°€ ì°¾ê³ ì í•˜ëŠ” ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§„ classëŠ” ë‹¤ìŒì„ í†µí•´ì„œ êµ¬í•  ìˆ˜ ìˆë‹¤.\n\n$$\n\\begin{align*}\nc_{MAP} &= \\argmax_{c \\in C}{P(c|d)} \\\\\n&= \\argmax_{c \\in C}{p(d|c)p(c)\\over p(d)} \\\\\n&= \\argmax_{c \\in C}{p(d|c)p(c)} \\\\\n&= \\argmax_{c \\in C}{p(w_{1}, w_{2}, ... , w_{N} | c)p(c)} \\\\\n&= \\argmax_{c \\in C}{\\prod_{i=1}^{N}p(w_{i})p(c)} \\\\\n&= \\argmax_{c \\in C}{\\log(\\prod_{i=1}^{N}p(w_{i})p(c))} \\\\\n&= \\argmax_{c \\in C}{\\sum_{i=1}^{N}\\log p(w_{i}) + \\log{p(c)}} \\\\\n\\end{align*}\n$$\n\nì—¬ê¸°ì„œ ìš°ë¦¬ê°€ language modelì„ ë¬´ì—‡ìœ¼ë¡œ ì •í–ˆëŠ”ì§€ê°€ ì¤‘ìš”í•˜ë‹¤. ìœ„ì—ì„œëŠ” uni-gramì´ë¼ê³  ê°€ì •í•´ì„œ í’€ì´í–ˆì§€ë§Œ, bi-gramì¸ ê²½ìš° documentì˜ í˜•íƒœê°€ $d={(w_{1}, w_{2}), (w_{2}, w_{3}), ... , (w_{N-1}, w_{N})}$ì´ë‹¤. ë”°ë¼ì„œ, ì „ì²´ì ì¸ í¬ê¸°ì™€ vocabularyìì²´ë„ ë°”ë€Œê²Œ ëœë‹¤.\n\nì¦‰, ìš°ë¦¬ëŠ” train setì„ í†µí•´ì„œ vocabularyë¥¼ ì™„ì„±í•œë‹¤. ê·¸ë¦¬ê³ , ê° wordì˜ count ë° í•„ìš”ì— ë”°ë¼ í•„ìš”í•œ word sequenceì˜ countë¥¼ ìˆ˜ì§‘í•˜ì—¬ $p(w_i)$ë¥¼ êµ¬í•œ í›„ ìœ„ì— ë°©ë²•ì„ í†µí•´ì„œ íŠ¹ì • classë¥¼ ì¶”ì¸¡í•  ìˆ˜ ìˆëŠ” ê²ƒì´ë‹¤.\n\n## Evaluation\n\nbinary classificaitonì˜ ê²°ê³¼ëŠ” ì•„ë˜ì™€ ê°™ì´ 4ê°œ ì¤‘ í•˜ë‚˜ë¡œ ê²°ì •ëœë‹¤.\n\n| prediction\\answer | True           | False          |\n| :---------------- | :------------- | :------------- |\n| Positive          | true positive  | false positive |\n| Negative          | false negative | true negative  |\n\nì´ë¥¼ ì‰½ê²Œ ì´í•´í• ë ¤ë©´, ë³‘(ì½”ë¡œë‚˜)ì˜ ì–‘ì„±/ìŒì„± íŒì •ì´ rowì— í•´ë‹¹í•˜ê³ , ì‹¤ì œ ë³‘ì˜ ì—¬ë¶€ë¥¼ columnìœ¼ë¡œ ìƒê°í•˜ë©´ ì‰½ë‹¤. ë˜í•œ, ê° cellì˜ ê°’ì´ í—·ê°ˆë¦´ ìˆ˜ ìˆëŠ”ë°, ìš°ë¦¬ê°€ ì›í•˜ëŠ” ê²ƒì´ ì˜ˆì¸¡ì˜ ì •í™•ë„ë¥¼ í™•ì¸í•˜ëŠ” ê²ƒì´ê¸° ë•Œë¬¸ì— ì˜ˆì¸¡ ê²°ê³¼ëŠ” ê·¸ëŒ€ë¡œ ë³´ì—¬ì£¼ë©´ì„œ, ì´ê²ƒì´ í‹€ë ¸ëŠ”ì§€ ë§ì•˜ëŠ”ì§€ë¥¼ ì•ì— true/falseë¡œ í‘œí˜„í–ˆë‹¤ê³  ìƒê°í•˜ë©´ ì‰½ë‹¤.\n\n\nclassificationì˜ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ëŠ” ì§€í‘œëŠ” ëŒ€í‘œì ìœ¼ë¡œ 4 ê°€ì§€ê°€ ìˆë‹¤.\n\n1. **Accuracy(ì •í™•ë„)**  \n   ê°€ì¥ ì‰½ê²Œ ê·¸ë¦¬ê³  ì¼ë°˜ì ìœ¼ë¡œ ìƒê°í•˜ëŠ” ì§€í‘œë‹¤. ìœ„ì˜ í‘œì—ì„œëŠ” ì „ì²´ ê²½ìš°ì˜ ìˆ˜ë¥¼ ë”í•˜ì—¬ ì˜³ê²Œ ì˜ˆì¸¡í•œ ê²ƒ(true postive, true negative)ì˜ í•©ì„ ë‚˜ëˆ„ëŠ” ê²ƒì´ë‹¤. \n   $tp + fn \\over tp + fp + fn + tn$  \n   í•˜ì§€ë§Œ, ì´ ë°©ì‹ì€ í•œê³„ê°€ ìˆë‹¤. ë°”ë¡œ, ë°ì´í„°ê°€ í•œìª½ìœ¼ë¡œ ì¹˜ìš°ì³ì ¸ìˆì„ ë•Œì´ë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ìš°ë¦¬ê°€ ì§„ì§œë¥¼ ì§„ì§œë¼ê³  ë§ì¶œí™•ë¥ ì€ ë†’ì§€ë§Œ, ê°€ì§œë¥¼ ê°€ì§œë¼ê³  ë§ì¶œ í™•ë¥ ì´ ë‚®ë‹¤ê³  í•  ë•Œ, ì´ë¥¼ ì œëŒ€ë¡œ ë°˜ì˜í•˜ê¸°ê°€ ì–´ë µë‹¤. ê·¸ëŸ°ë° ë°ì´í„°ì—ì„œ ì§„ì§œê°€ ê°€ì§œë³´ë‹¤ ì••ë„ì ìœ¼ë¡œ ë§ì„ ê²½ìš° ì •í™•ë„ëŠ” ì¢‹ì€ ì§€í‘œë¡œ ì“°ê¸° ì–´ë µë‹¤ëŠ” ê²ƒì´ë‹¤.\n2. **Precision(ì •ë°€ë„, ì •ë‹µë¥ )**  \n   ì‰½ê²Œ ì •ë‹µ ìì²´ë¥¼ ë§í í™•ë¥ ì…ë‹ˆë‹¤.  \n   $tp \\over tp + fn$\n3. **Recall(ì¬í˜„ìœ¨)**  \n   ì˜ˆì¸¡ì´ ë§ì„ í™•ë¥ ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.  \n   $tp \\over tp + fp$\n4. **F1 Score**  \n   ì¢€ ë” ì„¸ë¶„í™”ëœ í‰ê°€ì§€í‘œì´ë‹¤. ì¡°í™” í‰ê· ì— ê¸°ë°˜í•˜ì—¬ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì •í™•í•˜ê²Œ í‰ê°€í•  ë•Œ ì‚¬ìš©í•œë‹¤.  \n   $2 \\times {\\text{Precision} \\times \\text{Recall} \\over \\text{Precision} + \\text{Recall}}$\n\nì—¬ê¸°ê¹Œì§€ ë´¤ìœ¼ë©´, ìŠ¬ìŠ¬ multi classì˜ ê²½ìš°ì—ëŠ” ì–´ë–»ê²Œ í•´ì•¼í• ì§€ ê¶ê¸ˆí•  ê²ƒì´ë‹¤. ëŒ€ê²Œ ë‘ ê°€ì§€ ë°©ë²•ì„ í†µí•´ì„œ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.\n\n> **1. Micro Average**\n\nì „ì²´ classë¥¼ í•˜ë‚˜ì˜ binary tableë¡œ í•©ì¹˜ëŠ” ê²ƒì´ë‹¤. ì¦‰, í´ë˜ìŠ¤ê°€ A, B, C 3ê°œê°€ ìˆë‹¤ë©´, ê° í´ë˜ìŠ¤ ë³„ë¡œ ì˜ˆì¸¡ ì„±ê³µë„ë¥¼ binaryë¡œ í‘œì‹œí•˜ê³ , ì´ë¥¼ í•˜ë‚˜ì˜ í…Œì´ë¸”ë¡œ í•©ì¹˜ëŠ” ê²ƒì´ë‹¤. ê·¸ í›„ì—ëŠ” binaryì—ì„œ ê³„ì‚°í•˜ëŠ” ì‹ì„ ê·¸ëŒ€ë¡œì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.  \n\n> **2. Macro Average**\n\nmulti classì˜ ê²½ìš°ì—ë„ ë³„ë¡œ ë‹¤ë¥¼ ê²ƒì€ ì—†ë‹¤. ë‹¨ì§€ Precisionê³¼ Recall ê·¸ë¦¬ê³  Accuracyê°€ ì–´ë–»ê²Œ ë°”ë€ŒëŠ”ì§€ë§Œ ì•Œë©´ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆì„ ê²ƒì´ë‹¤.  \n\n| prediction\\answer | c1            | c2            | c3            | c4            |\n| :---------------- | :------------ | :------------ | :------------ | :------------ |\n| c1                | true positive | x             | x             | x             |\n| c2                | x             | true positive | x             | x             |\n| c3                | x             | x             | true positive | x             |\n| c4                | x             | x             | x             | true positive |\n\n- Precision: $c_{ii} \\over \\sum_{j}c_{ij}$\n- Recall: $c_{ii} \\over \\sum_{j}c_{ji}$\n- Accuracy: $c_{ii} \\over \\sum_{i}\\sum_{j}c_{ij}$\n\n## Case Study. Spam Filtering\n\nì´ˆê¸° NLPê°€ ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ì—ˆë˜ ì˜ˆì‹œ ì¤‘ì— í•˜ë‚˜ì´ë‹¤. ì—¬ëŸ¬ ê°œì˜ ë©”ì¼ì— spamì¸ì§€ hamì¸ì§€ë¥¼ labelingí•œ ë°ì´í„°ë¥¼ ê°–ê³  í›„ì— inputìœ¼ë¡œ mail ë°ì´í„°ê°€ ë“¤ì–´ì™”ì„ ë•Œ, ì´ë¥¼ filteringí•˜ëŠ” ê²ƒì´ë‹¤. ìœ„ì—ì„œ ì‚´í´ë³´ì•˜ë˜ í™•ë¥ ì„ ê·¸ëŒ€ë¡œ ì ìš©í•˜ë©´ ëœë‹¤. ì˜ˆì¸¡ì— í•„ìš”í•œ í™•ë¥ ì„ ìŠµë“í•˜ê³ , ì˜ˆì¸¡í•˜ëŠ” ë°©ë²•ê³¼ ì´ë¥¼ í‰ê°€í•˜ëŠ” ë°©ë²•ì˜ ìˆœìœ¼ë¡œ ì„¤ëª…í•˜ê² ë‹¤.\n\n### 0. Preprocessing\n\nì‚¬ì‹¤ mail dataì˜ í˜•íƒœê°€ ì´ìƒí•  ìˆ˜ë„ ìˆë‹¤. Subjectë¶€í„° ì‹œì‘í•˜ì—¬ ë‚ ì§œ ë°ì´í„° ê·¸ë¦¬ê³  íŠ¹ìˆ˜ ë¬¸ì ë“±ì´ ì¡´ì¬í•  ìˆ˜ ìˆëŠ”ë°, ì´ë¥¼ ë¨¼ì € ì²˜ë¦¬í•´ì„œ í›„ì— ìˆì„ Modeling ë‹¨ê³„ì—ì„œ ì˜ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í˜•íƒœë¥¼ ë³€í˜•í•´ì£¼ì–´ì•¼ í•œë‹¤.\n\n[ğŸ”— ì´ì „ Posting(Text Processing)](/posts/nlp-text-processing)ì—ì„œ ë°°ì› ë˜ ê¸°ìˆ ë“¤ì„ í™œìš©í•˜ì—¬ ì´ë¥¼ í•´ê²°í•  ìˆ˜ ìˆë‹¤.\n\nëŒ€í‘œì ìœ¼ë¡œ í•´ì¤„ ìˆ˜ ìˆëŠ” ì‘ì—…ë“¤ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.\n\n1. ëŒ€ì†Œë¬¸ì í†µì¼\n2. alphabetì´ í•˜ë‚˜ë¼ë„ ë“¤ì–´ìˆì§€ ì•Šì€ ë°ì´í„°ëŠ” ì‚­ì œ\n3. date, ì°¸ì¡° ë“±ì„ ì˜ë¯¸í•˜ëŠ” ë°ì´í„° ì‚­ì œ\n\n### 1. Modeling\n\nParameter Estimation / Learning / Modeling ë“±ìœ¼ë¡œ ë¶ˆë¦¬ëŠ” ë‹¨ê³„ì´ë‹¤. ì¼ë‹¨ ìš°ë¦¬ëŠ” train setìœ¼ë¡œë¶€í„° ìš°ë¦¬ê°€ ì›í•˜ëŠ” í™•ë¥ ì„ ì¶”ì¶œí•´ì•¼ í•œë‹¤. ê·¸ ì „ì— ìš°ë¦¬ê°€ ì–´ë–¤ language modelì„ ì´ìš©í• ì§€ ì„ íƒí•´ì•¼ í•œë‹¤. ë¨¼ì € uni-gramì¸ ê²½ìš°ì—ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë°©ë²•ìœ¼ë¡œ train setì´ ì •ì˜ëœë‹¤.\n$$\n\\text{TrainSet} = {(d_{1}, c_{1}),  (d_{2}, c_{2}), ..., (d_{N}, c_{N})}\n$$\n$$\nd_{i} = \\begin{cases}\n  {w_{1}, w_{2}, ... , w_{M_{i}}} \\quad&\\text{unigram} \\\\\n  {(<s>, w_{1}), (w_{1}, w_{2}), ... , (w_{M_{i}}, </s>)} \\qquad&\\text{bigram}\n\\end{cases}\n$$\n\nì´ì œ ìš°ë¦¬ê°€ ì›í•˜ëŠ” parameter, ì¦‰ í™•ë¥ ì€ ë‹¤ìŒê³¼ ê°™ì€ ë°ì´í„°ì´ë‹¤.\n\n> **unigram**\n\n$$\n\\begin{align*}\np(w_{i}|c_{j}) &= {\\text{count}(w_{i}, c_{j}) \\over \\sum_{w \\in V} \\text{count}(w, c_{j})} \\\\\np(c_{j}) &= {\\sum_{i = 1}^{N}{1[c_{i} = c_{j}]} \\over N}\n\\end{align*}\n$$\n\n> **bigram**\n\n$$\n\\begin{align*}\np(w_{i}|w_{i-1},c_{j}) &= {\\text{count}((w_{i-1}, w_{i}), c_{j}) \\over \\sum_{(w^{(1)}, w^{(2)}) \\in V} \\text{count}((w^{(1)}, w^{(2)}), c_{j})} \\\\\np(c_{j}) &= {\\sum_{i = 1}^{N}{1[c_{i} = c_{j}]} \\over N}\n\\end{align*}\n$$\n\nì—¬ê¸°ì„œ ìš°ë¦¬ëŠ” ë°˜ë“œì‹œ Smoothingì„ í•´ì£¼ì–´ì•¼ í•œë‹¤. ì™œëƒí•˜ë©´, spam mailì—ì„œ ì•ˆ ë³¸ ë‹¨ì–´ê°€ ë‚˜ì˜¬ ê°€ëŠ¥ì„±ì´ ë„ˆë¬´ë‚˜ ë†’ê¸° ë•Œë¬¸ì´ë‹¤. ë”°ë¼ì„œ, ì‹¤ì œ $p(w_{i}|c_{j})$ëŠ” ì•„ë˜ì™€ ê°™ì´ ë³€ê²½ëœë‹¤. (ê°„ë‹¨í•œ ì˜ˆì‹œë¥¼ ë“¤ê¸° ìœ„í•´ì„œ Add-1 ë°©ì‹ì„ ì‚¬ìš©í–ˆë‹¤. - í•´ë‹¹ ë‚´ìš©ì´ ê¸°ì–µì´ ë‚˜ì§€ ì•ŠëŠ”ë‹¤ë©´, [ğŸ”— ì´ì „ í¬ìŠ¤íŒ…](/posts/nlp-language-modeling)ì„ ë‹¤ì‹œ ë³´ê³  ì˜¤ì.)\n\n$$\np(w_{i}|c_{j}) = {\\text{count}(w_{i}, c_{j}) + 1 \\over \\sum_{w \\in V} \\text{count}(w, c_{j}) + |V|}\n$$\n\nì£¼ì˜í•  ì ì€ ë‹¤ì‹œ í•œ ë²ˆ ê°•ì¡°í•˜ì§€ë§Œ, $V$ëŠ” í›„ì— Estimationì—ì„œ inputìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ë‹¨ì¼ documentê¹Œì§€ í¬í•¨í•œ Vocabularyì´ë‹¤.\n\n### 2. Estimation\n\nì´ì œ ìš°ë¦¬ê°€ ì–»ì€ parameterë¥¼ ì´ìš©í•´ì„œ ì‹¤ì œ input dataì— ëŒ€í•œ estimationì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.\n\nì´ ê²½ìš° ë‹¤ìŒê³¼ ê°™ì€ ê³¼ì •ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.\n\n$$\n\\hat{c} = \\argmax_{c \\in C} p(c)\\prod_{w \\in d_{\\text{input}}}p(w|c)\n$$\n\në¬¼ë¡  ì–´ë–¤ n-gramì„ ì“°ëƒì— ë”°ë¼ $d_{\\text{input}}$ë„ í˜•íƒœê°€ ë‹¬ë¼ì§ˆ ê²ƒì´ë‹¤.\n\n### 3. Evaluation\n\nì´ì œ í‰ê°€ë¥¼ ìˆ˜í–‰í•  ê²ƒì´ë‹¤. í‰ê°€ëŠ” ìš°ë¦¬ê°€ ì•Œì•„ë´¤ë˜ Accuracyì™€ F1 Scoreë¥¼ ì¶”ì¶œí•  ìˆ˜ ìˆë‹¤. Binary Classificationì´ê¸° ë•Œë¬¸ì— ì‰½ê²Œ êµ¬í•  ìˆ˜ ìˆì„ ê²ƒì´ë‹¤.\n\n\n| prediction\\answer | True                                                                       | False                                                                     |\n| :---------------- | :------------------------------------------------------------------------- | :------------------------------------------------------------------------ |\n| Positive          | $\\sum_{(d, c) \\in D_{\\text{test}}} 1[\\hat{c}_{d} = c, c = \\text{spam}]$    | $\\sum_{(d, c) \\in D_{\\text{test}}} 1[\\hat{c}_{d} \\neq c, c = \\text{ham}]$ |\n| Negative          | $\\sum_{(d, c) \\in D_{\\text{test}}} 1[\\hat{c}_{d} \\neq c, c = \\text{spam}]$ | $\\sum_{(d, c) \\in D_{\\text{test}}} 1[\\hat{c}_{d} = c, c = \\text{ham}]$    |\n\n\n## Reference\n\n- Tumbnail : Photo by [David Ballew](https://unsplash.com/@daveballew?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@daveballew?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n","slug":"nlp-classification","date":"2022-10-21 21:53","title":"[NLP] 4. Classification","category":"AI","tags":["NLP","Classification","SpamFiltering","F1Score"],"desc":"ì´ì „ Postingì—ì„œëŠ” sentenceì˜ ì ì ˆì„±ì„ í™•ì¸í•œë‹¤ë“ ì§€ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ìœ ì¶”í•œë‹¤ë“ ì§€ ì˜¤íƒ€ë¥¼ ì •ì •í•˜ëŠ” ë“±ì— í•„ìš”í•œ ê¸°ë³¸ì ì¸ Language Modeling ë°©ì‹ì„ ì‚´í´ë³´ì•˜ë‹¤. ì´ë²ˆì—ëŠ” ì‹¤ì œë¡œ ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ëŠ” ì˜ˆì œì¸ Classificationì„ Language Modelì„ ì´ìš©í•˜ì—¬ í•  ìˆ˜ ìˆëŠ”ì§€ë¥¼ ë°°ìš°ë©°, ì´ë¥¼ ì§ì ‘ Spam Filteringì—ì„œ ì–´ë–»ê²Œ ì‚¬ìš©í•˜ëŠ”ì§€ ì‚´í´ë³¸ë‹¤. ì£¼ì˜í• ì ì€ í•´ë‹¹ Postingì€ Naive Bayes ë°©ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ ì§„í–‰í•˜ëŠ” Classificationì´ë‹¤. ë” ë‹¤ì–‘í•œ ë°©ë²•ë¡ ì„ ì›í•œë‹¤ë©´ í•´ë‹¹ í¬ìŠ¤íŒ…ì€ ë„ì›€ì„ ì£¼ê¸° ì–´ë µë‹¤. ë§Œì•½ ì§€ê¸ˆ ë§ì´ ì´í•´ê°€ ì•ˆëœë‹¤ë©´, ê·¸ëƒ¥ ê³„ì† ì½ìœ¼ì‹œë©´ ë˜ê² ë‹¤.","thumbnailSrc":"https://euidong.github.io/images/nlp-thumbnail.jpg"}],"params":{"subject":"SpamFiltering"}},"__N_SSG":true}