{"pageProps":{"posts":[{"content":"\n## Intro\n\n이전 Posting에서는 sentence의 적절성을 확인한다든지 다음 단어를 유추한다든지 오타를 정정하는 등에 필요한 기본적인 Language Modeling 방식을 살펴보았다. 이번에는 실제로 가장 많이 사용되는 예제인 Classification을 Language Model을 이용하여 할 수 있는지를 배우며, 이를 직접 Spam Filtering에서 어떻게 사용하는지 살펴본다. 주의할점은 해당 Posting은 Naive Bayes 방식을 기반으로 진행하는 Classification이다. 더 다양한 방법론을 원한다면 해당 포스팅은 도움을 주기 어렵다. 만약 지금 말이 이해가 안된다면, 그냥 계속 읽으시면 되겠다.\n\n## Classification\n\n기본적으로 input이 들어왔을 때, 이를 알맞은 분류로 나누는 기능을 하는 것이다. 단순히 사전 지식에 기반해서 이를 수행할 수도 있지만, Language Modeling을 이용하면, 더 정확도 높은 분류를 수행할 수 있다.\n\n일반적으로 많이 사용하는 Classification 도구는 아래와 같다.\n\n1. Naive Bayes\n2. Hidden Markov Model(HMM)\n3. Maximum Entropy Model(MaxEnt)\n   1. Logistic Regression\n   2. Support Vector Machine\n   3. Neural Network(Deep Learning)\n4. K Nearest Neighbors\n\n해당 Posting에서는 **Naive Bayes Classifier**를 이용한 분류를 수행할 것이다. 3번 방법은 기본적으로 각 단어를 Random Variable로 치환해서 처리하는 과정이 필요한데 이는 후에 더 자세히 다룰 것이기 때문에 여기서는 기본적인 Classifier를 활용하는 방법을 배우고 후에 가서 word를 vector로 변환하는 과정을 거친 후에 더 훌륭한 기술들을 활용해보겠다.  \n따라서, 앞으로 3개의 Posting 동안은 Naive Bayes, HMM, MaxEnt 방식에 대해서 알아볼 것이고, 그 후에는 word를 vector 데이터로 치환하여 처리를 하는 방식을 배워볼 것이다.\n\n기본적으로 Classification은 데이터가 주어졌을 때, 해당 데이터가 특정 class에 속할 확률을 제시하는 것이다. 따라서, 특정 class에서 해당 데이터가 얼마나 자주 발생되는지와 실제로 해당 class의 빈도가 가장 중요하다.\n\n이를 수식적으로 표현하기 위해서 다음 변수들을 먼저 살펴보자.\n\n- **documents($D$)**: 여러 개의 Document를 의미하며, 하나의 Document는 대게 여러 개의 words를 포함한다. 각 document는 $d_{i} \\in D$의 형태로 표현한다.\n- **classes($C$)**: class는 두 개 이상을 가진다. 각 클래스는 $c_{i} \\in C$의 형태로 표현된다.\n- **labeled dataset**: 이는 (document($d_{i}$), class($c_{i}$))가 하나씩 mapping된 형태로 존재한다. 우리가 가지는 dataset으로 학습, 평가 시에 사용한다. 대게 평가에 사용되는 데이터는 학습 시에 사용하는 것을 금지하기 때문에 별도로 분리하여 사용한다.\n- **word($w$)**: 하나의 word를 의미하며 NLP 학습 시에 사용하는 가장 작은 단위이다. 대게 document 하나에 있는 단어의 수는 N으로 표기하고, unique한 단어의 수는 V(size of vocabulary)로 표시한다.\n\n따라서, 우리가 찾고자 하는 가장 높은 확률을 가진 class는 다음을 통해서 구할 수 있다.\n\n$$\n\\begin{align*}\nc_{MAP} &= \\argmax_{c \\in C}{P(c|d)} \\\\\n&= \\argmax_{c \\in C}{p(d|c)p(c)\\over p(d)} \\\\\n&= \\argmax_{c \\in C}{p(d|c)p(c)} \\\\\n&= \\argmax_{c \\in C}{p(w_{1}, w_{2}, ... , w_{N} | c)p(c)} \\\\\n&= \\argmax_{c \\in C}{\\prod_{i=1}^{N}p(w_{i})p(c)} \\\\\n&= \\argmax_{c \\in C}{\\log(\\prod_{i=1}^{N}p(w_{i})p(c))} \\\\\n&= \\argmax_{c \\in C}{\\sum_{i=1}^{N}\\log p(w_{i}) + \\log{p(c)}} \\\\\n\\end{align*}\n$$\n\n여기서 우리가 language model을 무엇으로 정했는지가 중요하다. 위에서는 uni-gram이라고 가정해서 풀이했지만, bi-gram인 경우 document의 형태가 $d={(w_{1}, w_{2}), (w_{2}, w_{3}), ... , (w_{N-1}, w_{N})}$이다. 따라서, 전체적인 크기와 vocabulary자체도 바뀌게 된다.\n\n즉, 우리는 train set을 통해서 vocabulary를 완성한다. 그리고, 각 word의 count 및 필요에 따라 필요한 word sequence의 count를 수집하여 $p(w_i)$를 구한 후 위에 방법을 통해서 특정 class를 추측할 수 있는 것이다.\n\n## Evaluation\n\nbinary classificaiton의 결과는 아래와 같이 4개 중 하나로 결정된다.\n\n| prediction\\answer | True           | False          |\n| :---------------- | :------------- | :------------- |\n| Positive          | true positive  | false positive |\n| Negative          | false negative | true negative  |\n\n이를 쉽게 이해할려면, 병(코로나)의 양성/음성 판정이 row에 해당하고, 실제 병의 여부를 column으로 생각하면 쉽다. 또한, 각 cell의 값이 헷갈릴 수 있는데, 우리가 원하는 것이 예측의 정확도를 확인하는 것이기 때문에 예측 결과는 그대로 보여주면서, 이것이 틀렸는지 맞았는지를 앞에 true/false로 표현했다고 생각하면 쉽다.\n\n\nclassification의 성능을 측정하는 지표는 대표적으로 4 가지가 있다.\n\n1. **Accuracy(정확도)**  \n   가장 쉽게 그리고 일반적으로 생각하는 지표다. 위의 표에서는 전체 경우의 수를 더하여 옳게 예측한 것(true postive, true negative)의 합을 나누는 것이다. \n   $tp + fn \\over tp + fp + fn + tn$  \n   하지만, 이 방식은 한계가 있다. 바로, 데이터가 한쪽으로 치우쳐져있을 때이다. 예를 들어, 우리가 진짜를 진짜라고 맞출확률은 높지만, 가짜를 가짜라고 맞출 확률이 낮다고 할 때, 이를 제대로 반영하기가 어렵다. 그런데 데이터에서 진짜가 가짜보다 압도적으로 많을 경우 정확도는 좋은 지표로 쓰기 어렵다는 것이다.\n2. **Precision(정밀도, 정답률)**  \n   쉽게 정답 자체를 맞힐 확률입니다.  \n   $tp \\over tp + fn$\n3. **Recall(재현율)**  \n   예측이 맞을 확률을 의미합니다.  \n   $tp \\over tp + fp$\n4. **F1 Score**  \n   좀 더 세분화된 평가지표이다. 조화 평균에 기반하여 모델의 성능을 정확하게 평가할 때 사용한다.  \n   $2 \\times {\\text{Precision} \\times \\text{Recall} \\over \\text{Precision} + \\text{Recall}}$\n\n여기까지 봤으면, 슬슬 multi class의 경우에는 어떻게 해야할지 궁금할 것이다. 대게 두 가지 방법을 통해서 수행할 수 있다.\n\n> **1. Micro Average**\n\n전체 class를 하나의 binary table로 합치는 것이다. 즉, 클래스가 A, B, C 3개가 있다면, 각 클래스 별로 예측 성공도를 binary로 표시하고, 이를 하나의 테이블로 합치는 것이다. 그 후에는 binary에서 계산하는 식을 그대로사용할 수 있다.  \n\n> **2. Macro Average**\n\nmulti class의 경우에도 별로 다를 것은 없다. 단지 Precision과 Recall 그리고 Accuracy가 어떻게 바뀌는지만 알면 쉽게 이해할 수 있을 것이다.  \n\n| prediction\\answer | c1            | c2            | c3            | c4            |\n| :---------------- | :------------ | :------------ | :------------ | :------------ |\n| c1                | true positive | x             | x             | x             |\n| c2                | x             | true positive | x             | x             |\n| c3                | x             | x             | true positive | x             |\n| c4                | x             | x             | x             | true positive |\n\n- Precision: $c_{ii} \\over \\sum_{j}c_{ij}$\n- Recall: $c_{ii} \\over \\sum_{j}c_{ji}$\n- Accuracy: $c_{ii} \\over \\sum_{i}\\sum_{j}c_{ij}$\n\n## Case Study. Spam Filtering\n\n초기 NLP가 가장 많이 사용되었던 예시 중에 하나이다. 여러 개의 메일에 spam인지 ham인지를 labeling한 데이터를 갖고 후에 input으로 mail 데이터가 들어왔을 때, 이를 filtering하는 것이다. 위에서 살펴보았던 확률을 그대로 적용하면 된다. 예측에 필요한 확률을 습득하고, 예측하는 방법과 이를 평가하는 방법의 순으로 설명하겠다.\n\n### 0. Preprocessing\n\n사실 mail data의 형태가 이상할 수도 있다. Subject부터 시작하여 날짜 데이터 그리고 특수 문자 등이 존재할 수 있는데, 이를 먼저 처리해서 후에 있을 Modeling 단계에서 잘 사용할 수 있도록 형태를 변형해주어야 한다.\n\n[🔗 이전 Posting(Text Processing)](/posts/nlp-text-processing)에서 배웠던 기술들을 활용하여 이를 해결할 수 있다.\n\n대표적으로 해줄 수 있는 작업들은 다음과 같다.\n\n1. 대소문자 통일\n2. alphabet이 하나라도 들어있지 않은 데이터는 삭제\n3. date, 참조 등을 의미하는 데이터 삭제\n\n### 1. Modeling\n\nParameter Estimation / Learning / Modeling 등으로 불리는 단계이다. 일단 우리는 train set으로부터 우리가 원하는 확률을 추출해야 한다. 그 전에 우리가 어떤 language model을 이용할지 선택해야 한다. 먼저 uni-gram인 경우에는 다음과 같은 방법으로 train set이 정의된다.\n$$\n\\text{TrainSet} = {(d_{1}, c_{1}),  (d_{2}, c_{2}), ..., (d_{N}, c_{N})}\n$$\n$$\nd_{i} = \\begin{cases}\n  {w_{1}, w_{2}, ... , w_{M_{i}}} \\quad&\\text{unigram} \\\\\n  {(<s>, w_{1}), (w_{1}, w_{2}), ... , (w_{M_{i}}, </s>)} \\qquad&\\text{bigram}\n\\end{cases}\n$$\n\n이제 우리가 원하는 parameter, 즉 확률은 다음과 같은 데이터이다.\n\n> **unigram**\n\n$$\n\\begin{align*}\np(w_{i}|c_{j}) &= {\\text{count}(w_{i}, c_{j}) \\over \\sum_{w \\in V} \\text{count}(w, c_{j})} \\\\\np(c_{j}) &= {\\sum_{i = 1}^{N}{1[c_{i} = c_{j}]} \\over N}\n\\end{align*}\n$$\n\n> **bigram**\n\n$$\n\\begin{align*}\np(w_{i}|w_{i-1},c_{j}) &= {\\text{count}((w_{i-1}, w_{i}), c_{j}) \\over \\sum_{(w^{(1)}, w^{(2)}) \\in V} \\text{count}((w^{(1)}, w^{(2)}), c_{j})} \\\\\np(c_{j}) &= {\\sum_{i = 1}^{N}{1[c_{i} = c_{j}]} \\over N}\n\\end{align*}\n$$\n\n여기서 우리는 반드시 Smoothing을 해주어야 한다. 왜냐하면, spam mail에서 안 본 단어가 나올 가능성이 너무나 높기 때문이다. 따라서, 실제 $p(w_{i}|c_{j})$는 아래와 같이 변경된다. (간단한 예시를 들기 위해서 Add-1 방식을 사용했다. - 해당 내용이 기억이 나지 않는다면, [🔗 이전 포스팅](/posts/nlp-language-modeling)을 다시 보고 오자.)\n\n$$\np(w_{i}|c_{j}) = {\\text{count}(w_{i}, c_{j}) + 1 \\over \\sum_{w \\in V} \\text{count}(w, c_{j}) + |V|}\n$$\n\n주의할 점은 다시 한 번 강조하지만, $V$는 후에 Estimation에서 input으로 사용하는 단일 document까지 포함한 Vocabulary이다.\n\n### 2. Estimation\n\n이제 우리가 얻은 parameter를 이용해서 실제 input data에 대한 estimation을 수행할 수 있다.\n\n이 경우 다음과 같은 과정을 수행할 수 있다.\n\n$$\n\\hat{c} = \\argmax_{c \\in C} p(c)\\prod_{w \\in d_{\\text{input}}}p(w|c)\n$$\n\n물론 어떤 n-gram을 쓰냐에 따라 $d_{\\text{input}}$도 형태가 달라질 것이다.\n\n### 3. Evaluation\n\n이제 평가를 수행할 것이다. 평가는 우리가 알아봤던 Accuracy와 F1 Score를 추출할 수 있다. Binary Classification이기 때문에 쉽게 구할 수 있을 것이다.\n\n\n| prediction\\answer | True                                                                       | False                                                                     |\n| :---------------- | :------------------------------------------------------------------------- | :------------------------------------------------------------------------ |\n| Positive          | $\\sum_{(d, c) \\in D_{\\text{test}}} 1[\\hat{c}_{d} = c, c = \\text{spam}]$    | $\\sum_{(d, c) \\in D_{\\text{test}}} 1[\\hat{c}_{d} \\neq c, c = \\text{ham}]$ |\n| Negative          | $\\sum_{(d, c) \\in D_{\\text{test}}} 1[\\hat{c}_{d} \\neq c, c = \\text{spam}]$ | $\\sum_{(d, c) \\in D_{\\text{test}}} 1[\\hat{c}_{d} = c, c = \\text{ham}]$    |\n\n\n## Reference\n\n- Tumbnail : Photo by [David Ballew](https://unsplash.com/@daveballew?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@daveballew?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n","slug":"nlp-classification","date":"2022-10-21 21:53","title":"[NLP] 4. Classification","category":"AI","tags":["NLP","Classification","SpamFiltering","F1Score"],"desc":"이전 Posting에서는 sentence의 적절성을 확인한다든지 다음 단어를 유추한다든지 오타를 정정하는 등에 필요한 기본적인 Language Modeling 방식을 살펴보았다. 이번에는 실제로 가장 많이 사용되는 예제인 Classification을 Language Model을 이용하여 할 수 있는지를 배우며, 이를 직접 Spam Filtering에서 어떻게 사용하는지 살펴본다. 주의할점은 해당 Posting은 Naive Bayes 방식을 기반으로 진행하는 Classification이다. 더 다양한 방법론을 원한다면 해당 포스팅은 도움을 주기 어렵다. 만약 지금 말이 이해가 안된다면, 그냥 계속 읽으시면 되겠다.","thumbnailSrc":"https://euidong.github.io/images/nlp-thumbnail.jpg"}],"params":{"subject":"SpamFiltering"}},"__N_SSG":true}