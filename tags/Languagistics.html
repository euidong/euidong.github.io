<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="initial-scale=1.0, width=device-width"/><meta property="og:type" content="blog"/><meta property="og:site_name" content="JustLog"/><meta property="og:image" content="https://euidong.github.io/logo192.png"/><title>#Languagistics | JustLog</title><meta name="description" content="#Languagistics 관련 Posting"/><meta property="og:description" content="#Languagistics 관련 Posting"/><meta property="og:title" content="#Languagistics | JustLog"/><link rel="canonical" href="https://euidong.github.io/tags/Languagistics"/><meta property="og:url" content="https://euidong.github.io/tags/Languagistics"/><meta name="next-head-count" content="11"/><link rel="icon" href="https://euidong.github.io/favicon.png"/><link rel="apple-touch-icon" href="https://euidong.github.io/logo192.png"/><link rel="preload" href="/_next/static/css/d4ec5c8b3df09443.css" as="style"/><link rel="stylesheet" href="/_next/static/css/d4ec5c8b3df09443.css" data-n-g=""/><link rel="preload" href="/_next/static/css/6dc16d084a5153e5.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6dc16d084a5153e5.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js" id="Adsense-id" data-ad-client="ca-pub-7452732177557701" async="" defer="" data-nscript="beforeInteractive"></script><script src="/_next/static/chunks/webpack-9b312e20a4e32339.js" defer=""></script><script src="/_next/static/chunks/framework-81da43a8dcd978d9.js" defer=""></script><script src="/_next/static/chunks/main-7b6c38cbad60dfcf.js" defer=""></script><script src="/_next/static/chunks/pages/_app-8c8de51645108dcb.js" defer=""></script><script src="/_next/static/chunks/675-ae8e8a351ce30ae2.js" defer=""></script><script src="/_next/static/chunks/pages/tags/%5Bsubject%5D-0fc8f67b45fbbd0f.js" defer=""></script><script src="/_next/static/WVqR2qamn-AxDkQTWbEYe/_buildManifest.js" defer=""></script><script src="/_next/static/WVqR2qamn-AxDkQTWbEYe/_ssgManifest.js" defer=""></script><script src="/_next/static/WVqR2qamn-AxDkQTWbEYe/_middlewareManifest.js" defer=""></script></head><body><div id="__next"><div class="Layout_wrapper__dKJSz root"><header class="Layout_header__XosLl" style="position:static"><div><button tabindex="1" class="SideBarToggler_search_bar_toggler__CEuUg"><svg stroke="currentColor" fill="none" stroke-width="0" viewBox="0 0 24 24" height="35px" width="35px" xmlns="http://www.w3.org/2000/svg"><path d="M2 6C2 5.44772 2.44772 5 3 5H21C21.5523 5 22 5.44772 22 6C22 6.55228 21.5523 7 21 7H3C2.44772 7 2 6.55228 2 6Z" fill="currentColor"></path><path d="M2 12.0322C2 11.4799 2.44772 11.0322 3 11.0322H21C21.5523 11.0322 22 11.4799 22 12.0322C22 12.5845 21.5523 13.0322 21 13.0322H3C2.44772 13.0322 2 12.5845 2 12.0322Z" fill="currentColor"></path><path d="M3 17.0645C2.44772 17.0645 2 17.5122 2 18.0645C2 18.6167 2.44772 19.0645 3 19.0645H21C21.5523 19.0645 22 18.6167 22 18.0645C22 17.5122 21.5523 17.0645 21 17.0645H3Z" fill="currentColor"></path></svg></button><nav class="SideBar_side_bar__wrapper--close__8Nwnr"><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/">Home</a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/tags">Tags</a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/Algorithm">Algorithm<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->11<!-- -->)<!-- --></span></a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/Computer%20Architecture">Computer Architecture<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->7<!-- -->)<!-- --></span></a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/Tech">Tech<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->17<!-- -->)<!-- --></span></a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/Web">Web<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->4<!-- -->)<!-- --></span></a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/Paper">Paper<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->2<!-- -->)<!-- --></span></a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/Network">Network<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->11<!-- -->)<!-- --></span></a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/AI">AI<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->19<!-- -->)<!-- --></span></a></nav></div><a class="Logo_logo___yD0t" tabindex="1" href="/"></a><div><button class="SearchBarToggler_search_bar_toggler__3dHbA" tabindex="2"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="25px" width="25px" xmlns="http://www.w3.org/2000/svg"><path d="M11.742 10.344a6.5 6.5 0 1 0-1.397 1.398h-.001c.03.04.062.078.098.115l3.85 3.85a1 1 0 0 0 1.415-1.414l-3.85-3.85a1.007 1.007 0 0 0-.115-.1zM12 6.5a5.5 5.5 0 1 1-11 0 5.5 5.5 0 0 1 11 0z"></path></svg></button></div></header><section><div class="RowCard_row_card__list__background___xFj5"><h1 class="RowCard_row_card__list__title__t4a2h"> Languagistics</h1><label class="RowCard_row_card__list__select__wrapper__TZ4_9"><select class="RowCard_row_card__list__select__dxkxA"><option class="RowCard_row_card__list__select__option__GRKZU">최신순<!-- --></option><option class="RowCard_row_card__list__select__option__GRKZU">AtoZ<!-- --></option><option class="RowCard_row_card__list__select__option__GRKZU">ZtoA<!-- --></option></select></label><ul class="RowCard_row_card__list__wrapper__5Gtgi"><div class="RowCard_row_card__wrapper__kohuv"><a class="RowCard_row_card__thumbnail__wrapper__bedY4" href="/posts/nlp-linguistics"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:200px;height:200px;background:none;opacity:1;border:0;margin:0;padding:0;position:relative"><img alt="[NLP] 1. Linguistics" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fixed" class="RowCard_row_card__thumbnail__Dh_84" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="[NLP] 1. Linguistics" srcSet="https://euidong.github.io/images/nlp-thumbnail.jpg?imwidth=256 1x, https://euidong.github.io/images/nlp-thumbnail.jpg?imwidth=640 2x" src="https://euidong.github.io/images/nlp-thumbnail.jpg?imwidth=640" decoding="async" data-nimg="fixed" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" class="RowCard_row_card__thumbnail__Dh_84" loading="lazy"/></noscript></span></a><div class="RowCard_row_card__tray__trcA5"><a class="RowCard_row_card__tray__title__lVniM" tabindex="-1" href="/posts/nlp-linguistics">[NLP] 1. Linguistics</a><div class="RowCard_row_card__tray__date__3cY_j">2022년 10월 19일 09시 03분</div><ul class="RowCard_row_card__tray__tag__qXmOl"><a class="RowCard_row_card__tray__tag__li__7_3Zt" tabindex="-1" href="/tags/NLP"># <!-- -->NLP<!-- --></a><a class="RowCard_row_card__tray__tag__li__7_3Zt" tabindex="-1" href="/tags/Languagistics"># <!-- -->Languagistics<!-- --></a></ul></div></div></ul></div></section><footer class="Layout_footer__EL5v8"><div class="Layout_footer__copyright__r5baC"><span>Copyright © euidong</span><br/><span>모든 컨텐츠에 대한 저작권은 작성자에게 존재합니다. <!-- --><br/>불법 복제를 통한 상업적 사용을 절대적으로 금지합니다. <!-- --><br/>단, 비상업적 이용의 경우 출처 및 링크를 적용한다면 자유롭게 사용가능 합니다.<!-- --></span><span>Also I use photos by<!-- --> <!-- --><a href="https://unsplash.com/@lorenzoherrera?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" tabindex="-1">Lorenzo Herrera</a> <!-- -->on<!-- --> <!-- --><a href="https://unsplash.com/s/photos/tech?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" tabindex="-1">Unsplash</a></span></div><div class="Layout_footer__contents__YZWSm"><a class="Layout_footer__contents__link__K_TKH" href="https://github.com/euidong" target="_blank" rel="noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="60" width="60" xmlns="http://www.w3.org/2000/svg"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path></svg><span>github</span></a><a class="Layout_footer__contents__link__K_TKH" href="https://euidong.github.io/portfolio" target="_blank" rel="noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="60" width="60" xmlns="http://www.w3.org/2000/svg"><path d="M6 8a3 3 0 1 0 0-6 3 3 0 0 0 0 6zm-5 6s-1 0-1-1 1-4 6-4 6 3 6 4-1 1-1 1H1zM11 3.5a.5.5 0 0 1 .5-.5h4a.5.5 0 0 1 0 1h-4a.5.5 0 0 1-.5-.5zm.5 2.5a.5.5 0 0 0 0 1h4a.5.5 0 0 0 0-1h-4zm2 3a.5.5 0 0 0 0 1h2a.5.5 0 0 0 0-1h-2zm0 3a.5.5 0 0 0 0 1h2a.5.5 0 0 0 0-1h-2z"></path></svg><span>portfolio</span></a><a class="Layout_footer__contents__link__K_TKH" href="https://chrome.google.com/webstore/detail/bonfire/nkooidijgbppkojdgkoafcoppnohdfka?hl=ko" target="_blank" rel="noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" version="1.1" viewBox="0 0 16 16" height="60" width="60" xmlns="http://www.w3.org/2000/svg"><path d="M5.016 16c-1.066-2.219-0.498-3.49 0.321-4.688 0.897-1.312 1.129-2.61 1.129-2.61s0.706 0.917 0.423 2.352c1.246-1.387 1.482-3.598 1.293-4.445 2.817 1.969 4.021 6.232 2.399 9.392 8.631-4.883 2.147-12.19 1.018-13.013 0.376 0.823 0.448 2.216-0.313 2.893-1.287-4.879-4.468-5.879-4.468-5.879 0.376 2.516-1.364 5.268-3.042 7.324-0.059-1.003-0.122-1.696-0.649-2.656-0.118 1.823-1.511 3.309-1.889 5.135-0.511 2.473 0.383 4.284 3.777 6.197z"></path></svg><span>chat</span></a></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"content":"\n## Intro\n\nNatural Language(자연어, 사람이 사용하는 통상 언어)를 input으로 활용하고자 하는 노력은 컴퓨터의 등장부터 시작하여 여러 번 시도되어 왔다. 지금까지도 완벽하게 이를 처리하는 것은 힘들다. 왜 Natural Language를 다루는 것은 어렵고, 이를 해결하기 위해서 NLP에서는 어떤 방식을 활용할지에 대한 개략적인 overview를 제시한다. 또한, Natural Language의 특성과 분석 단계를 이해하기 위해서 Linguistics(언어학)을 간략하게 정리한다.\n\n## NLP\n\nNatural Language Processing의 약자로 사람이 사용하는 언어를 input으로 하여 원하는 값을 추출해내는 것이 목표이다. 이를 위해서 우리는 사람의 언어를 이해하거나 다룰 수 있는 능력을 컴퓨터에게 부여해야 한다.\n\n먼저, 이러한 필요가 있는 대표적인 usecase를 살펴보면 다음과 같다.\n\n### Usecase\n\n- **Spam Detection**  \n  가장 간단한 예시로 mail에서 spam 여부를 확인하는 기능이다.\n- **POS tagging / NER**  \n  특정 단어 단위의 처리를 수행하게 되는데 단어의 품사와 대략적인 의미를 가진 category로 분류로 tagging하는 과정이다. 이를 기반으로 하여 다른 usecase에서 활용하는 경우가 많다. 품사와 category는 단어의 뜻을 추론하는데 큰 도움을 주며, 이것이 문장의 이해 등에 도움을 주기 때문이다.\n- **Sentiment Analysis**  \n  감정/여론 분석 등의 영역을 의미하며, 텍스트 또는 대화에서의 긍정/부정 여부를 판단하거나 평점 등을 추출하는 기능이다.\n- **Conference Resolution**  \n  \"he\", \"she\" 등 대명사, 생략 단어 등을 원래의 단어로 대체하거나 채우는 과정을 수행한다. 이 역시도 여러 영역에서 이를 기반으로 추가적인 작업을 할 수 있다.  \n- **Word Sense Disambiguation(WSD)**  \n  특정 단어가 주어졌을 때, 동의어, 동음이의어 등에서 가르키는 진짜 의미를 헷갈리지 않게 명확하게 다시 한 번 처리한다. 이 역시도 다른 NLP usecase에서 두루 사용된다.\n- **Parsing**  \n  문장에서 단어들을 의미를 가지는 단위(구, 절, 문장)로 다시 grouping한다. 이 과정을 잘 수행하기 위해서는 이전 단계에서 WSD와 Conference Resolution, POS tagging, NER이 이루어지면 좋다. 이 과정을 통해서 문장의 개략적인 의미를 파악할 수 있다.\n- **Machine Translation(MT)**  \n  특정 언어를 또 다른 Natural Language로 변경하는 기능이다.\n- **Information Extraction(IE)**  \n  특정 문장에서 사용자에게 의미있을만한 데이터를 추출하는 것이다.\n- **Q\u0026A**  \n  특정 사용자가 질문을 하였을 때, 이 뜻을 이해하고, 이에 적절한 대답을 수행하는 방식이다.\n- **Paraphrase**  \n  문장의 뜻을 이해하고, 더 쉬운 형태의 표현으로 변환하는 기능이다.\n- **Summarization**  \n  여러 문장으로 이루어진 글의 의미를 이해하고, 적절한 내용으로 요약하는 기능이다.\n- **Dialog**  \n  Natural Language를 사용하는 사람과 1:1로 담화를 주고 받는 것이다. 의미를 이해할 뿐만 아니라 자신이 내보낼 output에 대해서도 적절하게 생성할 수 있는 능력이 필요하다.\n\n위와 같이 많은 usecase가 있는데 이를 구현하는 것은 지금까지도 굉장히 challenge한 부분이다. 그것은 Natural Language가 가지는 몇몇 특징 때문이다.\n\n### Why is NLP difficult?\n\n여기서는 Natural Language 중에서 영어를 기반으로 한 설명이지만, 한국어도 매우 유사하다.\n\n- **non-standard** : Natural Language를 사용하는 사람들이 표준을 항상 따르지는 않는다는 것이다. 우리는 약어를 사용하거나 문법에 맞지 않는 비문을 사용하여 의사소통을 하기 때문에 이것을  시스템이 이해하게 하는 것은 어렵다.\n- **segmentation** issues : 의미를 가지는 단어 단위로 묶는 것이 어렵다는 것이다. 우리는 문장의 띄어쓰기를 어디로 받아들이냐에 따라서 의미가 달라지는 것을 본 경우가 있을 것이다.\n- **idioms** : 관용구의 사용은 NLP에서 예외처리로 해주어야 하는 것이다. 단어 그대로의 의미와 다른 의미를 가지기 때문이다.\n- **neologisms** : 신조어는 계속해서 생겨나기 때문에 이를 계속해서 업데이트 해주는 것도 부담이 된다.\n- **world knowledge** : 사전 지식을 알고 있어야 이해할 수 있는 단어, 문장이 존재한다. 즉, 어떤 지식을 가지고 있느냐에 따라서 해석이 달라진다는 것이다.\n- **tricky entity names** : 고유 명사 중에서 특히 contents(노래, 그림, 소설) 등의 제목이 해석 시에 헷갈리게 한다. 예를 들면, \"Let it be\"라는 비틀즈의 노래는 문장 중간에 들어가면, 하나의 문장으로 받아들여지게 되는데 이를 잘 해결할 수 있도록 해야 한다.\n\n위의 내용을 요약하자면, 다양한 단어가 다양한 현상과 다양한 법칙(Grammer)의 영향을 받기에 어려우며, 단어가 가지는 모호성이 문제를 야기한다는 것이다.\n\n### Solutions\n\n이러한 문제를 해결하기 위해서 크게 두 가지 방식을 사용할 수 있다.\n\n- Rule based approach  \n  Gammer와 같은 법칙을 모두 적용해서 prgoramming을 하는 것이다. 하지만, 이 방식은 비문과 같은 문장을 제대로 처리할 수 없을 뿐만 아니라 정확한 형태의 문장이라도 여러 의미로 해석되는 문장에서 경향성과 문맥을 전혀 파악할 수 없다.\n- Statistic based approach  \n  그래서 최근에는 경향성과 문맥을 파악할 수 있도록 AI 기술, ML, Deep Learning을 이용하여 NLP를 수행하는 것이 하나의 trend로 자리 잡았다. 그렇다면, 어떻게 통계적인 접근법이 경향성과 문맥을 포함할 수 있을까? 이는 통계가 가지는 경향성이라는 특징과 conditional probability를 사용할 때의 문맥을 포함한 경향성을 파악할 수 있다는 점을 활용해서 가능하다.\n\n## Linguistics\n\n결국 앞으로 통계적인 방식을 활용하더라도 우리는 최소한의 언어학적인 기본이 필요하다. 왜냐하면, 통계에 사용할 데이터를 처리하기 위해서이다. 우리가 사용할 데이터는 text 또는 음성이다. 이를 적절하게 처리하여 통계에 사용할 유의미한 데이터로 변환하는 과정이 필요하다. 이를 위해서 언어학에 대한 이해가 필요한 것이다.\n\n일반적으로 언어를 분석할 때, 사용할 수 있는 도구는 **Grammar**이다. 이는 특정 language에서 허용되는 규칙의 집합을 정리한 것이다. 이것의 종류는 크게 두 가지로 나뉜다.\n\n- **Classic Grammar**  \n  사람이 실제로 언어를 사용함에 있어 발생하는 이상한 습관과 같은 언어 표현이다. 이러한 법칙들은 대게 예제들을 통해서 정의되는데 이런 것을 명확하게 구분할 수 있는 명백한 도구가 존재하지는 않는다. 예를 들면, 감탄사와 같은 것들이 여기에 포함되겠다. 이는 이러한 변칙적인 형태 때문에 programming적으로 표현하는 것이 불가능하다.\n- **Explicit Grammar**  \n  명백하게 정의되어 있는 언어 규칙을 의미한다. 이는 Programm으로 구현할 수 있으며, 여러 Grammar 정리 내용이 이미 정리되어 있다. (CFG, LFG, GPSG, HPSG, ....)  \n  이를 문법적으로 분석하기 위해서 우리는 6단계의 순차적인 처리가 필요하다.\n\n### 6 Layers in Language\n\n각 단계는 input과 output을 가진다. 단계적으로 진행되기 때문에 이전 단계의 output이 다음 단계의 input이 되며, 때때로 몇 단계는 생략될 수 있기에 유연하게 생각하도록 하자.\n\n각 단계에서 실제로 특정 문장이 처리되는 과정을 이해하기 위해서 \"Astronomers saw stars with telescope\"라는 문장이 음성 또는 text로 들어왔을 때를 가정하여 각 단계에는 무엇을 하고 이를 통해서 어떻게 이 문장을 바꿀 수 있는지를 확인해보겠다.\n\n\u003e **1. Phonetics/Orthography(음성학/맞춤법)**\n\n먼저 Orthography는 맞춤법 검사를 의미하며, character sequence로 input이 들어오면, 이를 맞춤법에 맞는지를 확인하여 이것이 수정된 sequence로 반환한다.  \n예시 문장에 있는 \"telescope\"는 문법에 맞지 않으므로 \"telescopes\"로 바뀌어야 한다.\n\n| input                                 | output                                 |\n| :------------------------------------ | :------------------------------------- |\n| Astronomers saw stars with telescope. | Astronomers saw stars with telescopes. |\n\nPhonetics는 음성학을 의미하며, 혀와 음성의 영향을 주는 다양한 근육의 위치 형태, 모양, 빈도를 활용하여 자음과 모음을 분류하는 작업을 수행한다. Orthoography와는 달리 억양이라는 것을 추가적으로 활용할 수 있다.\n\n| input                                                       | output                                 |\n| :---------------------------------------------------------- | :------------------------------------- |\n| Astronomers saw stars with telescopes.를 의미하는 음성 신호 | əsˈtrɒnəməz sɔː stɑːz wɪð ˈtɛlɪskəʊps. |\n\n*\u003chttps://tophonetics.com/\u003e 을 통해서 변환하여 얻을 수 있다.\n\n\u003e **2. Phonology/Lexicalization(음운론/어휘화)**\n\nPhonology은 음운론으로 소리와 phonemes(음소)사이의 관계를 이용하여, 음소를 특정 word로 변환하고, Lexicalization에서는 해당 단어를 사전에서의 형태로 변환하는 과정을 수행한다.\n\n| input                                  | output                                 |\n| :------------------------------------- | :------------------------------------- |\n| əsˈtrɒnəməz sɔː stɑːz wɪð ˈtɛlɪskəʊps. | Astronomers saw stars with telescopes. |\n\n\u003e **3. Morphology(어형론)**\n\nMorphology는 어형론으로 음소의 구성을 기본형(lemma)의 형태로 변환하며, 각 단어들을 형태학적인 의미를 갖는 카테고리(category, tag)로 분류한다.\n여기서 사용되는 lemma와 category가 무엇인지 좀 더 자세히 살펴보자.\n\n- **lemma**  \n  - 사전에 표기되는 단어의 기본형으로, 사전에서 word를 찾는 pointer가 된다.  \n  - 동음이의어의 경우 특정 뜻을 지칭하고 싶은 경우에는 numbering을 수행하기도 한다.\n  - 더 나아가서는 형태소(morpeheme)까지 구분하기도 한다. 이는 혼자서 쓰일 수 있는 자립 형태소(root)와 의존 형태소(stem)으로 나눌 수 있다.  \n    - 예를 들면, quotations -\u003e quote[root] + -ation[stem] + -s[stem]\n    - 위와 같은 형태로 세분화할 수도 있지만, 대게는 lemma 단위에서 그친다.\n- **categorizing**  \n  - category는 정하기 나름이며, 이미 정해져있는 tagset들도(Brown, Penn, Multext) 많이 존재하고, 억양이나 실제 분류 등을 수행하는 것도 가능하다.\n  - **POS tagging**은 category를 분류하는 방법 중에서 가장 유명한데, 이는 여러 언어에서 거의 호환되기 때문에 이 방식을 활용하여 분석하는 것이 가장 안정적인 방법이라고 할 수 있다. 이는 별도의 Posting에서 더 자세히 다루도록 하겠다.\n\n또한, 단어의 형태는 언어마다 다양하기 때문에 어느정도 언어마다 다른 작업을 해주어야 한다. 크게 구분되는 형태로 언어를 3개의 종류로 나눌 수 있다.\n\n1. **Analytical Language(고립어)**  \n   하나의 단어가 대게 하나의 morpheme을 가진다. 따라서, 하나 이상의 category로 구분되어질 수 있다.  \n   ex. English, Chinese, Italian\n2. **Inflective Fusional Language(굴절어)**  \n   prefix/suffix/infix가 모두 morpheme에 영향을 미치며, morpheme의 정의 자체가 애매해지는 언어 형태  \n   ex. Czech, Russian, Polish, ...\n3. **Agglutinative Language(교착어)**  \n   하나의 단어에는 morpheme이 명확하게 구분되고, prefix/suffix/infix 또한 명확하게 구분 가능하다. 따라서, 각 morpheme에 명확한 category를 mapping하는 것이 가능하다.  \n   ex. Korean, ...\n\n| input                                  | output(based on Brown tagset)                                         |\n| :------------------------------------- | :-------------------------------------------------------------------- |\n| Astronomers saw stars with telescopes. | (astronomer/NNS) (see/VBD) (star/NNS) (with/IN) (telescope/NNS) (./.) |\n\n\u003e **4. Syntax(통사론)**\n\nlemma나 morpheme을 구문의 요소인 S(Subject, 주어), V(Verb, 동사), O(Object, 목적어)와 같은 요소로 분류한다. 이 분류를 수행할 때에는 문장의 구성요소를 알아야 한다. 이를 bottom-up으로 살펴보자.\n\n- **Word(단어)**  \n  사전에 명시된 하나의 단위라고 볼 수 있다. 이는 관용어(dark horse)를 포함한다.\n- **Phrase(구)**  \n  둘 이상의 단어 또는 구의 결합으로 만들어진다. 대게 하나의 문법적인 의미로 변환되어진다.  \n  - 대표적인 예시\n    - Noun : a new book\n    - Adjective : brand new\n    - Adverbial : so much\n    - Prepositional : in a class\n    - Verb : catch a ball\n  - **Elipse(생략)**  \n    대게 단어 또는 구가 생략되는 경우가 많다. 특히 담화의 경우 더욱 그렇다.  \n    이를 추론을 통해서 추가할 수도 있다.\n- **Clause(절)**  \n  절은 주어와 서술어를 갖춘 하나의 문장과 유사하지만, 문장 요소로서 더 상위 문장에 속하는 경우이다.  \n  또한, 영어에서는 특히 접속사로 연결된 절이 아닌 경우에는 해당 절이 지칭하는 대상이 절 내부에서 생략된다. 이를 gap이라고 한다.\n- **Sentense**  \n  하나 이상의 절로 이루어지고, 영어에서는 시작 시에 대문자로 표기하며 종료 시에는 구분자로 .?!로 끝난다.\n\n결국 우리는 이러한 요소를 적절하게 표시해야 하는데, 이를 위해서 tree 구조를 사용하는 것이 일반적이다. 대표적으로 두 가지의 구조가 있다.\n\n1. **phrase structure(derivation tree)**\n   문장을 기점으로 절, 구, 단어로 top-down으로 내려가는 구조를 가진다.  \n   각 단위를 묶을 때에는 ()를 이용하고, 그 뒤애 해당하는 내용이 무슨 구, 절인지를 표기한다.\n2. **dependency structure**  \n   단어 간의 관계에 더 집중하여 나타낸다. 따라서, 사람이 보기에는 불명확해 보일 수 있지만 특정 usecase에서는 유용하다.\n\n| input                                                                 | output (phrase structure)                                                              |\n| :-------------------------------------------------------------------- | :------------------------------------------------------------------------------------- |\n| (astronomer/NNS) (see/VBD) (star/NNS) (with/IN) (telescope/NNS) (./.) | ((astronomer/NNS)NP ((see/VBD)V ((star/NNS)NP ((with/IN)P (telescope/NNS)NP)PP)NP)VP)S |\n\n![nlp-phase-structure](/images/nlp-phase-structure.jpg)\n\n\u003e **5. Semantics(Meaning, 의미론)**\n\n간단하게는 주어, 목적어와 같은 tag나 \"Agent\"나 \"Effect\"와 같은 tag를 적용하며, 전체적인 의미를 유추해낸다.\n\n| input                                                                                  | output                                                                                                |\n| :------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------- |\n| ((astronomer/NNS)NP ((see/VBD)V ((star/NNS)NP ((with/IN)P (telescope/NNS)NP)PP)NP)VP)S | ((astronomer/NNS)NP/agent ((see/VBD)V ((star/NNS)NP/affected ((with/IN)P (telescope/NNS)NP)PP)NP)VP)S |\n\n\u003e **6. Discourse/Pragmatics(담화/화용론)**\n\n실제 대화 등과 같은 목표를 해결하기 위해서 앞서 보았던 문장 구조를 이용한다.\n\n만약, 해당 데이터를 통해서 하고자 하는 것이 이 이야기를 한 사람이 식당 내부에 있는지를 판단하고자 한다고 가정해보자.\n\n| input                                                                                                 | output |\n| :---------------------------------------------------------------------------------------------------- | :----- |\n| ((astronomer/NNS)NP/agent ((see/VBD)V ((star/NNS)NP/affected ((with/IN)P (telescope/NNS)NP)PP)NP)VP)S | False  |\n\n## Reference\n\n- Tumbnail : Photo by [David Ballew](https://unsplash.com/@daveballew?utm_source=unsplash\u0026utm_medium=referral\u0026utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@daveballew?utm_source=unsplash\u0026utm_medium=referral\u0026utm_content=creditCopyText)\n- text to phonetic converter, \u003chttps://tophonetics.com\u003e\n","slug":"nlp-linguistics","date":"2022-10-19 09:03","title":"[NLP] 1. Linguistics","category":"AI","tags":["NLP","Languagistics"],"desc":"Natural Language(자연어, 사람이 사용하는 통상 언어)를 input으로 활용하고자 하는 노력은 컴퓨터의 등장부터 시작하여 여러 번 시도되어 왔다. 지금까지도 완벽하게 이를 처리하는 것은 힘들다. 왜 Natural Language를 다루는 것은 어렵고, 이를 해결하기 위해서 NLP에서는 어떤 방식을 활용할지에 대한 개략적인 overview를 제시한다. 또한, Natural Language의 특성과 분석 단계를 이해하기 위해서 Linguistics(언어학)을 간략하게 정리한다.","thumbnailSrc":"https://euidong.github.io/images/nlp-thumbnail.jpg"}],"params":{"subject":"Languagistics"}},"__N_SSG":true},"page":"/tags/[subject]","query":{"subject":"Languagistics"},"buildId":"WVqR2qamn-AxDkQTWbEYe","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>