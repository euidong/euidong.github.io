<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="initial-scale=1.0, width=device-width"/><meta name="description" content="Network ë¶„ì•¼ì— ê´€ì‹¬ì´ ë§ì€ ê°œë°œìë¡œ Computer Engineering ê´€ë ¨ Postingì„ ì£¼ë¡œ ë‹¤ë£¹ë‹ˆë‹¤."/><meta property="og:description" content="Network ë¶„ì•¼ì— ê´€ì‹¬ì´ ë§ì€ ê°œë°œìë¡œ Computer Engineering ê´€ë ¨ Postingì„ ì£¼ë¡œ ë‹¤ë£¹ë‹ˆë‹¤."/><meta property="og:type" content="blog"/><meta property="og:site_name" content="JustLog"/><meta property="og:image" content="https://euidong.github.io/logo192.png"/><title>#GeneralClassifier | JustLog</title><meta property="og:title" content="#GeneralClassifier | JustLog"/><link rel="canonical" href="https://euidong.github.io/tags/GeneralClassifier"/><meta property="og:url" content="https://euidong.github.io/tags/GeneralClassifier"/><meta name="next-head-count" content="11"/><link rel="icon" href="https://euidong.github.io/favicon.png"/><link rel="apple-touch-icon" href="https://euidong.github.io/logo192.png"/><script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-7452732177557701" crossorigin="anonymous"></script><link rel="preload" href="/_next/static/css/d4ec5c8b3df09443.css" as="style"/><link rel="stylesheet" href="/_next/static/css/d4ec5c8b3df09443.css" data-n-g=""/><link rel="preload" href="/_next/static/css/6dc16d084a5153e5.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6dc16d084a5153e5.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-9b312e20a4e32339.js" defer=""></script><script src="/_next/static/chunks/framework-81da43a8dcd978d9.js" defer=""></script><script src="/_next/static/chunks/main-7b6c38cbad60dfcf.js" defer=""></script><script src="/_next/static/chunks/pages/_app-8fae2bc55ffc7161.js" defer=""></script><script src="/_next/static/chunks/675-ae8e8a351ce30ae2.js" defer=""></script><script src="/_next/static/chunks/pages/tags/%5Bsubject%5D-2ecacdd7ae5454e8.js" defer=""></script><script src="/_next/static/q7OR7R1IAToqrDLy0qrQN/_buildManifest.js" defer=""></script><script src="/_next/static/q7OR7R1IAToqrDLy0qrQN/_ssgManifest.js" defer=""></script><script src="/_next/static/q7OR7R1IAToqrDLy0qrQN/_middlewareManifest.js" defer=""></script></head><body><div id="__next"><div class="Layout_wrapper__dKJSz root"><header class="Layout_header__XosLl" style="position:sticky"><div><button tabindex="1" class="SideBarToggler_search_bar_toggler__CEuUg"><svg stroke="currentColor" fill="none" stroke-width="0" viewBox="0 0 24 24" height="35px" width="35px" xmlns="http://www.w3.org/2000/svg"><path d="M2 6C2 5.44772 2.44772 5 3 5H21C21.5523 5 22 5.44772 22 6C22 6.55228 21.5523 7 21 7H3C2.44772 7 2 6.55228 2 6Z" fill="currentColor"></path><path d="M2 12.0322C2 11.4799 2.44772 11.0322 3 11.0322H21C21.5523 11.0322 22 11.4799 22 12.0322C22 12.5845 21.5523 13.0322 21 13.0322H3C2.44772 13.0322 2 12.5845 2 12.0322Z" fill="currentColor"></path><path d="M3 17.0645C2.44772 17.0645 2 17.5122 2 18.0645C2 18.6167 2.44772 19.0645 3 19.0645H21C21.5523 19.0645 22 18.6167 22 18.0645C22 17.5122 21.5523 17.0645 21 17.0645H3Z" fill="currentColor"></path></svg></button><nav class="SideBar_side_bar__wrapper--close__8Nwnr"><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/">Home</a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/tags">Tags</a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/Algorithm">Algorithm<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->11<!-- -->)<!-- --></span></a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/Computer%20Architecture">Computer Architecture<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->7<!-- -->)<!-- --></span></a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/Tech">Tech<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->17<!-- -->)<!-- --></span></a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/Web">Web<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->4<!-- -->)<!-- --></span></a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/Network">Network<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->11<!-- -->)<!-- --></span></a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/AI">AI<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->9<!-- -->)<!-- --></span></a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/Paper">Paper<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->1<!-- -->)<!-- --></span></a></nav></div><a class="Logo_logo___yD0t" tabindex="1" href="/"></a><div><button class="SearchBarToggler_search_bar_toggler__3dHbA" tabindex="2"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="25px" width="25px" xmlns="http://www.w3.org/2000/svg"><path d="M11.742 10.344a6.5 6.5 0 1 0-1.397 1.398h-.001c.03.04.062.078.098.115l3.85 3.85a1 1 0 0 0 1.415-1.414l-3.85-3.85a1.007 1.007 0 0 0-.115-.1zM12 6.5a5.5 5.5 0 1 1-11 0 5.5 5.5 0 0 1 11 0z"></path></svg></button></div></header><section><div class="RowCard_row_card__list__background___xFj5"><h1 class="RowCard_row_card__list__title__t4a2h"> General Classifier</h1><label class="RowCard_row_card__list__select__wrapper__TZ4_9"><select class="RowCard_row_card__list__select__dxkxA"><option class="RowCard_row_card__list__select__option__GRKZU">ìµœì‹ ìˆœ<!-- --></option><option class="RowCard_row_card__list__select__option__GRKZU">AtoZ<!-- --></option><option class="RowCard_row_card__list__select__option__GRKZU">ZtoA<!-- --></option></select></label><ul class="RowCard_row_card__list__wrapper__5Gtgi"><div class="RowCard_row_card__wrapper__kohuv"><a class="RowCard_row_card__thumbnail__wrapper__bedY4" href="/posts/ml-svm"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:200px;height:200px;background:none;opacity:1;border:0;margin:0;padding:0;position:relative"><img alt="[ML] 4. SVM" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fixed" class="RowCard_row_card__thumbnail__Dh_84" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="[ML] 4. SVM" srcSet="https://euidong.github.io/images/ml-thumbnail.jpg?imwidth=256 1x, https://euidong.github.io/images/ml-thumbnail.jpg?imwidth=640 2x" src="https://euidong.github.io/images/ml-thumbnail.jpg?imwidth=640" decoding="async" data-nimg="fixed" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" class="RowCard_row_card__thumbnail__Dh_84" loading="lazy"/></noscript></span></a><div class="RowCard_row_card__tray__trcA5"><a class="RowCard_row_card__tray__title__lVniM" tabindex="-1" href="/posts/ml-svm">[ML] 4. SVM</a><div class="RowCard_row_card__tray__date__3cY_j">2022ë…„ 10ì›” 18ì¼ 17ì‹œ 29ë¶„</div><ul class="RowCard_row_card__tray__tag__qXmOl"><a class="RowCard_row_card__tray__tag__li__7_3Zt" tabindex="-1" href="/tags/ML"># <!-- -->ML<!-- --></a><a class="RowCard_row_card__tray__tag__li__7_3Zt" tabindex="-1" href="/tags/SVM"># <!-- -->SVM<!-- --></a><a class="RowCard_row_card__tray__tag__li__7_3Zt" tabindex="-1" href="/tags/GeneralClassifier"># <!-- -->GeneralClassifier<!-- --></a></ul></div></div></ul></div></section><footer class="Layout_footer__EL5v8"><div class="Layout_footer__copyright__r5baC"><span>Copyright Â© euidong</span><br/><span>ëª¨ë“  ì»¨í…ì¸ ì— ëŒ€í•œ ì €ì‘ê¶Œì€ ì‘ì„±ìì—ê²Œ ì¡´ì¬í•©ë‹ˆë‹¤. <!-- --><br/>ë¶ˆë²• ë³µì œë¥¼ í†µí•œ ìƒì—…ì  ì‚¬ìš©ì„ ì ˆëŒ€ì ìœ¼ë¡œ ê¸ˆì§€í•©ë‹ˆë‹¤. <!-- --><br/>ë‹¨, ë¹„ìƒì—…ì  ì´ìš©ì˜ ê²½ìš° ì¶œì²˜ ë° ë§í¬ë¥¼ ì ìš©í•œë‹¤ë©´ ììœ ë¡­ê²Œ ì‚¬ìš©ê°€ëŠ¥ í•©ë‹ˆë‹¤.<!-- --></span><span>Also I use photos by<!-- --> <!-- --><a href="https://unsplash.com/@lorenzoherrera?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" tabindex="-1">Lorenzo Herrera</a> <!-- -->on<!-- --> <!-- --><a href="https://unsplash.com/s/photos/tech?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" tabindex="-1">Unsplash</a></span></div><div class="Layout_footer__contents__YZWSm"><a class="Layout_footer__contents__link__K_TKH" href="https://github.com/euidong" target="_blank" rel="noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="60" width="60" xmlns="http://www.w3.org/2000/svg"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path></svg><span>github</span></a><a class="Layout_footer__contents__link__K_TKH" href="https://euidong.github.io/portfolio" target="_blank" rel="noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="60" width="60" xmlns="http://www.w3.org/2000/svg"><path d="M6 8a3 3 0 1 0 0-6 3 3 0 0 0 0 6zm-5 6s-1 0-1-1 1-4 6-4 6 3 6 4-1 1-1 1H1zM11 3.5a.5.5 0 0 1 .5-.5h4a.5.5 0 0 1 0 1h-4a.5.5 0 0 1-.5-.5zm.5 2.5a.5.5 0 0 0 0 1h4a.5.5 0 0 0 0-1h-4zm2 3a.5.5 0 0 0 0 1h2a.5.5 0 0 0 0-1h-2zm0 3a.5.5 0 0 0 0 1h2a.5.5 0 0 0 0-1h-2z"></path></svg><span>portfolio</span></a><a class="Layout_footer__contents__link__K_TKH" href="https://chrome.google.com/webstore/detail/bonfire/nkooidijgbppkojdgkoafcoppnohdfka?hl=ko" target="_blank" rel="noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" version="1.1" viewBox="0 0 16 16" height="60" width="60" xmlns="http://www.w3.org/2000/svg"><path d="M5.016 16c-1.066-2.219-0.498-3.49 0.321-4.688 0.897-1.312 1.129-2.61 1.129-2.61s0.706 0.917 0.423 2.352c1.246-1.387 1.482-3.598 1.293-4.445 2.817 1.969 4.021 6.232 2.399 9.392 8.631-4.883 2.147-12.19 1.018-13.013 0.376 0.823 0.448 2.216-0.313 2.893-1.287-4.879-4.468-5.879-4.468-5.879 0.376 2.516-1.364 5.268-3.042 7.324-0.059-1.003-0.122-1.696-0.649-2.656-0.118 1.823-1.511 3.309-1.889 5.135-0.511 2.473 0.383 4.284 3.777 6.197z"></path></svg><span>chat</span></a></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"content":"\n## Intro\n\nìš°ë¦¬ëŠ” Classificationì„ í•˜ê¸° ìœ„í•´ì„œ Logistic Regressionì„ ìˆ˜í–‰í•˜ì˜€ë‹¤. ê·¸ ê²°ê³¼ ê²°êµ­ Classificationë„ ê²°êµ­ì€ ì„ ì„ ê¸‹ëŠ” ê²ƒì´ë¼ëŠ” ê²°ë¡ ì„ ë‚´ë¦¬ê²Œ ë˜ì—ˆë‹¤. í•˜ì§€ë§Œ, ì—¬ê¸°ì„œ ê·¸ì¹˜ì§€ ì•Šê³  í•˜ë‚˜ ë” ê³ ë¯¼í•´ ë³¼ ìˆ˜ ìˆëŠ” ê²ƒì´ ìˆë‹¤. ë°”ë¡œ ì£¼ì–´ì§„ ë°ì´í„°ì— ëŒ€í•´ì„œ ì™„ë²½í•˜ê²Œ êµ¬ë¶„í•˜ëŠ” decision boundaryê°€ ì—¬ëŸ¬ ê°œ ìˆì„ ë•Œ, ì–´ë–¤ ê²ƒì´ ê°€ì¥ ì¢‹ì€ ê²ƒì¼ê¹Œ? ì´ê²ƒì— ëŒ€í•œ ì•„ì´ë””ì–´ë¥¼ ì œì‹œí•˜ëŠ” ê²ƒì´ SVMì´ë‹¤. í•´ë‹¹ Postingì—ì„œëŠ” ì´ì— ëŒ€í•´ì„œ ì‚´í´ë³´ë„ë¡ í•˜ê² ë‹¤.\n\n## (Hard Margin) SVM\n\nSoft Vector Machineì˜ ì•½ìë¡œ, ìœ„ì—ì„œ ì œì‹œí•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ì„œ Marginì´ë¼ëŠ” ê²ƒì„ ë„ì…í•˜ì˜€ë‹¤.\n\n\u003e **Margin**\n\n**Margin**ì´ë€ decison boundaryì™€ ê°€ì¥ ê°€ê¹Œìš´ ê° classì˜ ë‘ ì  ì‚¬ì´ì˜ ê±°ë¦¬ë¥¼ 2ë¡œ ë‚˜ëˆˆ ê°’ì´ë‹¤.\n\n![svm-1](/images/svm-1.jpg)\n\nìœ„ì˜ ê·¸ë¦¼ì€ ë˜‘ê°™ì€ ë°ì´í„° ë¶„í¬ì—ì„œ ëŒ€í‘œì ì¸ decision boundary ë‘ ê°œë¥¼ ì œì‹œí•œ ê²ƒì´ë‹¤. ì—¬ê¸°ì„œ ìš°ë¦¬ëŠ” êµ‰ì¥íˆ ë§ì€ decision boundaryë¥¼ ê·¸ë¦´ ìˆ˜ ìˆë‹¤. ê·¸ ì¤‘ì—ì„œë„ íŒŒë€ìƒ‰ ì‹¤ì„ ì´ ì§ê´€ì ìœ¼ë¡œ ê°€ì¥ ì ì ˆí•œ decision boundaryê°€ ë  ê²ƒì´ë¼ê³  ì§ì‘í•  ìˆ˜ ìˆë‹¤. ê·¸ ì´ìœ ëŠ” í•„ì—°ì ìœ¼ë¡œ dataëŠ” noiseì— ì˜í•œ ì˜¤ì°¨ê°€ ë°œìƒí•  ìˆ˜ ìˆëŠ”ë° ì‹¤ì œ ë°ì´í„°ì˜ ì˜¤ì°¨ì˜ í—ˆìš© ë²”ìœ„ë¥¼ ìš°ë¦¬ëŠ” **margin**(=capability of unexpected noise)ë§Œí¼ í™•ë³´í•  ìˆ˜ ìˆë‹¤ëŠ” ì˜ë¯¸ë¡œ ì´ë¥¼ í•´ì„í•  ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ, ì´ marginì„ í¬ê²Œ í•˜ë©´ í•  ìˆ˜ë¡ ì¢‹ì€ ì„±ëŠ¥ì„ ê°€ì§€ëŠ” ì„ ì„ ê·¸ì„ ìˆ˜ ìˆì„ ê²ƒì´ë¼ëŠ” ê²°ë¡ ì„ ë‚´ë¦´ ìˆ˜ ìˆë‹¤.\n\nì´ê²ƒì´ SVMì˜ í•µì‹¬ ì•„ì´ë””ì–´ì´ë‹¤.\n\nê·¸ë ‡ë‹¤ë©´, marginì„ ìˆ˜í•™ì ìœ¼ë¡œ ì •ì˜í•´ë³´ì. ìš°ë¦¬ê°€ decision boundaryë¥¼ $f(\\bold{x}) := \\bold{w}^{\\top}\\bold{x} + b = 0$ì´ë¼ê³  í•œë‹¤ë©´, ì ($\\bold{x}_{i}$)ê³¼ vector ì§ì„  vector ì‚¬ì´ì˜ ê±°ë¦¬ ê³µì‹ì„ í†µí•´ì„œ ${{|f(\\bold{x}_{i})|}\\over{||\\bold{w}||}}$ë¼ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.\n\në”°ë¼ì„œ marginì€ ìˆ˜í•™ì ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ë‹¤.\n\n$$\n\\min_{i}{{|f(\\bold{x}_{i})|}\\over{||\\bold{w}||}}\n$$\n\n```plaintext\n ğŸ¤” Canonical(ë²•ì¹™ê¹Œì§€ëŠ” ì•„ë‹ˆì§€ë§Œ ì‚¬ì‹¤ìƒ í‘œì¤€í™”ëœ) SVM\n\n SVMì—ì„œëŠ” f(x) = 0ì¸ ë“±ì‹ í˜•íƒœë¥¼ ê°™ëŠ”ë‹¤. ì¦‰ f(x)ì— ì–´ë–¤ ê°’ì„ ê³±í•´ë„ ë˜‘ê°™ë‹¤ëŠ” ê²ƒì´ë‹¤.\n ê·¸ëŸ°ë° marginì˜ í¬ê¸°ë¥¼ êµ¬í•  ë•Œì—ëŠ”, wì™€ bì— ì–´ë–¤ ê°’ì´ ê³±í•´ì§„ë‹¤ë©´ ì´ ê°’ì´ êµ‰ì¥íˆ ë‹¬ë¼ì§€ê²Œ ëœë‹¤.\n ë”°ë¼ì„œ, ì¼ë°˜ì ìœ¼ë¡œ ìš°ë¦¬ëŠ” marginì—ì„œì˜ |f(x)| = 1ì´ ë  ìˆ˜ ìˆë„ë¡ ì„¤ì •í•œë‹¤. \n ì´ë ‡ê²Œ í•˜ë©´ ê³„ì‚°ì´ êµ‰ì¥íˆ ì‰¬ì›Œì§„ë‹¤.\n```\n\n![svm-2](/images/svm-2.jpg)\n\në”°ë¼ì„œ, ìš°ë¦¬ëŠ” ìœ„ì˜ ê·¸ë¦¼ê³¼ ê°™ì€ í˜•íƒœë¡œ $\\bold{x}^{-}$ì™€ $\\bold{x}^{+}$ë¥¼ ì°¾ì„ ìˆ˜ ìˆëŠ” ê²ƒì´ë‹¤.\n\nì´ì œ ë§ˆì§€ë§‰ìœ¼ë¡œ marginì„ ì •ì˜í•´ë³´ì.\n\n$$\n\\begin{align*}\n\\rho \u0026= {1\\over2}\\{ {{|f(\\bold{x}^{+})|}\\over{||\\bold{w}||}} - {{|f(\\bold{x}^{-})|}\\over{||\\bold{w}||}}  \\} \\\\\n\u0026= {1\\over2}{1\\over{||\\bold{w}||}}\\{\\bold{w}^{\\top}\\bold{x}^{+} - \\bold{w}^{\\top}\\bold{x}^{-}\\} \\\\\n\u0026= {1\\over{||\\bold{w}||}}\n\\end{align*}\n$$\n\n\u003e **Optimization**\n\nê·¸ë ‡ë‹¤ë©´, ì´ì œ ìš°ë¦¬ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•  ì¤€ë¹„ê°€ ëœ ê²ƒì´ë‹¤. ìš°ë¦¬ê°€ í•˜ê³ ì í•˜ëŠ” ê²ƒì€ marginì„ ìµœëŒ€í™”í•˜ë©´ì„œë„, ëª¨ë“  dataë¥¼ ì˜¤ë¥˜ì—†ì´ ë¶„ë¥˜í•˜ëŠ” ê²ƒì´ë‹¤. ì´ëŠ” ë‹¤ìŒê³¼ ê°™ì€ Constraint Optimization í˜•íƒœë¡œ ë³€í™˜í•  ìˆ˜ ìˆë‹¤.\n\n$$\n\\begin{align*}\n  \\text{maximize}   \\quad \u0026 {1\\over{||\\bold{w}||}} \u0026\\\\\n  \\text{subject to} \\quad \u0026 y_{i}(\\bold{w}^{\\top}\\bold{x}_{i} + b) \\geq 1, \u0026 i = 1, ..., N\n\\end{align*}\n$$\n\nConditional Optimizationì€ ì´ì „ Posting([[ML] 0. Base Knowledge](/posts/ml-base-knowledge))ì—ì„œ ë‹¤ë£¬ë°” ìˆë‹¤. í•´ë‹¹ ë‚´ìš©ì— ëŒ€í•´ ë¯¸ìˆ™í•˜ë‹¤ë©´ í•œ ë²ˆ ì‚´í´ë³´ê³  ì˜¤ë„ë¡ í•˜ì.\n\nìœ„ ë‚´ìš©ì„ ìˆ™ì§€í•˜ì˜€ë‹¤ë©´, ìœ„ì˜ í¼ì´ ë‹¤ì†Œ ë°”ë€Œì–´ì•¼ í•œë‹¤ëŠ” ê²ƒì„ ì•Œ ê²ƒì´ë‹¤. í•´ë‹¹ í˜•íƒœë¥¼ ë°”ê¾¸ë©´ì„œ, minimize í˜•íƒœë¥¼ ë¯¸ë¶„ì´ ê°„í¸í•  ìˆ˜ ìˆë„ë¡ ë°”ê¾¸ë„ë¡ í•˜ê² ë‹¤.\n\n$$\n\\begin{align*}\n  \\text{minimize}   \\quad \u0026 {1\\over2}||\\bold{w}|| \u0026\\\\\n  \\text{subject to} \\quad \u0026 1 - y_{i}(\\bold{w}^{\\top}\\bold{x}_{i} + b) \\leq 0, \u0026 i = 1, ..., N\n\\end{align*}\n$$\n\nìš°ì„  lagrangianì€ ë‹¤ìŒê³¼ ê°™ë‹¤.\n\n$$\n\\mathcal{L} = {1\\over2}||\\bold{w}|| + \\sum_{i=1}^{N}\\alpha_{i}(1 - y_{i}(\\bold{w}^{\\top}\\bold{x}_{i} + b))\n$$\n\nì´ê²ƒì— KKT Conditionì„ ì ìš©í•˜ì—¬ ì •ë¦¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ë“±ì‹ì„ ì–»ì„ ìˆ˜ ìˆë‹¤.\n\n$$\n\\bold{w} = \\sum_{i=1}^{N}\\alpha_{i}y_{i}\\bold{x}_{i}\n$$\n\n$$\n\\sum_{i=1}^{N}\\alpha_{i}y_{i} = 0\n$$\n\nì´ë¥¼ $\\mathcal{L}$ì— ëŒ€ì…í•˜ì—¬ ì‹ì„ ì •ë¦¬í•˜ë©´, ë‹¤ìŒê³¼ ê°™ë‹¤.\n\n$$\n\\mathcal{L} = -{1\\over2}\\sum_{i=1}^{N}\\sum_{j=1}^{N}\\alpha_{i}\\alpha_{j}y_{i}y_{j}\\bold{x}_{i}^{\\top}\\bold{x}_{j} + \\sum_{i=1}^{N}\\alpha_{i}\n$$\n\nì´ì œ ì´ê²ƒì„ ì´ìš©í•´ì„œ Dual Problemì„ ì •ì˜í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.\n\n$$\n\\begin{align*}\n  \\text{maximize}   \\quad \u0026 -{1\\over2}\\sum_{i=1}^{N}\\sum_{j=1}^{N}\\alpha_{i}\\alpha_{j}y_{i}y_{j}\\bold{x}_{i}^{\\top}\\bold{x}_{j} + \\sum_{i=1}^{N}\\alpha_{i} \u0026\\\\\n  \\text{subject to} \\quad \u0026 \\sum_{i=1}^{N}\\alpha_{i}y_{i} = 0, \u0026 \\\\\n  \u0026 \\alpha_{i} \\geq 0, \u0026 i = 1, ..., N \n\\end{align*}\n$$\n\nì´ ì‹ì—ì„œ ëˆˆì—¬ê²¨ ë³¼ì ì€ ë°”ë¡œ constraint ë¶€ë¶„ì´ë‹¤. ì´ ê³¼ì •ì„ í†µí•´ì„œ ê²°ë¡ ì ìœ¼ë¡œ constraint ë¶€ë¶„ì´ ë¶€ë“±ì‹ì—ì„œ ë“±ì‹ì´ ë˜ì—ˆë‹¤. ì´ëŠ” ì—°ì‚° ê³¼ì •ì„ ë§¤ìš° ê°„ë‹¨í•˜ê²Œ í•œë‹¤. ë¿ë§Œ ì•„ë‹ˆë¼ $\\bold{x}_{i}^{\\top}\\bold{x}_{j}$ëŠ” í•œ ë²ˆ ê³„ì‚°í•˜ë©´, ì „ì²´ ê³¼ì •ì—ì„œ ê³„ì†í•´ì„œ ì¬ì‚¬ìš©í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ì»´í“¨íŒ… ì‹œì—ëŠ” êµ‰ì¥í•œ ì´ì ì„ ë°œíœ˜í•  ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ, ì‹¤ì œë¡œ ê°’ì„ êµ¬í•  ë•Œì—ëŠ” ì´ê²ƒì„ ì´ìš©í•˜ì—¬ ê°’ì„ êµ¬í•˜ëŠ” ê²ƒì´ ê°€ì¥ ì¼ë°˜ì ì´ë‹¤.\n\n## (Soft Margin) SVM\n\nSVMì˜ ëª¨ë“  ì ˆì°¨ë¥¼ ì‚´í´ë³¸ ê²ƒ ê°™ì§€ë§Œ, ìš°ë¦¬ê°€ ê°„ê³¼í•œ ì‚¬ì‹¤ì´ í•˜ë‚˜ ìˆë‹¤. ë°”ë¡œ ê·¸ê²ƒì€ ìš°ë¦¬ëŠ” dataê°€ í•˜ë‚˜ì˜ ì„ ì„ í†µí•´ì„œ ì™„ë²½í•˜ê²Œ ë‚˜ë‰˜ì–´ì§„ë‹¤ê³  ê°€ì •í–ˆë‹¤. í•˜ì§€ë§Œ, ì‹¤ì œ ë°ì´í„°ëŠ” ê·¸ë ‡ì§€ ì•Šì„ ê°€ëŠ¥ì„±ì´ í¬ë‹¤. ë”°ë¼ì„œ, ìš°ë¦¬ëŠ” ì–´ëŠ ì •ë„ì˜ ì˜¤ì°¨ë¥¼ í—ˆìš©í•  ìˆ˜ ìˆë„ë¡ í•´ì•¼ í•œë‹¤. ì´ë¥¼ slack($\\zeta$)ì´ë¼ê³  í•œë‹¤.\n\n![svm-2](/images/svm-2.jpg)\n\nì´ë¥¼ ì ìš©í•˜ë©´, ìš°ë¦¬ì˜ ëª©ì í•¨ìˆ˜ì™€ ì œì•½ ì¡°ê±´ì„ ë³€ê²½í•´ì•¼ í•œë‹¤. ì´ë¥¼ ë³€ê²½í•˜ëŠ” ë°©ë²•ì€ ë‘ ê°€ì§€ê°€ ì¡´ì¬í•˜ëŠ”ë° ê° ê° slack variableì˜ L2-normì„ ëª©ì í•¨ìˆ˜ì— ë”í•˜ëŠ” ë°©ì‹ê³¼ L1-normì„ ë”í•˜ëŠ” ë°©ì‹ì´ë‹¤.\n\n\u003e **L2-norm Optimization**\n\në¨¼ì € L2-normì„ ë”í•˜ëŠ” ë°©ì‹ì„ ì•Œì•„ë³´ì\n$$\n\\begin{align*}\n  \\text{minimize}   \\quad \u0026 {1\\over2}||\\bold{w}|| + C\\sum_{i=1}^{N}\\zeta_{i}^{2} \u0026\\\\\n  \\text{subject to} \\quad \u0026 1 - y_{i}(\\bold{w}^{\\top}\\bold{x}_{i} + b) - \\zeta_{i} \\leq 0, \u0026 i = 1, ..., N\n\\end{align*}\n$$\n\nì—¬ê¸°ì„œ $C$ëŠ” margin ìµœëŒ€í™”ì™€ slackness ì •ë„ì˜ ìƒëŒ€ê°’ì„ ì˜ë¯¸í•œë‹¤. ë§Œì•½, slacknessë³´ë‹¤ marginì˜ ìµœëŒ€í™”ê°€ ì¤‘ìš”í•˜ë‹¤ë©´, Cê°’ì€ ì»¤ì§€ê³  ë°˜ëŒ€ë¼ë©´ ì´ ê°’ì€ ì‘ì•„ì§„ë‹¤.\n\nìš°ì„  lagrangianì„ ë¨¼ì € êµ¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.\n\n$$\n\\mathcal{L} = {1\\over2}||\\bold{w}|| + {C\\over2}\\sum_{i=1}^{N}\\zeta_{i}^{2} + \\sum_{i=1}^{N}\\alpha_{i}(1 - \\zeta_{i} y_{i}(\\bold{w}^{\\top}\\bold{x}_{i} + b))\n$$\n\nKKT conditionì„ ì´ìš©í•˜ì—¬ ì£¼ìš” ê°’ë“¤ì„ êµ¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ë“±ì‹ì„ ì–»ì„ ìˆ˜ ìˆë‹¤.\n\n$$\n\\bold{w} = \\sum_{i=1}^{N}\\alpha_{i}y_{i}\\bold{x}_{i}\n$$\n\n$$\n\\sum_{i=1}^{N}\\alpha_{i}y_{i} = 0\n$$\n\n$$\n\\boldsymbol{\\zeta} = {\\alpha\\over{C}}\n$$\n\në§ˆì§€ë§‰ìœ¼ë¡œ ì´ë¥¼ Dual Problemìœ¼ë¡œ ì¬ì •ì˜í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì•„ì§„ë‹¤.\n\n$$\n\\begin{align*}\n  \\text{maximize}   \\quad \u0026 -{1\\over2}\\sum_{i=1}^{N}\\sum_{j=1}^{N}\\alpha_{i}\\alpha_{j}y_{i}y_{j}(\\bold{x}_{i}^{\\top}\\bold{x}_{j} + {1\\over{C}}\\delta_{ij}) + \\sum_{i=1}^{N}\\alpha_{i} \u0026\\\\\n  \\text{subject to} \\quad \u0026 \\sum_{i=1}^{N}\\alpha_{i}y_{i} = 0, \u0026 \\\\\n  \u0026 \\alpha_{i} \\geq 0, \u0026 i = 1, ..., N \n\\end{align*}\n$$\n\nì—¬ê¸°ì„œ $\\delta_{ij}$ëŠ” ë‹¨ìœ„í–‰ë ¬ì´ë‹¤. ê¸°ì¡´ hard margin svmê³¼ ë¹„êµí–ˆì„ ë•Œ, ${1\\over{C}}\\delta_{ij}$ ì™¸ì—ëŠ” ë°”ë€Œì§€ ì•ŠëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.\n\n\u003e **L1-norm Optimization**\n\nê·¸ ë‹¤ìŒì€ L1-normì´ë‹¤.\n$$\n\\begin{align*}\n  \\text{minimize}   \\quad \u0026 {1\\over2}||\\bold{w}|| + C\\sum_{i=1}^{N}\\zeta_{i} \u0026\\\\\n  \\text{subject to} \\quad \u0026 1 - y_{i}(\\bold{w}^{\\top}\\bold{x}_{i} + b) - \\zeta_{i} \\leq 0, \u0026 \\\\\n  \u0026 \\zeta_{i} \\geq 0 \u0026 i = 1, ..., N\n\\end{align*}\n$$\n\nì—¬ê¸°ì„œëŠ” slack variableì´ ë°˜ë“œì‹œ 0ë³´ë‹¤ í¬ê±°ë‚˜ ê°™ë‹¤ëŠ” ê²ƒì„ ì£¼ì˜í•˜ì.\n\nlagrangianì€ ë‹¤ìŒê³¼ ê°™ë‹¤.\n\n$$\n\\mathcal{L} = {1\\over2}||\\bold{w}|| + C\\sum_{i=1}^{N}\\zeta_{i} + \\sum_{i=1}^{N}\\alpha_{i}(1 - \\zeta_{i} y_{i}(\\bold{w}^{\\top}\\bold{x}_{i} + b)) -  \\sum_{i=1}^{N}\\beta_{i}\\zeta_{i}\n$$\n\nKKT conditionì„ ì´ìš©í•˜ì—¬ ì£¼ìš” ê°’ë“¤ì„ êµ¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ë“±ì‹ì„ ì–»ì„ ìˆ˜ ìˆë‹¤.\n\n$$\n\\bold{w} = \\sum_{i=1}^{N}\\alpha_{i}y_{i}\\bold{x}_{i}\n$$\n\n$$\n\\sum_{i=1}^{N}\\alpha_{i}y_{i} = 0\n$$\n\n$$\n\\sum_{i=1}^{N}\\beta_{i} = C\n$$\n\në§ˆì§€ë§‰ìœ¼ë¡œ ì´ë¥¼ Dual Problemìœ¼ë¡œ ì¬ì •ì˜í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì•„ì§„ë‹¤.\n\n$$\n\\begin{align*}\n  \\text{maximize}   \\quad \u0026 -{1\\over2}\\sum_{i=1}^{N}\\sum_{j=1}^{N}\\alpha_{i}\\alpha_{j}y_{i}y_{j}\\bold{x}_{i}^{\\top}\\bold{x}_{j} + \\sum_{i=1}^{N}\\alpha_{i} \u0026\\\\\n  \\text{subject to} \\quad \u0026 \\sum_{i=1}^{N}\\alpha_{i}y_{i} = 0, \u0026 \\\\\n  \u0026 0 \\leq \\alpha_{i} \\leq C, \u0026 i = 1, ..., N \n\\end{align*}\n$$\n\nê²°êµ­ ê¸°ì¡´ Hard marginê³¼ ë¹„êµí–ˆì„ ëŒ€ëŠ” ë§ˆì§€ë§‰ constraintì— $\\alpha_{i} \\leq C$ê°€ ì¶”ê°€ëœ ê²ƒ ë°–ì— ì—†ë‹¤.\n\n---\n\në§ˆì§€ë§‰ìœ¼ë¡œ ì—¬ê¸°ì„œ í•˜ë‚˜ì˜ insightë¥¼ ë” ì–»ì„ ìˆ˜ ìˆë‹¤.  \nL1-normì˜ optimizationìœ¼ë¡œ ëŒì•„ê°€ë³´ì.\n\n$$\n\\begin{align*}\n  \\text{minimize}   \\quad \u0026 {1\\over2}||\\bold{w}|| + C\\sum_{i=1}^{N}\\zeta_{i} \u0026\\\\\n  \\text{subject to} \\quad \u0026 1 - y_{i}(\\bold{w}^{\\top}\\bold{x}_{i} + b) - \\zeta_{i} \\leq 0, \u0026 \\\\\n  \u0026 \\zeta_{i} \\geq 0 \u0026 i = 1, ..., N\n\\end{align*}\n$$\n\nëª©ì  í•¨ìˆ˜ì˜ slack variableì— constraintì˜ ê°’ì„ ëŒ€ì…í•˜ì—¬, ë‹¤ìŒê³¼ ê°™ì´ ë³€í™˜ì´ ê°€ëŠ¥í•˜ë‹¤.\n\n$$\n\\min {C^{\\prime}\\over2}||\\bold{w}|| + \\sum_{i=1}^{N}max\\{ 0, 1 - y_{i}(\\bold{w}^{\\top}\\bold{x}_{i} + b) \\}\n$$\n\nì´ í˜•íƒœëŠ” logistric regressionì— regularizationì„ ìˆ˜í–‰í•œ ê²ƒê³¼ ë™ì¼í•œ í˜•íƒœë¥¼ ê°€ì§€ê²Œ ëœë‹¤. ì¦‰, ì´ì „ logistic regressionì—ì„œ regularizationì„ ë‹¤ë£¨ì§€ ì•Šì•˜ëŠ”ë°, ê²°êµ­ì€ soft margin svmì˜ L1-norm ëª©ì í•¨ìˆ˜ê°€ logistic regression ì¤‘ì—ì„œë„ hinge functionì´ë¼ëŠ” ê²ƒì„ ì´ìš©í–ˆì„ ë•Œì˜ regularizationì´ ë˜ëŠ” ê²ƒì´ë‹¤.\n\n## Generalization\n\nì—¬íƒœê¹Œì§€ ì‚´í´ë³¸ Regressionì„ í†µí•´ì„œ ìš°ë¦¬ëŠ” Generalí•œ Classification ë°©ì‹ì„ ì§€ì •í•  ìˆ˜ ìˆë‹¤. ìš°ì„  ì•„ë˜ ì‹ì„ ì‚´í´ë³´ì.\n\n- Linear Regression(Quadratic Loss)  \n  $\\min {C^{\\prime}\\over2}||\\bold{w}|| + \\sum_{i=1}^{N}{1\\over2}(1 - y_{i}(\\bold{w}^{\\top}\\phi(\\bold{x}_{i})) )^{2}$\n- Logit Regresion(Log Loss)  \n  $\\min {C^{\\prime}\\over2}||\\bold{w}|| + \\sum_{i=1}^{N}\\log( 1 + \\exp[-y_{i}(\\bold{w}^{\\top}\\phi(\\bold{x}_{i})]) )$\n- Binary SVM(Hinge Loss)  \n  $\\min {C^{\\prime}\\over2}||\\bold{w}|| + \\sum_{i=1}^{N}max\\{ 0, 1 - y_{i}(\\bold{w}^{\\top}\\phi(\\bold{x}_{i})) \\}$\n\nì—¬íƒœê¹Œì§€ ë‚˜ì˜¨ ì‹ë“¤ì„ ì‚´í´ë³´ë©´ ìœ„ì™€ ê°™ë‹¤. ìš°ë¦¬ëŠ” ì—¬ê¸°ì„œ ì•„ë˜ì™€ ê°™ì€ ì¼ë°˜ì ì¸ í˜•íƒœì˜ Classificationì„ ì œì‹œí•  ìˆ˜ ìˆë‹¤. \n\n- General Classification  \n  $\\min {C^{\\prime}\\over2}||\\bold{w}|| + \\sum_{i=1}^{N}\\varepsilon\\log( 1 + \\exp[-y_{i}(\\bold{w}^{\\top}\\phi(\\bold{x}_{i})]) )$\n\nì—¬ê¸°ì„œ $\\varepsilon$ì´ 1ì´ë©´ ë°”ë¡œ logistic regressionì´ ë˜ê³ , $\\varepsilon$ì´ 0ì— ìˆ˜ë ´í•  ìˆ˜ë¡ SVMì´ ëœë‹¤. ì•„ë˜ ê·¸ë¦¼ì„ ë³´ë©´ ì´ë¥¼ ì•Œ ìˆ˜ ìˆë‹¤.\n\n![compare-regressions](/images/compare-regressions.jpg)\n\n## Reference\n\n- Tumbnail : Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=unsplash\u0026utm_medium=referral\u0026utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@markuswinkler?utm_source=unsplash\u0026utm_medium=referral\u0026utm_content=creditCopyText)","slug":"ml-svm","date":"2022-10-18 17:29","title":"[ML] 4. SVM","category":"AI","tags":["ML","SVM","GeneralClassifier"],"desc":"ìš°ë¦¬ëŠ” Classificationì„ í•˜ê¸° ìœ„í•´ì„œ Logistic Regressionì„ ìˆ˜í–‰í•˜ì˜€ë‹¤. ê·¸ ê²°ê³¼ ê²°êµ­ Classificationë„ ê²°êµ­ì€ ì„ ì„ ê¸‹ëŠ” ê²ƒì´ë¼ëŠ” ê²°ë¡ ì„ ë‚´ë¦¬ê²Œ ë˜ì—ˆë‹¤. í•˜ì§€ë§Œ, ì—¬ê¸°ì„œ ê·¸ì¹˜ì§€ ì•Šê³  í•˜ë‚˜ ë” ê³ ë¯¼í•´ ë³¼ ìˆ˜ ìˆëŠ” ê²ƒì´ ìˆë‹¤. ë°”ë¡œ ì£¼ì–´ì§„ ë°ì´í„°ì— ëŒ€í•´ì„œ ì™„ë²½í•˜ê²Œ êµ¬ë¶„í•˜ëŠ” decision boundaryê°€ ì—¬ëŸ¬ ê°œ ìˆì„ ë•Œ, ì–´ë–¤ ê²ƒì´ ê°€ì¥ ì¢‹ì€ ê²ƒì¼ê¹Œ? ì´ê²ƒì— ëŒ€í•œ ì•„ì´ë””ì–´ë¥¼ ì œì‹œí•˜ëŠ” ê²ƒì´ SVMì´ë‹¤. í•´ë‹¹ Postingì—ì„œëŠ” ì´ì— ëŒ€í•´ì„œ ì‚´í´ë³´ë„ë¡ í•˜ê² ë‹¤.","thumbnailSrc":"https://euidong.github.io/images/ml-thumbnail.jpg"}],"params":{"subject":"GeneralClassifier"}},"__N_SSG":true},"page":"/tags/[subject]","query":{"subject":"GeneralClassifier"},"buildId":"q7OR7R1IAToqrDLy0qrQN","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>