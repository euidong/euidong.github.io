<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="initial-scale=1.0, width=device-width"/><meta property="og:type" content="blog"/><meta property="og:site_name" content="JustLog"/><meta property="og:image" content="https://euidong.github.io/logo192.png"/><title>#Factorization | JustLog</title><meta name="description" content="#Factorization 관련 Posting"/><meta property="og:description" content="#Factorization 관련 Posting"/><meta property="og:title" content="#Factorization | JustLog"/><link rel="canonical" href="https://euidong.github.io/tags/Factorization"/><meta property="og:url" content="https://euidong.github.io/tags/Factorization"/><meta name="next-head-count" content="11"/><link rel="icon" href="https://euidong.github.io/favicon.png"/><link rel="apple-touch-icon" href="https://euidong.github.io/logo192.png"/><link rel="preload" href="/_next/static/css/d4ec5c8b3df09443.css" as="style"/><link rel="stylesheet" href="/_next/static/css/d4ec5c8b3df09443.css" data-n-g=""/><link rel="preload" href="/_next/static/css/6dc16d084a5153e5.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6dc16d084a5153e5.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js" id="Adsense-id" data-ad-client="ca-pub-7452732177557701" async="" defer="" data-nscript="beforeInteractive"></script><script src="/_next/static/chunks/webpack-9b312e20a4e32339.js" defer=""></script><script src="/_next/static/chunks/framework-81da43a8dcd978d9.js" defer=""></script><script src="/_next/static/chunks/main-7b6c38cbad60dfcf.js" defer=""></script><script src="/_next/static/chunks/pages/_app-8c8de51645108dcb.js" defer=""></script><script src="/_next/static/chunks/675-ae8e8a351ce30ae2.js" defer=""></script><script src="/_next/static/chunks/pages/tags/%5Bsubject%5D-0fc8f67b45fbbd0f.js" defer=""></script><script src="/_next/static/JTjNvUb3F58nrRICrLlJh/_buildManifest.js" defer=""></script><script src="/_next/static/JTjNvUb3F58nrRICrLlJh/_ssgManifest.js" defer=""></script><script src="/_next/static/JTjNvUb3F58nrRICrLlJh/_middlewareManifest.js" defer=""></script></head><body><div id="__next"><div class="Layout_wrapper__dKJSz root"><header class="Layout_header__XosLl" style="position:static"><div><button tabindex="1" class="SideBarToggler_search_bar_toggler__CEuUg"><svg stroke="currentColor" fill="none" stroke-width="0" viewBox="0 0 24 24" height="35px" width="35px" xmlns="http://www.w3.org/2000/svg"><path d="M2 6C2 5.44772 2.44772 5 3 5H21C21.5523 5 22 5.44772 22 6C22 6.55228 21.5523 7 21 7H3C2.44772 7 2 6.55228 2 6Z" fill="currentColor"></path><path d="M2 12.0322C2 11.4799 2.44772 11.0322 3 11.0322H21C21.5523 11.0322 22 11.4799 22 12.0322C22 12.5845 21.5523 13.0322 21 13.0322H3C2.44772 13.0322 2 12.5845 2 12.0322Z" fill="currentColor"></path><path d="M3 17.0645C2.44772 17.0645 2 17.5122 2 18.0645C2 18.6167 2.44772 19.0645 3 19.0645H21C21.5523 19.0645 22 18.6167 22 18.0645C22 17.5122 21.5523 17.0645 21 17.0645H3Z" fill="currentColor"></path></svg></button><nav class="SideBar_side_bar__wrapper--close__8Nwnr"><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/">Home</a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/tags">Tags</a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/Algorithm">Algorithm<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->11<!-- -->)<!-- --></span></a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/Computer%20Architecture">Computer Architecture<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->7<!-- -->)<!-- --></span></a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/Tech">Tech<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->17<!-- -->)<!-- --></span></a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/Web">Web<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->4<!-- -->)<!-- --></span></a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/Paper">Paper<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->2<!-- -->)<!-- --></span></a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/Network">Network<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->11<!-- -->)<!-- --></span></a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/AI">AI<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->19<!-- -->)<!-- --></span></a></nav></div><a class="Logo_logo___yD0t" tabindex="1" href="/"></a><div><button class="SearchBarToggler_search_bar_toggler__3dHbA" tabindex="2"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="25px" width="25px" xmlns="http://www.w3.org/2000/svg"><path d="M11.742 10.344a6.5 6.5 0 1 0-1.397 1.398h-.001c.03.04.062.078.098.115l3.85 3.85a1 1 0 0 0 1.415-1.414l-3.85-3.85a1.007 1.007 0 0 0-.115-.1zM12 6.5a5.5 5.5 0 1 1-11 0 5.5 5.5 0 0 1 11 0z"></path></svg></button></div></header><section><div class="RowCard_row_card__list__background___xFj5"><h1 class="RowCard_row_card__list__title__t4a2h"> Factorization</h1><label class="RowCard_row_card__list__select__wrapper__TZ4_9"><select class="RowCard_row_card__list__select__dxkxA"><option class="RowCard_row_card__list__select__option__GRKZU">최신순<!-- --></option><option class="RowCard_row_card__list__select__option__GRKZU">AtoZ<!-- --></option><option class="RowCard_row_card__list__select__option__GRKZU">ZtoA<!-- --></option></select></label><ul class="RowCard_row_card__list__wrapper__5Gtgi"><div class="RowCard_row_card__wrapper__kohuv"><a class="RowCard_row_card__thumbnail__wrapper__bedY4" href="/posts/ml-graphical-model"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:200px;height:200px;background:none;opacity:1;border:0;margin:0;padding:0;position:relative"><img alt="[ML] 8. Graphical Model" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fixed" class="RowCard_row_card__thumbnail__Dh_84" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="[ML] 8. Graphical Model" srcSet="https://euidong.github.io/images/ml-thumbnail.jpg?imwidth=256 1x, https://euidong.github.io/images/ml-thumbnail.jpg?imwidth=640 2x" src="https://euidong.github.io/images/ml-thumbnail.jpg?imwidth=640" decoding="async" data-nimg="fixed" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" class="RowCard_row_card__thumbnail__Dh_84" loading="lazy"/></noscript></span></a><div class="RowCard_row_card__tray__trcA5"><a class="RowCard_row_card__tray__title__lVniM" tabindex="-1" href="/posts/ml-graphical-model">[ML] 8. Graphical Model</a><div class="RowCard_row_card__tray__date__3cY_j">2022년 11월 14일 13시 08분</div><ul class="RowCard_row_card__tray__tag__qXmOl"><a class="RowCard_row_card__tray__tag__li__7_3Zt" tabindex="-1" href="/tags/ML"># <!-- -->ML<!-- --></a><a class="RowCard_row_card__tray__tag__li__7_3Zt" tabindex="-1" href="/tags/GraphicalModel"># <!-- -->GraphicalModel<!-- --></a><a class="RowCard_row_card__tray__tag__li__7_3Zt" tabindex="-1" href="/tags/ConditionalIndependence"># <!-- -->ConditionalIndependence<!-- --></a><a class="RowCard_row_card__tray__tag__li__7_3Zt" tabindex="-1" href="/tags/MarkovRandomField"># <!-- -->MarkovRandomField<!-- --></a><a class="RowCard_row_card__tray__tag__li__7_3Zt" tabindex="-1" href="/tags/BayesianNetwork"># <!-- -->BayesianNetwork<!-- --></a><a class="RowCard_row_card__tray__tag__li__7_3Zt" tabindex="-1" href="/tags/FactorGraph"># <!-- -->FactorGraph<!-- --></a><a class="RowCard_row_card__tray__tag__li__7_3Zt" tabindex="-1" href="/tags/D-Seperation"># <!-- -->D-Seperation<!-- --></a><a class="RowCard_row_card__tray__tag__li__7_3Zt" tabindex="-1" href="/tags/Factorization"># <!-- -->Factorization<!-- --></a><a class="RowCard_row_card__tray__tag__li__7_3Zt" tabindex="-1" href="/tags/MarkovProperty"># <!-- -->MarkovProperty<!-- --></a><a class="RowCard_row_card__tray__tag__li__7_3Zt" tabindex="-1" href="/tags/MessagePassing"># <!-- -->MessagePassing<!-- --></a><a class="RowCard_row_card__tray__tag__li__7_3Zt" tabindex="-1" href="/tags/BeliefPropagation"># <!-- -->BeliefPropagation<!-- --></a><a class="RowCard_row_card__tray__tag__li__7_3Zt" tabindex="-1" href="/tags/Chow-LiuAlgorithm"># <!-- -->Chow-LiuAlgorithm<!-- --></a></ul></div></div></ul></div></section><footer class="Layout_footer__EL5v8"><div class="Layout_footer__copyright__r5baC"><span>Copyright © euidong</span><br/><span>모든 컨텐츠에 대한 저작권은 작성자에게 존재합니다. <!-- --><br/>불법 복제를 통한 상업적 사용을 절대적으로 금지합니다. <!-- --><br/>단, 비상업적 이용의 경우 출처 및 링크를 적용한다면 자유롭게 사용가능 합니다.<!-- --></span><span>Also I use photos by<!-- --> <!-- --><a href="https://unsplash.com/@lorenzoherrera?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" tabindex="-1">Lorenzo Herrera</a> <!-- -->on<!-- --> <!-- --><a href="https://unsplash.com/s/photos/tech?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" tabindex="-1">Unsplash</a></span></div><div class="Layout_footer__contents__YZWSm"><a class="Layout_footer__contents__link__K_TKH" href="https://github.com/euidong" target="_blank" rel="noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="60" width="60" xmlns="http://www.w3.org/2000/svg"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path></svg><span>github</span></a><a class="Layout_footer__contents__link__K_TKH" href="https://euidong.github.io/portfolio" target="_blank" rel="noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="60" width="60" xmlns="http://www.w3.org/2000/svg"><path d="M6 8a3 3 0 1 0 0-6 3 3 0 0 0 0 6zm-5 6s-1 0-1-1 1-4 6-4 6 3 6 4-1 1-1 1H1zM11 3.5a.5.5 0 0 1 .5-.5h4a.5.5 0 0 1 0 1h-4a.5.5 0 0 1-.5-.5zm.5 2.5a.5.5 0 0 0 0 1h4a.5.5 0 0 0 0-1h-4zm2 3a.5.5 0 0 0 0 1h2a.5.5 0 0 0 0-1h-2zm0 3a.5.5 0 0 0 0 1h2a.5.5 0 0 0 0-1h-2z"></path></svg><span>portfolio</span></a><a class="Layout_footer__contents__link__K_TKH" href="https://chrome.google.com/webstore/detail/bonfire/nkooidijgbppkojdgkoafcoppnohdfka?hl=ko" target="_blank" rel="noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" version="1.1" viewBox="0 0 16 16" height="60" width="60" xmlns="http://www.w3.org/2000/svg"><path d="M5.016 16c-1.066-2.219-0.498-3.49 0.321-4.688 0.897-1.312 1.129-2.61 1.129-2.61s0.706 0.917 0.423 2.352c1.246-1.387 1.482-3.598 1.293-4.445 2.817 1.969 4.021 6.232 2.399 9.392 8.631-4.883 2.147-12.19 1.018-13.013 0.376 0.823 0.448 2.216-0.313 2.893-1.287-4.879-4.468-5.879-4.468-5.879 0.376 2.516-1.364 5.268-3.042 7.324-0.059-1.003-0.122-1.696-0.649-2.656-0.118 1.823-1.511 3.309-1.889 5.135-0.511 2.473 0.383 4.284 3.777 6.197z"></path></svg><span>chat</span></a></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"content":"\n## Intro\n\nMachine Learning은 주어진 data를 가장 잘 설명할 수 있는 pattern(Model)을 찾는 것이 목표라고 하였다. 그렇다면, \"data가 가지는 여러가지 정보(feature)들 중에서 어떤 feature를 중점적으로 보고 이용할 수 있을까?\" 그리고, \"만약 여러 feature들이 서로 연관이 있다면 이를 연산의 최적화를 위해 이용할 수 있지 않을까?\" 라는 접근이 가능하다. 여기서 Graphical Model은 이러한 관계를 시각적으로 표현할 수 있으며, 이를 통해서 연산 최적화에 대한 insight를 얻을 수 있다.\n\n## Relation\n\n각 feature들 즉, Random Variable들 간의 관계는 크게 세 가지 종류가 있다.\n\n1. **Correlation(상관관계)**  \n   쉽게 생각하면 두 Random Variable이 있을 때, 서로가 값 추정에 영향을 준다는 것이다. 즉, 특정 Random Variable의 값이 관측되었을 때, Random Variable이 가지는 값의 범위가 제한되고, 확률이 변화한다.  \n   즉, $X$와$Y$가 서로 Correlation이 존재한다면, $P(X) \\neq P(X|Y)$  \n   그렇기에 두 Random Variable이 서로 독립(independence)이라면, Correlation이 존재하지 않는 것이다.  \n2. **Causality(인과관계)**  \n   쉽게 Correlation과 헷갈릴 수 있지만, Causality는 원인과 결과가 나타나는 관계를 의미한다. 쉬운 예시로 X라는 사건과 Y라는 사건이 빈번하게 같이 발생한다고, 쉽게 X라는 사건이 Y의 원인이라고 말할 수는 없는 것과 같은 원리이다. 또한, 중요한 특징 중에 하나는 방향이 분명하다는 것이다. 원인과 결과는 대게 분리되기 때문에 원인이 되는 사건과 결과가 되는 사건이 분명이 구분된다. 결론적으로, Causality를 가지는 두 사건은 서로 Correlation이 있는 것은 자명하지만, Correlation이 존재한다고 Causality를 단정할 수 있는 것은 아니다. 즉, Correlation이 Causality를 포함하는 개념이다. 그렇기에 서로 독립이라면, Causality도 존재하지 않는 것이다.\n3. **Independence(독립)**  \n   위에 제시된 두 가지는 dependence 관계를 나타낸다. 이는 두 Random Variable의 값이 서로의 값에 영향을 전혀 주지 않음을 의미한다.  \n   즉, $X$와 $Y$가 서로 독립하다면, $P(X) = P(X|Y), P(Y) = P(Y|X)$이다.  \n   (결과적으로 Independence가 아니라면 최소한의 Correlation이 존재한다.)\n\n이러한 관계를 어떻게 활용할 수 있을지를 고민해보자. 우리가 집중적으로 살펴볼 것은 **Independence**이다. 만약, 우리가 구하고자 하는 결과값($Y$)가 존재할 때, 특정 feature($X_{1}$)가 서로 독립한다고 하자. $P(Y|X_{1})=P(Y)$에 의해서 $X_{1}$는 전혀 쓸모가 없는 정보임을 알 수가 있다. 이렇게 명확한 independence를 안다면 해당 feature를 Learning 및 Estimation에서 제거하는 것은 쉬울 것이다. 하지만, 우리는 이러한 관계를 명확하게 밝히기 어려울 때가 많다. 그렇다면 결국 우리가 Machine Learning을 통해서 구하고자 하는 식인 아래 식을 어떻게 하면 좀 더 최적화할 수 있을까?\n\n$$\nP(Y|X_{1}, X_{2}, \\cdots, X_{N}) = \\frac{P(Y, X_{1}, X_{2}, \\cdots, X_{N})}{P(X_{1}, X_{2}, \\cdots, X_{N})}\n$$\n\n여기서의 핵심은 바로 **Joint Probability**에 있다. 우리는 결국 좋든 싫든 **Joint Probability**를 구해야 한다.\n\n$$\n\\begin{align*}\nP(X_{1}, X_{2}, \\cdots, X_{N}) \u0026= P(X_{1} | X_{2}, X_{3}, \\cdots, X_{N}) \\times P(X_{2}, X_{3}, \\cdots, X_{N})\\\\\n\u0026= P(X_{1} | X_{2}, X_{3}, \\cdots, X_{N}) \\times P(X_{2} |, X_{3}, X_{4}, \\cdots, X_{N}) \\times P(X_{3}, X_{4}, \\cdots, X_{N}) \\\\\n\u0026= \\prod_{i=1}^{N} P(X_{i} | X_{i+1}, X_{i+2}, \\cdots, X_{N})\n\\end{align*}\n$$\n\n위에 제시한 **Probability Chain Rule**에 의해서 우리는 Joint Probability는 각각의 Random Variable 의 Conditional Probability라고 할 수 있다. 그렇다면, 우리는 Random Variable이 N개 있고, 각 Random Variable의 dimension이 L이라고 할 때, 다음과 같아짐을 알 수 있다.\n\n$$\nL^{N} \\times L^{N-1} \\times \\cdots \\times L^{1} = O(L^{N})\n$$\n\n이러한 연산을 어떻게 하면 좀 더 최적화할 수 있을까? Hint는 Conditional Probability 각 각의 변수의 양을 줄이는 것이다. 우리가 어떤 관계가 있을 때, 이 Random Variable의 갯수를 줄일 수 있을까? 바로 변수 간 Conditional Independence가 이에 대한 해답을 제시한다.\n\n### Conditional Independence\n\nConditional Independence는 Conditional Probability처럼 특정 정보(다른 Random Variable의 값)가 주어졌을 때, 두 Random Variable이 서로 독립이라는 것이다.\n\n쉽게 예를 들어 설명한다면, \"과음\"과 \"빨간 얼굴\" 사이의 관계라고 할 수 있다. 일반적으로 우리는 \"빨간 얼굴\"인 사람이 \"과음\"을 했을 것이라고 판단할 것이다. 즉, \"빨간 얼굴\"과 \"과음\" 사이에는 관계가 존재한다(dependency). 하지만, \"혈중 알코올 농도\"라는 정보가 주어진다면 어떨까? \"혈중 알코올 농도\"가 주어진다면, 사실 \"빨간 얼굴\"은 더 이상 \"과음\" 여부를 판단하는 기준에 영향을 1도 주지 않을 것이다. 이때에는 \"과음\"과 \"빨간 얼굴\"은 independence하다. 우리는 이런 경우를 다음과 같이 표현할 수 있다.\n\n$$\n\\text{과음} \\not\\!\\perp\\!\\!\\!\\perp \\text{빨간 얼굴}\n$$\n$$\n\\text{과음} \\perp\\!\\!\\!\\!\\perp \\text{빨간 얼굴} |\\ \\text{혈중 알코올 농도}\n$$\n\n즉, 확률에 적용하면 다음과 같다.\n\n$$\nP(\\text{과음} | \\text{빨간 얼굴, 혈중 알코올 농도}) = P(\\text{과음} | \\text{혈중 알코올 농도})\n$$\n\n여기서 우리가 하고 싶었던 것이 나왔다. 바로 \"빨간 얼굴\"이라는 Random Variable이 없어졌다. 즉, \"과음\"과 \"빨간 얼굴\" 사이의 관계 같은 것을 찾을 수 있다면, 우리는 계산 과정을 단순화할 수 있다.\n\n즉, 이것이 우리가 **Graph**를 통해서 찾고자 하는 것이다.\n\n## Graphical Model\n\n**Graphical Model**은 **Graph**를 이용해서 Random Variable들의 관계를 표현하고, 이를 통해서 **Joint Probability**를 계산하는 방법이다. **Graph**를 그리는 방법은 기본적으로 Random Variable 하나 하나가 Graph의 Node가 되고, 각 Node간의 관계가 Edge가 된다. 그런데, 이 관계가 Correlation이냐, Causality냐에 따라서 두 가지 종류로 나뉘게 된다. \u003cmark\u003e**Correlation**은 일반적으로 관계의 방향이 없기에 **Undirected Graph**\u003c/mark\u003e로 표현하고, \u003cmark\u003e**Causality**는 관계의 방향이 있기에 **Directed Graph**\u003c/mark\u003e로 표현한다. 이는 아래에서 더 자세히 다루도록 하겠다.\n\n### Markov Random Field(Undirected Graphical Model, Correlation)\n\n**Markov Random Field**(MRF)라고 불리며, **Correlation**를 표현한 Graph이다. 각 Node는 Random Variable을 의미하며, Edge는 Correlation를 의미한다. 즉, 두 Node가 Edge로 연결되어 있다면, 두 Random Variable은 Independence하지 않다는 것이다.\n\n![ml-undirected-graph-1](/images/ml-undirected-graph-1.jpg)\n\n여기서 중요한 것은 Random Variable을 대표하는 Node와 Correlation을 대표하는 Edge이기 때문에, Graph $G=(V, E)$에서 Random Variable의 집합 $X = \\{X_{1}, X_{2}, \\cdots, X_{|V|}\\}$이고, $\\{1,2, \\cdots, |V|\\}$가 주어질 때 반드시 아래에 제시된 **Markov Property들**을 만족해야 한다.\n\n1. \u003cmark\u003e**Pairwise Markov Property**\u003c/mark\u003e  \n   인접하지 않은 Node 두 개는 다른 모든 Node가 주어질 때 conditionally independent하다.  \n   (아래에서 \\는 포함하지 않는다는 의미이다.)\n   $$\n   X_{i} \\perp\\!\\!\\!\\!\\perp X_{j} | X_{S\\backslash\\{i, j\\}}\n   $$\n2. \u003cmark\u003e**Local Markov Property**\u003c/mark\u003e  \n   한 Node에 인접한 모든 Node(Neighbors)가 주어질 때, 해당 Node는 다른 모든 Node와 conditionally independent하다.  \n   (아래에서 $\\mathcal{N}_{i}$는 Node i와 인접한 모든 Node를 의미한다.)\n   $$\n   X_{i} \\perp\\!\\!\\!\\!\\perp X_{S\\backslash \\mathcal{N}_{i}} | X_{\\mathcal{N}_{i}}\n   $$\n3. \u003cmark\u003e**Global Markov Property**\u003c/mark\u003e  \n   만약, Node들의 Subset으로 이루어진 $A, B$가 특정 subset $C$가 주어질 때, 서로 conditionally independent하다면, $A, B$에 속하는 어떤 subset이라도 서로 independent하다.  \n   (subset간의 conditionally independent를 확인하기 위해서는 특정 Subset들간에 이어지는 모든 경로를 차단할 수 있는 subset이 있는지를 확인한다.)  \n   $$\n   \\begin{align*}\n   X_{A} \u0026\\perp\\!\\!\\!\\!\\perp X_{B} | X_{C} \\\\\n   X_{\\text{subset of }A} \u0026\\perp\\!\\!\\!\\!\\perp X_{\\text{subset of }B} | X_{C} \\\\\n   \\end{align*}\n   $$  \n   ![ml-global-markov-property](/images/ml-global-markov-property.jpg)\n\n따라서, 우리는 이전 그림에서 Conditional Independence를 활용할 수 있다. $X_{1}, X_{4}$의 경우 다른 모든 Random Variable과 correlation이 존재하지만, $X_{2}, X_{3}$의 경우 $X_{1}, X_{4}$만 알면 된다. 즉, $X_{2} \\perp\\!\\!\\!\\!\\perp X_{3} | X_{1}, X_{4}$이다. 따라서, 우리는 이 관계를 확률 식에서 녹여낼 수 있다.\n\n$$\n\\begin{align*}\nP(X_{1}, X_{2}, X_{3}, X_{4}) \u0026= P(X_{2}|X_{1},\\cancel{X_{3}},X_{4})P(X_{1}, X_{3}, X_{4}) (\\because X_{2} \\perp\\!\\!\\!\\!\\perp X_{3} | X_{1}, X_{4}) \\\\\n\u0026= P(X_{2}|X_{1},X_{4})P(X_{1}, X_{3}, X_{4})\n\\end{align*}\n$$\n\n또한, 우리는 Graph를 통해서 Joint Probability를 다음과 같이 정의할 수 있다.\n\n$$\nP(\\cap_{i=1}^{N}X_{i}) = \\frac{1}{Z} \\prod_{C \\in \\mathcal{C}} \\psi_{C}(\\cap_{X_{j}\\in C}X_{j})\n$$\n\n식이 다소 난해하다. 하나 하나 해석을 해보도록 하자. 먼저, $P(\\cap_{i=1}^{N}X_{i})$이다. 이는 Joint Probability를 표현하는 방법 중의 하나로 단순히 이를 정리하면, $P(\\cap_{i=1}^{N}X_{i})=P(X_{1} \\cap X_{2} \\cap \\cdots \\cap X_{N})=P(X_{1}, X_{2}, \\cdots, X_{N})$이다. 다음은 $C$와 $\\mathcal{C}$이다. 둘 다 아마 집합일 것이라는 것은 $\\in$ 기호 덕분에 알 수 있을 것이다. 그렇다면, 어떤 데이터를 담고 있는 집합일까? 이는 Random Variable들로 이루어진 부분 집합이다. 이를 \u003cmark\u003e**Clique($C$)**\u003c/mark\u003e라고 한다. Clique는 Graph에서 Node들의 부분 집합으로, Graph에서 **Fully Connected Node**의 집합을 의미한다. 이것이 가지는 의미는 사실상 하나의 Node로 합칠 수 있다는 것이다.(이를 Graph 상에서의 인수분해(**factorization**)라고도 한다.) Clique에 속하는 Node끼리는 서로 완벽하게 연결되어 있기 때문에 이 중에 하나의 Node라도 다른 Node와 연결을 가진다면, 이에 속하는 모든 Node가 이 관계로 연결된다는 것이다. 추가적으로 Clique들 중에서 다른 Clique에 속하지 않는 Clique들을 \u003cmark\u003e**Maximal Clique($\\mathcal{C}$)**\u003c/mark\u003e라고 한다. 아래 그림에서는 Maximal Clique를 빨간색으로 표기한 것이다.\n\n![ml-max-clique](/images/ml-max-clique.jpg)\n\n마지막으로 $\\psi$이다. 이는 \u003cmark\u003e**Clique Potential Function**\u003c/mark\u003e로, 각 Clique의 Node(Random Variable)를 parameter로 사용하는 함수로 확률과 비슷한 성질을 가지지만 확률처럼 합이 1이 아닐 수도 있고, 값 자체가 음수일 수도 있다. 즉, 이를 구할 때에는 각 Random Variable의 경우의 수와 해당 경우의 상대적 확률로 이루어진 table을 작성하고, 이를 표현할 수 있는 함수를 찾아낸 것이 $\\psi$이다. 대게의 경우 $\\psi$는 해당 Parameter로 이루어진 Condition Probability 또는 Joint Probability가 되는 경우가 많다. 하지만, 그렇지 않은 경우에도 $\\psi$로 표현이 가능하다.(이에 대한 엄밀한 증명은 여기서 다루지 않을 뿐만 아니라 중요하지 않다.) 여기서 \u003cmark\u003e$Z$\u003c/mark\u003e의 의미를 마지막으로 짚어보자면, 단순한 normalization이다. $\\psi$가 운좋게도 Joint Probability, Conditional Probability로 쉽게 구해진다면 $Z=1$이다. 하지만, 그렇지 않을 경우에는 이들의 합이 1이 아니기 때문에 Normalization이 필요한 것이다.\n\n$$\n\\begin{align*}\nZ \u0026= \\sum_{X_{1}}\\sum_{X_{2}} \\cdots \\sum_{X_{N}}{\\prod_{C \\in \\mathcal{C}} \\psi_{C}(\\cap_{X_{j}\\in C}X_{j})} \\\\\n\u0026= \\sum_{X_{1}, X_{2}, \\cdots, X_{N}}{\\prod_{C \\in \\mathcal{C}} \\psi_{C}(\\cap_{X_{j}\\in C}X_{j})}\n\\end{align*}\n$$\n\n결론적으로 의미를 따지자면, 위에서 구한 **Maximal Clique**에 특정 함수를 취한 $\\psi$가 인수분해(**factorization**)에서 하나의 인자(**factor**)가 되는 것이다. 따라서, 이를 **factor function**이라고도 부른다.\n\n자, 마지막으로 우리가 4개의 Random Variable 4개($A, B, C, D$)가 있을 때, Graph로 그릴 수 있는 형태를 네 개 정도 가정하여 예시들을 살펴볼 것이다.\n\n![ml-undirected-graph-2](/images/ml-undirected-graph-2.jpg)\n\n1. $A, B, C, D$가 선형으로 이루어진다.  \n   여기서는 **Maximal Clique**가 3개이다($\\{\\{A, B\\}, \\{ B, C\\}, \\{ C, D\\}\\}$). 따라서, 이를 통해서 Joint Probability를 추정하면 다음과 같다.  \n   $$\n   P(A, B, C, D) = \\frac{1}{Z} \\times \\psi_{1}(A, B) \\times \\psi_{2}(B, C) \\times \\psi_{3}(C, D)\n   $$  \n   여기서 직접적으로 한 번 $P(A, B, C, D)$를 추정해보자.  \n   $$\n   \\begin{align*}\n   P(A, B, C, D) \u0026= P(A| B, C, D) \\times P(B | C, D) \\times P(C, D) \\\\\n   \u0026= P(A|B) \\times P(B|C) \\times P(C, D)\n   \\end{align*}\n   $$  \n   즉, 이렇게 일렬로 된 Graph에서는 마지막 $\\psi$를 제외하고는 모두 Conditional Probability이고, 마지막 $\\psi$는 Joint Probability이다. 그리고, $Z$는 1이라는 것을 알 수 있다.\n2. $A, B, C, D$가 모두 완벽하게 연결되어 있다.  \n   이 경우에는  **Maximal Clique**가 1개이다($\\{\\{A, B, C, D\\}\\}$). 따라서, Joint Probability를 다음과 같이 추정할 수 있다.  \n   $$\n   P(A, B, C, D) = \\frac{1}{Z} \\times \\psi(A, B, C, D)\n   $$  \n   결론적으로 Clique가 하나기 때문에 줄일 수 있는 변수가 없다. 즉, $\\psi$가 Joint Probability이고, $Z$는 1이다.\n3. **Maximal Clique**가 2개이다($\\{\\{A, B, D\\}\\, \\{A, C, D\\}\\}$). 따라서, 다음과 같이 정리된다.  \n   $$\n   \\begin{align*}\n   P(A, B, C, D) \u0026= P(B|A, C, D) \\times P(A, C, D) \\\\\n   \u0026= P(B|A,D) \\times P(A, C, D) \\\\\n   \u0026= \\frac{1}{Z} \\times \\psi_{1}(A, B, D) \\times \\psi_{2}(A, C, D) \\\\\n   \\end{align*}\n   $$\n4. **Maximal Clique**가 4개이다($\\{\\{A, B\\}, \\{ A, C\\}, \\{ B, D\\}, \\{ C, D\\}\\ \\}$).  \n   $$\n   \\begin{align*}\n   P(A, B, C, D) \u0026= P(A|B, C, D) \\times P(B|C, D) \\times P(C, D) \\\\\n   \u0026= P(A|B, C) \\times P(B|D) \\times P(C, D) \\\\\n   \u0026= \\frac{P(A, B, C)}{P(B, C)} \\times P(B|D) \\times P(C, D) \\\\\n   \u0026= \\frac{P(B, C| A)}{P(A)P(B, C)} \\times P(B|D) \\times P(C, D) \\\\\n   \u0026= \\frac{P(B|A)P(C|A)}{P(A)P(B, C)} \\times P(B|D) \\times P(C, D) \\\\\n   \u0026= \\frac{1}{P(B,C)} \\times P(A, B) \\times P(C|A) \\times P(B|D) \\times P(C, D) \\\\\n   \u0026\\neq \\frac{1}{Z} \\times \\psi_{1}(A, B) \\times \\psi_{2}(A, C) \\times \\psi_{3}(B, D) \\times \\psi_{4}(C, D) \\\\\n   \\end{align*}\n   $$  \n   이것이 바로 $\\psi$를 확률 함수라고 부르지 않는 이유이다.  \n   우리가 $\\psi$를 확률 함수 형태로 표현하기 위해서는 **Chordal graph**(4개 이상의 Node로 이루어진 Cycle에서는 중간에 반드시 Cycle을 이루는 Edge가 아닌 Edge가 존재하는 Graph) 형태를 가져야 한다는 것이다. $\\psi$가 확률 함수로 표현되지 않는다고 우리가 하고자 하는 일에 영향을 주지는 않으니 그런가보다 하고 넘어가도 무방하다.\n\n여기서 우리는 **factorization**이라는 개념을 익혔고, 이것이 가능하기 위해서는 Chordal graph가 주어진 상황에서 Markov Property를 만족해야 함을 확인했다. 그리고, 우리는 이러한 **factorization** 형태를 좀 더 명확하게 나타내기 위해서 다음과 같은 형태로 표현하고, 이를 \u003cmark\u003e**factor graph**\u003c/mark\u003e라고 정의한다. 따라서, 각 **factor**(인수)는 **Maximal Clique** 단위로 생성된다.\n\n![ml-factor-graph-1](/images/ml-factor-graph-1.jpg)\n\n### Bayesian Network(Directed Graphical Model, Causality)\n\n**Bayesian Network**라고 불리며, **Causality**를 표현한 Graph이다. 각 Node는 Random Variable을 의미하며, Edge는 Causality(원인($C$) -\u003e 결과($R$))를 의미한다. 그렇기에 굉장히 명확하게 표현이 될 수 있다. 왜냐하면, $P(R, C) = P(C|R)P(R)$임을 명백하게 드러낸다. 그렇기에 우리는 해당 Graph가 주어지는 순간 Joint Probability를 다음과 같이 유추할 수 있는 것이다.\n\n![ml-bayesian-network](/images/ml-bayesian-network.jpg)\n\n즉, 이것을 식으로 나타내면 다음과 같다.\n\n$$\nP(\\cap_{i=1}^{N}X_{i}) = \\prod_{i \\in \\{1, 2, \\cdots, N\\}} P(X_{i}| \\cap_{j \\in \\text{Parents}(X_{i})} X_{j})\n$$\n\n이러한 점 때문에 Bayesian Network에서는 Cycle이 존재할 수 없다. 왜냐하면, Cycle이 존재한다는 것은 각 Random Varaible이 서로 원인과 결과가 되는 것이 때문에 사실상 하나의 사건이라는 의미를 내포하는 것이다. 그렇기에 이는 사실상 존재할 수 없다.\n\n여기서도 마찬가지로 Conditional Independence를 찾을 수 있다. 뿐만 아니라 Marginal Independence에 대한 힌트도 얻을 수 있다. 이때 우리는 \u003cmark\u003e**D-Seperation**\u003c/mark\u003e이라는 방법을 활용한다. 이를 위해서는 자신과 주변 2개의 Node가 이룰 수 있는 관계 3가지를 정의해야 한다.\n\n![ml-bayesian-network-2](/images/ml-bayesian-network-2.jpg)\n\n1. **head-to-tail**  \n   이 경우에는 $X \\rightarrow Y \\rightarrow Z$의 관계를 의미한다. 따라서, $X$와 $Z$는 $Y$가 주어질 때, 서로 Independent하다.  \n   $$\n   \\begin{align*}\n   P(X, Z | Y) \u0026= \\frac{P(X,Y,Z)}{P(Y)}\\\\\n   \u0026= \\frac{P(X)P(Y|X)P(Z|Y)}{P(Y)}\\\\\n   \u0026= \\frac{P(X, Y)}{P(Y)} \\times P(Z|Y) \\\\\n   \u0026= P(X | Y)P(Z | Y)\n   \\end{align*}\n   $$\n2. **tail-to-tail**  \n   이 경우에는 $X \\leftarrow Y \\rightarrow Z$의 관계를 의미한다. 따라서, $X$와 $Z$는 $Y$가 주어질 때, 서로 Independent하다.  \n   $$\n   \\begin{align*}\n   P(X, Z | Y) \u0026= \\frac{P(X, Y, Z)}{P(Y)} \\\\\n   \u0026= \\frac{P(X|Y)P(Y)P(Z|Y)}{P(Y)} \\\\\n   \u0026= P(X | Y)P(Z | Y)\n   \\end{align*}\n   $$\n3. **head-to-head**  \n   이 경우에는 $X \\rightarrow Y \\leftarrow Z$의 관계를 의미한다. 따라서, $X$와 $Z$는 서로 Independent하다.  \n   즉, Conditional Independence가 아니라 Marginal Independence이다.  \n   $$\n   \\begin{align*}\n   P(X, Z) \u0026= \\sum_{Y} P(X, Y, Z) \\\\\n   \u0026= \\sum_{Y} P(X)P(Y|X,Z)P(Z) \\\\\n   \u0026= P(X)P(Z)\\sum_{Y} P(Y|X,Z) \\\\\n   \u0026= P(X)P(Z)\n   \\end{align*}\n   $$\n\n이 관계에서 중요한 것은 $X,Z$간 edge가 존재해서는 안된다는 점이다. 위의 관계를 활용하면, 인접한 관계에서의 Conditional Independence는 판별이 가능하다.하지만, \u003cmark\u003e**D-Seperation**\u003c/mark\u003e을 통해서 이를 더 넓은 범위로 확장할 수 있다. 세 Node의 집합 $A, B, C$가 주어질 때, $A \\perp\\!\\!\\!\\!\\perp B | C$이기 위해서는 다음 조건을 만족해야 한다.\n\n1. A에서 B로 가는 경로가 하나 이상 존재한다.(여기서 경로는 방향을 신경쓰지 않고 연결 여부에 따라 결정한다.)\n2. 모든 경로에 대해서, C에 속하는 Node가 적어도 하나 head-to-tail 또는 tail-to-tail 관계를 중계할 수 있어야 한다.\n3. 모든 경로에 대해서, C에 속하는 Node는 head-to-head 관계를 중계하면 안되며, head-to-head 관계를 중계하는 Node의 자손이여도 안된다.\n\n즉, $A, B, C$가 이러한 조건을 모두 만족할 때, 우리는 $C$가 $A, B$를 Block했다고 하며, $A \\perp\\!\\!\\!\\!\\perp B | C$이다.\n\n예를 들어 아래와 같은 두 경우를 예를 들어볼 수 있다.\n\n![ml-d-seperation](/images/ml-d-seperation.jpg)\n\n왼쪽의 경우 C의 parent가 A에서 B로 가는 경로에서 head-to-head를 중계하고 있다. 따라서, A와 B는 Conditionally Independence를 만족하지 않는다. 반면, 오른쪽의 경우 C가 A에서 B로 가는 경로에서 head-to-tail 관계를 중계하고 있으므로, A와 B는 Conditionally Independence를 만족한다. 여기서 재밌는 점은 A와 B는 두 경우 모두 Marginal Independence를 만족한다는 점이다. 왜냐하면, A에서 B로 가는 경로가 순방향만으로는 이루어지지 않기 때문이다.\n\n마지막으로, Bayesian Network도 **factorization**이 가능하다 A, B의 **Causality**가 $P(A|B)P(B)$를 의미한다는 점을 활용해서 우리는 다음과 같은 형태로 정의하는 것이 가능하다.\n즉, 초기 시작 점은 자신만을 가지는 factor를 가지고, head-to-head 관계는 하나로 통일하며, 나머지 관계(head-to-head, 등)는 별도로 factor를 분리한다. 즉, 다음과 같은 형태를 가진다.\n\n![ml-factor-graph-2](/images/ml-factor-graph-2.jpg)\n\n```plaintext\n 🤔 Markov Blankets\n\n Markov Blanket은 특정 Node에 대한 정보(관계)가 있는 모든 Node를 의미한다. \n 즉, 특정 Random Variable의 확률이 궁금하다면, 이 Markov Blanket만 가지면 된다. \n 그 중에서도 가장 작은 크기로 모든 필요한 정보를 담은 subset을 Markov Boundary라고 한다. \n Markov Boundary는 Markov Random Field에서는 Neighbor이고,\n Bayesian Network에서는 Parent, Child, Co-Parent이다.\n```\n\n![ml-markov-boundary](/images/ml-markov-boundary.jpg)\n\n### Factor Graph\n\n앞 서 본 두 가지 Graph 표현 방법은 각 각 장단점을 가지고 있다.\n\n1. Markov Random Field는 Joint Probability를 Potential이라는 임의의 변수를 통해서 추정하는 것이 가능하다. 따라서, 명확성이 떨이지지만, Conditional Independence를 파악하는 것은 더 분명하고 쉽다.\n2. Bayesian Network는 Joint Probability를 명확하게 판별할 수 있다. 하지만, Conditional Independence를 판별하는 것이 더 어렵고 복잡하다.\n\n이러한 장단점을 모두 살릴 수 있는 방법으로 제시된 것이 Factor Graph이다. 위에서 각 각 Factor Graph를 표현하는 방법에 대해서는 제시하였으므로 여기서는 다루지 않는다. Factor Graph는 근본적으로 Graph의 요소들을 인수분해(Factorization)하여 인수(Factor)로 분리해낸 것이다. 그렇기에 더 명확한 구분이 가능하다. 각 Node는 Factor와 기존 Node에 해당하는 값이 두 개 다 존재하고, Factor는 꽉 찬 네모, 기존 Node(Variable)는 비어있는 동그라미로 표현하는 것이 일반적이다.\n\n그리고, 여기서는 Joint Probability를 다음과 같이 정의한다.\n\nVariable Node는 $\\{X_{1},X_{2}, \\cdots, X_{N}\\}$이고, Factor Node가 $\\{f_{1},f_{2}, \\cdots, f_{M}\\}$일 때, $f_{j}$와 이웃한 Variable Node의 집합을 $\\mathcal{N}_{j}$라고 하자.\n\n$$\nP(X_{1}, X_{2}, \\cdots, X_{N}) = \\prod_{j=1}^{M}{f_{j}(\\cap_{X \\in \\mathcal{N}_{j}} X)}\n$$\n\n이렇게 표현하는 것은 확실히 Markov Random Field에서는 명확하다. 하지만, Bayesian Network에서는 표현할 수 있는 정보를 어느정도 잃었다고 볼 수도 있다. 어차피 Conditional Probability인데, 다르게 표현한 것이기 때문이다. 하지만, 이를 이용하게 되면 기존에 문제였던 Conditional Independence를 쉽게 파악할 수 있다. 왜냐하면 Factor Graph에서는 Conditional Independence를 확인하기 위해서 해당 집합으로 이어지는 모든 경로에서 중간에 하나라도 Variable Node가 껴있는지만 확인해도 충분하다.\n\n![ml-factor-graph-3](/images/ml-factor-graph-3.jpg)\n\n따라서, 앞으로의 과정에서는 Factor Graph를 Main으로 하여 설명을 진행하도록 하겠다.\n\n## Message Passing\n\n우리는 앞의 Graph 표현을 통해서 Feature를 Factor로 압축하는 과정을 익혔다. 이 역시 엄청난 계산 효율을 가져온다. 하지만, 이를 더 효과적으로 활용할 수 있는 방법이 있다. 그것은 Message Passing 방법이다. 우선 우리가 해결하고자하는 문제를 정의해보자. 우리는 Joint Probability($P(X_{1}, X_{2}, \\cdots, X_{N})$)가 주어졌을 때, 다음 값을 구하고 싶을 수 있다.\n\n1. \u003cmark\u003e**Marginalization**\u003c/mark\u003e  \n   Marginal Probability는 Joint Probability에서 구하고자 하는 Random Variable을 제외한 모든 경우의 수를 더한 것이다.\n   $$\n   \\begin{align*}\n   P(X_{i}) \u0026= \\sum_{X_{j}}P(X_{i}, X_{j}) \\\\\n   \u0026= \\sum_{X_{j}, X_{k}}P(X_{i}, X_{j}, X_{k}) \\\\\n   \u0026= \\cdots \\\\\n   \u0026= \\sum_{X_{-i}}P(X_{1}, X_{2}, \\cdots, X_{N})\n   \\end{align*}\n   $$  \n   즉, 이를 일반적인 방법으로 풀고자하면 Random Variable($X_{i}$)이 각 각 $\\mathbb{R}^{L}$로 정의된다고 할 때, $L^{N-1}$번의 합연산이 필요하다.\n2. \u003cmark\u003e**Maximization**\u003c/mark\u003e  \n   Joint Probability의 최댓값을 갖게 하는 경우의 수($\\hat{X}$)를 구하고자 한다면 다음을 구해야 한다.  \n   $$\n   \\hat{X} = \\argmax_{X_{1}, X_{2}, \\cdots, X_{N}} P(X_{1}, X_{2}, \\cdots, X_{N})\n   $$  \n   이 또한 무식하게 풀고자하면, $L^{N-1}$번의 max 연산이 필요하다.\n\n그렇다면, 이를 한 번 가장 간단한 형태인 일자형 Factor Graph로 표현해보자.\n\n![ml-bp-1](/images/ml-bp-1.jpg)\n\n여기서 $P(X_{2})$를 알고 싶다고 해보자. 그 경우 다음과 같이 식이 정리되는 것을 볼 수 있다.\n\n$$\n\\begin{align*}\nP(X_{2}) \u0026= \\sum_{X_{1}}P(X_{1},X_{2}) \\\\\n\u0026= \\sum_{X_{1}, X_{3}, X_{4}, X_{5}}P(X_{1}, X_{2}, X_{3}, X_{4}, X_{5}) \\\\\n\u0026= \\sum_{X_{1}}\\sum_{X_{3}}\\sum_{X_{4}}\\sum_{X_{5}}P(X_{1}, X_{2}, X_{3}, X_{4}, X_{5}) \\\\\n\u0026= \\sum_{X_{1}}\\sum_{X_{3}}\\sum_{X_{4}}\\sum_{X_{5}}f_{a}(X_{1}, X_{2})f_{b}(X_{2}, X_{3})f_{c}(X_{3}, X_{4})f_{d}(X_{4}, X_{5}) \\\\\n\u0026= (\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))(\\sum_{X_{3}}\\sum_{X_{4}}\\sum_{X_{5}}f_{b}(X_{2}, X_{3})f_{c}(X_{3}, X_{4})f_{d}(X_{4}, X_{5})) \\\\\n\u0026= (\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))(\\sum_{X_{3}}\\sum_{X_{4}}f_{b}(X_{2}, X_{3})f_{c}(X_{3}, X_{4})\\sum_{X_{5}}f_{d}(X_{4}, X_{5})) \\\\\n\u0026= (\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))(\\sum_{X_{3}}f_{b}(X_{2}, X_{3})\\sum_{X_{4}}f_{c}(X_{3}, X_{4})\\sum_{X_{5}}f_{d}(X_{4}, X_{5}))\n\\end{align*}\n$$\n\n이것이 의미하는 바는 무엇일까? 이는 단순하게 순서를 바꾸어 재조합하는 것만으로 Computing을 줄일 수 있음을 보여줬다. 먼저, 앞의 $\\sum$연산만 단독으로 할 때, $L$번의 연산이 필요하고, 뒤에 연속해서 나오는 3번의 $\\sum$을 구하기 위해서는 결국 $L^{3}$의 연산이 필요하다. 즉, $L + L^{3}$의 합연산으로 marginalization 결과를 구할 수 있다는 것이다. 그렇기에 더 효율적인 연산이 가능한 것이다. 이는 특히 Graph의 중앙에 있는 값을 구할 때 더 도드라지게 나타난다. 전체 marginalization 결과를 나타내면 다음과 같다.\n\n$$\n\\begin{align*}\nP(X_{1}) \u0026= \\sum_{X_{2}}f_{a}(X_{1}, X_{2})\\sum_{X_{3}}f_{b}(X_{2}, X_{3})\\sum_{X_{4}}f_{c}(X_{3}, X_{4})\\sum_{X_{5}}f_{d}(X_{4}, X_{5}) \\rightarrow L^{4} \\\\\nP(X_{2}) \u0026= (\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))(\\sum_{X_{3}}f_{b}(X_{2}, X_{3})\\sum_{X_{4}}f_{c}(X_{3}, X_{4})\\sum_{X_{5}}f_{d}(X_{4}, X_{5})) \\rightarrow L^{3} + L \\\\\nP(X_{3}) \u0026= (\\sum_{X_{2}}f_{b}(X_{2}, X_{3})\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))(\\sum_{X_{4}}f_{c}(X_{3}, X_{4})\\sum_{X_{5}}f_{d}(X_{4}, X_{5})) \\rightarrow 2L^{2} \\\\\nP(X_{4}) \u0026= (\\sum_{X_{3}}f_{c}(X_{3}, X_{4})\\sum_{X_{2}}f_{b}(X_{2}, X_{3})\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))(\\sum_{X_{5}}f_{d}(X_{4}, X_{5})) \\rightarrow L^{3} + L \\\\\nP(X_{5}) \u0026= \\sum_{X_{4}}f_{d}(X_{4}, X_{5})\\sum_{X_{3}}f_{c}(X_{3}, X_{4})\\sum_{X_{2}}f_{b}(X_{2}, X_{3})\\sum_{X_{1}}f_{a}(X_{1}, X_{2}) \\rightarrow L^{4}\n\\end{align*}\n$$\n\n이것이 끝이 아니다. 우리는 중복된 연산을 별도로 저장해두어서 더 빠른 연산을 수행하는 것도 가능하다. 예를 들어 다음과 같은 과정이라고 할 수 있다.\n\n$$\n\\begin{align*}\nP(X_{2}) \u0026= \\underbrace{(\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))}_{\\red{\\mu_{a\\rightarrow2}(X_{2})}}(\\sum_{X_{3}}f_{b}(X_{2}, X_{3})\\sum_{X_{4}}f_{c}(X_{3}, X_{4})\\sum_{X_{5}}f_{d}(X_{4}, X_{5})) \\\\\nP(X_{3}) \u0026= \\underbrace{(\\sum_{X_{2}}f_{b}(X_{2}, X_{3})\\red{\\mu_{a\\rightarrow2}(X_{2})})}_{\\red{\\mu_{b\\rightarrow3}(X_{3})}}(\\sum_{X_{4}}f_{c}(X_{3}, X_{4})\\sum_{X_{5}}f_{d}(X_{4}, X_{5})) \\\\\nP(X_{4}) \u0026= \\underbrace{(\\sum_{X_{3}}f_{c}(X_{3}, X_{4})\\red{\\mu_{b\\rightarrow3}(X_{3})})}_{\\red{\\mu_{c\\rightarrow4}(X_{4})}}(\\sum_{X_{5}}f_{d}(X_{4}, X_{5})) \\\\\nP(X_{5}) \u0026= \\underbrace{\\sum_{X_{4}}f_{d}(X_{4}, X_{5})\\red{\\mu_{c\\rightarrow4}(X_{4})}}_{\\red{\\mu_{d\\rightarrow5}(X_{5})}}\n\\end{align*}\n$$\n\n![ml-bp-2](/images/ml-bp-2.jpg)\n\n즉, 이전 Marginalization에서 계산했던 $\\mu_{\\text{factor}\\rightarrow\\text{variable}}(X_{\\text{variable}})$를 저장해서, 다음 Marginalization 연산 시에 사용할 수 있기 때문에 전체 Marginalization을 구하는데에도 더 빠른 연산이 가능하다. 이 방식은 역으로 진행하는 것도 가능한데 다음과 같다.\n\n$$\n\\begin{align*}\nP(X_{4}) \u0026= (\\sum_{X_{3}}f_{c}(X_{3}, X_{4})\\sum_{X_{2}}f_{b}(X_{2}, X_{3})\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))\\underbrace{(\\sum_{X_{5}}f_{d}(X_{4}, X_{5}))}_{\\blue{\\mu_{d\\rightarrow4}(X_{4})}} \\\\\nP(X_{3}) \u0026= (\\sum_{X_{2}}f_{b}(X_{2}, X_{3})\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))\\underbrace{(\\sum_{X_{4}}f_{c}(X_{3}, X_{4})\\blue{\\mu_{d\\rightarrow4}(X_{4})})}_{\\blue{\\mu_{c\\rightarrow3}(X_{3})}} \\\\\nP(X_{2}) \u0026= (\\sum_{X_{1}}f_{a}(X_{1}, X_{2}))\\underbrace{(\\sum_{X_{3}}f_{b}(X_{2}, X_{3})\\blue{\\mu_{c\\rightarrow3}(X_{3})})}_{\\blue{\\mu_{b\\rightarrow2}(X_{2})}} \\\\\nP(X_{1}) \u0026= \\underbrace{\\sum_{X_{2}}f_{a}(X_{1}, X_{2})\\blue{\\mu_{b\\rightarrow2}(X_{2})}}_{\\blue{\\mu_{a\\rightarrow1}(X_{1})}}\n\\end{align*}\n$$\n\n![ml-bp-3](/images/ml-bp-3.jpg)\n\n이를 합쳐서 표현하면 다음과 같은 형태를 가지는 것을 알 수 있다.\n\n$$\n\\begin{align*}\nP(X_{1}) \u0026= \\blue{\\mu_{a\\rightarrow1}(X_{1})} \u0026= \\red{\\mu^{-}(X_{1})}\\blue{\\mu^{+}(X_{1})} \\\\\nP(X_{2}) \u0026= \\red{\\mu_{a\\rightarrow2}(X_{2})}\\blue{\\mu_{b\\rightarrow2}(X_{2})}\u0026= \\red{\\mu^{-}(X_{2})}\\blue{\\mu^{+}(X_{2})} \\\\\nP(X_{3}) \u0026= \\red{\\mu_{b\\rightarrow3}(X_{3})}\\blue{\\mu_{c\\rightarrow3}(X_{3})}\u0026= \\red{\\mu^{-}(X_{3})}\\blue{\\mu^{+}(X_{3})} \\\\\nP(X_{4}) \u0026= \\red{\\mu_{c\\rightarrow4}(X_{4})}\\blue{\\mu_{d\\rightarrow4}(X_{4})}\u0026= \\red{\\mu^{-}(X_{4})}\\blue{\\mu^{+}(X_{4})} \\\\\nP(X_{5}) \u0026= \\red{\\mu_{d\\rightarrow5}(X_{5})}\u0026= \\red{\\mu^{-}(X_{5})}\\blue{\\mu^{+}(X_{5})} \\\\\n\u0026\\therefore P(X_{i}) = \\red{\\mu^{-}(X_{i})}\\blue{\\mu^{+}(X_{i})} \\\\\n\\end{align*}\n$$\n\n![ml-bp-4](/images/ml-bp-4.jpg)\n\n$\\mu^{+}$와 $\\mu^{-}$의 방향이 헷갈릴 수 있는데, 이는 자신($X_{i}$)을 기준으로 큰 쪽에서 왔는지 작은 쪽에서 왔는지를 표시한다고 생각하면 쉽다. 따라서, $\\mu$는 다음과 같이 정의되어질 수 있다.\n\n$$\n\\begin{align*}\n\\mu^{-}(X_{1}) \u0026= 1,\\, \\mu^{+}(X_{N}) = 1 \\text{이고,}\\\\\n\\mu^{-}(X_{i}) \u0026= \\sum_{X_{i-1}}f_{i}(i-1, i)\\mu^{-}(X_{i-1}) \\\\\n\\mu^{+}(X_{i}) \u0026= \\sum_{X_{i+1}}f_{i}(i, i+1)\\mu^{+}(X_{i+1}) \\\\\n\\end{align*}\n$$\n\n여기서 $\\mu$가 바로 \u003cmark\u003e**Message**\u003c/mark\u003e를 의미한다. 즉, 우리가 마치 운동장에서 사람 수를 세기 위해서 앞 사람이 말한 수 + 1을 반복하면서 진행하는 것처럼 Message를 전달하며 전체 확률을 구해나가는 것이다. 이러한 방법을 **Message Passing**이라고 하며, 이 방법을 통해서 우리는 Marginal Probability를 더 효과적으로 구할 수 있다. 왜냐하면, $\\mu^{-}(X_{i})$를 구하기 위한 연산량이 $(i-1) \\times L$이라는 것과, $mu^{+}(X_{i})$를 구하기 위한 연산량이 $(N-i) \\times L$이라는 것을 알고 있다. 따라서, 각 각의 Marginalization을 구하기 위한 연산량이 $L^{N-1}$에서 $(N-1)L$로 줄어들었다.\n\n여기까지 우리는 Line으로 되어있는 가장 간단한 Factor Graph에서의 \u003cmark\u003e**Sum-Product Belief Propagation**\u003c/mark\u003e을 알아본 것이다. 이제부터 우리는 더 복잡한 상황에서의 Belief Propagation(BP)을 살펴볼 것이다. Belief Propagation과 Message Passing은 대게 비슷한 의미로 사용되어 진다(일부는 Message Passing 후에 데이터를 가공하는 작업을 분리하고 이를 통합하여 Belief Propagation이라고 하기도 한다.)\n\n### Sum-Product Belief Propagation\n\n합의 곱을 통해서 Marginal Probability를 구하는 방법으로, 앞 서 보았던 Linear Factor Graph 뿐만 아니라 Tree형태의 Factor Graph에서도 사용할 수 있다. 물론 Cycle이 존재하는 Factor Graph가 존재할 수도 있지만, 이 경우에 대해서는 특별한 알고리즘을 별도로 적용하는 것이 일반적이다. 따라서, 여기서는 Tree형태의 Factor Graph에서 일반적으로 적용할 수 있는 방법을 제시한다.\n\n우선 아래 그림을 통해서 대략적인 이해를 해보도록 하자.\n\n![ml-sum-product-bp-1](/images/ml-sum-product-bp-1.jpg)\n\n우리는 위에서 Line Factor Graph에서 어떻게 Marginal Probability를 어떻게 구하는지를 보았다. Tree 구조에서도 동일하게 결국 Marginal Probability를 자신과 이웃한 Factor Node들로 부터 전달된 Message의 곱이라고 할 수 있다. 단지 다른 점은 이웃한 factor가 복수 개라는 것이다.  \n(factor 또는 variable에 해당하는 Node 중에서 index가 i인 Node와 인접한 Node(Node i가 factor라면 variable, variable이라면 factor이다.)들의 index 집합을 $\\mathcal{N}_{i}$ 라고하고, 값은 종류의 Node의 index를 모아둔 집합 I가 있을 때 $X_{I} = \\{X_{i}\\}_{i \\in I}$라고 하자.)\n\n$$\nP(X_{i}) = \\prod_{p \\in \\mathcal{N}_{i}}\\mu_{p \\rightarrow i}(X_{i})\n$$\n\n그렇다면, 여기서 $\\mu_{p \\rightarrow i}(X_{i})$를 각 각 어떻게 구할 수 있을까? 그러기 위해서 빨간색 부분을 자세히 봐보자.\n\n![ml-sum-product-bp-2](/images/ml-sum-product-bp-2.jpg)\n\n여기서도 기존 Linear Factor Graph와 다른 점은 Factor Node역시 여러 개의 Variable Node와 연결된다는 점이다. 이 부분만 떼어서 자세히 보면 다음과 같다.\n\n![ml-sum-product-bp-3](/images/ml-sum-product-bp-3.jpg)\n\n그렇기에 이전 Variable Node로 부터 오는 Message들과 factor 값을 함께 곱하는 과정이 필요하다. 여기서, Varaible Node에서 factor Node로 오는 Message를 $\\nu$라고 정의한다면, 다음과 같이 표현할 수 있다. 여기서 주의할 점은 Factor Node와 이웃한 Variable Node 중에서 Message를 전달할 Variable Node는 연산에서 제외해야 한다는 점이다.\n\n$$\n\\mu_{u \\rightarrow i}(X_{i}) = \\sum_{X_{\\mathcal{N}_{u}\\backslash\\{i\\}}}f_{u}(X_{\\mathcal{N}})\\prod_{j \\in \\mathcal{N}\\backslash\\{i\\}}{\\nu_{j \\rightarrow u}(x_{j})}\n$$\n\n그리고 마지막으로 $\\nu$를 구하는 과정은 다음과 같다.\n\n![ml-sum-product-bp-4](/images/ml-sum-product-bp-4.jpg)\n\n$$\n\\nu_{j \\rightarrow u}(X_{j}) = \\prod_{v \\in \\mathcal{N}_{j}\\backslash\\{u\\}}\\mu_{v \\rightarrow j}(X_{j})\n$$\n\n따라서, Marginal Probability($P(X_{i})$)를 구하고자 할 때 우리는 Leaf Node에서 부터 시작해서 차례차례 값을 구하면서, $\\mu_{\\mathcal{N}_{i} \\rightarrow i}$를 모두 구할 때까지 연산을 수행해야 한다.\n\n```plaintext\n 🤔 Loopy Sum-Product BP\n\n 우리는 Sum-Product BP를 Tree에서만 쓸 수 있다고 제한하였지만, \n 사실 Cycle이 존재하는 Factor Graph에서도 동일한 BP를 사용할 수 있다.\n 하지만, 이 경우에는 비례 관계를 통해서 나타낼 수 밖에 없기 때문에\n 결과값에 대해서 100% 확신할 수는 없다.\n```\n\n### Max Product Belief Propagation\n\nBelief Propagation은 앞 서 살펴보았던 Marginal Probability를 구할 때에도 사용할 수 있지만, Maximization 문제를 풀 때에도 사용할 수 있다. 마찬가지로 가장 간단한 예시인 Linear Factor Graph를 가정해보자.\n\n![ml-bp-1](/images/ml-bp-1.jpg)\n\n$$\nP(X_{1}, X_{2}, X_{3}, X_{4}, X_{5}) = f_{a}(X_{1}, X_{2})f_{b}(X_{2}, X_{3})f_{c}(X_{3}, X_{4})f_{d}(X_{4}, X_{5})\n$$\n\n이 경우에 $P(X_{1}, X_{2}, X_{3}, X_{4}, X_{5})$를 최대로 만드는 $\\hat{x_{1}}, \\hat{x_{2}}, \\hat{x_{3}}, \\hat{x_{4}}, \\hat{x_{5}}$를 찾아보자.  \n\n$$\n\\begin{align*}\n\u0026\\max_{X_{1}, X_{2}, X_{3}, X_{4}, X_{5}} f_{a}(X_{1}, X_{2})f_{b}(X_{2}, X_{3})f_{c}(X_{3}, X_{4})f_{d}(X_{4}, X_{5})\\\\\n\u0026= \\max_{X_{1}}\\{f_{a}(X_{1}, X_{2})\\max_{X_{2}}\\{\\max_{X_{3}}\\{f_{b}(X_{2}, X_{3}) \\max_{X_{4}}\\{f_{c}(X_{3}, X_{4})\\max_{X_{5}}\\{f_{d}(X_{4}, X_{5})\\}\\}\\}\\}\\}\\\\\n\u0026= \\max_{X_{2}}\\{\\max_{X_{1}}\\{f_{a}(X_{1}, X_{2})\\} \\max_{X_{3}}\\{f_{b}(X_{2}, X_{3}) \\max_{X_{4}}\\{f_{c}(X_{3}, X_{4})\\max_{X_{5}}\\{f_{d}(X_{4}, X_{5})\\}\\}\\}\\}\\\\\n\u0026= \\max_{X_{3}}\\{\\max_{X_{2}}\\{f_{b}(X_{2}, X_{3})\\max_{X_{1}}\\{f_{a}(X_{1}, X_{2})\\}\\} \\max_{X_{4}}\\{f_{c}(X_{3}, X_{4})\\max_{X_{5}}\\{f_{d}(X_{4}, X_{5})\\}\\}\\}\\\\\n\u0026= \\max_{X_{4}}\\{\\max_{X_{3}}\\{f_{c}(X_{3}, X_{4})\\max_{X_{2}}\\{f_{b}(X_{2}, X_{3})\\max_{X_{1}}\\{f_{a}(X_{1}, X_{2})\\}\\}\\}\\max_{X_{5}}\\{f_{d}(X_{4}, X_{5})\\}\\}\\\\\n\u0026= \\max_{X_{5}}\\{f_{d}(X_{4}, X_{5})\\max_{X_{4}}\\{\\max_{X_{3}}\\{f_{c}(X_{3}, X_{4})\\max_{X_{2}}\\{f_{b}(X_{2}, X_{3})\\max_{X_{1}}\\{f_{a}(X_{1}, X_{2})\\}\\}\\}\\}\\}\\\\\n\\end{align*}\n$$\n\nMarginalization과 굉장히 유사하다고 하다. 이를 이전에 사용한 Tree 구조에 반영해도 동일하다.\n\n![ml-sum-product-bp-1](/images/ml-sum-product-bp-1.jpg)\n\n단, 여기서 Message와 최종 결과를 다음과 같이 재정의하면 끝난다.\n\n$$\n\\begin{align*}\n\\max P(X_{1}, X_{2}, \\cdots, X_{N}) \u0026= \\max_{X_{i}}\\{\\prod_{p\\in\\mathcal{N}_{i}}\\mu_{p \\rightarrow i}(X_{i})\\} \\\\\n\\mu_{u \\rightarrow i}(X_{i}) \u0026= \\max_{\\mathcal{N}_{u}\\backslash\\{i\\}}\\{f_{u}(\\mathcal{N}_{i})\\prod_{j \\in \\mathcal{N}_{u}\\backslash\\{i\\}}\\nu_{j \\rightarrow u}(X_{j})\\} \\\\\n\\nu_{j \\rightarrow u}(X_{j}) \u0026= \\prod_{v\\in\\mathcal{N}_{j}\\backslash\\{u\\}}\\mu_{v \\rightarrow j}(X_{j})\n\\end{align*}\n$$\n\n추가적으로 Max Sum Belief Propagation을 소개하겠다. 이는 Maximization 문제를 풀 때, $\\log$를 취한 결과도 동일하다는 점을 활용하여 문제를 푸는 것이다. 따라서, 다음과 같이 식이 조금 변화한다. 이 방식을 쓰면, 너무 작은 probability로 인한 문제를 피할 수 있다.\n\n$$\n\\begin{align*}\n\\max \\red{\\log} P(X_{1}, X_{2}, \\cdots, X_{N}) \u0026= \\max_{X_{i}}\\{\\red{\\sum_{p\\in\\mathcal{N}_{i}}}\\mu_{p \\rightarrow i}(X_{i})\\} \\\\\n\\mu_{u \\rightarrow i}(X_{i}) \u0026= \\max_{\\mathcal{N}_{u}\\backslash\\{i\\}}\\{\\red{\\log} f_{u}(\\mathcal{N}_{i}) + \\red{\\sum_{j \\in \\mathcal{N}_{u}\\backslash\\{i\\}}}\\nu_{j \\rightarrow u}(X_{j})\\} \\\\\n\\nu_{j \\rightarrow u}(X_{j}) \u0026= \\red{\\sum_{v\\in\\mathcal{N}_{j}\\backslash\\{u\\}}}\\mu_{v \\rightarrow j}(X_{j})\n\\end{align*}\n$$\n\n## Construction from Data\n\n앞에서는 Graph를 통해서 연산 과정을 Optimization하는 방법을 알아보았다면, 여기서는 실제 관측 data를 이용해서 어떻게 Graph를 구조화할 수 있는지에 대해서 알아볼 것이다. 이를 수행하기 위해 많은 Algorithm이 존재하지만 가장 기본이 될 수 있는 Algorithm인 **Chow-Liu Algorithm**만 살펴보도록 하겠다.\n\n### Chow-Liu Algorithm\n\n제일 먼저 구해야할 것은 **Joint Probability**이다. 이는 Empirical distribution을 이용하여 구할 수 있다. 아래는 feature가 N개인 총 K개의 data가 있을 때, 다음과 같이 **Joint Probability**를 구한 것이다.\n\n$$\np(X_{1}=x_{1}, X_{2}=x_{2}, \\cdots, X_{N}=x_{n}) = \\frac{1}{K} \\sum_{k=1}^{K} \\mathbb{1}[x^{(k)}=(x_{1}, x_{2}, \\cdots, x_{n})]\n$$\n\n위와 같이 **Joint Probability**가 주어졌을 때, **Chow-Liu Algorithm**에서는 **Second Order Conditional Probability**(총 두개의 Random Variable로 구성된 Conditional Probability. 즉, Condtion도 하나이고, 확률을 구하고자 하는 변수도 하나이다.)와 **Marginal Probability**로 Graph를 가정하고 **Bayesian Network**를 구성한다. 이 경우에는 형태가 Tree 형태로 만들어지기 때문에 결론적으로 head-to-head 관계가 만들어지지 않는다.(각 각의 node는 하나의 parent만 갖기 때문이다.)\n\n![ml-chow-liu-1](/images/ml-chow-liu-1.jpg)\n\n따라서, 위와 같은 Graph로 추정했다면, 확률은 다음과 같아진다.\n\n$$\np(x_{1}, x_{2}, \\cdots, x_{n}) = p(x_{6}|x_{5})p(x_{5}|x_{2})p(x_{4}|x_{2})p(x_{3}|x_{2})p(x_{2}|x_{1})p(x_{1})\n$$\n\n여기서 이제 우리는 다음과 같은 문제만 풀면 끝이다. Empirical distribution으로 구한 Joint Probability($p$)와 우리가 추정한 Graph에서의 Joint Probability($p_{\\intercal}$)사이의 차이가 최소가 되도록 하면 된다. 이를 위해서 사용하는 것이 **KL Divergence**이다. 따라서, 우리가 구하고 싶은 **Bayesian Network**는 다음과 같이 구할 수 있다.\n\n$$\n\\argmin_{\\intercal\\text{:tree}} KL(p||p_{\\intercal})) = \\argmin_{\\intercal\\text{:tree}} \\sum_{x^{(k)} \\in \\mathcal{D}}p(x^{(k)})\\log \\frac{p(x^{(k)})}{p_{\\intercal}(x^{(k)})}\n$$\n\n그렇다면, 좀 더 면밀하게 $p_{\\intercal}$을 정의해보자.\n\n$$\n\\begin{align*}\np_{\\intercal}(x_{1}, x_{2}, \\cdots, x_{N}) \u0026= \\prod_{i=1}^{N}p(x_{i}|x_{\\text{parent}(i)})\\, (\\because \\text{Bayesian Network Definition})\\\\\n\u0026= p(x_{root})\\prod_{(i,j) \\in E}p(x_{j}|x_{i})\n\\end{align*}\n$$\n\n여기서 V는 node의 집합을 의미하고, E는 edge를 저장하며 각 tuple(i,j)는 (parent, child)를 의미한다. 그리고, Tree에서는 단 하나의 Node만 Root이고 parent가 없기 때문에 해당 Root만 marginal Probability를 가지는 것을 알 수 있다.\n\n$$\n\\begin{align*}\np_{\\intercal}(x_{1}, x_{2}, \\cdots, x_{N}) \u0026= p(x_{root})\\prod_{(i,j) \\in E}p(x_{j}|x_{i})\\\\\n\u0026= p(x_{root})\\prod_{(i,j) \\in E} \\frac{p(x_{j},x_{i})}{p(x_{i})}\\\\\n\u0026= \\red{p(x_{root})}\\prod_{(i,j) \\in E} \\frac{p(x_{j},x_{i})\\red{p(x_{j})}}{p(x_{i})p(x_{j})}\\\\\n\u0026= \\prod_{i\\in V}p(x_{i}) \\prod_{(i,j) \\in E} \\frac{p(x_{j},x_{i})}{p(x_{i})p(x_{j})}\\\\\n\\end{align*}\n$$\n\n마지막이 좀 애매할 수 있는 tree이기 때문에 가능한 것이다. 특정 node로 가는 path는 단 하나이기 때문에 $j$로 끝나는 edge도 하나일 수 밖에 없다. 따라서, $p(x_{root})\\prod_{(i,j) \\in E} p(x_{j}) = \\prod_{i=V}p(x_{i})$일 수 있는 것이다.\n\n이것이 정의되면, 우리는 이제 최적의 Tree인 $\\intercal_{*}$를 찾을 수 있다.\n\n$$\n\\begin{align*}\n\\intercal_{*} \u0026= \\argmin_{\\intercal\\text{:tree}} KL(p||p_{\\intercal})\\\\\n\u0026= \\argmin_{\\intercal\\text{:tree}} \\sum_{x^{(k)} \\in \\mathcal{D}}p(x^{(k)})\\log \\frac{p(x^{(k)})}{p_{\\intercal}(x^{(k)})}\\\\\n\u0026= \\argmin_{\\intercal\\text{:tree}} \\sum_{x^{(k)} \\in \\mathcal{D}}\\cancel{p(x^{(k)})\\log{p(x^{(k)})}} -p(x^{(k)})\\log{p_{\\intercal}(x^{(k)})}\\\\\n\u0026= \\argmax_{\\intercal\\text{:tree}} \\sum_{x^{(k)} \\in \\mathcal{D}}p(x^{(k)})\\log{p_{\\intercal}(x^{(k)})}\\\\\n\u0026= \\argmax_{\\intercal\\text{:tree}} \\sum_{x^{(k)} \\in \\mathcal{D}}p(x^{(k)})\\log({\\prod_{i\\in V}p(x_{i}^{(k)}) \\prod_{(i,j) \\in E} \\frac{p(x_{j}^{(k)},x_{i}^{(k)})}{p(x_{i}^{(k)})p(x_{j}^{(k)})}})\\\\\n\u0026= \\argmax_{\\intercal\\text{:tree}} \\sum_{x^{(k)} \\in \\mathcal{D}}\\sum_{i\\in V}p(x^{(k)})\\log(p(x_{i}^{(k)})) + \\sum_{x^{(k)} \\in \\mathcal{D}}\\sum_{(i,j) \\in E} p(x^{(k)})\\log({\\frac{p(x_{j}^{(k)},x_{i}^{(k)})}{p(x_{i}^{(k)})p(x_{j}^{(k)})}})\\\\\n\u0026= \\argmax_{\\intercal\\text{:tree}} \\sum_{i\\in V}\\sum_{x^{(k)} \\in \\mathcal{D}}p(x^{(k)})\\log(p(x_{i}^{(k)})) + \\sum_{(i,j) \\in E}\\sum_{x^{(k)}_{i}, x^{(k)}_{j}} p(x^{(k)}_{i}, x^{(k)}_{j})\\log({\\frac{p(x_{j}^{(k)},x_{i}^{(k)})}{p(x_{i}^{(k)})p(x_{j}^{(k)})}})\\, (\\because \\text{marginalization})\\\\\n\u0026= \\argmax_{\\intercal\\text{:tree}} \\cancel{\\sum_{i\\in V}-H(X_{i})} + \\sum_{(i,j) \\in E}I(X_{i}, X_{j})\\, (\\because H(X_{i})\\text{는 constant이다.})\\\\\n\u0026= \\argmax_{\\intercal\\text{:tree}}\\sum_{(i,j) \\in E}I(X_{i}, X_{j})\\\\\n\\end{align*}\n$$\n\n마지막 marginalization은 헷갈린다면, 해당 Posting의 Sum-Product BP 부분을 다시 보고오도록 하자.\n\n자, 이제 우리가 얻은 결론은 다음과 같다. 결국, 최적의 Tree는 $I(X_{i}, X_{j})$가 최대가 되는 Tree이다. I(Mutual Information)이 헷갈린다면, [Information Theory](/posts/ml-base-knowledge#Information-Theory) 정리해놓은 Posting을 다시 보고 오자. 결국, $X_{i}, X_{j}$간의 모든 Mutual Information을 구해서 weighted graph를 구축한다음에 Kruskal Algorithm을 통해서 최적 Tree를 찾으면 되는 것이다.\n\n따라서, 과정은 다음과 같다.\n\n1. 가능한 모든 (i,j) 쌍에 대하여 $I(X_{i}, X_{j})$를 구하여, Weighted Graph를 구성한다.\n2. Kruskal Algorithm을 수행한다.\n   1. weight의 내림차순으로 Edge를 정렬한다.\n   2. 하나씩 Edge를 뽑으면서, Cycle이 생기는지 확인하여 생기면 버리고, Cycle이 생기지 않으면 Tree에 추가한다.(Cycle 여부는 동일한 Node가 두 개 다 존재하는지 확인)\n   3. 모든 Node를 뽑았다면 종료하고, 그렇지 않다면 2번을 반복 시행한다.\n\n이렇게 Graph를 만들게 되면, 우리는 Joint Probability를 이전에 배운 Optimization 방법을 통해서 쉽게 구할 수 있다. 그리고, 이를 Model에 직접 적용할 수 있다. 예를 들면, 우리가 Classification을 수행할 때이다.\n\n$$\n\\argmax_{\\mathcal{l} \\in \\{0,1,2,\\cdots, 9\\}} p_{\\mathcal{l}} \\times p(x^{\\text{new}}|\\mathcal{l}^{\\text{new}}=\\mathcal{l}) \\propto \\argmax_{\\mathcal{l} \\in \\{0,1,2,\\cdots, 9\\}} p_{\\mathcal{l}} \\times p_{\\intercal}(x^{\\text{new}})\n$$\n\n위와 같이 추정하여 계산을 획기적으로 줄일 수 있다.\n\n## Reference\n\n- Tumbnail : Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=unsplash\u0026utm_medium=referral\u0026utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@markuswinkler?utm_source=unsplash\u0026utm_medium=referral\u0026utm_content=creditCopyText)\n- Medium[Chullin], Graphical Model이란 무엇인가요?, \u003chttps://medium.com/@chullino/graphical-model%EC%9D%B4%EB%9E%80-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80%EC%9A%94-2d34980e6d1f\u003e\n- Wiki, Markov Random Field, \u003chttps://en.wikipedia.org/wiki/Markov_random_field\u003e\n- Adaptive Computation and Machine Learning, Thomas G. Dietterich\n- \u003chttps://cedar.buffalo.edu/~srihari/CSE574/Chap8/Ch8-PGM-Inference/Ch8.3.2-FactorGraphs.pdf\u003e\n","slug":"ml-graphical-model","date":"2022-11-14 13:08","title":"[ML] 8. Graphical Model","category":"AI","tags":["ML","GraphicalModel","ConditionalIndependence","MarkovRandomField","BayesianNetwork","FactorGraph","D-Seperation","Factorization","MarkovProperty","MessagePassing","BeliefPropagation","Chow-LiuAlgorithm"],"desc":"Machine Learning은 주어진 data를 가장 잘 설명할 수 있는 pattern(Model)을 찾는 것이 목표라고 하였다. 그렇다면, \"data가 가지는 여러가지 정보(feature)들 중에서 어떤 feature를 중점적으로 보고 이용할 수 있을까?\" 그리고, \"만약 여러 feature들이 서로 연관이 있다면 이를 연산의 최적화를 위해 이용할 수 있지 않을까?\" 라는 접근이 가능하다. 여기서 Graphical Model은 이러한 관계를 시각적으로 표현할 수 있으며, 이를 통해서 연산 최적화에 대한 insight를 얻을 수 있다.","thumbnailSrc":"https://euidong.github.io/images/ml-thumbnail.jpg"}],"params":{"subject":"Factorization"}},"__N_SSG":true},"page":"/tags/[subject]","query":{"subject":"Factorization"},"buildId":"JTjNvUb3F58nrRICrLlJh","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>