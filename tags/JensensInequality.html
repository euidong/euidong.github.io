<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="initial-scale=1.0, width=device-width"/><meta property="og:type" content="blog"/><meta property="og:site_name" content="JustLog"/><meta property="og:image" content="https://euidong.github.io/logo192.png"/><title>#JensensInequality | JustLog</title><meta name="description" content="#JensensInequality 관련 Posting"/><meta property="og:description" content="#JensensInequality 관련 Posting"/><meta property="og:title" content="#JensensInequality | JustLog"/><link rel="canonical" href="https://euidong.github.io/tags/JensensInequality"/><meta property="og:url" content="https://euidong.github.io/tags/JensensInequality"/><meta name="next-head-count" content="11"/><link rel="icon" href="https://euidong.github.io/favicon.png"/><link rel="apple-touch-icon" href="https://euidong.github.io/logo192.png"/><link rel="preload" href="/_next/static/css/d4ec5c8b3df09443.css" as="style"/><link rel="stylesheet" href="/_next/static/css/d4ec5c8b3df09443.css" data-n-g=""/><link rel="preload" href="/_next/static/css/6dc16d084a5153e5.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6dc16d084a5153e5.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js" id="Adsense-id" data-ad-client="ca-pub-7452732177557701" async="" defer="" data-nscript="beforeInteractive"></script><script src="/_next/static/chunks/webpack-9b312e20a4e32339.js" defer=""></script><script src="/_next/static/chunks/framework-81da43a8dcd978d9.js" defer=""></script><script src="/_next/static/chunks/main-7b6c38cbad60dfcf.js" defer=""></script><script src="/_next/static/chunks/pages/_app-8d9b43c3d8042477.js" defer=""></script><script src="/_next/static/chunks/675-ae8e8a351ce30ae2.js" defer=""></script><script src="/_next/static/chunks/pages/tags/%5Bsubject%5D-0fc8f67b45fbbd0f.js" defer=""></script><script src="/_next/static/6SENXQ_RcGFHETqFmw7p-/_buildManifest.js" defer=""></script><script src="/_next/static/6SENXQ_RcGFHETqFmw7p-/_ssgManifest.js" defer=""></script><script src="/_next/static/6SENXQ_RcGFHETqFmw7p-/_middlewareManifest.js" defer=""></script></head><body><div id="__next"><div class="Layout_wrapper__dKJSz root"><header class="Layout_header__XosLl" style="position:static"><div><button tabindex="1" class="SideBarToggler_search_bar_toggler__CEuUg"><svg stroke="currentColor" fill="none" stroke-width="0" viewBox="0 0 24 24" height="35px" width="35px" xmlns="http://www.w3.org/2000/svg"><path d="M2 6C2 5.44772 2.44772 5 3 5H21C21.5523 5 22 5.44772 22 6C22 6.55228 21.5523 7 21 7H3C2.44772 7 2 6.55228 2 6Z" fill="currentColor"></path><path d="M2 12.0322C2 11.4799 2.44772 11.0322 3 11.0322H21C21.5523 11.0322 22 11.4799 22 12.0322C22 12.5845 21.5523 13.0322 21 13.0322H3C2.44772 13.0322 2 12.5845 2 12.0322Z" fill="currentColor"></path><path d="M3 17.0645C2.44772 17.0645 2 17.5122 2 18.0645C2 18.6167 2.44772 19.0645 3 19.0645H21C21.5523 19.0645 22 18.6167 22 18.0645C22 17.5122 21.5523 17.0645 21 17.0645H3Z" fill="currentColor"></path></svg></button><nav class="SideBar_side_bar__wrapper--close__8Nwnr"><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/">Home</a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/tags">Tags</a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/Algorithm">Algorithm<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->11<!-- -->)<!-- --></span></a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/Computer%20Architecture">Computer Architecture<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->7<!-- -->)<!-- --></span></a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/Tech">Tech<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->17<!-- -->)<!-- --></span></a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/Web">Web<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->4<!-- -->)<!-- --></span></a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/Paper">Paper<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->2<!-- -->)<!-- --></span></a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/Network">Network<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->11<!-- -->)<!-- --></span></a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/AI">AI<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->20<!-- -->)<!-- --></span></a><a class="SideBar_side_bar__li__crDBH" tabindex="-1" href="/categories/Memoir">Memoir<!-- --><span class="SideBar_side_bar__li__cnt__9QV_z">(<!-- -->1<!-- -->)<!-- --></span></a></nav></div><a class="Logo_logo___yD0t" tabindex="1" href="/"></a><div><button class="SearchBarToggler_search_bar_toggler__3dHbA" tabindex="2"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="25px" width="25px" xmlns="http://www.w3.org/2000/svg"><path d="M11.742 10.344a6.5 6.5 0 1 0-1.397 1.398h-.001c.03.04.062.078.098.115l3.85 3.85a1 1 0 0 0 1.415-1.414l-3.85-3.85a1.007 1.007 0 0 0-.115-.1zM12 6.5a5.5 5.5 0 1 1-11 0 5.5 5.5 0 0 1 11 0z"></path></svg></button></div></header><section><div class="RowCard_row_card__list__background___xFj5"><h1 class="RowCard_row_card__list__title__t4a2h"> Jensens Inequality</h1><label class="RowCard_row_card__list__select__wrapper__TZ4_9"><select class="RowCard_row_card__list__select__dxkxA"><option class="RowCard_row_card__list__select__option__GRKZU">최신순<!-- --></option><option class="RowCard_row_card__list__select__option__GRKZU">AtoZ<!-- --></option><option class="RowCard_row_card__list__select__option__GRKZU">ZtoA<!-- --></option></select></label><ul class="RowCard_row_card__list__wrapper__5Gtgi"><div class="RowCard_row_card__wrapper__kohuv"><a class="RowCard_row_card__thumbnail__wrapper__bedY4" href="/posts/ml-em-algorithm"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:200px;height:200px;background:none;opacity:1;border:0;margin:0;padding:0;position:relative"><img alt="[ML] 10. EM Algorithm" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fixed" class="RowCard_row_card__thumbnail__Dh_84" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="[ML] 10. EM Algorithm" srcSet="https://euidong.github.io/images/ml-thumbnail.jpg?imwidth=256 1x, https://euidong.github.io/images/ml-thumbnail.jpg?imwidth=640 2x" src="https://euidong.github.io/images/ml-thumbnail.jpg?imwidth=640" decoding="async" data-nimg="fixed" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" class="RowCard_row_card__thumbnail__Dh_84" loading="lazy"/></noscript></span></a><div class="RowCard_row_card__tray__trcA5"><a class="RowCard_row_card__tray__title__lVniM" tabindex="-1" href="/posts/ml-em-algorithm">[ML] 10. EM Algorithm</a><div class="RowCard_row_card__tray__date__3cY_j">2022년 11월 24일 20시 15분</div><ul class="RowCard_row_card__tray__tag__qXmOl"><a class="RowCard_row_card__tray__tag__li__7_3Zt" tabindex="-1" href="/tags/ML"># <!-- -->ML<!-- --></a><a class="RowCard_row_card__tray__tag__li__7_3Zt" tabindex="-1" href="/tags/EM-Algorithm"># <!-- -->EM-Algorithm<!-- --></a><a class="RowCard_row_card__tray__tag__li__7_3Zt" tabindex="-1" href="/tags/JensensInequality"># <!-- -->JensensInequality<!-- --></a><a class="RowCard_row_card__tray__tag__li__7_3Zt" tabindex="-1" href="/tags/GibbsInequality"># <!-- -->GibbsInequality<!-- --></a></ul></div></div></ul></div></section><footer class="Layout_footer__EL5v8"><div class="Layout_footer__copyright__r5baC"><span>Copyright © euidong</span><br/><span>모든 컨텐츠에 대한 저작권은 작성자에게 존재합니다. <!-- --><br/>불법 복제를 통한 상업적 사용을 절대적으로 금지합니다. <!-- --><br/>단, 비상업적 이용의 경우 출처 및 링크를 적용한다면 자유롭게 사용가능 합니다.<!-- --></span><span>Also I use photos by<!-- --> <!-- --><a href="https://unsplash.com/@lorenzoherrera?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" tabindex="-1">Lorenzo Herrera</a> <!-- -->on<!-- --> <!-- --><a href="https://unsplash.com/s/photos/tech?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" tabindex="-1">Unsplash</a></span></div><div class="Layout_footer__contents__YZWSm"><a class="Layout_footer__contents__link__K_TKH" href="https://github.com/euidong" target="_blank" rel="noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="60" width="60" xmlns="http://www.w3.org/2000/svg"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path></svg><span>github</span></a><a class="Layout_footer__contents__link__K_TKH" href="https://euidong.github.io/portfolio" target="_blank" rel="noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="60" width="60" xmlns="http://www.w3.org/2000/svg"><path d="M6 8a3 3 0 1 0 0-6 3 3 0 0 0 0 6zm-5 6s-1 0-1-1 1-4 6-4 6 3 6 4-1 1-1 1H1zM11 3.5a.5.5 0 0 1 .5-.5h4a.5.5 0 0 1 0 1h-4a.5.5 0 0 1-.5-.5zm.5 2.5a.5.5 0 0 0 0 1h4a.5.5 0 0 0 0-1h-4zm2 3a.5.5 0 0 0 0 1h2a.5.5 0 0 0 0-1h-2zm0 3a.5.5 0 0 0 0 1h2a.5.5 0 0 0 0-1h-2z"></path></svg><span>portfolio</span></a><a class="Layout_footer__contents__link__K_TKH" href="https://chrome.google.com/webstore/detail/bonfire/nkooidijgbppkojdgkoafcoppnohdfka?hl=ko" target="_blank" rel="noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" version="1.1" viewBox="0 0 16 16" height="60" width="60" xmlns="http://www.w3.org/2000/svg"><path d="M5.016 16c-1.066-2.219-0.498-3.49 0.321-4.688 0.897-1.312 1.129-2.61 1.129-2.61s0.706 0.917 0.423 2.352c1.246-1.387 1.482-3.598 1.293-4.445 2.817 1.969 4.021 6.232 2.399 9.392 8.631-4.883 2.147-12.19 1.018-13.013 0.376 0.823 0.448 2.216-0.313 2.893-1.287-4.879-4.468-5.879-4.468-5.879 0.376 2.516-1.364 5.268-3.042 7.324-0.059-1.003-0.122-1.696-0.649-2.656-0.118 1.823-1.511 3.309-1.889 5.135-0.511 2.473 0.383 4.284 3.777 6.197z"></path></svg><span>chat</span></a></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"content":"\n## Intro\n\n주어지는 data에 항상 feature, label이 정확하게 매칭되지는 않는다. 이럴 경우 우리는 각 data에 대한 label과 주어진 data와 label을 잘 설명할 수 있는 probability distribution을 모두 구해야 한다. 여기서 label과 probability distribution을 동시에 구하기 위해서는 어떻게 해야할지에 대한 방법 중에서 대표적인 EM Algorithm에 대해서 살펴보도록 하겠다.\n\n## Problem\n\n여태까지 우리가 살펴봤던 supervised learning에서는 학습(learning) 시에는 feature와 label이 모두 동시에 주어지고, 예측/추론(inference)을 수행할 때에는 feature만 존재하는 data가 주어졌다. 따라서, 학습 시에 feature 정보들을 특정 pattern에 녹여냈을 때, label값을 얻는지를 확인할 수 있었다. 하지만, label이 주어지지 않은 data를 학습시킬 때에는 어떻게 해야할까? 우리는 label이 있어야 해당 data가 가진 실제 결과값을 알고 probability distribution을 얼마나 수정할지를 알 수 있었다. 하지만, 이 값을 모르니 probability distribution을 만들 수 없다. 정확한 probability distribution이 있다면, 반대로 label을 생성하는 것도 가능할 것이다. 하지만, 우리는 아무것도 알 수 없다.\n\n이렇게 답답한 상황에서 우리는 다음과 같은 아이디어를 발상해낼 수 있다. 만약, 대략적인 label을 안다면, 이것을 이용해서 최적의 확률 분포를 찾고, 이 확률 분포에 맞는 label을 다시 생성하고 이를 기반으로 다시 확률 분포를 찾는다면 어떨까? 이렇게 반복하면 꽤나 그럴싸한 분포를 만들 수 있지 않을까? 이 과정을 예를 들자면, 다음과 같다.\n\n각 기 다른 나라(label)의 동전 3종류(500원, 100cent, 100엔)를 구분하고 싶다고 하자. 이때, 알 수 있는 정보는 무게(feature) 밖에 없다고 가정하겠다. 이때 우리는 어떻게 구분할 수 있을까? 우리가 길 거리에서 무작위로 동전을 수집했다고 하자. 각 동전은 흠집도 있을 것이고 공장마다 조금씩 무게가 차이있을 수 있다. 그 결과 다음과 같은 분포가 나왔다고 하자.\n\n![ml-em-algorithm-1](/images/ml-em-algorithm-1.jpg)\n\n그래서 우리는 확률 분포가 아마 Gaussian distribution이라고 생각할 것이다. 따라서, 임의의 Gaussian Distribution을 따르는 세 개의 분포를 아래와 같이 가정해보는 것이다.\n\n![ml-em-algorithm-2](/images/ml-em-algorithm-2.jpg)\n\n그렇다면, 우리는 이 분포에 따라 가장 적절한 label을 생성할 수 있다. 아래와 같이 생성할 수 있다.\n\n![ml-em-algorithm-3](/images/ml-em-algorithm-3.jpg)\n\n그러면 결과적으로 우리는 다음과 같은 label된 data를 갖게 되는 것이다.\n\n![ml-em-algorithm-4](/images/ml-em-algorithm-4.jpg)\n\n이렇게 labeling data를 이용해서 우리는 더 효과적인 확률 분포 변수를 찾아보면 아래와 같이 이전과는 사뭇 다른 분포를 가진다는 것을 알 수 있다.\n\n![ml-em-algorithm-5](/images/ml-em-algorithm-5.jpg)\n\n결과적으로 해당 분포가 이전에 임의로 추정했던 분포보다 더 적절하다는 것을 알 수 있다. 이 과정을 계속해서 반복하면 어떻게 될까?\n\n![ml-em-algorithm-6](/images/ml-em-algorithm-6.jpg)\n\n반복을 통해서 우리는 그럴싸한 확률분포를 습득했다. 대략 머릿속으로는 그럴 수 있을 것 같다는 생각이 들 것이다. 그렇다면, 이것이 어떻게 가능하며 수학적으로 표현이 가능할까? 이를 이제부터 자세히 알아보도록 하겠다.\n\n## Base Knowledge\n\n본론으로 들어가기에 앞 서 우리는 두 가지 정의를 알아야 EM Algorithm을 증명하고 설명할 수 있다.\n\n1. Jensen’s Inequality\n2. Gibb's Inequality\n\n이 두 가지를 모두 안다면 바로 다음으로 넘어가는 것이 좋다. 하지만, 알지 못한다면 이 정의에 대해서 먼저 알아보고 가도록 하자.\n\n### Jensen’s Inequality\n\n일반적으로 우리는 다음 성질을 만족하는 집합을 Convex set이라고 한다.\n\n$$\n\\lambda x + (1-\\lambda)y \\in C,\\quad \\forall x, y \\in C \\text{ and } \\forall\\lambda\\in[0,1]\n$$\n\n즉, 집합에서 random으로 고른 두 수 사이의 수도 집합에 포함되는 집합이라는 것이다. convex set이라고 불리는 이유는 결국 이러한 집합을 2, 3 차원상에 그려보면 볼록하게 튀어나오는 형태라는 것을 알 수 있기 때문이다.\n\n또한, 아래와 같은 조건을 만족하는 함수(f)를 Convex function이라고 한다.\n\n$$\nf(\\lambda x + (1-\\lambda)y) \\leq \\lambda f(x) + (1-\\lambda)f(y),\\quad \\forall x,y \\in C(\\text{Convex set}) \\text{ and } \\forall\\lambda \\in [0,1]\n$$\n\n아래로 볼록한 함수에서는 위와 같은 과정이 너무나 당연하게도 성립한다. 사잇값의 함수값보다 함수값의 사잇값이 더 크기 때문이다.\n\n![ml-convex-function](/images/ml-convex-function.jpg)\n\n반대로 concave(위로 볼록) 함수인 경우에는 반대로 다음과 같이 정의된다.\n\n$$\nf(\\lambda x + (1-\\lambda)y) \\geq \\lambda f(x) + (1-\\lambda)f(y),\\quad \\forall x,y \\in C(\\text{Convex set}) \\text{ and } \\forall\\lambda \\in [0,1]\n$$\n\n여기서 Jensen's Inequality는 다음과 같은 수식이 convex에서 성립한다는 것이다.\n\n$$\nE[f(X)] \\geq f(E[X])\n$$\n\nconvex function에서는 어찌보면 당연해보인다. 그렇지만 이는 EM Algorithm에서 토대로 사용되는 아이디어이기 때문에 반드시 기억하자. 반대로 Concave function인 경우에는 다음과 같다.\n\n$$\nE[f(X)] \\leq f(E[X])\n$$\n\n### Gibb's Inequality\n\nKL divergence 식에 Jensen's Inequality를 적용하여 KL divergence가 항상 0보다 크거나 같고, KL divergence가 0이 되기 위해서는 두 확률분포가 같아야 한다는 것을 증명한 것이다.\n\n이에 대한 증명을 간단하게 하면 다음과 같다.\n\n$$\n\\begin{align*}\nKL(p||q) \u0026= \\sum_{i}{p_{i}\\log\\frac{p_{i}}{q_{i}}} \\\\\n\u0026= -\\sum_{i}p_{i}\\log{\\frac{q_{i}}{p_{i}}} \\\\\n\u0026= E_{p}[-\\log{\\frac{q_{i}}{p_{i}}}] \\geq -\\log{E_{p}[\\frac{q_{i}}{p_{i}}]}\\, (\\because \\text{Jensen's Inequality}) \\\\\n\u0026= -\\log{\\sum_{i}p_{i}\\frac{q_{i}}{p_{i}}} = -\\log{1} = 0\\\\\n\\therefore KL(p||q) \u0026\\geq 0\n\\end{align*}\n$$\n\n## EM Algorithm\n\n우리는 parametric estimation 방법을 사용하기 위해서 다음과 같은 Likelihood를 계산했다.\n\n$$\n\\begin{align*}\n\\mathcal{L}(\\theta) \u0026= \\log p(D| \\theta) \\\\\n\\mathcal{L}(\\theta) \u0026= \\log \\prod_{x\\in D} p(x| \\theta) \\\\\n\u0026= \\sum_{x\\in D} \\log{p(x|\\theta)}\n\\end{align*}\n$$\n\n그렇지만 우리가 이 값을 구하는 것이 어렵다는 것을 위에서 제시했다. 따라서, 이를 다음과 같이 바꿔서 풀어보자는 것이다.\n\n$$\n\\begin{align*}\n\\mathcal{L}(\\theta) \u0026= \\sum_{x\\in D} \\log{p(x|\\theta)} \\\\\n\u0026= \\sum_{x\\in D} \\log{\\int_{z \\in K}p(x, z|\\theta)} dz\n\\end{align*}\n$$\n\n이렇게 바꾸게 된다고 무슨 이득이 있을까? 단순히 식이 더 복잡해보인다. 하지만, 이 식을 다음과 같이 바꿀 수 있다.\n\n$$\n\\begin{align*}\n\\mathcal{L}(\\theta) \u0026= \\sum_{x\\in D} \\log{p(x|\\theta)} \\\\\n\u0026= \\sum_{x\\in D} \\log{\\int_{z \\in K} p(x, z|\\theta)} dz \\\\\n\u0026= \\sum_{x\\in D} \\log{\\int_{z \\in K} p(x, z|\\theta) \\frac{p(z|x, \\theta^{\\prime})}{p(z| x, \\theta^{\\prime})} dz} \\\\\n\u0026= \\sum_{x\\in D} \\log{\\int_{z \\in K} p(z|x, \\theta^{\\prime}) \\frac{p(x, z|\\theta)}{p(z| x, \\theta^{\\prime})} dz} \\\\\n\u0026= \\sum_{x\\in D} \\log{E_{z|x, \\theta^{\\prime}}{[\\frac{p(x, z|\\theta)}{p(z| x, \\theta^{\\prime})}]}} \\geq \\sum_{x\\in D} E_{z|x, \\theta^{\\prime}}{[\\log{\\frac{p(x, z|\\theta)}{p(z| x, \\theta^{\\prime})}}]}\\,(\\because \\text{Jensen's Inequality}) = \\mathcal{F}(p_{z|x, \\theta^{\\prime}}, \\theta)\n\\end{align*}\n$$\n\n이를 통해서 우리는 아래와 같은 과정을 수행해볼 수 있다.\n\n$$\n\\begin{align*}\n\\mathcal{L}(\\theta) - \\mathcal{F}(p_{z|x, \\theta^{\\prime}}, \\theta) \u0026= \\sum_{x\\in D} \\log{p(x|\\theta)} - \\sum_{x\\in D}\\{\\int_{z|x, \\theta^{\\prime}}{p(z|x,\\theta^{\\prime})\\log{\\frac{p(x, z|\\theta)}{p(z| x, \\theta^{\\prime})}}}\\} \\\\\n\u0026= \\sum_{x\\in D} \\log{p(x|\\theta)} - \\sum_{x\\in D}\\{\\int_{z|x, \\theta^{\\prime}}{p(z|x,\\theta^{\\prime})\\log{\\frac{p(z|x, \\theta)p(x|\\theta)}{p(z| x, \\theta^{\\prime})}}}\\} \\\\\n\u0026= \\sum_{x\\in D} \\log{p(x|\\theta)} - \\sum_{x\\in D}\\{\\int_{z|x, \\theta^{\\prime}}{p(z|x,\\theta^{\\prime})\\log{p(x|\\theta)}} + \\int_{z|x, \\theta^{\\prime}}{p(z|x,\\theta^{\\prime})\\log{\\frac{p(z|x, \\theta)}{p(z| x, \\theta^{\\prime})}}}\\} \\\\\n\u0026= \\sum_{x\\in D}\\{\\int_{z|x, \\theta^{\\prime}}{p(z|x,\\theta^{\\prime})\\log{\\frac{p(z|x, \\theta^{\\prime})}{p(z| x, \\theta)}}}\\} \\\\\n\u0026= \\sum_{x\\in D}{KL(p_{z|x, \\theta^{\\prime}}, p_{z|x, \\theta})}\n\\end{align*}\n$$\n\n우리가 원하는 것은 결국 해당 값의 minization이다. 따라서, 우리는 모든 $x$에 대해서 KL-divergence의 최솟값을 구해야 한다(모든 사건은 독립이기 때문이다). KL-divergence는 0과 같거나 큰 수이고, KL-divergence는 $p_{z|x, \\theta^{\\prime}} = p_{z|x, \\theta}$일 때, 0이므로 이를 만족할 수 있는 값을 찾는 것이 중요하다.\n\n따라서, 우리는 다음과 같은 insight를 얻을 수 있다.\n\n1. $\\mathcal{F}(p_{z|x, \\theta^{(t-1)}}, \\theta^{(t)}) \\leq \\mathcal{L}(\\theta^{(t)})$ 아래 식에 의해서 이를 증명할 수 있다.  \n   $\\mathcal{F}(p_{z|x, \\theta}, \\theta^{(t)}) \\leq \\mathcal{L}(\\theta^{(t)}) (\\because \\text{Jensen's Inequality})$\n2. $\\mathcal{L}(\\theta^{(t)}) = \\mathcal{F}(p_{z|x, \\theta^{(t)}}, \\theta^{(t)})$ 바로 위에서 살펴보았 듯이 $p_{z|x, \\theta^{\\prime}} = p_{z|x, \\theta}$일 때, 등식이 성립한다. (Gibb's Inequality)\n3. $\\mathcal{F}(p_{z|x, \\theta^{(t)}}, \\theta^{(t)}) \\leq \\mathcal{F}(p_{z|x, \\theta^{(t)}}, \\theta^{(t+1)})$  \n   여기서 $\\theta^{(t+1)}$은 다음과 같이 구할 수 있다.  \n   $\\theta^{(t+1)} = \\argmax_{\\theta}{\\mathcal{F}(p_{z|x, \\theta^{(t)}}, \\theta)}$\n4. $\\mathcal{F}(p_{z|x, \\theta^{(t)}}, \\theta^{(t+1)}) \\leq \\mathcal{L}(\\theta^{(t+1)})$  \n   이는 1번과 동일한 식이다.\n5. $\\mathcal{L}(\\theta^{(t)}) \\leq \\mathcal{L}(\\theta^{(t+1)})$\n\n결론적으로, 5번에 의해서 우리는 매단계가 이전보다 같거나 크다는 것을 알 수 있다. 또한, 각 단계를 차례대로 설명한다면 다음과 같다.\n\n1. 이전 확률과 현재 parameter의 추정치를 이용해서 구한 $\\mathcal{F}(p_{z|x, \\theta^{(t-1)}}, \\theta^{(t)})$는 $\\theta^{(t)}) \\leq \\mathcal{L}(\\theta^{(t)})$보다 작다는 것을 Jensen's Inequality에 의해서 알 수 있다.\n2. 우리는 이제 $\\mathcal{F}(p_{z|x, \\theta}, \\theta^{(t)})$를 최대화하기 위해서 $p_{z|x, \\theta}$를 $p_{z|x, \\theta^{(t)}}$로 업데이트 한다. 그렇다면, 이 결과는 앞 서 보았듯이 이 값은 $\\mathcal{L}(\\theta^{(t)})$와 동일한 결과를 갖는다.\n3. 여기서 우리가 얻은 $ \\mathcal{F}(p_{z|x, \\theta^{(t)}}, \\theta)$를 최대화할 수 있는 $\\theta^{(t+1)}$를 구한다면, 이는 당연하게도 $\\mathcal{F}(p_{z|x, \\theta^{(t)}}, \\theta^{(t)})$ 보다 크다.\n4. 이렇게 얻은 새로운 parameter에 의한 결과는 역시 당연하게도 1번과 같은 결론에 도달하게 된다.\n5. 결국 우리는 1~4번 까지의 과정을 거치면서 $\\mathcal{L}(\\theta)$를 계속해서 증가시킬 수 있다.\n\n결국 우리가 해야할 것은 다음값을 매차시마다 구하는 것이다.\n\n$$\n\\theta^{(t+1)} = \\argmax_{\\theta}{\\mathcal{F}(p_{z|x, \\theta^{(t)}}, \\theta)}\n$$\n\n이를 위해서 먼저 우리는 $\\mathcal{F}(p_{z|x, \\theta^{(t)}}, \\theta)$의 식을 좀 더 정리해볼 것이다.\n\n$$\n\\begin{align*}\n\\mathcal{F}(p_{z|x, \\theta^{\\prime}}, \\theta) \u0026= \\sum_{x\\in D} E_{z|x, \\theta^{\\prime}}{[\\log{\\frac{p(x, z|\\theta)}{p(z| x, \\theta^{\\prime})}}]} \\\\\n\u0026= \\sum_{x\\in D}\\{\\int_{z|x, \\theta^{\\prime}}{p(z|x,\\theta^{\\prime})\\log{\\frac{p(x, z|\\theta)}{p(z| x, \\theta^{\\prime})}}}\\}\\\\\n\u0026= \\sum_{x\\in D}\\{\\int_{z|x, \\theta^{\\prime}}{p(z|x,\\theta^{\\prime})\\log{p(x, z|\\theta)}} + \\int_{z|x, \\theta^{\\prime}}{p(z|x, \\theta^{\\prime})}{\\log{\\frac{1}{p(z|x, \\theta^{\\prime})}}}\\} \\\\\n\u0026= \\sum_{x\\in D}\\{\\int_{z|x, \\theta^{\\prime}}{p(z|x,\\theta^{\\prime})\\log{p(x, z|\\theta)}} + H(p_{z|x,\\theta^{\\prime}})\\}\n\\end{align*}\n$$\n\n위 식에서 우리는 $\\argmax_{\\theta}{\\mathcal{F}(p_{z|x, \\theta^{(t)}}, \\theta)}$를 구하기 위한 과정에서 $H(p_{z|x,\\theta^{\\prime}})$는 필요없다는 것을 알 수 있다.\n\n$$\n\\begin{align*}\n\\mathcal{Q}(\\theta; \\theta^{\\prime}) \u0026= \\mathcal{F}(p_{z|x, \\theta^{(t)}}, \\theta) - H(p_{z|x,\\theta^{\\prime}}) \\\\\n\u0026= \\sum_{x\\in D}\\{\\int_{z|x, \\theta^{\\prime}}{p(z|x,\\theta^{\\prime})\\log{p(x, z|\\theta)}}\\} \\\\\n\u0026= \\sum_{x\\in D}\\{ E_{z|x, \\theta^{\\prime}}[\\log{p(x, z|\\theta)}] \\}\n\\end{align*}\n$$\n\n그 결과 우리는 다음과 같은 결론을 내릴 수 있다.\n\n$$\n\\begin{align*}\n\\theta^{(t+1)} \u0026= \\argmax_{\\theta} \\mathcal{Q}(\\theta; \\theta^{(t)}) \\\\\n\u0026= \\argmax_{\\theta} \\sum_{x\\in D}\\{ E_{z|x, \\theta^{(t)}}[\\log{p(x, z|\\theta)}] \\}\n\\end{align*}\n$$\n\n따라서, 우리는 이를 효과적으로 구하기 위해서 EM Algorithm을 다음과 같이 정의하고, 단계에 따라 수행한다.\n\n1. Expectation Step  \n   앞에서 제시한 $\\mathcal{Q}(\\theta; \\theta^{(t)})$의 식을 구하는 단계이다. 즉, 변수를 $\\theta$ 외에는 모두 없애는 단계이다. Expectation 단계라고 부르는 이유는 $\\mathcal{Q}(\\theta; \\theta^{(t)})$가 $\\sum_{x\\in D}\\{ E_{z|x, \\theta^{\\prime}}[\\log{p(x, z|\\theta)}] \\}$와 같이 Expectation의 합의 형태로 표현되기 때문이다.  \n   이를 좀 더 쉽게 표현하자면 다음과 같이 말할 수도 있다. 이전 parameter $\\theta^{(t)}$가 주어졌을 때, 각 데이터에 대한 latent variable $z$의 확률을 구하는 것이다. 즉, $p(z|x, \\theta^{(t)})$를 구하는 것이다.\n2. Maximization Step  \n   이제 앞 서 구한 $\\mathcal{Q}(\\theta; \\theta^{(t)})$를 $\\theta$에 대해 최대화하여, $\\theta^{(t+1)}$를 구하는 단계이다.\n\n이것이 EM Algorithm의 본질이다.\n\n그래서 앞 선 Clustering에서 살펴보았던 것처럼 EM Algorithm을 다음과 같이 정의할 수도 있는 것이다.\n\n1. 초기 parameter $\\theta^{(0)}$를 설정한다.  \n2. 이를 기반으로 data가 해당 분포에서 $z$일 확률을 구한다.\n3. 구한 확률을 바탕으로 해당 확률과 data를 잘 표현할 수 있는 새로운 parameter $\\theta^{(t+1)}$를 구한다.\n4. 2, 3번 과정을 parameter가 일정 수준에 수렴할 때까지 반복한다.\n\n## Reference\n\n- Tumbnail : Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=unsplash\u0026utm_medium=referral\u0026utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@markuswinkler?utm_source=unsplash\u0026utm_medium=referral\u0026utm_content=creditCopyText)\n","slug":"ml-em-algorithm","date":"2022-11-24 20:15","title":"[ML] 10. EM Algorithm","category":"AI","tags":["ML","EM-Algorithm","JensensInequality","GibbsInequality"],"desc":"주어지는 data에 항상 feature, label이 정확하게 매칭되지는 않는다. 이럴 경우 우리는 각 data에 대한 label과 주어진 data와 label을 잘 설명할 수 있는 probability distribution을 모두 구해야 한다. 여기서 label과 probability distribution을 동시에 구하기 위해서는 어떻게 해야할지에 대한 방법 중에서 대표적인 EM Algorithm에 대해서 살펴보도록 하겠다.","thumbnailSrc":"https://euidong.github.io/images/ml-thumbnail.jpg"}],"params":{"subject":"JensensInequality"}},"__N_SSG":true},"page":"/tags/[subject]","query":{"subject":"JensensInequality"},"buildId":"6SENXQ_RcGFHETqFmw7p-","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>