---
slug: "ml-nn"
title: "[ML] 6. Neural Network"
date: "2022-10-20 09:00"
category: "AI"
tags: ["ML", "NeuralNetwork", "Perceptron", "Backpropagation", "CrossEntropyLoss"]
thumbnailSrc: "/images/ml-thumbnail.jpg"
---

## Intro

ìš°ë¦¬ëŠ” Linear Regression, Logistic Regression, SVMì„ ê±°ì¹˜ë©° dataë¡œ ë¶€í„° ìœ ì˜ë¯¸í•œ patternì„ ë°œê²¬í•˜ëŠ” ê³¼ì •ì„ ì•Œì•„ë³´ì•˜ë‹¤. ì´ ê³¼ì •ì€ ìš°ë¦¬ì—ê²Œ ëª…í™•í•œ ì‹ í•˜ë‚˜ë¥¼ ì œì‹œí•˜ì˜€ê³ , ëª¨ë“  ê³¼ì •ì„ ìš°ë¦¬ê°€ ì œì–´í•  ìˆ˜ ìˆê²Œ í•˜ì˜€ë‹¤. í•˜ì§€ë§Œ, ì‹¤ì œ ë°ì´í„°ë¥¼ ìš°ë¦¬ê°€ ëª¨ë‘ ëª…í™•í•˜ê²Œ ì´í•´í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë¶„ë¥˜í•  ìˆ˜ ìˆëŠ” ê²ƒì¸ì§€ëŠ” ì˜ë¬¸ì´ ë“¤ ìˆ˜ ìˆë‹¤. ê·¸ë ‡ë‹¤ë©´, ìš°ë¦¬ê°€ ì´í•´í•˜ì§€ëŠ” ëª»í•˜ì§€ë§Œ, ì•Œì•„ì„œ ìµœì ì˜ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¤ê²Œ í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆì„ê¹Œ? ì´ëŸ° ë§ˆë²•ê°™ì€ ì¼ì— ëŒ€í•œ ì•„ì´ë””ì–´ë¥¼ ì œì‹œí•˜ëŠ” ê²ƒì´ Neural Networkì´ë‹¤.
ëŒ€ê²Œ ì•Œì§€ ëª»í•˜ì§€ë§Œ inputì´ ë“¤ì–´ì™”ì„ ë•Œ, ì´ë¥¼ ì²˜ë¦¬í•´ì„œ outputì„ ì „ë‹¬í•˜ëŠ” ì‹œìŠ¤í…œì„ ìš°ë¦¬ì˜ ì‹ ì²´ì—ì„œ ì°¾ê²Œ ëœë‹¤. ë°”ë¡œ ìš°ë¦¬ ëª¸ì„ ì´ë£¨ëŠ” ì‹ ê²½ë§ì´ë‹¤. ì˜ˆì‹œë¡œ ìš°ë¦¬ëŠ” ëˆˆì„ í†µí•´ ë¹›ì´ë¼ëŠ” inputì„ ë°›ìœ¼ë©´, ìš°ë¦¬ ëˆˆê³¼ ë‡Œì—ì„œ ë¬´ìŠ¨ ì¼ì´ ë°œìƒí•˜ëŠ”ì§€ëŠ” ëª¨ë¥´ì§€ë§Œ ê²°ê³¼ì ìœ¼ë¡œ ìš°ë¦¬ëŠ” ë¬¼ì²´ë¥¼ ë³¼ ìˆ˜ ìˆë‹¤. ì´ ê³¼ì •ì„ ì¶”ì¸¡ì˜ ê³¼ì •ì— ë„ì…í•˜ë©´ ì–´ë–»ê²Œ ë ê¹Œ?

## Perceptron

Perception(ì¸ì§€ ëŠ¥ë ¥) + Neuron(ì‹ ê²½ ì„¸í¬)ì˜ í•©ì„±ì–´ì´ë‹¤. ì¤‘ê³ ë“±í•™êµ ìƒëª… ìˆ˜ì—…ì„ ë“¤ì—ˆë‹¤ë©´, ìš°ë¦¬ì˜ ëª¨ë“  ì‹ ê²½ì€ ë‰´ëŸ°ì´ë¼ëŠ” ë‹¨ìœ„ ì„¸í¬ë¡œ ì´ë£¨ì–´ì§„ë‹¤ëŠ” ê²ƒì„ ë°°ì› ì„ ê²ƒì´ë‹¤. ì¦‰, ìš°ë¦¬ì˜ ì‹ ê²½ ì„¸í¬ë¥¼ ì»´í“¨í„° ê³µí•™ì—ì„œ í™œìš©í•˜ê¸° ìœ„í•´ì„œ, ìˆ˜í•™ì ìœ¼ë¡œ ë³€í™˜í•œ ê²ƒì´ë‹¤. í˜•íƒœë¥¼ ë¨¼ì € ì‚´í´ë³´ì.

$$
y = sign(\bold{w}^{\top}\bold{x} + b)
$$

![nn-perceptron-1](/images/nn-perceptron-1.jpg)

ëŒ€ë‹¨í•œ ê²ƒì„ ê¸°ëŒ€í–ˆë‹¤ë©´ ì‹¤ë§í•˜ê² ì§€ë§Œ, simpleí•œ ê²ƒì´ ìµœê³ ë¼ëŠ” ì—°êµ¬ì˜ ì§„ë¦¬ì— ë”°ë¼ì„œ ìœ„ì˜ ì‹ì€ ê½¤ë‚˜ í•©ë¦¬ì ì´ë‹¤. ìš°ë¦¬ê°€ Linear Regressionê³¼ Logistic Regressionì„ ë°°ì› ìœ¼ë‹ˆ ì•Œ ê²ƒì´ë‹¤. ì´ëŠ” ì‚¬ì‹¤ Linear Regressionì„ ì´ìš©í•´ì„œ ìš°ë¦¬ê°€ Classificationì„ ìˆ˜í–‰í•  ë•Œ ì‚¬ìš©í–ˆë˜ ì‹ì´ë‹¤. ì¦‰, perceptron í•˜ë‚˜ëŠ” inputì„ ì„ í˜•ìœ¼ë¡œ êµ¬ë¶„í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” decision boundaryë¥¼ ì°¾ëŠ” ê²ƒê³¼ ê°™ë‹¤.

> **Optimization**

ê·¸ë ‡ë‹¤ë©´, í•´ë‹¹ perceptronì„ í†µí•´ì„œ ëª¨ë“  ë°ì´í„°ë¥¼ êµ¬ë¶„í•˜ê¸° ìœ„í•´ì„œëŠ” ë‹¤ìŒì„ ë§Œì¡±í•˜ëŠ” $\bold{w}$ë¥¼ ì°¾ì•„ì•¼ í•œë‹¤.

$$
y_{n} =
\begin{cases}
1  &\text{ if  } \bold{x}_{n} \in \mathcal{C}_{1} \\
-1 &\text{ if  } \bold{x}_{n} \in \mathcal{C}_{2} \\
\end{cases}
$$
$$
y_{n}\bold{w}^{\top}\bold{x}_{n} \gt 0, \forall n
$$

ê²°êµ­ Loss í•¨ìˆ˜ëŠ” perceptronì˜ ì˜ëª»ëœ classification ê²°ê³¼ë¥¼ ìµœì†Œí™”í•˜ëŠ” ê²ƒì´ë‹¤.

$$
\mathcal{J}(\bold{w}) = - \sum_{n \in \mathcal{M}(\bold{w})}{y_{n}\bold{w}^{\top}\bold{x}_{n}} \quad( \mathcal{M}(\bold{w}) = \{ n : y_{n}\bold{w}^{\top}\bold{x}_{n} \} )
$$
$$
\nabla_{\bold{w}}\mathcal{J}(\bold{w}) = - \sum_{n \in \mathcal{M}(\bold{w})}{y_{n}\bold{x}_{n}}
$$

ë”°ë¼ì„œ, ìš°ë¦¬ê°€ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” Gradient Descentì‹ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.

$$
\bold{w}_{t+1} = \bold{w}_{t} + \alpha\sum_{n \in \mathcal{M}(\bold{w})}{y_{n}\bold{x}_{n}}
$$

ê°„ë‹¨í•œ ì˜ˆì‹œë¡œ AND, OR Gateë¥¼ percentronì„ í†µí•´ í‘œí˜„í•´ë³´ì.

![nn-and-gate](/images/nn-and-gate.jpg)
![nn-or-gate](/images/nn-or-gate.jpg)

í•˜ì§€ë§Œ, ìš°ë¦¬ê°€ ë‹¤ë£¨ëŠ” ë°ì´í„°ëŠ” í•­ìƒ ì™„ë²½í•˜ê²Œ ì„ ìœ¼ë¡œ ë‚˜ë‰˜ì–´ì§€ì§€ëŠ” ì•ŠëŠ”ë‹¤. í•˜ë‚˜ì˜ perceptronìœ¼ë¡œëŠ” ì•„ë˜ì˜ XORì¡°ì°¨ë„ êµ¬ë¶„í•´ë‚¼ ìˆ˜ ì—†ë‹¤.

![nn-multi-line-example](/images/nn-multi-line-example.jpg)

## Multilayer Perceptron

ìœ„ì˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ì„œ ë‚˜ì˜¨ ê²ƒì´ perceptronì„ ë‹¤ì¸µìœ¼ë¡œ ìŒ“ì•„ì„œ í•´ê²°í•˜ëŠ” ë°©ë²•ì´ë‹¤. ì´ì œëŠ” í•˜ë‚˜ì˜ ì‹ ê²½ì„¸í¬ì˜€ë˜ perceptronì„ ì§„ì§œ ì‹ ê²½ë§ì²˜ëŸ¼ ì—°ê²°í•´ë³´ìëŠ” ê²ƒì´ë‹¤.

ë¨¼ì € ì¶”ìƒì ì¸ ì˜ˆì‹œë¥¼ ìƒê°í•´ë³´ì. ìš°ë¦¬ê°€ XOR Gateë¥¼ ë§Œë“¤ê¸° ìœ„í•´ì„œëŠ” ì–´ë–¤ Gateë¥¼ ê²°í•©í•´ì•¼í• ê¹Œ?

$$
a \oplus b = ab + \bar{a}\bar{b}
$$

ìš°ë¦¬ëŠ” AND Gate 2ê°œ ì—°ì‚°ì„ ìˆ˜í–‰í•˜ê³ , í•´ë‹¹ ê²°ê³¼ê°’ì„ ì´ìš©í•´ì„œ OR Gate ì—°ì‚°ì„ ìˆ˜í–‰í•˜ë©´ XOR Gateë¥¼ í‘œí˜„í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ì•Œê³  ìˆë‹¤. ê·¸ë ‡ë‹¤ë©´, ê° GateëŠ” ìš°ë¦¬ê°€ perceptronìœ¼ë¡œ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆì—ˆëŠ”ë° ê·¸ëƒ¥ ì´ê²ƒì„ gateë¡œ í‘œí˜„í•˜ë“¯ì´ ë˜‘ê°™ì´ ë‚˜íƒ€ë‚´ë©´ í’€ ìˆ˜ ìˆì§€ ì•Šì„ê¹Œ?

ê·¸ë˜ì„œ ì§ì ‘ ìˆ˜í–‰í•´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ì€ ê°’ì„ êµ¬í•  ìˆ˜ ìˆë‹¤.

![nn-xor-gate](/images/nn-xor-gate.jpg)

```plaintext
 ğŸ¤” Insight

 ìœ„ì˜ ê³¼ì •ì„ ë³´ë‹¤ë³´ë©´ ë†€ë¼ìš´ ê²ƒì„ í•˜ë‚˜ ë°œê²¬í•  ìˆ˜ ìˆë‹¤. ë°”ë¡œ ì™¼ ìª½ ê·¸ë¦¼ì˜ ë³€í™”ì´ë‹¤. 
 ì²«ë²ˆì§¸, ë‘ ê°œì˜ perceptronì„ í†µí•´ì„œ ë§Œë“¤ì–´ì§„ outputì´ ì´ë£¨ëŠ” ê²°ê³¼ê°’ì˜ í˜•íƒœë¡œ featureë¥¼ ë³€í™˜í•˜ë©´, 
 í•˜ë‚˜ì˜ perceptronìœ¼ë¡œ decision boundaryë¥¼ ê·¸ë¦´ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì´ë‹¤. 
 ì´ëŠ” ë§ˆì¹˜ ì´ì „ linear regressionì—ì„œ ë°°ì› ë˜ basis function(Ï•)ì´ í–ˆë˜ ì—­í• ì´ë‹¤.

 ê·¸ë ‡ë‹¤ë©´, ì´ë¥¼ ë”ìš± í™•ì¥í•´ë³´ì. 
 ë§Œì•½ í•´ë‹¹ Layerê°€ ë” ê¹Šì–´ì§„ë‹¤ê³  í•´ë„, ì¶œë ¥ ì§ì „ì˜ layerëŠ” ë‹¨ìˆœíˆ ì´ì „ ëª¨ë“  layerëŠ” ì…ë ¥ ë°ì´í„°ë¥¼ ê°€ê³µí•´ì„œ
featureë¥¼ ë³€í™˜í•˜ëŠ” í•˜ë‚˜ì˜ basis function(Ï•)ë¥¼ ì·¨í•œ ê²ƒìœ¼ë¡œ ì´í•´í•  ìˆ˜ ìˆë‹¤.
```

ê²°ë¡ ì ìœ¼ë¡œ ìš°ë¦¬ëŠ” ë” ë³µì¡í•˜ê³ , ì–´ë ¤ìš´ ë¬¸ì œì˜ ê²½ìš°ì—ë„ ë” ê¹Šê²Œ ì‹ ê²½ë§ì„ êµ¬ì„±í•˜ë©´ ê²°êµ­ì€ ë¬¸ì œë¥¼ í’€ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì´ë‹¤.

> **Universal Approximation Theorem**

ìœ„ì™€ ê°™ì€ ê¹Šì€ ì‹ ê²½ë§ êµ¬ì¡°ë¥¼ ì´ìš©í•˜ìëŠ” ì£¼ì¥ë„ ìˆì§€ë§Œ, ì´ì™€ ìœ ì‚¬í•˜ê²Œ ë„“ì€ ì‹ ê²½ë§ì„ ì“°ìëŠ” ì£¼ì¥ë„ ì¡´ì¬í–ˆë‹¤.  

![nn-universal-approx-theorem-1](/images/nn-universal-approx-theorem-1.jpg)

ë§Œì•½, ìš°ë¦¬ê°€ í•˜ë‚˜ì˜ Layerì™€ outputì—ì„œ ìµœì¢… output perceptronë§Œ ê°–ê³  ì²˜ë¦¬ë¥¼ í•œë‹¤ë©´, ê²°êµ­ ì—¬ëŸ¬ perceptronì˜ weighted í•©ìœ¼ë¡œ ë³¼ ìˆ˜ ìˆë‹¤. ê·¸ ê²½ìš° ìš°ë¦¬ëŠ” ê³„ë‹¨ í•¨ìˆ˜ì˜ weighted í•©ìœ¼ë¡œ ìƒê°í•  ìˆ˜ ìˆëŠ”ë° perceptronì´ ë§ì•„ì§ˆ ìˆ˜ë¡ ì´˜ì´˜í•´ì§€ë©° ì •ë‹µê³¼ ìœ ì‚¬í•œ ì¶”ë¡ ì´ ê°€ëŠ¥í•´ì§„ë‹¤.(ë§ˆì¹˜ ì ë¶„ì˜ ê°œë…ê³¼ ìœ ì‚¬í•˜ë‹¤. ë¬¼ë¡  ì´ëŠ” ì¶”ìƒì ì¸ ì„¤ëª…ì´ê¸° ë•Œë¬¸ì— ì‹¤ì œë¡œëŠ” ê³„ë‹¨í•¨ìˆ˜ì˜ í•©ì´ê¸° ë•Œë¬¸ì— ì¢€ ë‹¤ë¥´ë‹¤.)

![nn-universal-approx-theorem-2](/images/nn-universal-approx-theorem-2.jpg)

ìœ„ì˜ ê·¸ë¦¼ì„ ë³´ë©´ ì´í•´í•  ìˆ˜ ìˆë‹¤. í•˜ì§€ë§Œ, ì´ ë°©ì‹ì€ ê²°êµ­ ëª¨ë“  í•¨ìˆ˜ í˜•íƒœë¥¼ ê¸°ì–µí•˜ëŠ” ê²ƒì´ë‹¤.(**memorizer**) ì´ê²ƒì€ input dataê°€ ë§ì•„ì§ˆ ìˆ˜ë¡ ë³µì¡ë„ê°€ ê¸‰ê²©í•˜ê²Œ ì¦ê°€í•˜ê¸° ë•Œë¬¸ì— í•™ìŠµê³¼ ì˜ˆì¸¡ê³¼ì •ì— êµ‰ì¥íˆ ë§ì€ ì‹œê°„ì„ ì†Œëª¨í•œë‹¤.

> **Multilayer Optimization(Backpropagation)**

ê·¸ë ‡ë‹¤ë©´, ë„“ì€ ì‹ ê²½ë§ì´ í•œê³„ê°€ ìˆìœ¼ë‹ˆ ì„ íƒì§€ëŠ” inputê³¼ output ì‚¬ì´ì˜ layer(**hidden layer**)ì˜ ê°¯ìˆ˜ë¥¼ ëŠ˜ë ¤ì„œ ê¹Šì€ ì‹ ê²½ë§ì„ ë§Œë“œëŠ” ê²ƒì´ë‹¤. í•˜ì§€ë§Œ, ìš°ë¦¬ê°€ ì‚¬ìš©í•˜ê³  ìˆëŠ” perceptronì€ signí•¨ìˆ˜ë¡œ ê°ì‹¸ì ¸ìˆê¸° ë•Œë¬¸ì— ë¯¸ë¶„ ì‹œì— ê¸°ìš¸ê¸°ê°€ 0ì´ë¼ëŠ” ë¬¸ì œë¥¼ ê°–ëŠ”ë‹¤. ë˜í•œ, ê·¸ë ‡ë‹¤ê³  ì •ë‹µì˜ ê°¯ìˆ˜ë¥¼ ì´ìš©í•˜ê¸°ì—ëŠ” ê° perceptronì˜ ì˜í–¥ì„ ì „ë‹¬í•˜ê¸°ì— ë¶€ì¡±í•˜ë‹¤ëŠ” ê²ƒì´ ëª…í™•í•˜ë‹¤. ë”°ë¼ì„œ, ìš°ë¦¬ëŠ” perceptronì— ìˆëŠ” ì •ë‹µì„ íŒë³„í•˜ëŠ” í•¨ìˆ˜ signì„ ë‹¤ë¥¸ í•¨ìˆ˜ë¡œ ëŒ€ì²´í•˜ê¸°ë¡œ í•œë‹¤.

![nn-perceptron-2](/images/nn-perceptron-2.jpg)

ì—¬ê¸°ì„œ ì´ í•¨ìˆ˜ë¥¼ ìš°ë¦¬ëŠ” **activation function**ì´ë¼ê³  ë¶€ë¥´ê³  ëŒ€í‘œì ìœ¼ë¡œëŠ” ê°™ì€ ì¢…ë¥˜ê°€ ìˆë‹¤.

- **sigmoid**  
  ìš°ë¦¬ê°€ ê°€ì¥ ì‰½ê²Œ ìƒê°í•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜ì´ë‹¤. logistic regressionì—ì„œ ì‚¬ìš©í•´ë³¸ë§Œí¼ ê¸°ìš¸ê¸°ê°’ì„ íš¨ê³¼ì ìœ¼ë¡œ ê°€ì§ˆ ìˆ˜ ìˆë‹¤.
- **tanh**  
  sigmodì™€ êµ‰ì¥íˆ ìœ ì‚¬í•œ í•¨ìˆ˜ì´ë‹¤. ë”°ë¼ì„œ, ë¹„ìŠ·í•œ ìš©ë„ë¡œ ì‚¬ìš©ë  ìˆ˜ ìˆë‹¤.
- **ReLU**  
  ì¶œë ¥ ì‹œì ì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ì•Šì§€ë§Œ, ê° ê°ì˜ hidden layerì—ì„œ ì´ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°ê°€ ë§ë‹¤. ì™œëƒí•˜ë©´, sigmoid í•¨ìˆ˜ëŠ” ì¶œë ¥ê°’ì˜ í˜•íƒœê°€ [0, 1], tanhëŠ” [-1, 1]ì´ê¸° ë•Œë¬¸ì— ë°˜ë³µí•´ì„œ ì ìš©í•˜ë©´, gradientê°€ ì‚¬ë¼ì§€ëŠ” í˜„ìƒì´ ë°œìƒí•  ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ, ê¸°ìš¸ê¸°ë¥¼ ìˆëŠ” ê·¸ëŒ€ë¡œ ì ìš©í•  ìˆ˜ ìˆëŠ” ì´ëŸ¬í•œ í˜•íƒœë¥¼ ì¶œë ¥ ì´ì „ì—ëŠ” ë§ì´ ì‚¬ìš©í•œë‹¤.
- **Leaky ReLU**  
  ReLUê°€ ìŒìˆ˜ê°’ì„ ì™„ì „íˆ ë¬´ì‹œí•˜ëŠ”ë° Leaky ReLUëŠ” ì´ëŸ¬í•œ ë°ì´í„°ê°€ ì¡°ê¸ˆì´ë¼ë„ ì˜ë¯¸ ìˆëŠ” ê²½ìš°ì— ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.
- **ELU**  
  Leaky ReLUì™€ ë¹„ìŠ·í•œ ì´ìœ ì´ë‹¤.

  ![activation-functions](/images/activation-functions.png)
  
ìë£Œê°€ ë³´ì´ì§€ ì•ŠëŠ”ë‹¤ë©´ [ğŸ”— wikipedia](https://en.wikipedia.org/wiki/Activation_function)ë¥¼ ì°¸ê³ í•˜ì.

---

ì ì´ì œ ì‹¤ì œë¡œ ì–´ë–»ê²Œ optimizationì„ ìˆ˜í–‰í• ì§€ë¥¼ ì•Œì•„ë³´ë„ë¡ í•˜ì.

ë¨¼ì €, LossëŠ” ê°€ì¥ ë§ˆì§€ë§‰ layer(output layer)ì˜ outputê³¼ ì‹¤ì œ ê°’ê³¼ì˜ ì°¨ì´ê°€ ë  ê²ƒì´ë‹¤. ë”°ë¼ì„œ, ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜í•  ìˆ˜ ìˆë‹¤.

(ì•„ë˜ì„œ $\bold{h}_{L}$ì€ Lë²ˆì§¸ layerì˜ outputì„ ì˜ë¯¸í•œë‹¤.)

$$
\begin{align*}
\mathcal{L} &= \sum_{n=1}^{N}{\ell(y_n, \bold{h}_L)} \\
&= \sum_{n=1}^{N}{(y_{n} - \bold{h}_{L})^2} \\
&= \sum_{n=1}^{N}{(y_{n} - \sigma(\bold{w}_{L}^{\top}\bold{h}_{L-1} + b_{L-1}))^2} \\
&= \sum_{n=1}^{N}{(y_{n} - \sigma(\bold{w}_{L}^{\top}\sigma(\bold{w}_{L-1}^{\top}\bold{h}_{L-2} + b_{L-2}) + b_{L-1}))^2} \\
&= ...
\end{align*}
$$

ì—¬ê¸°ì„œ ì¤‘ìš”í•œ ê²ƒì€ ìš°ë¦¬ëŠ” ì „ì²´ $\bold{W}$ë¥¼ í•™ìŠµì‹œì¼œì•¼ í•œë‹¤ëŠ” ê²ƒì´ë‹¤. ìš°ë¦¬ëŠ” ì¶œë ¥ì¸µë§Œ í•™ìŠµí•˜ëŠ” ê²Œ ì•„ë‹ˆë¼ ì „ì²´ ëª¨ë“  layerì˜ $\bold{w}_{i}$ë¥¼ ì—…ë°ì´íŠ¸í•´ì•¼ í•œë‹¤ëŠ” ê²ƒì´ë‹¤.

ê·¸ëŸ¬ê¸° ìœ„í•´ì„œëŠ” ìš°ë¦¬ëŠ” ${{\partial\mathcal{L}}\over{\partial \bold{w}_{i}}}$ë¥¼ ëª¨ë‘ êµ¬í•´ì•¼ í•œë‹¤ëŠ” ê²ƒì´ë‹¤. ì•„ë§ˆ ê°€ì¥ ìŠµê´€ì ìœ¼ë¡œ í•˜ëŠ” í–‰ìœ„ëŠ” ìˆ«ìê°€ ì‘ì€ ê°’ë¶€í„° í¸ë¯¸ë¶„í•˜ë©´ì„œ ì§„í–‰í•˜ëŠ” ê²ƒì´ë‹¤. í•˜ì§€ë§Œ, ê·¸ë ‡ê²Œ í•˜ì§€ë§ê³  ë°˜ëŒ€ ìˆœì„œë¡œ ë¯¸ë¶„ì„ í•˜ë¼ëŠ” ê²ƒì´ **backpropagation**ì˜ main ideaì´ë‹¤.

$$
{{\partial\mathcal{L}}\over{\partial \bold{w}_{L}}} = \sum_{n=1}^{N}\{({\partial \bold{h}_L \over \partial \bold{w}_{L}} )\times\red{-2(y_{n} - \sigma(\bold{w}_{L}^{\top}\bold{h}_{L-1} + b_{L-1}))}\}
$$

$$
{{\partial\mathcal{L}}\over{\partial \bold{w}_{L-1}}} = \sum_{n=1}^{N}\{({\partial \bold{h}_{L} \over \partial \bold{w}_{L-1} })\times\red{-2(y_{n} - \sigma(\bold{w}_{L}^{\top}\bold{h}_{L-1} + b_{L-1}))}\}
$$

ì¦‰, ë‹¤ìŒê³¼ ê°™ì€ chain ruleì„ ì´ìš©í•˜ëŠ” ê²ƒì´ë‹¤.

$$
\begin{align*}
{{\partial\mathcal{L}}\over{\partial \bold{w}_{L}}} &= \red{ {{\partial\mathcal{L}}\over{\partial \bold{h}_{L}}} } {{\partial\bold{h}_{L}}\over{\partial \bold{w}_{L}}} \\
{{\partial\mathcal{L}}\over{\partial \bold{w}_{L-1}}} &= \red{ {{\partial\mathcal{L}}\over{\partial \bold{h}_{L}}} } {{\partial\bold{h}_{L}}\over{\partial \bold{w}_{L-1}}} \\
&= \red{ {{\partial\mathcal{L}}\over{\partial \bold{h}_{L}}} } {{\partial\bold{h}_{L}}\over{\partial \bold{h}_{L-1}}} {{\partial\bold{h}_{L-1}}\over{\partial \bold{w}_{L-1}}} \\
&= \blue{ {{\partial\mathcal{L}}\over{\partial \bold{h}_{L-1}}} } {{\partial\bold{h}_{L-1}}\over{\partial \bold{w}_{L-1}}} \\
{{\partial\mathcal{L}}\over{\partial \bold{w}_{L-2}}} &= \blue{ {{\partial\mathcal{L}}\over{\partial \bold{h}_{L-1}}} } {{\partial\bold{h}_{L}}\over{\partial \bold{w}_{L-2}}} \\
\end{align*}
$$

ìš°ë¦¬ëŠ” ë¹¨ê°„ìƒ‰ê³¼ íŒŒë€ìƒ‰ ë¶€ë¶„ì˜ ì—°ì‚°ì„ ì¬í™œìš©í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì´ë‹¤. ë˜í•œ, ${{\partial\bold{h}_{l}}\over{\partial \bold{w}_{l}}}$ì€ êµ‰ì¥íˆ ì‰¬ìš´ ì—°ì‚°ì´ê¸°ì— ìš°ë¦¬ê°€ ì‹ ê²½ ì¨ì„œ ê³„ì‚°í•´ì•¼ í•  ê°’ì€ ë§¤ë‹¨ê³„ë¥¼ ì—°ê²°í•´ì¤„ $ {{\partial\bold{h}_{l}}\over{\partial \bold{h}_{l-1}}}$ì´ë‹¤.

![ml-backpropagation](/images/ml-backpropagation.jpg)

## Loss Function

ìš°ì„  KL-Divergence, Entropy, Cross Entropyì— ëŒ€í•œ ì•½ê°„ì˜ ì´í•´ê°€ í•„ìš”í•˜ë‹ˆ ì´ì „ Posting([ğŸ”— Base Knowledge](posts/ml-base-knowledge))ì„ ì‚´í´ë³´ê³  ì˜¤ì.

ìœ„ì—ì„œëŠ” ìì—°ìŠ¤ëŸ½ê²Œ Lossë¥¼ ê³„ì‚°í•  ë•Œ, Squared Errorë¥¼ ì‚¬ìš©í•˜ì˜€ë‹¤. í•˜ì§€ë§Œ ê²½ìš°ì— ë”°ë¼ì„œëŠ” ë‹¤ì–‘í•œ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. multiclass classificationì—ì„œëŠ” **Cross Entropy Loss**ë¥¼ ì‚¬ìš©í•œë‹¤.

ìš°ì„  Cross Entropy LossëŠ” ëŒ€ê²Œ L2 Loss(Squared Error)ì™€ ê°™ì´ ë¹„êµë˜ì–´ì§„ë‹¤. ìš°ì„  ìš°ë¦¬ê°€ ì´ì „ [ğŸ”— Parametric Estimation](posts/ml-parametric-estimation)ì—ì„œ MLEë¥¼ ë‹¤ë£° ë•Œ, KL-Divergenceë¥¼ í†µí•´ì„œ MLEê°€ ìµœì  parameterë¥¼ ì°¾ì„ ê²ƒì´ë¼ëŠ” ê±¸ ì¦ëª…í•œ ì ì´ ìˆë‹¤. ê·¸ë ‡ë‹¤ë©´, ìš°ë¦¬ê°€ [ğŸ”— Logistic Regression](/posts/ml-logistic-regression)ì—ì„œ Squared Errorë¥¼ í†µí•´ì„œ Lossë¥¼ êµ¬í–ˆë˜ ê³µì‹ì„ í™•ì¸í•´ë³´ì.(Gradient Asecent Part)

ì—¬ê¸°ì„œ ìš°ë¦¬ëŠ” ë‹¤ìŒê³¼ ê³µì‹ì„ ë´¤ì—ˆë‹¤.

$$
\argmax_{\bold{w}} \sum_{n=1}^{N}y_{n}\log{\sigma(\bold{w}^{\top}\bold{x}_{n}) + (1-y_{n})\log{(1-\sigma(\bold{w}^{\top}\bold{x}_{n}))} }
$$

ì´ ê³µì‹ì„ Cross Entropyë¥¼ í†µí•´ì„œ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤.

$$
\begin{align*}
H_{q}(p) &= - \sum_{x \in \Omega}q(x)\log_{2}p(x) \\
&= \sum_{n=1}^{N}{[-y_{n}\log\hat{y}_{n} - (1- y_{n})\log(1-\hat{y}_{n})]}
\end{align*}
$$

ì¦‰, ì—¬ê¸°ì„œ ìš°ë¦¬ê°€ ì–»ì„ ìˆ˜ ìˆëŠ” insightëŠ” Cross EntropyëŠ” sigmoidë¥¼ ì·¨í•œ binary classificationì—ì„œ Squared Errorì™€ ê°™ê³ , ì´ëŸ¬í•œ Cross Entropyë¥¼ Squared Errorê°€ í•  ìˆ˜ ì—†ëŠ” Multiclassì—ëŠ” ì ìš©í•  ìˆ˜ ìˆì„ ê²ƒì´ë¼ëŠ” ì ì´ë‹¤. ì™œëƒí•˜ë©´, multiclass classificationì— ì‚¬ìš©ë˜ëŠ” Softmax Functionì„ ì´ìš©í•´ì„œ Sigmoid functionì„ ìœ ë„í•˜ê¸° ë•Œë¬¸ì´ë‹¤. ì ì‹œ ê¹Œë¨¹ì—ˆì„ê¹Œë´ Softmax í•¨ìˆ˜ë¥¼ ë‹¤ì‹œ ì ëŠ”ë‹¤.

$$
\hat{y}_{k} = {{\exp(\bold{w}_{k}^{\top}\bold{x})}\over{\sum_{i=1}^{K}{\exp(\bold{w}_{i}^{\top}\bold{x})}}}
$$

ë”°ë¼ì„œ, Cross Entropy Lossë¥¼ ëŒ€ì…í•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì€ Lossë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤.

$$
\mathcal{L} = \sum_{n=1}^{N}\sum_{k=1}^{K}[-y_{k,n}\log\hat{y}_{k,n}],\quad y_{k,n} = p(x_{n} \in C_{k}| x_{n})
$$

ì—¬ê¸°ì„œ $y_{k,n}$ì€ one-hot encodingëœ ë°ì´í„°ë¡œ, ì •ë‹µì¸ classë§Œ 1ì´ê³  ë‚˜ë¨¸ì§€ëŠ” ëª¨ë‘ 0ìœ¼ë¡œ ë˜ì–´ ìˆë‹¤. ë”°ë¼ì„œ, multiclass classificationì—ì„œëŠ” ìœ„ì™€ ê°™ì€ Lossë¥¼ ì£¼ë¡œ ì‚¬ìš©í•œë‹¤.

ì´ ë‘ê°€ì§€ ë¿ë§Œ ì•„ë‹ˆë¼ ì—¬ëŸ¬ê°€ì§€ Loss Functionì´ ì´ë¯¸ ì¡´ì¬í•œë‹¤. ì˜ˆì „ì— ì ê¹ ì„¤ëª…í–ˆë˜ L1 Lossë¶€í„° ì‹œì‘í•´ì„œ NLLLoss, KLDivLoss ë“±ë“± ì¡´ì¬í•˜ë©°, dataì˜ íŠ¹ì„±ê³¼ outputì˜ í˜•íƒœì— ë”°ë¼ì„œ ìš°ë¦¬ëŠ” ìŠ¤ìŠ¤ë¡œ Loss Functionì„ ìƒˆë¡œ ì •ì˜í•  ìˆ˜ë„ ìˆë‹¤.

## Reference

- Tumbnail : Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- activation function, wikipedia, <https://en.wikipedia.org/wiki/Activation_function>
