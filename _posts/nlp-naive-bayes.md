---
slug: "nlp-naive-bayes"
title: "[NLP] 5. Naive Bayes"
date: "2022-10-21 15:37"
category: "AI"
tags: ["NLP"]
thumbnailSrc: "/images/nlp-thumbnail.jpg"
---

## Intro

Naive Bayes Modelì€ ê°€ì¥ ì‰½ê²Œ Classificationì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” Modelì´ì§€ë§Œ, ì„±ëŠ¥ì´ ë‹¤ë¥¸ Modelì— ë¹„í•´ ë›°ì–´ë‚˜ì§€ëŠ” ì•Šë‹¤. ê·¸ëŸ¼ì—ë„ Naive BayesëŠ” ê°€ì¥ ê¸°ë³¸ì´ ë˜ëŠ” Modelì´ê¸°ì— ë¹„êµ ëŒ€ìƒìœ¼ë¡œ ë§ì´ ì‚¬ìš©ë˜ê³ , Classificationì˜ insightë¥¼ í‚¤ìš°ëŠ”ë° ë§ì€ ë„ì›€ì„ ì¤„ ìˆ˜ ìˆë‹¤. ì—¬ê¸°ì„œëŠ”, ì „ë°˜ì ì¸ ê°œë…ê³¼ ì´ë¥¼ ì§ì ‘ Spam Filteringì—ì„œ ì–´ë–»ê²Œ ì‚¬ìš©í•˜ëŠ”ì§€ ì‚´í´ë³¸ë‹¤.

## Naive Bayes Model

íŠ¹ì • classì—ì„œ í•´ë‹¹ ë°ì´í„°ê°€ ì–¼ë§ˆë‚˜ ìì£¼ ë°œìƒë˜ëŠ”ì§€ì™€ ì‹¤ì œë¡œ í•´ë‹¹ classì˜ ë¹ˆë„ë¥¼ í™œìš©í•˜ì—¬, classificationì„ ìˆ˜í–‰í•˜ëŠ” ê²ƒì´ë‹¤. ìš°ì„  ì´ë¥¼ ìˆ˜ì‹ì ìœ¼ë¡œ í‘œí˜„í•˜ê¸° ìœ„í•´ì„œ ë‹¤ìŒ ë³€ìˆ˜ë“¤ì„ ë¨¼ì € ì •ì˜í•´ë³´ì.

- **documents($D$)**: ì—¬ëŸ¬ ê°œì˜ Documentë¥¼ ì˜ë¯¸í•˜ë©°, í•˜ë‚˜ì˜ DocumentëŠ” ëŒ€ê²Œ ì—¬ëŸ¬ ê°œì˜ wordsë¥¼ í¬í•¨í•œë‹¤. ê° documentëŠ” $d_{i} \in D$ì˜ í˜•íƒœë¡œ í‘œí˜„í•œë‹¤.
- **classes($C$)**: classëŠ” ë‘ ê°œ ì´ìƒì„ ê°€ì§„ë‹¤. ê° í´ë˜ìŠ¤ëŠ” $c_{i} \in C$ì˜ í˜•íƒœë¡œ í‘œí˜„ëœë‹¤.
- **labeled dataset**: ì´ëŠ” (document($d_{i}$), class($c_{i}$))ê°€ í•˜ë‚˜ì”© mappingëœ í˜•íƒœë¡œ ì¡´ì¬í•œë‹¤. ìš°ë¦¬ê°€ ê°€ì§€ëŠ” datasetìœ¼ë¡œ í•™ìŠµ, í‰ê°€ ì‹œì— ì‚¬ìš©í•œë‹¤. ëŒ€ê²Œ í‰ê°€ì— ì‚¬ìš©ë˜ëŠ” ë°ì´í„°ëŠ” í•™ìŠµ ì‹œì— ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ê¸ˆì§€í•˜ê¸° ë•Œë¬¸ì— ë³„ë„ë¡œ ë¶„ë¦¬í•˜ì—¬ ì‚¬ìš©í•œë‹¤.
- **word($w$)**: í•˜ë‚˜ì˜ wordë¥¼ ì˜ë¯¸í•˜ë©° NLP í•™ìŠµ ì‹œì— ì‚¬ìš©í•˜ëŠ” ê°€ì¥ ì‘ì€ ë‹¨ìœ„ì´ë‹¤. ëŒ€ê²Œ document í•˜ë‚˜ì— ìˆëŠ” ë‹¨ì–´ì˜ ìˆ˜ëŠ” Nìœ¼ë¡œ í‘œê¸°í•˜ê³ , uniqueí•œ ë‹¨ì–´ì˜ ìˆ˜ëŠ” V(size of vocabulary)ë¡œ í‘œì‹œí•œë‹¤.

ë”°ë¼ì„œ, ìš°ë¦¬ê°€ ì°¾ê³ ì í•˜ëŠ” ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§„ classëŠ” ë‹¤ìŒì„ í†µí•´ì„œ êµ¬í•  ìˆ˜ ìˆë‹¤.

$$
\begin{align*}
c_{MAP} &= \argmax_{c \in C}{P(c|d)} \\
&= \argmax_{c \in C}{p(d|c)p(c)\over p(d)} \\
&= \argmax_{c \in C}{p(d|c)p(c)} \\
&= \argmax_{c \in C}{p(w_{1}, w_{2}, ... , w_{N} | c)p(c)} \\
&= \argmax_{c \in C}{\prod_{i=1}^{N}p(w_{i}|c)p(c)} \\
&= \argmax_{c \in C}{\log(\prod_{i=1}^{N}p(w_{i}|c)p(c))} \\
&= \argmax_{c \in C}{\sum_{i=1}^{N}\log p(w_{i}|c) + \log{p(c)}} \\
\end{align*}
$$

ì—¬ê¸°ì„œ ìš°ë¦¬ê°€ language modelì„ ë¬´ì—‡ìœ¼ë¡œ ì •í–ˆëŠ”ì§€ê°€ ì¤‘ìš”í•˜ë‹¤. ìœ„ì—ì„œëŠ” uni-gramì´ë¼ê³  ê°€ì •í•´ì„œ í’€ì´í–ˆì§€ë§Œ, bi-gramì¸ ê²½ìš° documentì˜ í˜•íƒœê°€ $d={(w_{1}, w_{2}), (w_{2}, w_{3}), ... , (w_{N-1}, w_{N})}$ì´ë‹¤. ë”°ë¼ì„œ, ì „ì²´ì ì¸ í¬ê¸°ì™€ vocabularyìì²´ë„ ë°”ë€Œê²Œ ëœë‹¤.

ì¦‰, ìš°ë¦¬ëŠ” train setì„ í†µí•´ì„œ vocabularyë¥¼ ì™„ì„±í•œë‹¤. ê·¸ë¦¬ê³ , ê° wordì˜ count ë° í•„ìš”ì— ë”°ë¼ í•„ìš”í•œ word sequenceì˜ countë¥¼ ìˆ˜ì§‘í•˜ì—¬ $p(w_i)$ë¥¼ êµ¬í•œ í›„ ìœ„ì— ë°©ë²•ì„ í†µí•´ì„œ íŠ¹ì • classë¥¼ ì¶”ì¸¡í•  ìˆ˜ ìˆëŠ” ê²ƒì´ë‹¤.

ì´ì œ êµ¬ì²´ì ì¸ Naive Bayesì˜ ë™ì‘ ì ˆì°¨ëŠ” Spam Filteringì´ë¼ëŠ” Case Studyë¥¼ í†µí•´ì„œ ìì„¸íˆ ì‚´í´ë³´ë„ë¡ í•˜ì.

## Case Study. Spam Filtering

ì´ˆê¸° NLPê°€ ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ì—ˆë˜ ì˜ˆì‹œ ì¤‘ì— í•˜ë‚˜ì´ë‹¤. ì—¬ëŸ¬ ê°œì˜ ë©”ì¼ì— spamì¸ì§€ hamì¸ì§€ë¥¼ labelingí•œ ë°ì´í„°ë¥¼ ê°–ê³  í›„ì— inputìœ¼ë¡œ mail ë°ì´í„°ê°€ ë“¤ì–´ì™”ì„ ë•Œ, ì´ë¥¼ filteringí•˜ëŠ” ê²ƒì´ë‹¤. ìœ„ì—ì„œ ì‚´í´ë³´ì•˜ë˜ í™•ë¥ ì„ ê·¸ëŒ€ë¡œ ì ìš©í•˜ë©´ ëœë‹¤. ì˜ˆì¸¡ì— í•„ìš”í•œ í™•ë¥ ì„ ìŠµë“í•˜ê³ , ì˜ˆì¸¡í•˜ëŠ” ë°©ë²•ê³¼ ì´ë¥¼ í‰ê°€í•˜ëŠ” ë°©ë²•ì˜ ìˆœìœ¼ë¡œ ì„¤ëª…í•˜ê² ë‹¤.

### 0. Preprocessing

ì‚¬ì‹¤ mail dataì˜ í˜•íƒœê°€ ì´ìƒí•  ìˆ˜ë„ ìˆë‹¤. Subjectë¶€í„° ì‹œì‘í•˜ì—¬ ë‚ ì§œ ë°ì´í„° ê·¸ë¦¬ê³  íŠ¹ìˆ˜ ë¬¸ì ë“±ì´ ì¡´ì¬í•  ìˆ˜ ìˆëŠ”ë°, ì´ë¥¼ ë¨¼ì € ì²˜ë¦¬í•´ì„œ í›„ì— ìˆì„ Modeling ë‹¨ê³„ì—ì„œ ì˜ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í˜•íƒœë¥¼ ë³€í˜•í•´ì£¼ì–´ì•¼ í•œë‹¤.

[ğŸ”— ì´ì „ Posting(Text Processing)](/posts/nlp-text-processing)ì—ì„œ ë°°ì› ë˜ ê¸°ìˆ ë“¤ì„ í™œìš©í•˜ì—¬ ì´ë¥¼ í•´ê²°í•  ìˆ˜ ìˆë‹¤.

ëŒ€í‘œì ìœ¼ë¡œ í•´ì¤„ ìˆ˜ ìˆëŠ” ì‘ì—…ë“¤ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.

1. ëŒ€ì†Œë¬¸ì í†µì¼
2. alphabetì´ í•˜ë‚˜ë¼ë„ ë“¤ì–´ìˆì§€ ì•Šì€ ë°ì´í„°ëŠ” ì‚­ì œ
3. date, ì°¸ì¡° ë“±ì„ ì˜ë¯¸í•˜ëŠ” ë°ì´í„° ì‚­ì œ

### 1. Modeling

Parameter Estimation / Learning / Modeling ë“±ìœ¼ë¡œ ë¶ˆë¦¬ëŠ” ë‹¨ê³„ì´ë‹¤. ì¼ë‹¨ ìš°ë¦¬ëŠ” train setìœ¼ë¡œë¶€í„° ìš°ë¦¬ê°€ ì›í•˜ëŠ” í™•ë¥ ì„ ì¶”ì¶œí•´ì•¼ í•œë‹¤. ê·¸ ì „ì— ìš°ë¦¬ê°€ ì–´ë–¤ language modelì„ ì´ìš©í• ì§€ ì„ íƒí•´ì•¼ í•œë‹¤. ë¨¼ì € uni-gramì¸ ê²½ìš°ì—ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë°©ë²•ìœ¼ë¡œ train setì´ ì •ì˜ëœë‹¤.
$$
\text{TrainSet} = {(d_{1}, c_{1}),  (d_{2}, c_{2}), ..., (d_{N}, c_{N})}
$$
$$
d_{i} = \begin{cases}
  {w_{1}, w_{2}, ... , w_{M_{i}}} \quad&\text{unigram} \\
  {(<s>, w_{1}), (w_{1}, w_{2}), ... , (w_{M_{i}}, </s>)} \qquad&\text{bigram}
\end{cases}
$$

ì´ì œ ìš°ë¦¬ê°€ ì›í•˜ëŠ” parameter, ì¦‰ í™•ë¥ ì€ ë‹¤ìŒê³¼ ê°™ì€ ë°ì´í„°ì´ë‹¤.

> **unigram**

$$
\begin{align*}
p(w_{i}|c_{j}) &= {\text{count}(w_{i}, c_{j}) \over \sum_{w \in V} \text{count}(w, c_{j})} \\
p(c_{j}) &= {\sum_{i = 1}^{N}{1[c_{i} = c_{j}]} \over N}
\end{align*}
$$

> **bigram**

$$
\begin{align*}
p(w_{i}|w_{i-1},c_{j}) &= {\text{count}((w_{i-1}, w_{i}), c_{j}) \over \sum_{(w^{(1)}, w^{(2)}) \in V} \text{count}((w^{(1)}, w^{(2)}), c_{j})} \\
p(c_{j}) &= {\sum_{i = 1}^{N}{1[c_{i} = c_{j}]} \over N}
\end{align*}
$$

ì—¬ê¸°ì„œ ìš°ë¦¬ëŠ” ë°˜ë“œì‹œ Smoothingì„ í•´ì£¼ì–´ì•¼ í•œë‹¤. ì™œëƒí•˜ë©´, spam mailì—ì„œ ì•ˆ ë³¸ ë‹¨ì–´ê°€ ë‚˜ì˜¬ ê°€ëŠ¥ì„±ì´ ë„ˆë¬´ë‚˜ ë†’ê¸° ë•Œë¬¸ì´ë‹¤. ë”°ë¼ì„œ, ì‹¤ì œ $p(w_{i}|c_{j})$ëŠ” ì•„ë˜ì™€ ê°™ì´ ë³€ê²½ëœë‹¤. (ê°„ë‹¨í•œ ì˜ˆì‹œë¥¼ ë“¤ê¸° ìœ„í•´ì„œ Add-1 ë°©ì‹ì„ ì‚¬ìš©í–ˆë‹¤. - í•´ë‹¹ ë‚´ìš©ì´ ê¸°ì–µì´ ë‚˜ì§€ ì•ŠëŠ”ë‹¤ë©´, [ğŸ”— ì´ì „ í¬ìŠ¤íŒ…](/posts/nlp-language-modeling)ì„ ë‹¤ì‹œ ë³´ê³  ì˜¤ì.)

$$
p(w_{i}|c_{j}) = {\text{count}(w_{i}, c_{j}) + 1 \over \sum_{w \in V} \text{count}(w, c_{j}) + |V|}
$$

ì£¼ì˜í•  ì ì€ ë‹¤ì‹œ í•œ ë²ˆ ê°•ì¡°í•˜ì§€ë§Œ, $V$ëŠ” í›„ì— Estimationì—ì„œ inputìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ë‹¨ì¼ documentê¹Œì§€ í¬í•¨í•œ Vocabularyì´ë‹¤.

### 2. Estimation

ì´ì œ ìš°ë¦¬ê°€ ì–»ì€ parameterë¥¼ ì´ìš©í•´ì„œ ì‹¤ì œ input dataì— ëŒ€í•œ estimationì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.

ì´ ê²½ìš° ë‹¤ìŒê³¼ ê°™ì€ ê³¼ì •ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.

$$
\hat{c} = \argmax_{c \in C} p(c)\prod_{w \in d_{\text{input}}}p(w|c)
$$

ë¬¼ë¡  ì–´ë–¤ n-gramì„ ì“°ëƒì— ë”°ë¼ $d_{\text{input}}$ë„ í˜•íƒœê°€ ë‹¬ë¼ì§ˆ ê²ƒì´ë‹¤.

### 3. Evaluation

ì´ì œ í‰ê°€ë¥¼ ìˆ˜í–‰í•  ê²ƒì´ë‹¤. í‰ê°€ëŠ” ìš°ë¦¬ê°€ ì•Œì•„ë´¤ë˜ Accuracyì™€ F1 Scoreë¥¼ ì¶”ì¶œí•  ìˆ˜ ìˆë‹¤. Binary Classificationì´ê¸° ë•Œë¬¸ì— ì‰½ê²Œ êµ¬í•  ìˆ˜ ìˆì„ ê²ƒì´ë‹¤.

| prediction\answer | True                                                                       | False                                                                     |
| :---------------- | :------------------------------------------------------------------------- | :------------------------------------------------------------------------ |
| Positive          | $\sum_{(d, c) \in D_{\text{test}}} 1[\hat{c}_{d} = c, c = \text{spam}]$    | $\sum_{(d, c) \in D_{\text{test}}} 1[\hat{c}_{d} \neq c, c = \text{ham}]$ |
| Negative          | $\sum_{(d, c) \in D_{\text{test}}} 1[\hat{c}_{d} \neq c, c = \text{spam}]$ | $\sum_{(d, c) \in D_{\text{test}}} 1[\hat{c}_{d} = c, c = \text{ham}]$    |

## Reference

- Tumbnail : Photo by [David Ballew](https://unsplash.com/@daveballew?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/@daveballew?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
